{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0305_FP_PF_final_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmK3ABaJ1JdJ",
        "outputId": "bc3c05fa-88a9-4556-940b-767008403614"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYpcd0o81Mwp",
        "outputId": "b8551a48-3ef0-4f91-dda4-1a2b41bf8979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ],
      "metadata": {
        "id": "gXpsWMnaR2UT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d601db-84a9-4e41-ded2-c4e113b05aa1",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 46.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 34.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 33.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=db99d4df878e62ae8f70ba20ef37705a141b68ba15959488698f3fedf9c8d01c\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41t9UJCx33di",
        "outputId": "f12247f7-6215-4cf0-843e-e0aadc03bf7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/GNN_PPI')"
      ],
      "metadata": {
        "id": "i98uHirS4E8R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorboardX #==2.1\n",
        "!pip install 'git+https://github.com/lanpa/tensorboardX'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eodp91zhFqW8",
        "outputId": "ce078579-36eb-4fb5-b959-409a13defb35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/lanpa/tensorboardX\n",
            "  Cloning https://github.com/lanpa/tensorboardX to /tmp/pip-req-build-6mxrm32z\n",
            "  Running command git clone -q https://github.com/lanpa/tensorboardX /tmp/pip-req-build-6mxrm32z\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.4.1+74d8a35) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.4.1+74d8a35) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.4.1+74d8a35) (3.17.3)\n",
            "Building wheels for collected packages: tensorboardX\n",
            "  Building wheel for tensorboardX (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorboardX: filename=tensorboardX-2.4.1-py2.py3-none-any.whl size=125259 sha256=6a71aa04dab085b15603e3c5f622a9805386b7d10f9c3e57e46e55efa893769b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w6n19l05/wheels/b7/a3/60/1fb0fb70622c281e7b4450c3102965499af9875bbcf6cd277e\n",
            "Successfully built tensorboardX\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \n",
        "#import os\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "#import argparse\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import copy\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch_geometric.nn import GINConv, JumpingKnowledge, global_mean_pool, SAGEConv   \n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset, DataLoader\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import gc\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.cuda.manual_seed(1)"
      ],
      "metadata": {
        "id": "4nreG4XZ4L3Z",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utils\n",
        "#For loading data\n",
        "   \n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def print_file(str_, save_file_path=None):\n",
        "    print(str_)\n",
        "    if save_file_path != None:\n",
        "        f = open(save_file_path, 'a')\n",
        "        print(str_, file=f)\n",
        "\n",
        "class Metrictor_PPI:\n",
        "    def __init__(self, pre_y, truth_y, is_binary=False):\n",
        "        self.TP = 0\n",
        "        self.FP = 0\n",
        "        self.TN = 0\n",
        "        self.FN = 0\n",
        "\n",
        "        if is_binary:\n",
        "            length = pre_y.shape[0]\n",
        "            for i in range(length):\n",
        "                if pre_y[i] == truth_y[i]:\n",
        "                    if truth_y[i] == 1:\n",
        "                        self.TP += 1\n",
        "                    else:\n",
        "                        self.TN += 1\n",
        "                elif truth_y[i] == 1:\n",
        "                    self.FN += 1\n",
        "                elif pre_y[i] == 1:\n",
        "                    self.FP += 1\n",
        "            self.num = length\n",
        "\n",
        "        else:\n",
        "            N, C = pre_y.shape\n",
        "            for i in range(N):\n",
        "                for j in range(C):\n",
        "                    if pre_y[i][j] == truth_y[i][j]:\n",
        "                        if truth_y[i][j] == 1:\n",
        "                            self.TP += 1\n",
        "                        else:\n",
        "                            self.TN += 1\n",
        "                    elif truth_y[i][j] == 1:\n",
        "                        self.FN += 1\n",
        "                    elif truth_y[i][j] == 0:\n",
        "                        self.FP += 1\n",
        "            self.num = N * C\n",
        "    \n",
        "    def show_result(self, is_print=False, file=None):\n",
        "        self.Accuracy = (self.TP + self.TN) / (self.num + 1e-10)\n",
        "        self.Precision = self.TP / (self.TP + self.FP + 1e-10)\n",
        "        self.Recall = self.TP / (self.TP + self.FN + 1e-10)\n",
        "        self.F1 = 2 * self.Precision * self.Recall / (self.Precision + self.Recall + 1e-10)\n",
        "        if is_print:\n",
        "            print_file(\"Accuracy: {}\".format(self.Accuracy), file)\n",
        "            print_file(\"Precision: {}\".format(self.Precision), file)\n",
        "            print_file(\"Recall: {}\".format(self.Recall), file)\n",
        "            print_file(\"F1-Score: {}\".format(self.F1), file)\n",
        "\n",
        "class UnionFindSet(object):\n",
        "    def __init__(self, m):\n",
        "        # m, n = len(grid), len(grid[0])\n",
        "        self.roots = [i for i in range(m)]\n",
        "        self.rank = [0 for i in range(m)]\n",
        "        self.count = m\n",
        "        \n",
        "        for i in range(m):\n",
        "            self.roots[i] = i\n",
        " \n",
        "    def find(self, member):\n",
        "        tmp = []\n",
        "        while member != self.roots[member]:\n",
        "            tmp.append(member)\n",
        "            member = self.roots[member]\n",
        "        for root in tmp:\n",
        "            self.roots[root] = member\n",
        "        return member\n",
        "        \n",
        "    def union(self, p, q):\n",
        "        parentP = self.find(p)\n",
        "        parentQ = self.find(q)\n",
        "        if parentP != parentQ:\n",
        "            if self.rank[parentP] > self.rank[parentQ]:\n",
        "                self.roots[parentQ] = parentP\n",
        "            elif self.rank[parentP] < self.rank[parentQ]:\n",
        "                self.roots[parentP] = parentQ\n",
        "            else:\n",
        "                self.roots[parentQ] = parentP\n",
        "                self.rank[parentP] -= 1\n",
        "            self.count -= 1\n",
        "\n",
        "\n",
        "def get_bfs_sub_graph(ppi_list, node_num, node_to_edge_index, sub_graph_size):\n",
        "\n",
        "    candiate_node = []\n",
        "    selected_edge_index = []\n",
        "    selected_node = []\n",
        "\n",
        "    random_node = random.randint(0, node_num - 1)\n",
        "    while len(node_to_edge_index[random_node]) > 5:\n",
        "        random_node = random.randint(0, node_num - 1)\n",
        "    candiate_node.append(random_node)\n",
        "\n",
        "    while len(selected_edge_index) < sub_graph_size:\n",
        "        cur_node = candiate_node.pop(0)\n",
        "        selected_node.append(cur_node)\n",
        "        for edge_index in node_to_edge_index[cur_node]:\n",
        "\n",
        "            if edge_index not in selected_edge_index:\n",
        "                selected_edge_index.append(edge_index)\n",
        "\n",
        "                end_node = -1\n",
        "                if ppi_list[edge_index][0] == cur_node:\n",
        "                    end_node = ppi_list[edge_index][1]\n",
        "                else:\n",
        "                    end_node = ppi_list[edge_index][0]\n",
        "\n",
        "                if end_node not in selected_node and end_node not in candiate_node:\n",
        "                    candiate_node.append(end_node)\n",
        "            else:\n",
        "                continue\n",
        "        # print(len(selected_edge_index), len(candiate_node))\n",
        "    node_list = candiate_node + selected_node\n",
        "    # print(len(node_list), len(selected_edge_index))\n",
        "    return selected_edge_index\n",
        "\n",
        "def get_dfs_sub_graph(ppi_list, node_num, node_to_edge_index, sub_graph_size):\n",
        "    \n",
        "    stack = []\n",
        "    selected_edge_index = []\n",
        "    selected_node = []\n",
        "\n",
        "    random_node = random.randint(0, node_num - 1)\n",
        "    while len(node_to_edge_index[random_node]) > 5:\n",
        "        random_node = random.randint(0, node_num - 1)\n",
        "    stack.append(random_node)\n",
        "\n",
        "    while len(selected_edge_index) < sub_graph_size:\n",
        "        # print(len(selected_edge_index), len(stack), len(selected_node))\n",
        "        cur_node = stack[-1]\n",
        "        if cur_node in selected_node:\n",
        "            flag = True\n",
        "            for edge_index in node_to_edge_index[cur_node]:\n",
        "                if flag:\n",
        "                    end_node = -1\n",
        "                    if ppi_list[edge_index][0] == cur_node:\n",
        "                        end_node = ppi_list[edge_index][1]\n",
        "                    else:\n",
        "                        end_node = ppi_list[edge_index][0]\n",
        "                    \n",
        "                    if end_node in selected_node:\n",
        "                        continue\n",
        "                    else:\n",
        "                        stack.append(end_node)\n",
        "                        flag = False\n",
        "                else:\n",
        "                    break\n",
        "            if flag:\n",
        "                stack.pop()\n",
        "            continue\n",
        "        else:\n",
        "            selected_node.append(cur_node)\n",
        "            for edge_index in node_to_edge_index[cur_node]:\n",
        "                if edge_index not in selected_edge_index:\n",
        "                    selected_edge_index.append(edge_index)\n",
        "    \n",
        "    return selected_edge_index\n",
        "\n",
        "class GNN_DATA:\n",
        "    def __init__(self, ppi_path, exclude_protein_path=None, max_len=2000, skip_head=True, p1_index=0, p2_index=1, label_index=2, graph_undirection=True, bigger_ppi_path=None):\n",
        "        self.ppi_list = []\n",
        "        self.ppi_dict = {}\n",
        "        self.ppi_label_list = []\n",
        "        self.protein_dict = {}\n",
        "        self.protein_name = {}\n",
        "        self.ppi_path = ppi_path\n",
        "        self.bigger_ppi_path = bigger_ppi_path\n",
        "        self.max_len = max_len\n",
        "\n",
        "        name = 0\n",
        "        ppi_name = 0\n",
        "        # maxlen = 0\n",
        "        self.node_num = 0\n",
        "        self.edge_num = 0\n",
        "        if exclude_protein_path != None:\n",
        "            with open(exclude_protein_path, 'r') as f:\n",
        "                ex_protein = json.load(f)\n",
        "                f.close()\n",
        "            ex_protein = {p:i for i, p in enumerate(ex_protein)}\n",
        "        else:\n",
        "            ex_protein = {}\n",
        "\n",
        "        class_map = {'reaction':0, 'binding':1, 'ptmod':2, 'activation':3, 'inhibition':4, 'catalysis':5, 'expression':6}\n",
        "\n",
        "        for line in tqdm(open(ppi_path)):\n",
        "            if skip_head:\n",
        "                skip_head = False\n",
        "                continue\n",
        "            line = line.strip().split('\\t')\n",
        "\n",
        "            if line[p1_index] in ex_protein.keys() or line[p2_index] in ex_protein.keys():\n",
        "                continue\n",
        "\n",
        "            # get node and node name\n",
        "            if line[p1_index] not in self.protein_name.keys():\n",
        "                self.protein_name[line[p1_index]] = name\n",
        "                name += 1\n",
        "            \n",
        "            if line[p2_index] not in self.protein_name.keys():\n",
        "                self.protein_name[line[p2_index]] = name\n",
        "                name += 1\n",
        "\n",
        "            # get edge and its label\n",
        "            temp_data = \"\"\n",
        "            if line[p1_index] < line[p2_index]:\n",
        "                temp_data = line[p1_index] + \"__\" + line[p2_index]\n",
        "            else:\n",
        "                temp_data = line[p2_index] + \"__\" + line[p1_index]\n",
        "\n",
        "            if temp_data not in self.ppi_dict.keys():\n",
        "                self.ppi_dict[temp_data] = ppi_name\n",
        "                temp_label = [0, 0, 0, 0, 0, 0, 0]\n",
        "                temp_label[class_map[line[label_index]]] = 1\n",
        "                self.ppi_label_list.append(temp_label)\n",
        "                ppi_name += 1\n",
        "            else:\n",
        "                index = self.ppi_dict[temp_data]\n",
        "                temp_label = self.ppi_label_list[index]\n",
        "                temp_label[class_map[line[label_index]]] = 1\n",
        "                self.ppi_label_list[index] = temp_label\n",
        "        \n",
        "        if bigger_ppi_path != None:\n",
        "            skip_head = True\n",
        "            for line in tqdm(open(bigger_ppi_path)):\n",
        "                if skip_head:\n",
        "                    skip_head = False\n",
        "                    continue\n",
        "                line = line.strip().split('\\t')\n",
        "\n",
        "                if line[p1_index] not in self.protein_name.keys():\n",
        "                    self.protein_name[line[p1_index]] = name\n",
        "                    name += 1\n",
        "                \n",
        "                if line[p2_index] not in self.protein_name.keys():\n",
        "                    self.protein_name[line[p2_index]] = name\n",
        "                    name += 1\n",
        "                \n",
        "                temp_data = \"\"\n",
        "                if line[p1_index] < line[p2_index]:\n",
        "                    temp_data = line[p1_index] + \"__\" + line[p2_index]\n",
        "                else:\n",
        "                    temp_data = line[p2_index] + \"__\" + line[p1_index]\n",
        "                \n",
        "                if temp_data not in self.ppi_dict.keys():\n",
        "                    self.ppi_dict[temp_data] = ppi_name\n",
        "                    temp_label = [0, 0, 0, 0, 0, 0, 0]\n",
        "                    temp_label[class_map[line[label_index]]] = 1\n",
        "                    self.ppi_label_list.append(temp_label)\n",
        "                    ppi_name += 1\n",
        "                else:\n",
        "                    index = self.ppi_dict[temp_data]\n",
        "                    temp_label = self.ppi_label_list[index]\n",
        "                    temp_label[class_map[line[label_index]]] = 1\n",
        "                    self.ppi_label_list[index] = temp_label\n",
        "\n",
        "        i = 0\n",
        "        for ppi in tqdm(self.ppi_dict.keys()):\n",
        "            name = self.ppi_dict[ppi]\n",
        "            assert name == i\n",
        "            i += 1\n",
        "            temp = ppi.strip().split('__')\n",
        "            self.ppi_list.append(temp)\n",
        "\n",
        "\n",
        "        ppi_num = len(self.ppi_list)\n",
        "        self.origin_ppi_list = copy.deepcopy(self.ppi_list)\n",
        "        assert len(self.ppi_list) == len(self.ppi_label_list)\n",
        "        for i in tqdm(range(ppi_num)):\n",
        "            seq1_name = self.ppi_list[i][0]\n",
        "            seq2_name = self.ppi_list[i][1]\n",
        "            # print(len(self.protein_name))\n",
        "            self.ppi_list[i][0] = self.protein_name[seq1_name]\n",
        "            self.ppi_list[i][1] = self.protein_name[seq2_name]\n",
        "        \n",
        "        if graph_undirection:\n",
        "            for i in tqdm(range(ppi_num)):\n",
        "                temp_ppi = self.ppi_list[i][::-1]\n",
        "                temp_ppi_label = self.ppi_label_list[i]\n",
        "                # if temp_ppi not in self.ppi_list:\n",
        "                self.ppi_list.append(temp_ppi)\n",
        "                self.ppi_label_list.append(temp_ppi_label)\n",
        "\n",
        "        self.node_num = len(self.protein_name)\n",
        "        self.edge_num = len(self.ppi_list)\n",
        "    \n",
        "    def get_protein_aac(self, pseq_path):\n",
        "        # aac: amino acid sequences\n",
        "\n",
        "        self.pseq_path = pseq_path\n",
        "        self.pseq_dict = {}\n",
        "        self.protein_len = []\n",
        "\n",
        "        for line in tqdm(open(self.pseq_path)):\n",
        "            line = line.strip().split('\\t')\n",
        "            if line[0] not in self.pseq_dict.keys():\n",
        "                self.pseq_dict[line[0]] = line[1]\n",
        "                self.protein_len.append(len(line[1]))\n",
        "        \n",
        "        print(\"protein num: {}\".format(len(self.pseq_dict)))\n",
        "        print(\"protein average length: {}\".format(np.average(self.protein_len)))\n",
        "        print(\"protein max & min length: {}, {}\".format(np.max(self.protein_len), np.min(self.protein_len)))\n",
        "\n",
        "    def embed_normal(self, seq, dim):\n",
        "        if len(seq) > self.max_len:\n",
        "            return seq[:self.max_len]\n",
        "        elif len(seq) < self.max_len:\n",
        "            less_len = self.max_len - len(seq)\n",
        "            return np.concatenate((seq, np.zeros((less_len, dim))))\n",
        "        return seq\n",
        "        \n",
        "\n",
        "    def vectorize(self, vec_path):\n",
        "        self.acid2vec = {}\n",
        "        self.dim = None\n",
        "        for line in open(vec_path):\n",
        "            line = line.strip().split('\\t')\n",
        "            temp = np.array([float(x) for x in line[1].split()])\n",
        "            self.acid2vec[line[0]] = temp\n",
        "            if self.dim is None:\n",
        "                self.dim = len(temp)\n",
        "        print(\"acid vector dimension: {}\".format(self.dim))\n",
        "\n",
        "        self.pvec_dict = {}\n",
        "\n",
        "        for p_name in tqdm(self.pseq_dict.keys()):\n",
        "            temp_seq = self.pseq_dict[p_name]\n",
        "            temp_vec = []\n",
        "            for acid in temp_seq:\n",
        "                temp_vec.append(self.acid2vec[acid])\n",
        "            temp_vec = np.array(temp_vec)\n",
        "\n",
        "            temp_vec = self.embed_normal(temp_vec, self.dim)\n",
        "\n",
        "            self.pvec_dict[p_name] = temp_vec\n",
        "\n",
        "    def get_feature_origin(self, pseq_path, vec_path):\n",
        "        self.get_protein_aac(pseq_path)\n",
        "\n",
        "        self.vectorize(vec_path)\n",
        "\n",
        "        self.protein_dict = {}\n",
        "        for name in tqdm(self.protein_name.keys()):\n",
        "            self.protein_dict[name] = self.pvec_dict[name]\n",
        "\n",
        "    def get_connected_num(self):\n",
        "        self.ufs = UnionFindSet(self.node_num)\n",
        "        ppi_ndary = np.array(self.ppi_list)\n",
        "        for edge in ppi_ndary:\n",
        "            start, end = edge[0], edge[1]\n",
        "            self.ufs.union(start, end)\n",
        "\n",
        "    def generate_data(self):\n",
        "        self.get_connected_num()\n",
        "\n",
        "        print(\"Connected domain num: {}\".format(self.ufs.count))\n",
        "\n",
        "        ppi_list = np.array(self.ppi_list)\n",
        "        ppi_label_list = np.array(self.ppi_label_list)\n",
        "\n",
        "        self.edge_index = torch.tensor(ppi_list, dtype=torch.long)\n",
        "        self.edge_attr = torch.tensor(ppi_label_list, dtype=torch.long)\n",
        "        self.x = []\n",
        "        i = 0\n",
        "        for name in self.protein_name:\n",
        "            assert self.protein_name[name] == i\n",
        "            i += 1\n",
        "            self.x.append(self.protein_dict[name])\n",
        "        \n",
        "        self.x = np.array(self.x)\n",
        "        self.x = torch.tensor(self.x, dtype=torch.float)\n",
        "\n",
        "        self.data = Data(x=self.x, edge_index=self.edge_index.T, edge_attr_1=self.edge_attr)\n",
        "    \n",
        "    def split_dataset(self, train_valid_index_path, test_size=0.2, random_new=False, mode='random'):\n",
        "        if random_new:\n",
        "            if mode == 'random':\n",
        "                ppi_num = int(self.edge_num // 2)\n",
        "                random_list = [i for i in range(ppi_num)]\n",
        "                random.shuffle(random_list)\n",
        "\n",
        "                self.ppi_split_dict = {}\n",
        "                self.ppi_split_dict['train_index'] = random_list[: int(ppi_num * (1-test_size))]\n",
        "                self.ppi_split_dict['valid_index'] = random_list[int(ppi_num * (1-test_size)) :]\n",
        "\n",
        "                jsobj = json.dumps(self.ppi_split_dict)\n",
        "                with open(train_valid_index_path, 'w') as f:\n",
        "                    f.write(jsobj)\n",
        "                    f.close()\n",
        "\n",
        "            elif mode == 'bfs' or mode == 'dfs':\n",
        "                print(\"use {} methed split train and valid dataset\".format(mode))\n",
        "                node_to_edge_index = {}\n",
        "                edge_num = int(self.edge_num // 2)\n",
        "                for i in range(edge_num):\n",
        "                    edge = self.ppi_list[i]\n",
        "                    if edge[0] not in node_to_edge_index.keys():\n",
        "                        node_to_edge_index[edge[0]] = []\n",
        "                    node_to_edge_index[edge[0]].append(i)\n",
        "\n",
        "                    if edge[1] not in node_to_edge_index.keys():\n",
        "                        node_to_edge_index[edge[1]] = []\n",
        "                    node_to_edge_index[edge[1]].append(i)\n",
        "                \n",
        "                node_num = len(node_to_edge_index)\n",
        "\n",
        "                sub_graph_size = int(edge_num * test_size)\n",
        "                if mode == 'bfs':\n",
        "                    selected_edge_index = get_bfs_sub_graph(self.ppi_list, node_num, node_to_edge_index, sub_graph_size)\n",
        "                elif mode == 'dfs':\n",
        "                    selected_edge_index = get_dfs_sub_graph(self.ppi_list, node_num, node_to_edge_index, sub_graph_size)\n",
        "                \n",
        "                all_edge_index = [i for i in range(edge_num)]\n",
        "\n",
        "                unselected_edge_index = list(set(all_edge_index).difference(set(selected_edge_index)))\n",
        "\n",
        "                self.ppi_split_dict = {}\n",
        "                self.ppi_split_dict['train_index'] = unselected_edge_index\n",
        "                self.ppi_split_dict['valid_index'] = selected_edge_index\n",
        "\n",
        "                assert len(unselected_edge_index) + len(selected_edge_index) == edge_num\n",
        "\n",
        "                jsobj = json.dumps(self.ppi_split_dict)\n",
        "                with open(train_valid_index_path, 'w') as f:\n",
        "                    f.write(jsobj)\n",
        "                    f.close()\n",
        "            \n",
        "            else:\n",
        "                print(\"your mode is {}, you should use bfs, dfs or random\".format(mode))\n",
        "                return\n",
        "        else:\n",
        "            with open(train_valid_index_path, 'r') as f:\n",
        "                self.ppi_split_dict = json.load(f)\n",
        "                f.close()"
      ],
      "metadata": {
        "id": "HOqGqsF37tBd",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "lqd6WLrhc4hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title base architecutures\n",
        "# mode: 'self' or 'ngb'\n",
        "# For graph embeding and hidden layer of neural net, follow the architecture in https://arxiv.org/pdf/2105.06709.pdf\n",
        "\n",
        "class GIN_Net_self(torch.nn.Module):\n",
        "    def __init__(self, in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1,\n",
        "                sigma=0.1,is_relative_detach = True, hidden=512, use_jk=False, pool_size=3, cnn_hidden=1, train_eps=True, \n",
        "                feature_fusion=None, class_num=7):\n",
        "        super(GIN_Net_self, self).__init__()\n",
        "        self.use_jk = use_jk\n",
        "        self.train_eps = train_eps\n",
        "        self.feature_fusion = feature_fusion\n",
        "        self.sigma=sigma\n",
        "        self.is_relative_detach = is_relative_detach       \n",
        "        self.conv1d = nn.Conv1d(in_channels=in_feature, out_channels=cnn_hidden, kernel_size=3, padding=0)\n",
        "        self.bn1 = nn.BatchNorm1d(cnn_hidden)\n",
        "        self.biGRU = nn.GRU(cnn_hidden, cnn_hidden, bidirectional=True, batch_first=True, num_layers=1)\n",
        "        self.maxpool1d = nn.MaxPool1d(pool_size, stride=pool_size)\n",
        "        self.global_avgpool1d = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(math.floor(in_len / pool_size), gin_in_feature)  \n",
        "\n",
        "    def reset_parameters(self):        \n",
        "        self.conv1d.reset_parameters()\n",
        "        self.fc1.reset_parameters()    \n",
        "\n",
        "    def forward(self, x, edge_index, train_edge_id, p=0.5):\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.conv1d(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.maxpool1d(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x, _ = self.biGRU(x)\n",
        "        x = self.global_avgpool1d(x)\n",
        "        x = x.squeeze()\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class GIN_Net_ngb(torch.nn.Module):\n",
        "    def __init__(self, in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1\n",
        "                ,sigma=0.1,is_relative_detach = True, hidden=512, use_jk=False, pool_size=3, cnn_hidden=1, train_eps=True, \n",
        "                feature_fusion=None, class_num=7):\n",
        "        super(GIN_Net_ngb, self).__init__()\n",
        "        self.use_jk = use_jk\n",
        "        self.train_eps = train_eps\n",
        "        self.feature_fusion = feature_fusion\n",
        "\n",
        "        self.sigma=sigma\n",
        "        self.is_relative_detach = is_relative_detach\n",
        "        self.gin_conv1 = GINConv( \n",
        "            nn.Sequential(\n",
        "                nn.Linear(gin_in_feature, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden),\n",
        "            ), train_eps=self.train_eps\n",
        "        )\n",
        "        self.gin_convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers - 1):\n",
        "            self.gin_convs.append(\n",
        "                GINConv(\n",
        "                    nn.Sequential(\n",
        "                        nn.Linear(hidden, hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(hidden, hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm1d(hidden),\n",
        "                    ), train_eps=self.train_eps\n",
        "                )\n",
        "            )\n",
        "        if self.use_jk:\n",
        "            mode = 'cat'\n",
        "            self.jump = JumpingKnowledge(mode)\n",
        "            self.lin1 = nn.Linear(num_layers*hidden, hidden)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(hidden, hidden)\n",
        "        self.lin2 = nn.Linear(hidden, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, class_num)\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        self.gin_conv1.reset_parameters()\n",
        "        for gin_conv in self.gin_convs:\n",
        "            gin_conv.reset_parameters()\n",
        "        \n",
        "        if self.use_jk:\n",
        "            self.jump.reset_parameters()\n",
        "        self.lin1.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "        self.fc2.reset_parameters()\n",
        "    \n",
        "    def forward(self, x, edge_index, train_edge_id, p=0.5):\n",
        "        x = self.gin_conv1(x, edge_index)\n",
        "        xs = [x]\n",
        "        for conv in self.gin_convs:\n",
        "            x = conv(x, edge_index)\n",
        "            xs += [x]\n",
        "\n",
        "        if self.use_jk:\n",
        "            x = self.jump(xs)\n",
        "        \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=p, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        node_id = edge_index[:, train_edge_id]\n",
        "        x1 = x[node_id[0]]\n",
        "        x2 = x[node_id[1]]\n",
        "\n",
        "        if self.feature_fusion == 'concat':\n",
        "            x = torch.cat([x1, x2], dim=1)\n",
        "        else:\n",
        "            x = torch.mul(x1, x2)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x        "
      ],
      "metadata": {
        "id": "AsA_hW2R7jZv",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loss functions\n",
        "\n",
        "#student loss (without KD)\n",
        "def loss_fn_s(logits_self, logits_ngb, labels):\n",
        "  alpha=0.3 \n",
        "  beta=0.3\n",
        "\n",
        "\n",
        "  kl_loss_fn = nn.KLDivLoss(reduction=\"batchmean\")#.to(device)\n",
        "  loss_fn_ce = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "  loss_fn_ce_1=loss_fn_ce(logits_self,labels)\n",
        "  loss_fn_ce_2=loss_fn_ce(logits_ngb,labels)\n",
        "  m=nn.LogSoftmax()\n",
        "\n",
        "  d_self=m(logits_self).detach()\n",
        "  d_ngb=m(logits_ngb).detach()\n",
        "\n",
        "\n",
        "  kl_loss = kl_loss_fn(d_self , d_ngb).detach()\n",
        "\n",
        "\n",
        "  return alpha*loss_fn_ce_1+beta*loss_fn_ce_2+(1.0-(alpha+beta))*kl_loss\n",
        "\n",
        "\n",
        "#student loss with KD\n",
        "def loss_fn_kd_s(logits_self, logits_ngb,  logits_t, labels):\n",
        "  alpha=0.3\n",
        "  beta=0.3\n",
        "  T=4.0\n",
        "  \n",
        "  kl_loss_fn = nn.KLDivLoss().to(device)\n",
        "  loss_fn_ce = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "  loss_fn_ce_1=loss_fn_ce(logits_self,labels)\n",
        "  loss_fn_ce_2=loss_fn_ce(logits_ngb,labels)\n",
        "\n",
        "  m = nn.Sigmoid()\n",
        "\n",
        "  d_self=m(logits_self/T)\n",
        "  d_ngb=m(logits_ngb/T)\n",
        "  d_t=m(logits_t/T)\n",
        "\n",
        "\n",
        "  kl_loss_t1=kl_loss_fn(d_self,d_t)*T*T\n",
        "  kl_loss_t2=kl_loss_fn(d_ngb,d_t)*T*T\n",
        "\n",
        "\n",
        "\n",
        "  return (0.5)*loss_fn_s(logits_self, logits_ngb, labels)+(0.5)*(kl_loss_t1+kl_loss_t2)\n"
      ],
      "metadata": {
        "id": "JYWOH-WDJkHT",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train\n",
        "\n",
        "def train_s(model_self, model_ngb, graph, ppi_list, loss_fn, optimizer_self, optimizer_ngb, device,\n",
        "        result_file_pathr, summary_writerr , save_path\n",
        "        ,scheduler1,scheduler2, batch_size=256, epochs=1\n",
        "        ): #epochs=1000 ,batch_size=512\n",
        "    for epoch in range(589,epochs):\n",
        "        steps = math.ceil(len(graph.train_mask) / batch_size)\n",
        "        model_self.train() \n",
        "        model_ngb.train()               \n",
        "        random.shuffle(graph.train_mask)\n",
        "        for step in range(steps):\n",
        "            if step == steps-1:\n",
        "              train_edge_id = graph.train_mask[step*batch_size:]\n",
        "            else:\n",
        "              train_edge_id = graph.train_mask[step*batch_size : step*batch_size + batch_size]\n",
        "            label = graph.edge_attr_1[train_edge_id]            \n",
        "            exact_input=graph.x\n",
        "            noise_1 = torch.randn_like(exact_input)\n",
        "            noisy_input = ((noise_1 + exact_input).detach() - exact_input).detach() + exact_input\n",
        "            ngb_output_self=model_ngb(model_self(noisy_input,graph.edge_index, train_edge_id),graph.edge_index, train_edge_id)\n",
        "\n",
        "            exact_self=model_self(graph.x,graph.edge_index, train_edge_id)\n",
        "            noise=torch.randn_like(exact_self)\n",
        "            noisy_input_ngb=((noise + exact_self).detach() - exact_self).detach() + exact_self\n",
        "            ngb_output_ngb=model_ngb(noisy_input_ngb,graph.edge_index, train_edge_id)\n",
        "\n",
        "            model_self.train()\n",
        "            model_ngb.train()\n",
        "\n",
        "            label = label.type(torch.FloatTensor).to(device)\n",
        "            self_loss=loss_fn_s(ngb_output_self, ngb_output_ngb, label)\n",
        "            ngb_loss=loss_fn_s(ngb_output_self, ngb_output_ngb, label)\n",
        "            \n",
        "            del exact_input,noise_1,exact_self,noise,noisy_input_ngb\n",
        "            gc.collect()\n",
        "            optimizer_self.zero_grad()\n",
        "            optimizer_ngb.zero_grad()\n",
        "\n",
        "            self_loss.backward(retain_graph=True)            \n",
        "            ngb_loss.backward(retain_graph=True) \n",
        "\n",
        "            optimizer_self.step()\n",
        "            optimizer_ngb.step()\n",
        "\n",
        "            m = nn.Sigmoid()\n",
        "            pre_result = ((m(ngb_output_ngb) > 0.5) == (m(ngb_output_self)> 0.5)).type(torch.FloatTensor).to(device)\n",
        "            metrics = Metrictor_PPI(pre_result.cpu().data, label.cpu().data)\n",
        "            metrics.show_result()\n",
        "            print_file(\"epoch: {}, step: {}, Train: label_loss: {}, precision: {}, recall: {}, f1: {}\"\n",
        "                        .format(epoch, step, ngb_loss, metrics.Precision, metrics.Recall, metrics.F1))\n",
        "            v=random.randint(0,100)\n",
        "            torch.save(model_self.state_dict(), '/content/drive/My Drive/GNN_PPI/'+str(v)+'self_train.ckpt')\n",
        "            torch.save(model_ngb.state_dict(), '/content/drive/My Drive/GNN_PPI/'+str(v)+'ngb_train.ckpt')  \n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            del metrics,pre_result,ngb_output_self,ngb_output_ngb\n",
        "            gc.collect()\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'state_dict': model_self.state_dict()},\n",
        "                    os.path.join(save_path, 'gnn_model_self_train.ckpt'))\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'state_dict': model_ngb.state_dict()},\n",
        "                    os.path.join(save_path, 'gnn_model_nbg_train.ckpt'))"
      ],
      "metadata": {
        "id": "sm1GAtBr7Rpc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_self.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUmLk1NeMKGY",
        "outputId": "3dd681e2-94cb-4b7f-d7ae-971d9462a760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GIN_Net_self(\n",
              "  (conv1d): Conv1d(13, 1, kernel_size=(3,), stride=(1,))\n",
              "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (biGRU): GRU(1, 1, batch_first=True, bidirectional=True)\n",
              "  (maxpool1d): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avgpool1d): AdaptiveAvgPool1d(output_size=1)\n",
              "  (fc1): Linear(in_features=666, out_features=256, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ngb.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf92hLCFMVQO",
        "outputId": "4489f456-83bb-4967-9d84-97f09f85b45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GIN_Net_ngb(\n",
              "  (gin_conv1): GINConv(nn=Sequential(\n",
              "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  ))\n",
              "  (gin_convs): ModuleList()\n",
              "  (lin1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \n",
        "#large dataset memory crash\n",
        "#initialization and train\n",
        "\n",
        "# ppi_path = \"/content/drive/My Drive/GNN_PPI/data/9606.protein.actions.all_connected.txt\"\n",
        "# ppi_data = GNN_DATA(ppi_path)\n",
        "\n",
        "# pseq_path = \"/content/drive/My Drive/GNN_PPI/data/protein.STRING_all_connected.sequences.dictionary.tsv\"\n",
        "# vec_path = \"/content/drive/My Drive/GNN_PPI/data/vec5_CTC.txt\"\n",
        "\n",
        "# ppi_data.get_feature_origin(pseq_path=pseq_path, vec_path=vec_path)\n",
        "# ppi_data.generate_data()\n",
        "\n",
        "# split_new=True\n",
        "# split_mode = \"bfs\"\n",
        "# train_valid_index_path = \"/content/drive/My Drive/GNN_PPI/string.bfs.fold1_truncated.json\"\n",
        "# ppi_data.split_dataset(train_valid_index_path, random_new=split_new, mode=split_mode)\n",
        "\n",
        "# split_new=False\n",
        "\n",
        "# graph = ppi_data.data\n",
        "\n",
        "# ppi_list = ppi_data.ppi_list\n",
        "\n",
        "# graph.train_mask = ppi_data.ppi_split_dict['train_index']\n",
        "# graph.val_mask = ppi_data.ppi_split_dict['valid_index']\n",
        "\n",
        "\n",
        "# # graph.edge_index_got = torch.cat((graph.edge_index[:, graph.train_mask], graph.edge_index[:, graph.train_mask][[1, 0]]), dim=1)\n",
        "# # graph.edge_attr_got = torch.cat((graph.edge_attr_1[graph.train_mask], graph.edge_attr_1[graph.train_mask]), dim=0)\n",
        "# # graph.train_mask_got = [i for i in range(len(graph.train_mask))]"
      ],
      "metadata": {
        "id": "eaMbh8vUhZ9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7566be5c-ea08-4d70-a148-87c879d0df80",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4775155it [00:14, 321855.80it/s]\n",
            "100%|██████████| 593397/593397 [00:01<00:00, 496181.17it/s]\n",
            "100%|██████████| 593397/593397 [00:00<00:00, 1105941.16it/s]\n",
            "100%|██████████| 593397/593397 [00:00<00:00, 620351.03it/s]\n",
            "15335it [00:00, 296137.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protein num: 15335\n",
            "protein average length: 603.6829475057059\n",
            "protein max & min length: 33423, 25\n",
            "acid vector dimension: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15335/15335 [00:05<00:00, 2889.39it/s]\n",
            "100%|██████████| 15335/15335 [00:00<00:00, 1553539.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected domain num: 1\n",
            "use bfs methed split train and valid dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialization and train\n",
        "\n",
        "ppi_path = \"/content/drive/My Drive/GNN_PPI/data/protein.actions.SHS27k.STRING.txt\"\n",
        "ppi_data = GNN_DATA(ppi_path)\n",
        "\n",
        "pseq_path = \"/content/drive/My Drive/GNN_PPI/data/protein.SHS27k.sequences.dictionary.tsv\"\n",
        "vec_path = \"/content/drive/My Drive/GNN_PPI/data/vec5_CTC.txt\"\n",
        "\n",
        "ppi_data.get_feature_origin(pseq_path=pseq_path, vec_path=vec_path)\n",
        "ppi_data.generate_data()\n",
        "\n",
        "split_new=True\n",
        "split_mode = \"bfs\"\n",
        "train_valid_index_path = \"/content/drive/My Drive/GNN_PPI/string.bfs.fold1_truncated.json\"\n",
        "ppi_data.split_dataset(train_valid_index_path, random_new=split_new, mode=split_mode)\n",
        "\n",
        "split_new=False\n",
        "\n",
        "graph = ppi_data.data\n",
        "\n",
        "ppi_list = ppi_data.ppi_list\n",
        "\n",
        "graph.train_mask = ppi_data.ppi_split_dict['train_index']\n",
        "graph.val_mask = ppi_data.ppi_split_dict['valid_index']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGSGoYO4LYcI",
        "outputId": "3556f7e0-4860-4c15-8699-e90ffd730f24",
        "cellView": "form"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "63409it [00:00, 132809.24it/s]\n",
            "100%|██████████| 7624/7624 [00:00<00:00, 788707.91it/s]\n",
            "100%|██████████| 7624/7624 [00:00<00:00, 804664.66it/s]\n",
            "100%|██████████| 7624/7624 [00:00<00:00, 1102477.98it/s]\n",
            "1690it [00:00, 7244.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protein num: 1690\n",
            "protein average length: 571.0644970414202\n",
            "protein max & min length: 5171, 51\n",
            "acid vector dimension: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1690/1690 [00:00<00:00, 1740.88it/s]\n",
            "100%|██████████| 1690/1690 [00:00<00:00, 1757593.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected domain num: 18\n",
            "use bfs methed split train and valid dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "#device = torch.device('cpu')\n",
        "graph.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFbfLCh-4Fxh",
        "outputId": "c65432c2-9344-4118-ef5a-78aec2485bac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[1690, 2000, 13], edge_index=[2, 15248], edge_attr_1=[15248, 7], train_mask=[6069], val_mask=[1555])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "model_self = GIN_Net_self(in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1,\n",
        "                sigma=0.1,is_relative_detach = True, pool_size=3, cnn_hidden=1).to(device)\n",
        "\n",
        "model_ngb = GIN_Net_ngb(in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1, \n",
        "                sigma=0.1,is_relative_detach = True, pool_size=3, cnn_hidden=1).to(device) \n",
        "\n",
        "optimizer_self = torch.optim.Adam(model_self.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "optimizer_ngb = torch.optim.Adam(model_ngb.parameters(), lr=0.001, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "ICbNmqZBbLgo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "use_lr_scheduler = \"True\"\n",
        "scheduler_1 = None\n",
        "scheduler_2 = None\n",
        "if use_lr_scheduler:\n",
        "    scheduler_1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_self, mode='min', factor=0.5, patience=20, verbose=True)\n",
        "    scheduler_2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_self, mode='min', factor=0.5, patience=20, verbose=True)\n",
        "\n",
        "description = \"test_string_bfs\"\n",
        "save_path = \"/content/drive/My Drive/GNN_PPI/save_model/\"\n",
        "time_stamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "save_path = os.path.join(save_path, \"gnn_{}_{}\".format(description, time_stamp))\n",
        "result_file_path = os.path.join(save_path, \"valid_results.txt\")\n",
        "os.mkdir(save_path)\n",
        "summary_writer = SummaryWriter(save_path)\n",
        "graph_only_train = \"False\"\n",
        "summary_writer = SummaryWriter(save_path)"
      ],
      "metadata": {
        "id": "sxy2UVcWa3sZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n",
        "    ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=1)\n",
        "summary_writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgA6GcTHbAH4",
        "outputId": "d28cea88-18ec-48d4-80f3-c2463b906f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, Train: label_loss: 0.41707131266593933, precision: 0.35396518375238356, recall: 0.5700934579438364, f1: 0.43675417656366156\n",
            "1\n",
            "epoch: 0, step: 1, Train: label_loss: 0.4033361077308655, precision: 0.3323029366305771, recall: 0.7190635451503814, f1: 0.45454545450217265\n",
            "2\n",
            "epoch: 0, step: 2, Train: label_loss: 0.3951815366744995, precision: 0.3066572237960123, recall: 0.7289562289561062, f1: 0.43170488530223916\n",
            "3\n",
            "epoch: 0, step: 3, Train: label_loss: 0.38447266817092896, precision: 0.2939093484419055, recall: 0.689368770764005, f1: 0.4121151936025353\n",
            "4\n",
            "epoch: 0, step: 4, Train: label_loss: 0.3779138922691345, precision: 0.2893470790377808, recall: 0.7159863945577013, f1: 0.4121390112169183\n",
            "5\n",
            "epoch: 0, step: 5, Train: label_loss: 0.37835419178009033, precision: 0.30486111111108993, recall: 0.745331069609381, f1: 0.4327254804910348\n",
            "6\n",
            "epoch: 0, step: 6, Train: label_loss: 0.36933231353759766, precision: 0.30769230769228634, recall: 0.744966442952895, f1: 0.4355076017241564\n",
            "7\n",
            "epoch: 0, step: 7, Train: label_loss: 0.364355206489563, precision: 0.28734858681020947, recall: 0.7597864768681921, f1: 0.4169921874601371\n",
            "8\n",
            "epoch: 0, step: 8, Train: label_loss: 0.3515498638153076, precision: 0.29103989535642305, recall: 0.7646048109964322, f1: 0.42160113686196443\n",
            "9\n",
            "epoch: 0, step: 9, Train: label_loss: 0.3625202775001526, precision: 0.32249502322492885, recall: 0.7665615141954626, f1: 0.45399346095780363\n",
            "10\n",
            "epoch: 0, step: 10, Train: label_loss: 0.354436993598938, precision: 0.3054619015508897, recall: 0.7190476190475049, f1: 0.42877425457240015\n",
            "11\n",
            "epoch: 0, step: 11, Train: label_loss: 0.3572331666946411, precision: 0.3026767330130197, recall: 0.7538461538460249, f1: 0.4319294808601529\n",
            "12\n",
            "epoch: 0, step: 12, Train: label_loss: 0.35242587327957153, precision: 0.2864901561439045, recall: 0.7469026548671244, f1: 0.4141315014319158\n",
            "13\n",
            "epoch: 0, step: 13, Train: label_loss: 0.33995771408081055, precision: 0.30626290433583575, recall: 0.7331136738054805, f1: 0.43203883490984724\n",
            "14\n",
            "epoch: 0, step: 14, Train: label_loss: 0.34850013256073, precision: 0.28373702422143365, recall: 0.6972789115645072, f1: 0.4033448105835378\n",
            "15\n",
            "epoch: 0, step: 15, Train: label_loss: 0.34250304102897644, precision: 0.30461329715058993, recall: 0.7172523961660195, f1: 0.42761904757716\n",
            "16\n",
            "epoch: 0, step: 16, Train: label_loss: 0.34206634759902954, precision: 0.29797297297295283, recall: 0.7461928934008889, f1: 0.4258812167626487\n",
            "17\n",
            "epoch: 0, step: 17, Train: label_loss: 0.35113516449928284, precision: 0.2907369844489323, recall: 0.7300509337859541, f1: 0.41586073496889175\n",
            "18\n",
            "epoch: 0, step: 18, Train: label_loss: 0.3518105745315552, precision: 0.30013550135499323, recall: 0.7334437086091501, f1: 0.42596153842028517\n",
            "19\n",
            "epoch: 0, step: 19, Train: label_loss: 0.34146758913993835, precision: 0.30148048452218695, recall: 0.7479131886476214, f1: 0.42973621099018283\n",
            "20\n",
            "epoch: 0, step: 20, Train: label_loss: 0.3388664126396179, precision: 0.2826379542395503, recall: 0.7142857142855927, f1: 0.4050144647616489\n",
            "21\n",
            "epoch: 0, step: 21, Train: label_loss: 0.3411867618560791, precision: 0.3202657807308757, recall: 0.731411229134942, f1: 0.4454713493106505\n",
            "22\n",
            "epoch: 0, step: 22, Train: label_loss: 0.3358296751976013, precision: 0.3144329896907014, recall: 0.7883683360257208, f1: 0.44956241359346294\n",
            "23\n",
            "epoch: 0, step: 23, Train: label_loss: 0.3382803797721863, precision: 0.2993527508090373, recall: 0.767634854771625, f1: 0.4307334109025377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n",
        "    ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=10)\n",
        "summary_writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnZiis3sWyF2",
        "outputId": "0aa43843-e692-4aea-f0cf-bacf0be47ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, Train: label_loss: 0.35008370876312256, precision: 0.31675392670154995, recall: 0.7857142857141581, f1: 0.4514925372724378\n",
            "epoch: 0, step: 1, Train: label_loss: 0.3366279602050781, precision: 0.3068987749838616, recall: 0.7933333333332011, f1: 0.44258484421821676\n",
            "epoch: 0, step: 2, Train: label_loss: 0.33981582522392273, precision: 0.32178547634907917, recall: 0.7957166392090945, f1: 0.45825426940866487\n",
            "epoch: 0, step: 3, Train: label_loss: 0.330141544342041, precision: 0.3040317250495503, recall: 0.754098360655614, f1: 0.4333490343443087\n",
            "epoch: 0, step: 4, Train: label_loss: 0.33630648255348206, precision: 0.3091032608695442, recall: 0.733870967741817, f1: 0.43499043972880613\n",
            "epoch: 0, step: 5, Train: label_loss: 0.33744385838508606, precision: 0.2899045020463649, recall: 0.7154882154880949, f1: 0.41262135918222004\n",
            "epoch: 0, step: 6, Train: label_loss: 0.3324030339717865, precision: 0.3011250827266511, recall: 0.7434640522874602, f1: 0.42863871875308457\n",
            "epoch: 0, step: 7, Train: label_loss: 0.32990697026252747, precision: 0.29892037786772613, recall: 0.7274220032839528, f1: 0.4237207077539881\n",
            "epoch: 0, step: 8, Train: label_loss: 0.33829545974731445, precision: 0.31670984455956497, recall: 0.7899838449110194, f1: 0.45214979191471943\n",
            "epoch: 0, step: 9, Train: label_loss: 0.32853543758392334, precision: 0.3050293925538664, recall: 0.7809364548493677, f1: 0.4387036166810267\n",
            "epoch: 0, step: 10, Train: label_loss: 0.3317508101463318, precision: 0.3095238095237896, recall: 0.8003327787020298, f1: 0.4464037122567206\n",
            "epoch: 0, step: 11, Train: label_loss: 0.3186671733856201, precision: 0.30258792302585913, recall: 0.7499999999998765, f1: 0.4312056737178581\n",
            "epoch: 0, step: 12, Train: label_loss: 0.32547521591186523, precision: 0.30559254327561214, recall: 0.7599337748343112, f1: 0.4358974358564853\n",
            "epoch: 0, step: 13, Train: label_loss: 0.3173326849937439, precision: 0.29622266401588493, recall: 0.7693631669533959, f1: 0.4277511961320654\n",
            "epoch: 0, step: 14, Train: label_loss: 0.3234747648239136, precision: 0.30624580255202777, recall: 0.7438825448612163, f1: 0.4338725023373295\n",
            "epoch: 0, step: 15, Train: label_loss: 0.32643628120422363, precision: 0.31538461538459517, recall: 0.8052373158754819, f1: 0.45324735141045647\n",
            "epoch: 0, step: 16, Train: label_loss: 0.31635284423828125, precision: 0.31522468142184334, recall: 0.7654723127034584, f1: 0.44655581943607114\n",
            "epoch: 0, step: 17, Train: label_loss: 0.3197399377822876, precision: 0.2758384668035403, recall: 0.7107583774249187, f1: 0.39743589739557467\n",
            "epoch: 0, step: 18, Train: label_loss: 0.33330991864204407, precision: 0.2933884297520459, recall: 0.7232597623088755, f1: 0.41744243014018206\n",
            "epoch: 0, step: 19, Train: label_loss: 0.32195889949798584, precision: 0.29716981132073467, recall: 0.7241379310343637, f1: 0.42140468223294586\n",
            "epoch: 0, step: 20, Train: label_loss: 0.3341359496116638, precision: 0.30790006752192384, recall: 0.7562189054725114, f1: 0.437619961571117\n",
            "epoch: 0, step: 21, Train: label_loss: 0.3261907398700714, precision: 0.2674187126741694, recall: 0.7209302325580105, f1: 0.3901258470079244\n",
            "epoch: 0, step: 22, Train: label_loss: 0.3297015428543091, precision: 0.29614604462472643, recall: 0.7336683417084198, f1: 0.4219653178780596\n",
            "epoch: 0, step: 23, Train: label_loss: 0.32767170667648315, precision: 0.278991596638632, recall: 0.6945606694559217, f1: 0.39808153473124486\n",
            "epoch: 1, step: 0, Train: label_loss: 0.3123679757118225, precision: 0.2849122807017344, recall: 0.6655737704916941, f1: 0.39901719897517945\n",
            "epoch: 1, step: 1, Train: label_loss: 0.3223506808280945, precision: 0.2790697674418402, recall: 0.6173633440513476, f1: 0.3843843843414666\n",
            "epoch: 1, step: 2, Train: label_loss: 0.3229195773601532, precision: 0.27388535031845196, recall: 0.6898395721923903, f1: 0.39209726439696463\n",
            "epoch: 1, step: 3, Train: label_loss: 0.3385816812515259, precision: 0.2988980716253238, recall: 0.7185430463574969, f1: 0.422178988285313\n",
            "epoch: 1, step: 4, Train: label_loss: 0.30173569917678833, precision: 0.2845070422535011, recall: 0.6677685950412119, f1: 0.399012345637072\n",
            "epoch: 1, step: 5, Train: label_loss: 0.311729371547699, precision: 0.30399999999997973, recall: 0.74025974025962, f1: 0.43100189031785413\n",
            "epoch: 1, step: 6, Train: label_loss: 0.3152370750904083, precision: 0.30367892976586597, recall: 0.7923211169283084, f1: 0.4390715666910374\n",
            "epoch: 1, step: 7, Train: label_loss: 0.322584867477417, precision: 0.2851378614660198, recall: 0.7504424778759733, f1: 0.4132553605838357\n",
            "epoch: 1, step: 8, Train: label_loss: 0.3065717816352844, precision: 0.30987821380241476, recall: 0.7658862876252899, f1: 0.44123314061404767\n",
            "epoch: 1, step: 9, Train: label_loss: 0.32968670129776, precision: 0.32949152542370647, recall: 0.7499999999998842, f1: 0.45784267541679985\n",
            "epoch: 1, step: 10, Train: label_loss: 0.31313106417655945, precision: 0.2970168612191766, recall: 0.8120567375885084, f1: 0.43494776824184306\n",
            "epoch: 1, step: 11, Train: label_loss: 0.3213987350463867, precision: 0.30501672240800637, recall: 0.7663865546217199, f1: 0.43636363632286634\n",
            "epoch: 1, step: 12, Train: label_loss: 0.3133940100669861, precision: 0.29419703103911643, recall: 0.7159277504103915, f1: 0.417025346682731\n",
            "epoch: 1, step: 13, Train: label_loss: 0.3117332458496094, precision: 0.2909090909090706, recall: 0.6921797004990529, f1: 0.4096504184713377\n",
            "epoch: 1, step: 14, Train: label_loss: 0.307513952255249, precision: 0.3002084781097776, recall: 0.7093596059112135, f1: 0.4218749999581711\n",
            "epoch: 1, step: 15, Train: label_loss: 0.3151127099990845, precision: 0.29639700883750536, recall: 0.7377326565142576, f1: 0.4228903976312286\n",
            "epoch: 1, step: 16, Train: label_loss: 0.31927552819252014, precision: 0.2928722653493089, recall: 0.67260940032404, f1: 0.4080629301445186\n",
            "epoch: 1, step: 17, Train: label_loss: 0.3282315731048584, precision: 0.2912692589875061, recall: 0.6508196721310407, f1: 0.4024328433429491\n",
            "epoch: 1, step: 18, Train: label_loss: 0.3133273124694824, precision: 0.29215976331358784, recall: 0.6454248366012016, f1: 0.40224032582263763\n",
            "epoch: 1, step: 19, Train: label_loss: 0.3127196729183197, precision: 0.29890909090906914, recall: 0.6748768472905295, f1: 0.41431451608644365\n",
            "epoch: 1, step: 20, Train: label_loss: 0.3177320957183838, precision: 0.29113018597995055, recall: 0.6851851851850698, f1: 0.40863453811071465\n",
            "epoch: 1, step: 21, Train: label_loss: 0.31492048501968384, precision: 0.30347222222220116, recall: 0.7247097844111567, f1: 0.4278022515491483\n",
            "epoch: 1, step: 22, Train: label_loss: 0.3205922544002533, precision: 0.2968970380817844, recall: 0.6958677685949263, f1: 0.41621354419926004\n",
            "epoch: 1, step: 23, Train: label_loss: 0.3081235885620117, precision: 0.28846153846151434, recall: 0.6927710843372104, f1: 0.4073199527329391\n",
            "epoch: 2, step: 0, Train: label_loss: 0.3140786588191986, precision: 0.30769230769228695, recall: 0.721518987341658, f1: 0.431409649910739\n",
            "epoch: 2, step: 1, Train: label_loss: 0.30055224895477295, precision: 0.32303559435860824, recall: 0.7434312210199778, f1: 0.45037453179293324\n",
            "epoch: 2, step: 2, Train: label_loss: 0.3000671863555908, precision: 0.3011049723756698, recall: 0.7414965986393296, f1: 0.4282907661671303\n",
            "epoch: 2, step: 3, Train: label_loss: 0.31432151794433594, precision: 0.3173144876324864, recall: 0.703761755485783, f1: 0.43740867019579444\n",
            "epoch: 2, step: 4, Train: label_loss: 0.31101053953170776, precision: 0.3188896411645011, recall: 0.769607843137129, f1: 0.4509334609446474\n",
            "epoch: 2, step: 5, Train: label_loss: 0.31580692529678345, precision: 0.31535269709541386, recall: 0.7438825448612163, f1: 0.4429334628041824\n",
            "epoch: 2, step: 6, Train: label_loss: 0.30858856439590454, precision: 0.3267663043478039, recall: 0.7990033222590034, f1: 0.46383799417283245\n",
            "epoch: 2, step: 7, Train: label_loss: 0.3086704611778259, precision: 0.32332878581171054, recall: 0.7441130298271986, f1: 0.4507845933956725\n",
            "epoch: 2, step: 8, Train: label_loss: 0.30372363328933716, precision: 0.3058659217876881, recall: 0.7030497592294216, f1: 0.4262773722204811\n",
            "epoch: 2, step: 9, Train: label_loss: 0.3059620261192322, precision: 0.2892329345531112, recall: 0.7110726643597385, f1: 0.4112056027602515\n",
            "epoch: 2, step: 10, Train: label_loss: 0.31260567903518677, precision: 0.3064285714285495, recall: 0.7055921052630418, f1: 0.4272908366111223\n",
            "epoch: 2, step: 11, Train: label_loss: 0.29971665143966675, precision: 0.28060128847528415, recall: 0.6723842195539155, f1: 0.3959595959180066\n",
            "epoch: 2, step: 12, Train: label_loss: 0.3090594410896301, precision: 0.29678770949718597, recall: 0.7154882154880949, f1: 0.4195459032161633\n",
            "epoch: 2, step: 13, Train: label_loss: 0.3089551031589508, precision: 0.2848620432512837, recall: 0.6262295081966186, f1: 0.3915940542880913\n",
            "epoch: 2, step: 14, Train: label_loss: 0.2998048663139343, precision: 0.2653208363373998, recall: 0.6433566433565309, f1: 0.37570188867734966\n",
            "epoch: 2, step: 15, Train: label_loss: 0.29466158151626587, precision: 0.2699083861874369, recall: 0.6707530647984814, f1: 0.3849246230746185\n",
            "epoch: 2, step: 16, Train: label_loss: 0.29802626371383667, precision: 0.2983814215341099, recall: 0.6871961102105855, f1: 0.4160942099675544\n",
            "epoch: 2, step: 17, Train: label_loss: 0.31350359320640564, precision: 0.29853723404253335, recall: 0.7754749568219731, f1: 0.4311089773962084\n",
            "epoch: 2, step: 18, Train: label_loss: 0.30123090744018555, precision: 0.30833917309037784, recall: 0.740740740740616, f1: 0.4354280058961058\n",
            "epoch: 2, step: 19, Train: label_loss: 0.3051246106624603, precision: 0.30704225352110515, recall: 0.7266666666665454, f1: 0.4316831682750283\n",
            "epoch: 2, step: 20, Train: label_loss: 0.29432377219200134, precision: 0.2882562277579866, recall: 0.6852791878171429, f1: 0.40581162320476805\n",
            "epoch: 2, step: 21, Train: label_loss: 0.30211490392684937, precision: 0.2934936350777727, recall: 0.7045840407469092, f1: 0.4143784323099137\n",
            "epoch: 2, step: 22, Train: label_loss: 0.291889488697052, precision: 0.28680027643398154, recall: 0.7192374350085408, f1: 0.41007905134259687\n",
            "epoch: 2, step: 23, Train: label_loss: 0.2922820448875427, precision: 0.269527896995685, recall: 0.6767241379308887, f1: 0.3855125843668237\n",
            "epoch: 3, step: 0, Train: label_loss: 0.31423085927963257, precision: 0.29842573579737863, recall: 0.7478559176671101, f1: 0.4266144813681859\n",
            "epoch: 3, step: 1, Train: label_loss: 0.30584895610809326, precision: 0.30097087378638687, recall: 0.7393526405450188, f1: 0.42779694426637693\n",
            "epoch: 3, step: 2, Train: label_loss: 0.29227352142333984, precision: 0.2919605077573842, recall: 0.7237762237760972, f1: 0.416080401969045\n",
            "epoch: 3, step: 3, Train: label_loss: 0.30033159255981445, precision: 0.28501400560222095, recall: 0.7216312056736308, f1: 0.40863453811197575\n",
            "epoch: 3, step: 4, Train: label_loss: 0.30451101064682007, precision: 0.3009292351679556, recall: 0.6598746081503667, f1: 0.4133529700109388\n",
            "epoch: 3, step: 5, Train: label_loss: 0.2998747229576111, precision: 0.2805495300072104, recall: 0.6381578947367371, f1: 0.38975389247386016\n",
            "epoch: 3, step: 6, Train: label_loss: 0.3109937906265259, precision: 0.29441624365480096, recall: 0.649599999999896, f1: 0.40518962071552067\n",
            "epoch: 3, step: 7, Train: label_loss: 0.3145598769187927, precision: 0.31658637302131337, recall: 0.733652312599564, f1: 0.4423076922655348\n",
            "epoch: 3, step: 8, Train: label_loss: 0.2879387438297272, precision: 0.3184319119669657, recall: 0.7455716586150167, f1: 0.44626506019897877\n",
            "epoch: 3, step: 9, Train: label_loss: 0.2986123561859131, precision: 0.33264033264030957, recall: 0.7582938388624394, f1: 0.46242774562230704\n",
            "epoch: 3, step: 10, Train: label_loss: 0.29814374446868896, precision: 0.3148788927335422, recall: 0.7471264367814865, f1: 0.443037974641784\n",
            "epoch: 3, step: 11, Train: label_loss: 0.2957571744918823, precision: 0.2899786780383589, recall: 0.6857142857141704, f1: 0.4075924075505922\n",
            "epoch: 3, step: 12, Train: label_loss: 0.2967684268951416, precision: 0.30348598769649326, recall: 0.7196110210695754, f1: 0.4269230768813074\n",
            "epoch: 3, step: 13, Train: label_loss: 0.2995903193950653, precision: 0.2791519434628778, recall: 0.682210708117326, f1: 0.3961885656558404\n",
            "epoch: 3, step: 14, Train: label_loss: 0.2937106192111969, precision: 0.2916962384669772, recall: 0.6838602329449777, f1: 0.4089552238386361\n",
            "epoch: 3, step: 15, Train: label_loss: 0.2867998480796814, precision: 0.29137691237828295, recall: 0.7053872053870865, f1: 0.41240157476173495\n",
            "epoch: 3, step: 16, Train: label_loss: 0.3037849962711334, precision: 0.3000683526999111, recall: 0.7208538587847748, f1: 0.42374517370362674\n",
            "epoch: 3, step: 17, Train: label_loss: 0.2927214205265045, precision: 0.2810320781031882, recall: 0.7196428571427286, f1: 0.40421263787330663\n",
            "epoch: 3, step: 18, Train: label_loss: 0.29336002469062805, precision: 0.2893470790377808, recall: 0.7385964912279406, f1: 0.4158024690953115\n",
            "epoch: 3, step: 19, Train: label_loss: 0.2974415421485901, precision: 0.31967213114751913, recall: 0.7267080745340486, f1: 0.4440227703560056\n",
            "epoch: 3, step: 20, Train: label_loss: 0.29396289587020874, precision: 0.3069800569800351, recall: 0.7100494233936226, f1: 0.42864246639242054\n",
            "epoch: 3, step: 21, Train: label_loss: 0.30030688643455505, precision: 0.30758327427354304, recall: 0.7508650519029842, f1: 0.43640020106480937\n",
            "epoch: 3, step: 22, Train: label_loss: 0.299760639667511, precision: 0.3007953723788647, recall: 0.6944908180299341, f1: 0.41977800197594445\n",
            "epoch: 3, step: 23, Train: label_loss: 0.2883914113044739, precision: 0.3302598491198382, recall: 0.7895791583164751, f1: 0.4657210401474821\n",
            "epoch: 4, step: 0, Train: label_loss: 0.28703537583351135, precision: 0.2884753042233151, recall: 0.686541737648946, f1: 0.40624999995829314\n",
            "epoch: 4, step: 1, Train: label_loss: 0.2944725751876831, precision: 0.2759381898454543, recall: 0.6578947368419898, f1: 0.3888024882942499\n",
            "epoch: 4, step: 2, Train: label_loss: 0.29534244537353516, precision: 0.26999316472998836, recall: 0.6638655462183758, f1: 0.3838678328062818\n",
            "epoch: 4, step: 3, Train: label_loss: 0.28740185499191284, precision: 0.27309782608693794, recall: 0.6677740863786266, f1: 0.38765670198383306\n",
            "epoch: 4, step: 4, Train: label_loss: 0.2990618050098419, precision: 0.27956254272041836, recall: 0.7003424657533047, f1: 0.39960918413113955\n",
            "epoch: 4, step: 5, Train: label_loss: 0.2929421365261078, precision: 0.30148048452218695, recall: 0.7479131886476214, f1: 0.42973621099018283\n",
            "epoch: 4, step: 6, Train: label_loss: 0.3012702167034149, precision: 0.30979827089334944, recall: 0.6708268330732182, f1: 0.42385411528448297\n",
            "epoch: 4, step: 7, Train: label_loss: 0.28317010402679443, precision: 0.2942446043165256, recall: 0.703958691910378, f1: 0.4150177574418923\n",
            "epoch: 4, step: 8, Train: label_loss: 0.2977009415626526, precision: 0.31372549019605644, recall: 0.73805601317945, f1: 0.4402948402529352\n",
            "epoch: 4, step: 9, Train: label_loss: 0.30106475949287415, precision: 0.31991951710259425, recall: 0.798994974874238, f1: 0.45689655168326015\n",
            "epoch: 4, step: 10, Train: label_loss: 0.2902489900588989, precision: 0.3299319727890932, recall: 0.7649842271292169, f1: 0.4610266159274318\n",
            "epoch: 4, step: 11, Train: label_loss: 0.2875479459762573, precision: 0.3021483021482812, recall: 0.7427597955705719, f1: 0.42955665020515355\n",
            "epoch: 4, step: 12, Train: label_loss: 0.2882459759712219, precision: 0.31944444444442227, recall: 0.7615894039733838, f1: 0.4500978473164414\n",
            "epoch: 4, step: 13, Train: label_loss: 0.29413706064224243, precision: 0.30056179775278785, recall: 0.7039473684209367, f1: 0.42125984247770665\n",
            "epoch: 4, step: 14, Train: label_loss: 0.30231642723083496, precision: 0.3060628195763107, recall: 0.6835236541597579, f1: 0.42280524718225704\n",
            "epoch: 4, step: 15, Train: label_loss: 0.296067476272583, precision: 0.30693763139451247, recall: 0.7041800643085684, f1: 0.4275256222124341\n",
            "epoch: 4, step: 16, Train: label_loss: 0.28349044919013977, precision: 0.29395017793592215, recall: 0.6917922948072542, f1: 0.4125874125455159\n",
            "epoch: 4, step: 17, Train: label_loss: 0.30461984872817993, precision: 0.30348258706465503, recall: 0.7069536423839888, f1: 0.4246643460543993\n",
            "epoch: 4, step: 18, Train: label_loss: 0.29975008964538574, precision: 0.285407725321868, recall: 0.6762711864405633, f1: 0.40140845066244457\n",
            "epoch: 4, step: 19, Train: label_loss: 0.286157488822937, precision: 0.3068893528183502, recall: 0.7301324503310049, f1: 0.4321411072586292\n",
            "epoch: 4, step: 20, Train: label_loss: 0.2971862852573395, precision: 0.3046448087431486, recall: 0.7252032520324023, f1: 0.42905242901072604\n",
            "epoch: 4, step: 21, Train: label_loss: 0.292376846075058, precision: 0.28998609179413837, recall: 0.738053097345002, f1: 0.41637543680418937\n",
            "epoch: 4, step: 22, Train: label_loss: 0.30160588026046753, precision: 0.3135768435561465, recall: 0.7350565428108666, f1: 0.4396135265280833\n",
            "epoch: 4, step: 23, Train: label_loss: 0.28753891587257385, precision: 0.2972972972972714, recall: 0.6902834008095768, f1: 0.41560024371167537\n",
            "epoch: 5, step: 0, Train: label_loss: 0.29529672861099243, precision: 0.2988980716253238, recall: 0.7508650519029842, f1: 0.4275862068557779\n",
            "epoch: 5, step: 1, Train: label_loss: 0.2858204245567322, precision: 0.30569574621483014, recall: 0.6740858505563315, f1: 0.4206349205919474\n",
            "epoch: 5, step: 2, Train: label_loss: 0.2930442690849304, precision: 0.3015873015872798, recall: 0.6785714285713184, f1: 0.4175824175397723\n",
            "epoch: 5, step: 3, Train: label_loss: 0.29888716340065, precision: 0.31223328591747423, recall: 0.7292358803985499, f1: 0.4372509959739086\n",
            "epoch: 5, step: 4, Train: label_loss: 0.2825901210308075, precision: 0.2838892831795398, recall: 0.6578947368419971, f1: 0.39662865637827244\n",
            "epoch: 5, step: 5, Train: label_loss: 0.29281386733055115, precision: 0.2977257064093523, recall: 0.7372013651875875, f1: 0.4241531663801821\n",
            "epoch: 5, step: 6, Train: label_loss: 0.2906656265258789, precision: 0.27125790583272863, recall: 0.6795774647886127, f1: 0.3877448517924313\n",
            "epoch: 5, step: 7, Train: label_loss: 0.2981036305427551, precision: 0.3114525139664587, recall: 0.6830015313934635, f1: 0.42781774576029585\n",
            "epoch: 5, step: 8, Train: label_loss: 0.2959650158882141, precision: 0.3037884203001927, recall: 0.7013201320130855, f1: 0.42394014958371434\n",
            "epoch: 5, step: 9, Train: label_loss: 0.29318568110466003, precision: 0.29884225759766286, recall: 0.7047781569964667, f1: 0.41971544711260866\n",
            "epoch: 5, step: 10, Train: label_loss: 0.28159067034721375, precision: 0.28611304954638617, recall: 0.7256637168140307, f1: 0.41041041036980597\n",
            "epoch: 5, step: 11, Train: label_loss: 0.2892661690711975, precision: 0.2849002849002646, recall: 0.7029876977151663, f1: 0.40547389757675517\n",
            "epoch: 5, step: 12, Train: label_loss: 0.2847975790500641, precision: 0.3043780403057467, recall: 0.7461669505961249, f1: 0.43237907202197834\n",
            "epoch: 5, step: 13, Train: label_loss: 0.2861790657043457, precision: 0.29466858789623235, recall: 0.6451104100945354, f1: 0.4045499505009284\n",
            "epoch: 5, step: 14, Train: label_loss: 0.28770726919174194, precision: 0.3204419889502541, recall: 0.7094801223240504, f1: 0.4414843006231246\n",
            "epoch: 5, step: 15, Train: label_loss: 0.29835081100463867, precision: 0.28758620689653186, recall: 0.6996644295300839, f1: 0.40762463338975624\n",
            "epoch: 5, step: 16, Train: label_loss: 0.29288721084594727, precision: 0.3124999999999778, recall: 0.7085346215779857, f1: 0.4337111877347098\n",
            "epoch: 5, step: 17, Train: label_loss: 0.2769352197647095, precision: 0.3058082575227218, recall: 0.7457337883957771, f1: 0.4337468982217356\n",
            "epoch: 5, step: 18, Train: label_loss: 0.2937433123588562, precision: 0.3021582733812732, recall: 0.7191780821916576, f1: 0.4255319148519096\n",
            "epoch: 5, step: 19, Train: label_loss: 0.2868753671646118, precision: 0.2785613540197265, recall: 0.6917688266198437, f1: 0.3971845147906008\n",
            "epoch: 5, step: 20, Train: label_loss: 0.2917596101760864, precision: 0.2917532917532715, recall: 0.6912972085384743, f1: 0.41033138397381397\n",
            "epoch: 5, step: 21, Train: label_loss: 0.3095874786376953, precision: 0.2997873848334302, recall: 0.696869851729704, f1: 0.4192269573414433\n",
            "epoch: 5, step: 22, Train: label_loss: 0.294173926115036, precision: 0.29271708683471337, recall: 0.7108843537413756, f1: 0.41468253964117907\n",
            "epoch: 5, step: 23, Train: label_loss: 0.2947733998298645, precision: 0.3194444444444167, recall: 0.7131782945735051, f1: 0.4412470023552979\n",
            "epoch: 6, step: 0, Train: label_loss: 0.2958274781703949, precision: 0.30103806228371616, recall: 0.7274247491637579, f1: 0.4258443465077447\n",
            "epoch: 6, step: 1, Train: label_loss: 0.28825637698173523, precision: 0.27669576897244613, recall: 0.7370304114488841, f1: 0.4023437499602711\n",
            "epoch: 6, step: 2, Train: label_loss: 0.2856157422065735, precision: 0.2781954887217855, recall: 0.7267857142855845, f1: 0.40237271375132133\n",
            "epoch: 6, step: 3, Train: label_loss: 0.2790689468383789, precision: 0.27732793522265337, recall: 0.7123050259964103, f1: 0.39922292370901363\n",
            "epoch: 6, step: 4, Train: label_loss: 0.2929096817970276, precision: 0.2976878612716548, recall: 0.6634460547502957, f1: 0.4109725685357535\n",
            "epoch: 6, step: 5, Train: label_loss: 0.29579153656959534, precision: 0.27450980392154867, recall: 0.6186579378067727, f1: 0.38028169009823004\n",
            "epoch: 6, step: 6, Train: label_loss: 0.295279324054718, precision: 0.28795438346398516, recall: 0.6767169179228346, f1: 0.40399999995808\n",
            "epoch: 6, step: 7, Train: label_loss: 0.278835266828537, precision: 0.2948369565217191, recall: 0.7257525083610826, f1: 0.41932367145645755\n",
            "epoch: 6, step: 8, Train: label_loss: 0.2842037081718445, precision: 0.3134948096885596, recall: 0.7462932454693992, f1: 0.441520467794553\n",
            "epoch: 6, step: 9, Train: label_loss: 0.2876294255256653, precision: 0.32187070151304525, recall: 0.7597402597401364, f1: 0.4521739130016289\n",
            "epoch: 6, step: 10, Train: label_loss: 0.29323744773864746, precision: 0.3168812589413221, recall: 0.7250409165301596, f1: 0.4410154305200979\n",
            "epoch: 6, step: 11, Train: label_loss: 0.2825736701488495, precision: 0.30188679245280825, recall: 0.6764227642275322, f1: 0.41746111385593165\n",
            "epoch: 6, step: 12, Train: label_loss: 0.28510135412216187, precision: 0.3235923022095279, recall: 0.7229299363056173, f1: 0.4470704086229183\n",
            "epoch: 6, step: 13, Train: label_loss: 0.2917185425758362, precision: 0.2862241256245335, recall: 0.7010489510488285, f1: 0.4064875823206715\n",
            "epoch: 6, step: 14, Train: label_loss: 0.2929067611694336, precision: 0.31100478468897397, recall: 0.7279999999998835, f1: 0.435823754747284\n",
            "epoch: 6, step: 15, Train: label_loss: 0.27883943915367126, precision: 0.2818645302257624, recall: 0.6537162162161058, f1: 0.3938931297288508\n",
            "epoch: 6, step: 16, Train: label_loss: 0.2900709807872772, precision: 0.27994227994225973, recall: 0.6830985915491754, f1: 0.39713408388912097\n",
            "epoch: 6, step: 17, Train: label_loss: 0.2893376052379608, precision: 0.2678966789667699, recall: 0.6237113402060783, f1: 0.3748064016099634\n",
            "epoch: 6, step: 18, Train: label_loss: 0.2972082197666168, precision: 0.28725701943842424, recall: 0.6487804878047725, f1: 0.39820359277179007\n",
            "epoch: 6, step: 19, Train: label_loss: 0.2884862422943115, precision: 0.28050490883588497, recall: 0.6600660066005511, f1: 0.39370078735967845\n",
            "epoch: 6, step: 20, Train: label_loss: 0.28239455819129944, precision: 0.3002070393374534, recall: 0.7154605263156717, f1: 0.42294603787761664\n",
            "epoch: 6, step: 21, Train: label_loss: 0.28384989500045776, precision: 0.299790356394109, recall: 0.6842105263156802, f1: 0.41690962094884426\n",
            "epoch: 6, step: 22, Train: label_loss: 0.2901889979839325, precision: 0.31730769230767053, recall: 0.7475728155338596, f1: 0.4455159112406656\n",
            "epoch: 6, step: 23, Train: label_loss: 0.2953436076641083, precision: 0.3256606990622058, recall: 0.7519685039368599, f1: 0.4544913741398053\n",
            "epoch: 7, step: 0, Train: label_loss: 0.2799675464630127, precision: 0.30240793201131, recall: 0.7152428810719069, f1: 0.4250871079721235\n",
            "epoch: 7, step: 1, Train: label_loss: 0.28892746567726135, precision: 0.31358381502887905, recall: 0.7126436781608024, f1: 0.4355243351306227\n",
            "epoch: 7, step: 2, Train: label_loss: 0.2822486162185669, precision: 0.29351032448375414, recall: 0.6655518394647716, f1: 0.4073694984221703\n",
            "epoch: 7, step: 3, Train: label_loss: 0.28099125623703003, precision: 0.29057971014490647, recall: 0.7035087719297011, f1: 0.41128205124063627\n",
            "epoch: 7, step: 4, Train: label_loss: 0.2782961130142212, precision: 0.2928416485900005, recall: 0.666118421052522, f1: 0.40683073827998595\n",
            "epoch: 7, step: 5, Train: label_loss: 0.2819380760192871, precision: 0.3155680224403706, recall: 0.7097791798106136, f1: 0.4368932038408434\n",
            "epoch: 7, step: 6, Train: label_loss: 0.3000327944755554, precision: 0.29816201497615397, recall: 0.7361344537813889, f1: 0.4244186046100871\n",
            "epoch: 7, step: 7, Train: label_loss: 0.2939675450325012, precision: 0.2920962199312514, recall: 0.695581014729837, f1: 0.4114230396485272\n",
            "epoch: 7, step: 8, Train: label_loss: 0.2870807945728302, precision: 0.2560801144491948, recall: 0.6336283185839586, f1: 0.3647478349054769\n",
            "epoch: 7, step: 9, Train: label_loss: 0.28687456250190735, precision: 0.2588832487309457, recall: 0.611301369862909, f1: 0.3637289862037064\n",
            "epoch: 7, step: 10, Train: label_loss: 0.29135915637016296, precision: 0.28447024673437704, recall: 0.6322580645160271, f1: 0.39239239234954953\n",
            "epoch: 7, step: 11, Train: label_loss: 0.28701338171958923, precision: 0.2842261904761693, recall: 0.607313195548393, f1: 0.3872275721815651\n",
            "epoch: 7, step: 12, Train: label_loss: 0.28346797823905945, precision: 0.29794762915779915, recall: 0.6970198675495535, f1: 0.41745166084050106\n",
            "epoch: 7, step: 13, Train: label_loss: 0.2838382422924042, precision: 0.31883024251067626, recall: 0.7061611374406467, f1: 0.4393120392691361\n",
            "epoch: 7, step: 14, Train: label_loss: 0.2968255281448364, precision: 0.3051575931231873, recall: 0.7171717171715963, f1: 0.4281407034756659\n",
            "epoch: 7, step: 15, Train: label_loss: 0.2948776185512543, precision: 0.30322128851538493, recall: 0.7596491228068842, f1: 0.4334334333926106\n",
            "epoch: 7, step: 16, Train: label_loss: 0.2762242555618286, precision: 0.31520223152020116, recall: 0.7483443708608032, f1: 0.4435721294970131\n",
            "epoch: 7, step: 17, Train: label_loss: 0.28596070408821106, precision: 0.2923076923076709, recall: 0.6843910806173783, f1: 0.4096509239826562\n",
            "epoch: 7, step: 18, Train: label_loss: 0.27704620361328125, precision: 0.3041958041957829, recall: 0.6959999999998886, f1: 0.4233576641912079\n",
            "epoch: 7, step: 19, Train: label_loss: 0.2753572463989258, precision: 0.26203966005663865, recall: 0.6514084507041106, f1: 0.3737373736964209\n",
            "epoch: 7, step: 20, Train: label_loss: 0.2808326184749603, precision: 0.27532290958529737, recall: 0.6899488926744991, f1: 0.3935860057900909\n",
            "epoch: 7, step: 21, Train: label_loss: 0.2865786552429199, precision: 0.27544097693349556, recall: 0.6812080536911608, f1: 0.3922705313599236\n",
            "epoch: 7, step: 22, Train: label_loss: 0.28430938720703125, precision: 0.29431895961668075, recall: 0.6825396825395742, f1: 0.4112864657636922\n",
            "epoch: 7, step: 23, Train: label_loss: 0.2849796414375305, precision: 0.2875647668393534, recall: 0.6594059405939289, f1: 0.40048105828598335\n",
            "epoch: 8, step: 0, Train: label_loss: 0.29060086607933044, precision: 0.3065106071689607, recall: 0.701842546063534, f1: 0.4266802443568273\n",
            "epoch: 8, step: 1, Train: label_loss: 0.28400760889053345, precision: 0.30818505338076096, recall: 0.7180762852403452, f1: 0.4312749003563395\n",
            "epoch: 8, step: 2, Train: label_loss: 0.28450697660446167, precision: 0.30484330484328315, recall: 0.7157190635450308, f1: 0.4275724275304891\n",
            "epoch: 8, step: 3, Train: label_loss: 0.28535643219947815, precision: 0.3321653819200888, recall: 0.7406249999998842, f1: 0.4586357038759267\n",
            "epoch: 8, step: 4, Train: label_loss: 0.28470757603645325, precision: 0.32271468144042087, recall: 0.7715231788078192, f1: 0.4550781249583669\n",
            "epoch: 8, step: 5, Train: label_loss: 0.2809576094150543, precision: 0.28446389496715646, recall: 0.6576728499155721, f1: 0.39714867612888494\n",
            "epoch: 8, step: 6, Train: label_loss: 0.28883177042007446, precision: 0.2854030501089117, recall: 0.6661016949151413, f1: 0.39959328923096793\n",
            "epoch: 8, step: 7, Train: label_loss: 0.2782962918281555, precision: 0.2685798381162422, recall: 0.639229422066438, f1: 0.37823834192720773\n",
            "epoch: 8, step: 8, Train: label_loss: 0.2829125225543976, precision: 0.2780522230063318, recall: 0.6566666666665572, f1: 0.39067922653228476\n",
            "epoch: 8, step: 9, Train: label_loss: 0.2723616361618042, precision: 0.29254571026720866, recall: 0.6944908180299341, f1: 0.41167738739021514\n",
            "epoch: 8, step: 10, Train: label_loss: 0.280128538608551, precision: 0.30326162387228983, recall: 0.7014446227928247, f1: 0.42344961236091305\n",
            "epoch: 8, step: 11, Train: label_loss: 0.27498841285705566, precision: 0.2857142857142656, recall: 0.663398692810349, f1: 0.3994097392594031\n",
            "epoch: 8, step: 12, Train: label_loss: 0.29506242275238037, precision: 0.3203551912568087, recall: 0.7552334943638075, f1: 0.4498800958813918\n",
            "epoch: 8, step: 13, Train: label_loss: 0.2905702292919159, precision: 0.2895480225988496, recall: 0.7093425605535104, f1: 0.4112337010620996\n",
            "epoch: 8, step: 14, Train: label_loss: 0.28032758831977844, precision: 0.2854030501089117, recall: 0.6485148514850414, f1: 0.39636913762771503\n",
            "epoch: 8, step: 15, Train: label_loss: 0.27878323197364807, precision: 0.27822878228780235, recall: 0.6304347826085902, f1: 0.3860727086108263\n",
            "epoch: 8, step: 16, Train: label_loss: 0.28248536586761475, precision: 0.27629629629627583, recall: 0.6408934707902678, f1: 0.3861283643470949\n",
            "epoch: 8, step: 17, Train: label_loss: 0.2877459228038788, precision: 0.2902985074626649, recall: 0.6264090177132646, f1: 0.396736358957191\n",
            "epoch: 8, step: 18, Train: label_loss: 0.2812202572822571, precision: 0.2661230541141389, recall: 0.6115843270867782, f1: 0.37086776855274883\n",
            "epoch: 8, step: 19, Train: label_loss: 0.294752299785614, precision: 0.29747292418770416, recall: 0.6488188976376931, f1: 0.4079207920360602\n",
            "epoch: 8, step: 20, Train: label_loss: 0.28266218304634094, precision: 0.2937411095305623, recall: 0.6803953871498055, f1: 0.41033283652018127\n",
            "epoch: 8, step: 21, Train: label_loss: 0.2873908579349518, precision: 0.3091032608695442, recall: 0.7634228187918182, f1: 0.440038684678465\n",
            "epoch: 8, step: 22, Train: label_loss: 0.28199833631515503, precision: 0.29796205200279, recall: 0.7162162162160952, f1: 0.42084367241503795\n",
            "epoch: 8, step: 23, Train: label_loss: 0.2935648262500763, precision: 0.29879101899824706, recall: 0.7424892703861068, f1: 0.42610837434326243\n",
            "epoch: 9, step: 0, Train: label_loss: 0.2885815501213074, precision: 0.30326704545452393, recall: 0.6931818181817057, f1: 0.4219367588508949\n",
            "epoch: 9, step: 1, Train: label_loss: 0.2943649888038635, precision: 0.2920420420420201, recall: 0.6284329563811585, f1: 0.3987698615660679\n",
            "epoch: 9, step: 2, Train: label_loss: 0.2674780786037445, precision: 0.29370134465673786, recall: 0.7106164383560426, f1: 0.4156234351113038\n",
            "epoch: 9, step: 3, Train: label_loss: 0.28004980087280273, precision: 0.3042253521126546, recall: 0.7035830618891362, f1: 0.4247787610197563\n",
            "epoch: 9, step: 4, Train: label_loss: 0.2814047932624817, precision: 0.2952973720608371, recall: 0.7426086956520447, f1: 0.4225630875396509\n",
            "epoch: 9, step: 5, Train: label_loss: 0.28125590085983276, precision: 0.3154639175257515, recall: 0.7427184466018215, f1: 0.4428364688437814\n",
            "epoch: 9, step: 6, Train: label_loss: 0.29392123222351074, precision: 0.3066104078762091, recall: 0.7032258064514995, f1: 0.4270323212113438\n",
            "epoch: 9, step: 7, Train: label_loss: 0.2734014093875885, precision: 0.3031988873435116, recall: 0.7159277504103915, f1: 0.4259892525228878\n",
            "epoch: 9, step: 8, Train: label_loss: 0.287996768951416, precision: 0.3069016152716368, recall: 0.6677316293928646, f1: 0.42052313878980885\n",
            "epoch: 9, step: 9, Train: label_loss: 0.27295374870300293, precision: 0.289589442815228, recall: 0.670628183361516, f1: 0.40450588833468815\n",
            "epoch: 9, step: 10, Train: label_loss: 0.28187263011932373, precision: 0.28921933085499707, recall: 0.6649572649571512, f1: 0.4031088082478669\n",
            "epoch: 9, step: 11, Train: label_loss: 0.27829936146736145, precision: 0.2825607064017452, recall: 0.648648648648539, f1: 0.3936442849397477\n",
            "epoch: 9, step: 12, Train: label_loss: 0.27556082606315613, precision: 0.29041916167662496, recall: 0.6360655737703875, f1: 0.3987667008818925\n",
            "epoch: 9, step: 13, Train: label_loss: 0.2867967486381531, precision: 0.31891137473828896, recall: 0.7442996742669797, f1: 0.4465070834948435\n",
            "epoch: 9, step: 14, Train: label_loss: 0.282417893409729, precision: 0.30577427821520303, recall: 0.8118466898953289, f1: 0.44423260243876056\n",
            "epoch: 9, step: 15, Train: label_loss: 0.28397101163864136, precision: 0.3162108072047821, recall: 0.7770491803277414, f1: 0.44950213367150166\n",
            "epoch: 9, step: 16, Train: label_loss: 0.2736823558807373, precision: 0.2794316644113478, recall: 0.7522768670308283, f1: 0.40749876661068435\n",
            "epoch: 9, step: 17, Train: label_loss: 0.2910136580467224, precision: 0.3025780189959089, recall: 0.7359735973596144, f1: 0.4288461538048199\n",
            "epoch: 9, step: 18, Train: label_loss: 0.2890394926071167, precision: 0.26633522727270836, recall: 0.6672597864767496, f1: 0.38071065985765945\n",
            "epoch: 9, step: 19, Train: label_loss: 0.2691115736961365, precision: 0.2939541348158239, recall: 0.6714285714284648, f1: 0.4088931850711863\n",
            "epoch: 9, step: 20, Train: label_loss: 0.28301185369491577, precision: 0.26372059871701614, recall: 0.6281833616297745, f1: 0.3714859437334122\n",
            "epoch: 9, step: 21, Train: label_loss: 0.2835797369480133, precision: 0.2803138373751583, recall: 0.6495867768593967, f1: 0.3916292974167397\n",
            "epoch: 9, step: 22, Train: label_loss: 0.2764342725276947, precision: 0.28850174216025865, recall: 0.6592356687897039, f1: 0.401357246685678\n",
            "epoch: 9, step: 23, Train: label_loss: 0.2874726355075836, precision: 0.29335634167383146, recall: 0.6868686868685481, f1: 0.4111245465118174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model_self.eval()\n",
        "  model_ngb.eval()"
      ],
      "metadata": {
        "id": "8vTCY2HtZrdR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n",
        "    ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=1000)\n",
        "summary_writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9OFAIsfEZ4TE",
        "outputId": "302fb7e7-5e19-46f1-88d4-bd7c2282cd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch: 352, step: 16, Train: label_loss: 0.10112673044204712, precision: 0.3150029886431372, recall: 0.8872053872052378, f1: 0.4649316276630944\n",
            "epoch: 352, step: 17, Train: label_loss: 0.11697559058666229, precision: 0.29895641497849607, recall: 0.8589065255730407, f1: 0.4435336975937116\n",
            "epoch: 352, step: 18, Train: label_loss: 0.10348707437515259, precision: 0.3442622950819463, recall: 0.8749999999998649, f1: 0.49411764701825456\n",
            "epoch: 352, step: 19, Train: label_loss: 0.0930759534239769, precision: 0.3231231231231037, recall: 0.8936877076410475, f1: 0.47463608288993264\n",
            "epoch: 352, step: 20, Train: label_loss: 0.0980043113231659, precision: 0.31899641577059024, recall: 0.8974789915964877, f1: 0.4706919347342932\n",
            "epoch: 352, step: 21, Train: label_loss: 0.10323260724544525, precision: 0.3167777104784787, recall: 0.8745819397991847, f1: 0.4650955980044944\n",
            "epoch: 352, step: 22, Train: label_loss: 0.12759210169315338, precision: 0.2897483118477416, recall: 0.8353982300883477, f1: 0.4302643572999151\n",
            "epoch: 352, step: 23, Train: label_loss: 0.11603257805109024, precision: 0.2958174904942741, recall: 0.8383620689653366, f1: 0.43732433947797456\n",
            "epoch: 353, step: 0, Train: label_loss: 0.09958530962467194, precision: 0.3157575757575566, recall: 0.8697829716192204, f1: 0.4633170297518964\n",
            "epoch: 353, step: 1, Train: label_loss: 0.10912994295358658, precision: 0.3308641975308438, recall: 0.8494453248810063, f1: 0.47623278538830793\n",
            "epoch: 353, step: 2, Train: label_loss: 0.11608121544122696, precision: 0.2996300863131751, recall: 0.8237288135591824, f1: 0.4394213381163588\n",
            "epoch: 353, step: 3, Train: label_loss: 0.10158459842205048, precision: 0.32131948686619904, recall: 0.8483870967740567, f1: 0.46610544967211764\n",
            "epoch: 353, step: 4, Train: label_loss: 0.1076815128326416, precision: 0.3032886723507732, recall: 0.8601036269428566, f1: 0.4484466456165234\n",
            "epoch: 353, step: 5, Train: label_loss: 0.11729401350021362, precision: 0.29532710280371993, recall: 0.8088737201363807, f1: 0.4326791419050934\n",
            "epoch: 353, step: 6, Train: label_loss: 0.11291708052158356, precision: 0.30276923076921214, recall: 0.8482758620688192, f1: 0.4462585033625502\n",
            "epoch: 353, step: 7, Train: label_loss: 0.10589642822742462, precision: 0.3038507821901141, recall: 0.8632478632477156, f1: 0.44948820645899906\n",
            "epoch: 353, step: 8, Train: label_loss: 0.11495575308799744, precision: 0.30191004312998754, recall: 0.8404802744423944, f1: 0.4442429736691414\n",
            "epoch: 353, step: 9, Train: label_loss: 0.12622728943824768, precision: 0.30198019801978326, recall: 0.8341880341878916, f1: 0.44343480232349314\n",
            "epoch: 353, step: 10, Train: label_loss: 0.1135672926902771, precision: 0.3069486404833651, recall: 0.8850174216026332, f1: 0.4558097801321989\n",
            "epoch: 353, step: 11, Train: label_loss: 0.10349340736865997, precision: 0.2967898243488615, recall: 0.8626760563378763, f1: 0.44164037851076604\n",
            "epoch: 353, step: 12, Train: label_loss: 0.10712043941020966, precision: 0.32691149909690986, recall: 0.8843648208467615, f1: 0.4773626373231855\n",
            "epoch: 353, step: 13, Train: label_loss: 0.09933016449213028, precision: 0.32244404113730657, recall: 0.8883333333331852, f1: 0.47314691518502566\n",
            "epoch: 353, step: 14, Train: label_loss: 0.11179454624652863, precision: 0.31884944920438685, recall: 0.8540983606555976, f1: 0.4643493760744523\n",
            "epoch: 353, step: 15, Train: label_loss: 0.10577493906021118, precision: 0.3370165745856147, recall: 0.8632075471696755, f1: 0.4847682118800971\n",
            "epoch: 353, step: 16, Train: label_loss: 0.10539016127586365, precision: 0.32171253822628, recall: 0.8429487179485828, f1: 0.4656927843778575\n",
            "epoch: 353, step: 17, Train: label_loss: 0.10597197711467743, precision: 0.330269607843117, recall: 0.8528481012656878, f1: 0.47614840985370566\n",
            "epoch: 353, step: 18, Train: label_loss: 0.11015062034130096, precision: 0.3206060606060412, recall: 0.8700657894735411, f1: 0.4685562444247338\n",
            "epoch: 353, step: 19, Train: label_loss: 0.098958820104599, precision: 0.3226392251815785, recall: 0.8853820598005173, f1: 0.47293700084811974\n",
            "epoch: 353, step: 20, Train: label_loss: 0.11008820682764053, precision: 0.319877675840959, recall: 0.8658940397349559, f1: 0.46717284498065825\n",
            "epoch: 353, step: 21, Train: label_loss: 0.08469723165035248, precision: 0.324471299093636, recall: 0.8935108153076715, f1: 0.47606382974810557\n",
            "epoch: 353, step: 22, Train: label_loss: 0.10152541100978851, precision: 0.316207951070317, recall: 0.8588039867108207, f1: 0.4622261957585643\n",
            "epoch: 353, step: 23, Train: label_loss: 0.11285175383090973, precision: 0.3237518910741056, recall: 0.8458498023713743, f1: 0.46827133475203453\n",
            "epoch: 354, step: 0, Train: label_loss: 0.10275541245937347, precision: 0.3251833740831097, recall: 0.85668276972611, f1: 0.47142224187411547\n",
            "epoch: 354, step: 1, Train: label_loss: 0.10701535642147064, precision: 0.3393939393939188, recall: 0.8695652173911692, f1: 0.48823016560909355\n",
            "epoch: 354, step: 2, Train: label_loss: 0.10218136012554169, precision: 0.3142509135200783, recall: 0.8528925619833301, f1: 0.45927903867889946\n",
            "epoch: 354, step: 3, Train: label_loss: 0.10176697373390198, precision: 0.3171619163128977, recall: 0.8819561551431901, f1: 0.4665477252063675\n",
            "epoch: 354, step: 4, Train: label_loss: 0.12595252692699432, precision: 0.3058676654182081, recall: 0.8419243986252848, f1: 0.44871794867881354\n",
            "epoch: 354, step: 5, Train: label_loss: 0.12788785994052887, precision: 0.29819089207733634, recall: 0.8020134228186573, f1: 0.43474306499000454\n",
            "epoch: 354, step: 6, Train: label_loss: 0.11285675317049026, precision: 0.2998102466792979, recall: 0.7860696517411632, f1: 0.4340659340259207\n",
            "epoch: 354, step: 7, Train: label_loss: 0.10314078629016876, precision: 0.3041079092581052, recall: 0.8280467445741522, f1: 0.4448430492880226\n",
            "epoch: 354, step: 8, Train: label_loss: 0.10965079069137573, precision: 0.32539682539680553, recall: 0.8527999999998634, f1: 0.47105612015440945\n",
            "epoch: 354, step: 9, Train: label_loss: 0.10921137034893036, precision: 0.3028083028082843, recall: 0.8522336769757985, f1: 0.44684684680811987\n",
            "epoch: 354, step: 10, Train: label_loss: 0.09468528628349304, precision: 0.32645631067959185, recall: 0.8649517684886069, f1: 0.4740088105328599\n",
            "epoch: 354, step: 11, Train: label_loss: 0.11782404780387878, precision: 0.3150517976843196, recall: 0.8837606837605326, f1: 0.4645103323960715\n",
            "epoch: 354, step: 12, Train: label_loss: 0.10606689751148224, precision: 0.29726443768995153, recall: 0.8489583333331859, f1: 0.4403421881650555\n",
            "epoch: 354, step: 13, Train: label_loss: 0.12082605063915253, precision: 0.31068560840022785, recall: 0.8598290598289128, f1: 0.4564428311769344\n",
            "epoch: 354, step: 14, Train: label_loss: 0.09912076592445374, precision: 0.31954436450837415, recall: 0.9018612521149065, f1: 0.4718902168714605\n",
            "epoch: 354, step: 15, Train: label_loss: 0.11294569075107574, precision: 0.3182651191203226, recall: 0.8771043771042294, f1: 0.46705513218858663\n",
            "epoch: 354, step: 16, Train: label_loss: 0.10018175095319748, precision: 0.3112462006078838, recall: 0.8737201365186221, f1: 0.4589870013059131\n",
            "epoch: 354, step: 17, Train: label_loss: 0.09305620193481445, precision: 0.3217286914765713, recall: 0.8758169934639091, f1: 0.47058823525478016\n",
            "epoch: 354, step: 18, Train: label_loss: 0.11074547469615936, precision: 0.29895641497849607, recall: 0.8528896672502884, f1: 0.44272727268879614\n",
            "epoch: 354, step: 19, Train: label_loss: 0.10961416363716125, precision: 0.33516148689821235, recall: 0.8661417322833281, f1: 0.48330404213898776\n",
            "epoch: 354, step: 20, Train: label_loss: 0.09662854671478271, precision: 0.30479659987854857, recall: 0.8595890410957432, f1: 0.4500224114359858\n",
            "epoch: 354, step: 21, Train: label_loss: 0.11866168677806854, precision: 0.3172541743970119, recall: 0.8621848739494349, f1: 0.46383363468034217\n",
            "epoch: 354, step: 22, Train: label_loss: 0.10659760236740112, precision: 0.32987804878046767, recall: 0.8754045307441949, f1: 0.47918511953504545\n",
            "epoch: 354, step: 23, Train: label_loss: 0.10594602674245834, precision: 0.3301258327164818, recall: 0.8660194174755599, f1: 0.47802786705537587\n",
            "epoch: 355, step: 0, Train: label_loss: 0.1217011958360672, precision: 0.29107692307690514, recall: 0.8476702508959054, f1: 0.4333486028020337\n",
            "epoch: 355, step: 1, Train: label_loss: 0.1107863336801529, precision: 0.31575720416920194, recall: 0.854063018241981, f1: 0.46105640103485235\n",
            "epoch: 355, step: 2, Train: label_loss: 0.10891686379909515, precision: 0.31249999999998085, recall: 0.8542713567837764, f1: 0.45760430682480385\n",
            "epoch: 355, step: 3, Train: label_loss: 0.09994717687368393, precision: 0.321559074299615, recall: 0.8502415458935828, f1: 0.4666372072071537\n",
            "epoch: 355, step: 4, Train: label_loss: 0.09969266504049301, precision: 0.3159490600363665, recall: 0.8597359735972178, f1: 0.462084257166864\n",
            "epoch: 355, step: 5, Train: label_loss: 0.11256255209445953, precision: 0.3157262905161875, recall: 0.8723051409617126, f1: 0.46364037016807286\n",
            "epoch: 355, step: 6, Train: label_loss: 0.0980755016207695, precision: 0.29509202453985917, recall: 0.8180272108842146, f1: 0.4337240757049095\n",
            "epoch: 355, step: 7, Train: label_loss: 0.10769994556903839, precision: 0.3086797066014481, recall: 0.8473154362414685, f1: 0.45250896053429157\n",
            "epoch: 355, step: 8, Train: label_loss: 0.11879304051399231, precision: 0.30905752753976073, recall: 0.8473154362414685, f1: 0.45291479816707053\n",
            "epoch: 355, step: 9, Train: label_loss: 0.11313867568969727, precision: 0.29404542664209365, recall: 0.837412587412441, f1: 0.4352567014608102\n",
            "epoch: 355, step: 10, Train: label_loss: 0.10731697082519531, precision: 0.2878048780487629, recall: 0.8597449908923752, f1: 0.43124714477736475\n",
            "epoch: 355, step: 11, Train: label_loss: 0.10338450968265533, precision: 0.3335365853658333, recall: 0.8908794788272164, f1: 0.4853593610960755\n",
            "epoch: 355, step: 12, Train: label_loss: 0.10684618353843689, precision: 0.31653349723415386, recall: 0.8684654300167169, f1: 0.4639639639247691\n",
            "epoch: 355, step: 13, Train: label_loss: 0.11834576725959778, precision: 0.34117647058821415, recall: 0.841221374045673, f1: 0.48546255502497904\n",
            "epoch: 355, step: 14, Train: label_loss: 0.12290102243423462, precision: 0.3253086419752885, recall: 0.859706362153204, f1: 0.47201074783294283\n",
            "epoch: 355, step: 15, Train: label_loss: 0.10421805083751678, precision: 0.3222691611345611, recall: 0.8899999999998516, f1: 0.47319450594231544\n",
            "epoch: 355, step: 16, Train: label_loss: 0.11510638892650604, precision: 0.3311218335343588, recall: 0.8926829268291231, f1: 0.48306203251657864\n",
            "epoch: 355, step: 17, Train: label_loss: 0.1136864498257637, precision: 0.32303891290918324, recall: 0.844911147011172, f1: 0.46738159066592844\n",
            "epoch: 355, step: 18, Train: label_loss: 0.11286783218383789, precision: 0.317538461538442, recall: 0.8486842105261762, f1: 0.4621585310843784\n",
            "epoch: 355, step: 19, Train: label_loss: 0.10479279607534409, precision: 0.3263803680981395, recall: 0.8608414239480807, f1: 0.4733096085010161\n",
            "epoch: 355, step: 20, Train: label_loss: 0.11235484480857849, precision: 0.32045866022931074, recall: 0.8924369747897659, f1: 0.47158081701258725\n",
            "epoch: 355, step: 21, Train: label_loss: 0.10720595717430115, precision: 0.322796352583567, recall: 0.8455414012737507, f1: 0.467223933087993\n",
            "epoch: 355, step: 22, Train: label_loss: 0.11468429863452911, precision: 0.30208333333331483, recall: 0.8427350427348986, f1: 0.44474515106620843\n",
            "epoch: 355, step: 23, Train: label_loss: 0.1133311539888382, precision: 0.3093093093092861, recall: 0.8459958932236457, f1: 0.4529961516924608\n",
            "epoch: 356, step: 0, Train: label_loss: 0.12021574378013611, precision: 0.29199755650578546, recall: 0.8313043478259423, f1: 0.4321880650609436\n",
            "epoch: 356, step: 1, Train: label_loss: 0.10055971890687943, precision: 0.31569230769228823, recall: 0.8479338842973805, f1: 0.4600896860590741\n",
            "epoch: 356, step: 2, Train: label_loss: 0.10861445963382721, precision: 0.32492307692305694, recall: 0.8543689320386967, f1: 0.4707980383015429\n",
            "epoch: 356, step: 3, Train: label_loss: 0.10577300190925598, precision: 0.29956763434216804, recall: 0.8290598290596872, f1: 0.44010889288292504\n",
            "epoch: 356, step: 4, Train: label_loss: 0.1051902025938034, precision: 0.3280584297017451, recall: 0.8923841059601171, f1: 0.4797507787768471\n",
            "epoch: 356, step: 5, Train: label_loss: 0.097621850669384, precision: 0.311711711711693, recall: 0.876689189189041, f1: 0.4599025254375559\n",
            "epoch: 356, step: 6, Train: label_loss: 0.1034136414527893, precision: 0.31820968730838023, recall: 0.8606965174127925, f1: 0.4646374216257204\n",
            "epoch: 356, step: 7, Train: label_loss: 0.10887940973043442, precision: 0.31407498463427697, recall: 0.855946398659823, f1: 0.4595323740614025\n",
            "epoch: 356, step: 8, Train: label_loss: 0.1030411645770073, precision: 0.32579462102687495, recall: 0.8638573743920803, f1: 0.4731469151843317\n",
            "epoch: 356, step: 9, Train: label_loss: 0.10679523646831512, precision: 0.3051869722557114, recall: 0.8709122203096608, f1: 0.4519874943786791\n",
            "epoch: 356, step: 10, Train: label_loss: 0.1105673611164093, precision: 0.3153374233128641, recall: 0.8638655462183421, f1: 0.46202247187088996\n",
            "epoch: 356, step: 11, Train: label_loss: 0.10068012028932571, precision: 0.31598062953993244, recall: 0.8685524126454461, f1: 0.4633821570846744\n",
            "epoch: 356, step: 12, Train: label_loss: 0.11537548899650574, precision: 0.3239436619718111, recall: 0.8477564102562744, f1: 0.46876384577297736\n",
            "epoch: 356, step: 13, Train: label_loss: 0.09535907208919525, precision: 0.3363255535607219, recall: 0.897763578274617, f1: 0.4893339137609154\n",
            "epoch: 356, step: 14, Train: label_loss: 0.11278524249792099, precision: 0.3144615384615191, recall: 0.8446280991734141, f1: 0.4582959640859801\n",
            "epoch: 356, step: 15, Train: label_loss: 0.09702792018651962, precision: 0.31223371880704126, recall: 0.8507462686565753, f1: 0.45681211037920166\n",
            "epoch: 356, step: 16, Train: label_loss: 0.09444320201873779, precision: 0.3379769836462545, recall: 0.8801261829651608, f1: 0.48840262578043075\n",
            "epoch: 356, step: 17, Train: label_loss: 0.11064359545707703, precision: 0.3119321623258442, recall: 0.8864027538724808, f1: 0.4614695340116286\n",
            "epoch: 356, step: 18, Train: label_loss: 0.12194287031888962, precision: 0.3176178660049431, recall: 0.8393442622949443, f1: 0.4608460845685869\n",
            "epoch: 356, step: 19, Train: label_loss: 0.11662684381008148, precision: 0.3155015197568197, recall: 0.869346733668196, f1: 0.46297948256570076\n",
            "epoch: 356, step: 20, Train: label_loss: 0.10424013435840607, precision: 0.31143552311433625, recall: 0.8663282571910547, f1: 0.45816554805949167\n",
            "epoch: 356, step: 21, Train: label_loss: 0.13045692443847656, precision: 0.3061480552070071, recall: 0.8106312292357457, f1: 0.4444444444046069\n",
            "epoch: 356, step: 22, Train: label_loss: 0.0972776859998703, precision: 0.3142685129439907, recall: 0.8656716417909012, f1: 0.4611307420103484\n",
            "epoch: 356, step: 23, Train: label_loss: 0.1091289147734642, precision: 0.30803906836962375, recall: 0.8723404255317293, f1: 0.4553026096226762\n",
            "epoch: 357, step: 0, Train: label_loss: 0.10888173431158066, precision: 0.29833230389127247, recall: 0.8429319371726277, f1: 0.4406934306182796\n",
            "epoch: 357, step: 1, Train: label_loss: 0.1015370562672615, precision: 0.30699638118212863, recall: 0.8641765704582572, f1: 0.45304850908455174\n",
            "epoch: 357, step: 2, Train: label_loss: 0.09674485772848129, precision: 0.3313325330131854, recall: 0.8817891373800508, f1: 0.4816753926304096\n",
            "epoch: 357, step: 3, Train: label_loss: 0.10927322506904602, precision: 0.3111653447223727, recall: 0.858585858585714, f1: 0.45678459467653854\n",
            "epoch: 357, step: 4, Train: label_loss: 0.10043225437402725, precision: 0.3264936632468119, recall: 0.8971807628522558, f1: 0.4787610619077353\n",
            "epoch: 357, step: 5, Train: label_loss: 0.11052466183900833, precision: 0.29728059332507434, recall: 0.848324514991032, f1: 0.44027459950386216\n",
            "epoch: 357, step: 6, Train: label_loss: 0.09059491008520126, precision: 0.32824893227575785, recall: 0.8566878980890354, f1: 0.4746360828888833\n",
            "epoch: 357, step: 7, Train: label_loss: 0.09746783971786499, precision: 0.3393829401088724, recall: 0.8738317757007984, f1: 0.4888888888485492\n",
            "epoch: 357, step: 8, Train: label_loss: 0.11446548998355865, precision: 0.3067484662576499, recall: 0.8389261744965034, f1: 0.44923629825365013\n",
            "epoch: 357, step: 9, Train: label_loss: 0.10303690284490585, precision: 0.3284760170005872, recall: 0.8573692551504187, f1: 0.47497805088176553\n",
            "epoch: 357, step: 10, Train: label_loss: 0.11881943047046661, precision: 0.3006736068585241, recall: 0.8539130434781123, f1: 0.44474637677303386\n",
            "epoch: 357, step: 11, Train: label_loss: 0.10813167691230774, precision: 0.3224212476837355, recall: 0.8599670510706985, f1: 0.46900269537808187\n",
            "epoch: 357, step: 12, Train: label_loss: 0.10732165724039078, precision: 0.30121951219510357, recall: 0.8487972508589606, f1: 0.4446444644077404\n",
            "epoch: 357, step: 13, Train: label_loss: 0.1291317343711853, precision: 0.3120743034055534, recall: 0.842809364548354, f1: 0.45549028464194635\n",
            "epoch: 357, step: 14, Train: label_loss: 0.10550510883331299, precision: 0.3143028846153657, recall: 0.8731218697828258, f1: 0.46221829426063527\n",
            "epoch: 357, step: 15, Train: label_loss: 0.11002103984355927, precision: 0.29036218538979186, recall: 0.8342151675483537, f1: 0.4307832422203066\n",
            "epoch: 357, step: 16, Train: label_loss: 0.10868322849273682, precision: 0.31507692307690366, recall: 0.8338762214982355, f1: 0.4573470298842268\n",
            "epoch: 357, step: 17, Train: label_loss: 0.1044563353061676, precision: 0.3226586102718838, recall: 0.8870431893686234, f1: 0.4731945059422327\n",
            "epoch: 357, step: 18, Train: label_loss: 0.114906907081604, precision: 0.30890369473044765, recall: 0.8717948717947227, f1: 0.4561717352028261\n",
            "epoch: 357, step: 19, Train: label_loss: 0.10254281759262085, precision: 0.3230115361262706, recall: 0.8678629690047523, f1: 0.4707964601374157\n",
            "epoch: 357, step: 20, Train: label_loss: 0.09802564978599548, precision: 0.3162650602409448, recall: 0.883838383838235, f1: 0.46583850927791226\n",
            "epoch: 357, step: 21, Train: label_loss: 0.0939793810248375, precision: 0.3152238805969961, recall: 0.8741721854303188, f1: 0.4633611232606945\n",
            "epoch: 357, step: 22, Train: label_loss: 0.10574677586555481, precision: 0.3276801938219063, recall: 0.8754045307441949, f1: 0.47686205372850116\n",
            "epoch: 357, step: 23, Train: label_loss: 0.11561411619186401, precision: 0.32169954476477075, recall: 0.8281249999998382, f1: 0.4633879781017251\n",
            "epoch: 358, step: 0, Train: label_loss: 0.11625802516937256, precision: 0.32591218305502, recall: 0.8513731825523665, f1: 0.47137745970947126\n",
            "epoch: 358, step: 1, Train: label_loss: 0.10836326330900192, precision: 0.3098847786537107, recall: 0.8646362098137285, f1: 0.4562499999611136\n",
            "epoch: 358, step: 2, Train: label_loss: 0.12683580815792084, precision: 0.2933579335793177, recall: 0.842756183745434, f1: 0.43521897806384235\n",
            "epoch: 358, step: 3, Train: label_loss: 0.08875709027051926, precision: 0.339199029126193, recall: 0.8873015873014464, f1: 0.4907813871416805\n",
            "epoch: 358, step: 4, Train: label_loss: 0.10412944108247757, precision: 0.3235831809871832, recall: 0.873355263157751, f1: 0.47220987101430817\n",
            "epoch: 358, step: 5, Train: label_loss: 0.10387483239173889, precision: 0.3343446601941545, recall: 0.8830128205126789, f1: 0.48503521122771964\n",
            "epoch: 358, step: 6, Train: label_loss: 0.10435046255588531, precision: 0.324770642201815, recall: 0.8592233009707347, f1: 0.47137150462059896\n",
            "epoch: 358, step: 7, Train: label_loss: 0.10967271029949188, precision: 0.30572851805726614, recall: 0.8407534246573902, f1: 0.44840182644486615\n",
            "epoch: 358, step: 8, Train: label_loss: 0.10612328350543976, precision: 0.32002419842708285, recall: 0.8700657894735411, f1: 0.46793454219858716\n",
            "epoch: 358, step: 9, Train: label_loss: 0.11904723197221756, precision: 0.307111390811812, recall: 0.8133333333331977, f1: 0.44586569205701343\n",
            "epoch: 358, step: 10, Train: label_loss: 0.10331346839666367, precision: 0.31607795371496245, recall: 0.8550247116967289, f1: 0.46153846149900984\n",
            "epoch: 358, step: 11, Train: label_loss: 0.116427943110466, precision: 0.30195599022003045, recall: 0.8712522045853842, f1: 0.4484793463076245\n",
            "epoch: 358, step: 12, Train: label_loss: 0.10335703194141388, precision: 0.32347504621070094, recall: 0.8495145631066586, f1: 0.46854082994662716\n",
            "epoch: 358, step: 13, Train: label_loss: 0.11189894378185272, precision: 0.32338611449449917, recall: 0.874794069192607, f1: 0.4722098710143491\n",
            "epoch: 358, step: 14, Train: label_loss: 0.09313870966434479, precision: 0.3341331733653069, recall: 0.8813291139239111, f1: 0.4845585036573513\n",
            "epoch: 358, step: 15, Train: label_loss: 0.10458872467279434, precision: 0.2982349360924955, recall: 0.8419243986252848, f1: 0.44044943816357707\n",
            "epoch: 358, step: 16, Train: label_loss: 0.10139406472444534, precision: 0.31801692865778003, recall: 0.8665568369026578, f1: 0.46528084914245843\n",
            "epoch: 358, step: 17, Train: label_loss: 0.11544102430343628, precision: 0.30601092896173004, recall: 0.874999999999848, f1: 0.45344129550812357\n",
            "epoch: 358, step: 18, Train: label_loss: 0.12954764068126678, precision: 0.31085223789084543, recall: 0.840796019900358, f1: 0.45389435985311616\n",
            "epoch: 358, step: 19, Train: label_loss: 0.10035627335309982, precision: 0.2970838396111606, recall: 0.8344709897609497, f1: 0.4381720429719904\n",
            "epoch: 358, step: 20, Train: label_loss: 0.10422816127538681, precision: 0.30829800121136836, recall: 0.8760757314972674, f1: 0.4560931899256076\n",
            "epoch: 358, step: 21, Train: label_loss: 0.1185663640499115, precision: 0.31038721573446154, recall: 0.8402662229615906, f1: 0.45332136441298615\n",
            "epoch: 358, step: 22, Train: label_loss: 0.09814879298210144, precision: 0.3258631132646683, recall: 0.8733766233764816, f1: 0.47463608288936115\n",
            "epoch: 358, step: 23, Train: label_loss: 0.12050358206033707, precision: 0.3096139288417631, recall: 0.8381147540981889, f1: 0.45218352677094437\n",
            "epoch: 359, step: 0, Train: label_loss: 0.10746606439352036, precision: 0.3251833740831097, recall: 0.8764415156505969, f1: 0.4743646901076051\n",
            "epoch: 359, step: 1, Train: label_loss: 0.10162635892629623, precision: 0.3193430656934112, recall: 0.8706467661690098, f1: 0.4672897195868583\n",
            "epoch: 359, step: 2, Train: label_loss: 0.11057925224304199, precision: 0.30540376442013933, recall: 0.8583617747438808, f1: 0.45051500220038804\n",
            "epoch: 359, step: 3, Train: label_loss: 0.10420580953359604, precision: 0.31146535867564, recall: 0.8396694214874645, f1: 0.4543828264363365\n",
            "epoch: 359, step: 4, Train: label_loss: 0.10130524635314941, precision: 0.3388480392156655, recall: 0.860031104198933, f1: 0.4861538461132527\n",
            "epoch: 359, step: 5, Train: label_loss: 0.10634105652570724, precision: 0.30629539951571993, recall: 0.8892794376096854, f1: 0.45565060779615635\n",
            "epoch: 359, step: 6, Train: label_loss: 0.10861513763666153, precision: 0.303945745992583, recall: 0.8618881118879611, f1: 0.44940747489304267\n",
            "epoch: 359, step: 7, Train: label_loss: 0.11352464556694031, precision: 0.3260738052026421, recall: 0.8764227642274997, f1: 0.47530864193573996\n",
            "epoch: 359, step: 8, Train: label_loss: 0.12519243359565735, precision: 0.30320150659131806, recall: 0.8145025295108238, f1: 0.4419030191735976\n",
            "epoch: 359, step: 9, Train: label_loss: 0.11130877584218979, precision: 0.31288723667903884, recall: 0.8388704318935483, f1: 0.4557761732455852\n",
            "epoch: 359, step: 10, Train: label_loss: 0.10568646341562271, precision: 0.3162650602409448, recall: 0.8853288364248085, f1: 0.4660452729305472\n",
            "epoch: 359, step: 11, Train: label_loss: 0.1042134240269661, precision: 0.31496062992124074, recall: 0.8595041322312629, f1: 0.4609929077621262\n",
            "epoch: 359, step: 12, Train: label_loss: 0.10853761434555054, precision: 0.32515337423310886, recall: 0.8520900321542038, f1: 0.47069271754434505\n",
            "epoch: 359, step: 13, Train: label_loss: 0.12260495126247406, precision: 0.3103879849812071, recall: 0.8252911813642553, f1: 0.45111414275241524\n",
            "epoch: 359, step: 14, Train: label_loss: 0.1107633039355278, precision: 0.3071342200725328, recall: 0.8523489932884475, f1: 0.45155555551657084\n",
            "epoch: 359, step: 15, Train: label_loss: 0.11986080557107925, precision: 0.32089552238803976, recall: 0.8242811501596127, f1: 0.46195165618164297\n",
            "epoch: 359, step: 16, Train: label_loss: 0.10522681474685669, precision: 0.31234718826403957, recall: 0.8474295190711695, f1: 0.456453773966855\n",
            "epoch: 359, step: 17, Train: label_loss: 0.10782517492771149, precision: 0.3302411873840241, recall: 0.847619047618913, f1: 0.4753004004936502\n",
            "epoch: 359, step: 18, Train: label_loss: 0.11649122834205627, precision: 0.2998149290561197, recall: 0.8279386712093989, f1: 0.440217391265273\n",
            "epoch: 359, step: 19, Train: label_loss: 0.11313172429800034, precision: 0.29227941176468797, recall: 0.8457446808509138, f1: 0.43442622946998344\n",
            "epoch: 359, step: 20, Train: label_loss: 0.12682315707206726, precision: 0.3034482758620499, recall: 0.8203389830507084, f1: 0.4430205949262123\n",
            "epoch: 359, step: 21, Train: label_loss: 0.11969274282455444, precision: 0.31265356265354344, recall: 0.8511705685617305, f1: 0.4573225516228383\n",
            "epoch: 359, step: 22, Train: label_loss: 0.11124512553215027, precision: 0.3147239263803488, recall: 0.8423645320195661, f1: 0.4582402858022499\n",
            "epoch: 359, step: 23, Train: label_loss: 0.13558804988861084, precision: 0.3171874999999752, recall: 0.8119999999998376, f1: 0.45617977524044867\n",
            "epoch: 360, step: 0, Train: label_loss: 0.11876651644706726, precision: 0.308943089430875, recall: 0.8019480519479217, f1: 0.44604966135935586\n",
            "epoch: 360, step: 1, Train: label_loss: 0.12002820521593094, precision: 0.3205918618988705, recall: 0.822784810126452, f1: 0.4614019520447866\n",
            "epoch: 360, step: 2, Train: label_loss: 0.13409052789211273, precision: 0.2977243994942922, recall: 0.814878892733423, f1: 0.43611111107187334\n",
            "epoch: 360, step: 3, Train: label_loss: 0.10422363132238388, precision: 0.3286153846153644, recall: 0.847619047618913, f1: 0.47361419064705407\n",
            "epoch: 360, step: 4, Train: label_loss: 0.12447552382946014, precision: 0.301538461538443, recall: 0.8139534883719578, f1: 0.4400538841095906\n",
            "epoch: 360, step: 5, Train: label_loss: 0.09433965384960175, precision: 0.32214765100669174, recall: 0.8502415458935828, f1: 0.46725663712824506\n",
            "epoch: 360, step: 6, Train: label_loss: 0.1130611002445221, precision: 0.3031618102913637, recall: 0.8218487394956602, f1: 0.44293478256928387\n",
            "epoch: 360, step: 7, Train: label_loss: 0.10890322923660278, precision: 0.301242236024826, recall: 0.8069883527452899, f1: 0.4387155133027522\n",
            "epoch: 360, step: 8, Train: label_loss: 0.09647972881793976, precision: 0.3264936632468119, recall: 0.9016666666665163, f1: 0.47939743017802605\n",
            "epoch: 360, step: 9, Train: label_loss: 0.11334086954593658, precision: 0.3037897310513262, recall: 0.8466780238499408, f1: 0.4471434997361723\n",
            "epoch: 360, step: 10, Train: label_loss: 0.11771021783351898, precision: 0.2858903265557433, recall: 0.8285714285712805, f1: 0.4251030691326825\n",
            "epoch: 360, step: 11, Train: label_loss: 0.1264931708574295, precision: 0.3099814011159138, recall: 0.8375209380233103, f1: 0.452488687743332\n",
            "epoch: 360, step: 12, Train: label_loss: 0.11697946488857269, precision: 0.31196054254005473, recall: 0.8363636363634981, f1: 0.4544229905306604\n",
            "epoch: 360, step: 13, Train: label_loss: 0.10270006954669952, precision: 0.3286240786240584, recall: 0.8615136876005053, f1: 0.4757670075188969\n",
            "epoch: 360, step: 14, Train: label_loss: 0.11991388350725174, precision: 0.3202979515828479, recall: 0.8255999999998679, f1: 0.4615384614981427\n",
            "epoch: 360, step: 15, Train: label_loss: 0.11589460074901581, precision: 0.30340557275539914, recall: 0.8390410958902672, f1: 0.44565711683225545\n",
            "epoch: 360, step: 16, Train: label_loss: 0.09214076399803162, precision: 0.32329921733893296, recall: 0.8689320388348107, f1: 0.47125932422545963\n",
            "epoch: 360, step: 17, Train: label_loss: 0.12256897985935211, precision: 0.2998149290561197, recall: 0.8321917808217753, f1: 0.4408163264916311\n",
            "epoch: 360, step: 18, Train: label_loss: 0.10906313359737396, precision: 0.30688806888066994, recall: 0.8400673400671986, f1: 0.449549549510314\n",
            "epoch: 360, step: 19, Train: label_loss: 0.13284499943256378, precision: 0.3252788104089018, recall: 0.8373205741625458, f1: 0.4685408299462702\n",
            "epoch: 360, step: 20, Train: label_loss: 0.11436168104410172, precision: 0.3075980392156674, recall: 0.8422818791944895, f1: 0.45062836620852625\n",
            "epoch: 360, step: 21, Train: label_loss: 0.1400810182094574, precision: 0.28727506426733374, recall: 0.7706896551722808, f1: 0.4185393258030966\n",
            "epoch: 360, step: 22, Train: label_loss: 0.11361299455165863, precision: 0.31990080595162307, recall: 0.8557213930346839, f1: 0.46570397107947814\n",
            "epoch: 360, step: 23, Train: label_loss: 0.10269699990749359, precision: 0.29548872180448904, recall: 0.8488120950322141, f1: 0.4383714444680558\n",
            "epoch: 361, step: 0, Train: label_loss: 0.10608566552400589, precision: 0.32450738916254157, recall: 0.8405103668260222, f1: 0.46823633936447606\n",
            "epoch: 361, step: 1, Train: label_loss: 0.10022059082984924, precision: 0.3235653235653038, recall: 0.850722311396332, f1: 0.4688191065500393\n",
            "epoch: 361, step: 2, Train: label_loss: 0.13153520226478577, precision: 0.3043209876543022, recall: 0.8327702702701295, f1: 0.44575045204032476\n",
            "epoch: 361, step: 3, Train: label_loss: 0.10271121561527252, precision: 0.33621221468227414, recall: 0.8515624999998669, f1: 0.4820875718302234\n",
            "epoch: 361, step: 4, Train: label_loss: 0.11292815953493118, precision: 0.315952824332693, recall: 0.8357963875203881, f1: 0.4585585585187032\n",
            "epoch: 361, step: 5, Train: label_loss: 0.11604216694831848, precision: 0.3057442865966457, recall: 0.8319327731091039, f1: 0.4471544715053709\n",
            "epoch: 361, step: 6, Train: label_loss: 0.1133783608675003, precision: 0.2898284313725312, recall: 0.8342151675483537, f1: 0.43019554339052\n",
            "epoch: 361, step: 7, Train: label_loss: 0.11357258260250092, precision: 0.3094801223241401, recall: 0.8620102214649298, f1: 0.455445544515537\n",
            "epoch: 361, step: 8, Train: label_loss: 0.1182238757610321, precision: 0.3069245165314843, recall: 0.8410256410254972, f1: 0.4497257769260475\n",
            "epoch: 361, step: 9, Train: label_loss: 0.12273270636796951, precision: 0.3023690773067143, recall: 0.8137583892616084, f1: 0.4409090908695473\n",
            "epoch: 361, step: 10, Train: label_loss: 0.13197961449623108, precision: 0.32620993086107314, recall: 0.8398058252425825, f1: 0.4698958804485671\n",
            "epoch: 361, step: 11, Train: label_loss: 0.11201851814985275, precision: 0.3047445255474267, recall: 0.8697916666665156, f1: 0.4513513513128827\n",
            "epoch: 361, step: 12, Train: label_loss: 0.11782573908567429, precision: 0.3024420788979147, recall: 0.8145025295108238, f1: 0.4410958903714273\n",
            "epoch: 361, step: 13, Train: label_loss: 0.09878373146057129, precision: 0.3207547169811125, recall: 0.8710743801651453, f1: 0.4688612099250315\n",
            "epoch: 361, step: 14, Train: label_loss: 0.10776032507419586, precision: 0.30006161429449785, recall: 0.8353344768437675, f1: 0.4415231187280719\n",
            "epoch: 361, step: 15, Train: label_loss: 0.1181057021021843, precision: 0.3143915997529145, recall: 0.8583473861718619, f1: 0.4602169981523972\n",
            "epoch: 361, step: 16, Train: label_loss: 0.1148023009300232, precision: 0.3086876155267832, recall: 0.8336106489183305, f1: 0.45053956830584174\n",
            "epoch: 361, step: 17, Train: label_loss: 0.10464838147163391, precision: 0.3317132442284124, recall: 0.8749999999998597, f1: 0.4810572686825595\n",
            "epoch: 361, step: 18, Train: label_loss: 0.10107778012752533, precision: 0.3163265306122259, recall: 0.8653530377666887, f1: 0.4632967032574559\n",
            "epoch: 361, step: 19, Train: label_loss: 0.11288326978683472, precision: 0.31426814268140746, recall: 0.8308943089429542, f1: 0.45604640781377226\n",
            "epoch: 361, step: 20, Train: label_loss: 0.11436930298805237, precision: 0.2905447714464439, recall: 0.7945205479450693, f1: 0.42549289312901883\n",
            "epoch: 361, step: 21, Train: label_loss: 0.11958624422550201, precision: 0.3133047210300237, recall: 0.855946398659823, f1: 0.4587073608224874\n",
            "epoch: 361, step: 22, Train: label_loss: 0.12149202823638916, precision: 0.3090684762492098, recall: 0.8280991735535821, f1: 0.45013477084986364\n",
            "epoch: 361, step: 23, Train: label_loss: 0.11066047847270966, precision: 0.31852409638551815, recall: 0.854545454545282, f1: 0.4640702138934661\n",
            "epoch: 362, step: 0, Train: label_loss: 0.11819291114807129, precision: 0.31611698817670714, recall: 0.8141025641024335, f1: 0.4554011653563491\n",
            "epoch: 362, step: 1, Train: label_loss: 0.11028340458869934, precision: 0.337492202121002, recall: 0.8184568835097097, f1: 0.4779151943049035\n",
            "epoch: 362, step: 2, Train: label_loss: 0.11059413850307465, precision: 0.2998768472906219, recall: 0.8396551724136483, f1: 0.4419237749158067\n",
            "epoch: 362, step: 3, Train: label_loss: 0.12119229137897491, precision: 0.3106200122774518, recall: 0.8489932885904615, f1: 0.4548314606348937\n",
            "epoch: 362, step: 4, Train: label_loss: 0.11180800944566727, precision: 0.3280196198650933, recall: 0.8784893267650445, f1: 0.47767857138893705\n",
            "epoch: 362, step: 5, Train: label_loss: 0.11468669772148132, precision: 0.28263546798027817, recall: 0.8611632270167239, f1: 0.4255910987110134\n",
            "epoch: 362, step: 6, Train: label_loss: 0.11507482826709747, precision: 0.2950519242516619, recall: 0.8734177215188293, f1: 0.4410958903731687\n",
            "epoch: 362, step: 7, Train: label_loss: 0.11450832337141037, precision: 0.31702786377707015, recall: 0.8663282571910547, f1: 0.464188576569979\n",
            "epoch: 362, step: 8, Train: label_loss: 0.1047365814447403, precision: 0.3117754728492793, recall: 0.8871527777776237, f1: 0.46139954849420534\n",
            "epoch: 362, step: 9, Train: label_loss: 0.10977979749441147, precision: 0.31176833025259937, recall: 0.8620102214649298, f1: 0.45791855199714526\n",
            "epoch: 362, step: 10, Train: label_loss: 0.11305619776248932, precision: 0.3249999999999802, recall: 0.8737704918031354, f1: 0.4737777777382136\n",
            "epoch: 362, step: 11, Train: label_loss: 0.09802976250648499, precision: 0.30579010856451716, recall: 0.8681506849313582, f1: 0.4522747546447519\n",
            "epoch: 362, step: 12, Train: label_loss: 0.11376223713159561, precision: 0.30280373831773816, recall: 0.8209459459458072, f1: 0.4424214838021918\n",
            "epoch: 362, step: 13, Train: label_loss: 0.10225740075111389, precision: 0.3192261185005853, recall: 0.8829431438125613, f1: 0.46891651861104133\n",
            "epoch: 362, step: 14, Train: label_loss: 0.10813601315021515, precision: 0.3219094247245825, recall: 0.8511326860840046, f1: 0.4671403196759437\n",
            "epoch: 362, step: 15, Train: label_loss: 0.10037344694137573, precision: 0.3214505224339077, recall: 0.831478537360758, f1: 0.46365248222924726\n",
            "epoch: 362, step: 16, Train: label_loss: 0.09778252243995667, precision: 0.29534313725488387, recall: 0.8183361629879764, f1: 0.4340387212577007\n",
            "epoch: 362, step: 17, Train: label_loss: 0.11378571391105652, precision: 0.31627056672758586, recall: 0.8494271685759657, f1: 0.4609236234062444\n",
            "epoch: 362, step: 18, Train: label_loss: 0.10972151160240173, precision: 0.3199505867819444, recall: 0.8491803278687132, f1: 0.46478241359860656\n",
            "epoch: 362, step: 19, Train: label_loss: 0.10791126638650894, precision: 0.3228200371057314, recall: 0.8312101910826701, f1: 0.46503340753204514\n",
            "epoch: 362, step: 20, Train: label_loss: 0.1146775633096695, precision: 0.31591737545563087, recall: 0.8768971332207627, f1: 0.4644930772276544\n",
            "epoch: 362, step: 21, Train: label_loss: 0.08897322416305542, precision: 0.3309395571513865, recall: 0.8977272727271269, f1: 0.4836029732881009\n",
            "epoch: 362, step: 22, Train: label_loss: 0.10096465796232224, precision: 0.334350213544824, recall: 0.8616352201256506, f1: 0.4817582417179181\n",
            "epoch: 362, step: 23, Train: label_loss: 0.11638450622558594, precision: 0.3080424886190965, recall: 0.8202020202018545, f1: 0.4478764478367017\n",
            "epoch: 363, step: 0, Train: label_loss: 0.10290935635566711, precision: 0.31848284166163043, recall: 0.8714991762766273, f1: 0.46649029978439055\n",
            "epoch: 363, step: 1, Train: label_loss: 0.09424208104610443, precision: 0.3168077388149748, recall: 0.8632619439866781, f1: 0.4635117204383453\n",
            "epoch: 363, step: 2, Train: label_loss: 0.11774498224258423, precision: 0.3226797787338462, recall: 0.8495145631066586, f1: 0.4677060133230873\n",
            "epoch: 363, step: 3, Train: label_loss: 0.11448433250188828, precision: 0.3319070904645274, recall: 0.84711388455525, f1: 0.4769433464680695\n",
            "epoch: 363, step: 4, Train: label_loss: 0.11817649751901627, precision: 0.3266457680250579, recall: 0.8256735340727692, f1: 0.4681042227805391\n",
            "epoch: 363, step: 5, Train: label_loss: 0.12852545082569122, precision: 0.32465057179159307, recall: 0.780152671755606, f1: 0.458501570169315\n",
            "epoch: 363, step: 6, Train: label_loss: 0.13819992542266846, precision: 0.3224755700325523, recall: 0.784469096671825, f1: 0.4570637118700246\n",
            "epoch: 363, step: 7, Train: label_loss: 0.11257793754339218, precision: 0.31426814268140746, recall: 0.855946398659823, f1: 0.4597390912787105\n",
            "epoch: 363, step: 8, Train: label_loss: 0.11351703107357025, precision: 0.2939024390243723, recall: 0.8546099290778626, f1: 0.43738656983483565\n",
            "epoch: 363, step: 9, Train: label_loss: 0.12004086375236511, precision: 0.29284833538839133, recall: 0.8620689655170849, f1: 0.4371836170812958\n",
            "epoch: 363, step: 10, Train: label_loss: 0.12754139304161072, precision: 0.2936708860759308, recall: 0.7891156462583692, f1: 0.42804428040323317\n",
            "epoch: 363, step: 11, Train: label_loss: 0.11760405451059341, precision: 0.2998149290561197, recall: 0.8293515358360359, f1: 0.4404168554208567\n",
            "epoch: 363, step: 12, Train: label_loss: 0.12125184386968613, precision: 0.31453634085211063, recall: 0.8465430016861978, f1: 0.45865692092893423\n",
            "epoch: 363, step: 13, Train: label_loss: 0.12670406699180603, precision: 0.3302639656230614, recall: 0.8485804416402446, f1: 0.4754750331014711\n",
            "epoch: 363, step: 14, Train: label_loss: 0.11118405312299728, precision: 0.29906542056072905, recall: 0.8205128205126802, f1: 0.4383561643443679\n",
            "epoch: 363, step: 15, Train: label_loss: 0.12689147889614105, precision: 0.27784730913640315, recall: 0.8117001828152081, f1: 0.41398601394797924\n",
            "epoch: 363, step: 16, Train: label_loss: 0.11521825194358826, precision: 0.3072660098521978, recall: 0.8429054054052629, f1: 0.4503610107911282\n",
            "epoch: 363, step: 17, Train: label_loss: 0.11883290112018585, precision: 0.2967101179391498, recall: 0.8284228769495964, f1: 0.43692870197209543\n",
            "epoch: 363, step: 18, Train: label_loss: 0.11419320106506348, precision: 0.2823674475955436, recall: 0.8077601410933319, f1: 0.418455915904929\n",
            "epoch: 363, step: 19, Train: label_loss: 0.11189799010753632, precision: 0.323656578134631, recall: 0.8317460317458997, f1: 0.4659848821294809\n",
            "epoch: 363, step: 20, Train: label_loss: 0.11577033996582031, precision: 0.3218673218673021, recall: 0.8520325203250646, f1: 0.4672313864960461\n",
            "epoch: 363, step: 21, Train: label_loss: 0.1259598582983017, precision: 0.29192546583849116, recall: 0.8245614035086272, f1: 0.4311926605117986\n",
            "epoch: 363, step: 22, Train: label_loss: 0.1190749853849411, precision: 0.31314984709478205, recall: 0.8366013071894057, f1: 0.455718736052891\n",
            "epoch: 363, step: 23, Train: label_loss: 0.11173002421855927, precision: 0.3300455235204605, recall: 0.8349328214969606, f1: 0.4730831973492255\n",
            "epoch: 364, step: 0, Train: label_loss: 0.11415416747331619, precision: 0.28474366893142156, recall: 0.8232142857141387, f1: 0.4231298760517206\n",
            "epoch: 364, step: 1, Train: label_loss: 0.12251333892345428, precision: 0.3345794392523156, recall: 0.84169278996852, f1: 0.47882300486339663\n",
            "epoch: 364, step: 2, Train: label_loss: 0.11941193044185638, precision: 0.3024420788979147, recall: 0.8076923076921726, f1: 0.4400911161334376\n",
            "epoch: 364, step: 3, Train: label_loss: 0.10527606308460236, precision: 0.3333333333333131, recall: 0.8755980861242622, f1: 0.4828496041816532\n",
            "epoch: 364, step: 4, Train: label_loss: 0.11231398582458496, precision: 0.3274173806609347, recall: 0.8842975206610107, f1: 0.47789191599446174\n",
            "epoch: 364, step: 5, Train: label_loss: 0.11523318290710449, precision: 0.3242236024844519, recall: 0.8557377049178925, f1: 0.47027027023037316\n",
            "epoch: 364, step: 6, Train: label_loss: 0.12336954474449158, precision: 0.3047559449311449, recall: 0.8184873949578456, f1: 0.44414044683684356\n",
            "epoch: 364, step: 7, Train: label_loss: 0.1174546480178833, precision: 0.3303030303030103, recall: 0.8650793650792277, f1: 0.4780701753985614\n",
            "epoch: 364, step: 8, Train: label_loss: 0.12062431871891022, precision: 0.3153988868274387, recall: 0.8557046979864336, f1: 0.4609127880310937\n",
            "epoch: 364, step: 9, Train: label_loss: 0.11153359711170197, precision: 0.31059683313030995, recall: 0.8747855917665738, f1: 0.4584269662534203\n",
            "epoch: 364, step: 10, Train: label_loss: 0.11958198249340057, precision: 0.32176069435831856, recall: 0.843902439024253, f1: 0.46588868936753086\n",
            "epoch: 364, step: 11, Train: label_loss: 0.12066729366779327, precision: 0.3105360443622729, recall: 0.8372093023254422, f1: 0.4530337078256562\n",
            "epoch: 364, step: 12, Train: label_loss: 0.10573284327983856, precision: 0.3157894736841912, recall: 0.8571428571427147, f1: 0.46153846149907113\n",
            "epoch: 364, step: 13, Train: label_loss: 0.12018060684204102, precision: 0.31874999999998005, recall: 0.8360655737703547, f1: 0.46153846149845335\n",
            "epoch: 364, step: 14, Train: label_loss: 0.11516821384429932, precision: 0.3039154754505715, recall: 0.8373287671231442, f1: 0.445964432245424\n",
            "epoch: 364, step: 15, Train: label_loss: 0.11959832906723022, precision: 0.30062111801240365, recall: 0.7882736156350507, f1: 0.43525179852114\n",
            "epoch: 364, step: 16, Train: label_loss: 0.1193602979183197, precision: 0.30339195979897593, recall: 0.8145025295108238, f1: 0.4421052631183062\n",
            "epoch: 364, step: 17, Train: label_loss: 0.10190854966640472, precision: 0.32309582309580326, recall: 0.8622950819670717, f1: 0.4700625558137439\n",
            "epoch: 364, step: 18, Train: label_loss: 0.1130109652876854, precision: 0.2988435788192149, recall: 0.8598949211907425, f1: 0.4435411020393695\n",
            "epoch: 364, step: 19, Train: label_loss: 0.11196395009756088, precision: 0.2993939393939212, recall: 0.8517241379308875, f1: 0.4430493273157317\n",
            "epoch: 364, step: 20, Train: label_loss: 0.12236455082893372, precision: 0.3001253132831892, recall: 0.8050420168065874, f1: 0.43724326787459095\n",
            "epoch: 364, step: 21, Train: label_loss: 0.12053588032722473, precision: 0.31351689612013056, recall: 0.8186274509802584, f1: 0.45339366511828266\n",
            "epoch: 364, step: 22, Train: label_loss: 0.10441221296787262, precision: 0.31359516616312305, recall: 0.876689189189041, f1: 0.46194926564873234\n",
            "epoch: 364, step: 23, Train: label_loss: 0.10760190337896347, precision: 0.3213213213212972, recall: 0.8611670020118992, f1: 0.4680153088723437\n",
            "epoch: 365, step: 0, Train: label_loss: 0.11550423502922058, precision: 0.31857318573183774, recall: 0.8561983471072965, f1: 0.4643657552271268\n",
            "epoch: 365, step: 1, Train: label_loss: 0.11352241784334183, precision: 0.33456108041741345, recall: 0.8678343949043203, f1: 0.48294195831158654\n",
            "epoch: 365, step: 2, Train: label_loss: 0.11988643556833267, precision: 0.29455909943712977, recall: 0.7956081081079737, f1: 0.4299406663229143\n",
            "epoch: 365, step: 3, Train: label_loss: 0.11729305982589722, precision: 0.3055040197897152, recall: 0.8473413379072302, f1: 0.4490909090519133\n",
            "epoch: 365, step: 4, Train: label_loss: 0.11378038674592972, precision: 0.3068322981366269, recall: 0.8401360544216258, f1: 0.4494995450017152\n",
            "epoch: 365, step: 5, Train: label_loss: 0.10485580563545227, precision: 0.33922046285016205, recall: 0.8649068322980022, f1: 0.4873140856987696\n",
            "epoch: 365, step: 6, Train: label_loss: 0.12237068265676498, precision: 0.29650436953805887, recall: 0.817555938037725, f1: 0.43518094361641746\n",
            "epoch: 365, step: 7, Train: label_loss: 0.10861892998218536, precision: 0.3080273802115552, recall: 0.8305369127515384, f1: 0.4493871992342073\n",
            "epoch: 365, step: 8, Train: label_loss: 0.10341866314411163, precision: 0.31391784181481824, recall: 0.8605042016805275, f1: 0.4600179694127206\n",
            "epoch: 365, step: 9, Train: label_loss: 0.1005050539970398, precision: 0.3132166566083094, recall: 0.869346733668196, f1: 0.46051464059988134\n",
            "epoch: 365, step: 10, Train: label_loss: 0.10599426925182343, precision: 0.29220380601594276, recall: 0.835087719298099, f1: 0.43292405635082454\n",
            "epoch: 365, step: 11, Train: label_loss: 0.10957245528697968, precision: 0.3199513381994939, recall: 0.8456591639870022, f1: 0.46425419236966187\n",
            "epoch: 365, step: 12, Train: label_loss: 0.11956663429737091, precision: 0.3134603564843077, recall: 0.8600337268126711, f1: 0.45945945942026495\n",
            "epoch: 365, step: 13, Train: label_loss: 0.11276125907897949, precision: 0.2881880024736989, recall: 0.8247787610618008, f1: 0.4271310723722155\n",
            "epoch: 365, step: 14, Train: label_loss: 0.10908107459545135, precision: 0.3009768009767826, recall: 0.8441780821916363, f1: 0.4437443743986541\n",
            "epoch: 365, step: 15, Train: label_loss: 0.12558168172836304, precision: 0.3087871287128522, recall: 0.850085178875494, f1: 0.453018610945888\n",
            "epoch: 365, step: 16, Train: label_loss: 0.12505696713924408, precision: 0.29236499068899485, recall: 0.8248686514884719, f1: 0.43171402379266643\n",
            "epoch: 365, step: 17, Train: label_loss: 0.10525280237197876, precision: 0.32044198895025655, recall: 0.8405797101447922, f1: 0.46399999995999386\n",
            "epoch: 365, step: 18, Train: label_loss: 0.10741231590509415, precision: 0.3388379204892759, recall: 0.8697017268444474, f1: 0.4876760562976327\n",
            "epoch: 365, step: 19, Train: label_loss: 0.10331986099481583, precision: 0.31582125603862826, recall: 0.8789915966385077, f1: 0.46468236335511415\n",
            "epoch: 365, step: 20, Train: label_loss: 0.1212678775191307, precision: 0.32193909260408193, recall: 0.8436482084689179, f1: 0.4660368870494937\n",
            "epoch: 365, step: 21, Train: label_loss: 0.12245406210422516, precision: 0.3147914032869586, recall: 0.790476190476065, f1: 0.45027124769882276\n",
            "epoch: 365, step: 22, Train: label_loss: 0.12406092882156372, precision: 0.3323076923076719, recall: 0.8585055643877808, f1: 0.47914818097125544\n",
            "epoch: 365, step: 23, Train: label_loss: 0.12708133459091187, precision: 0.3146322971948207, recall: 0.8434959349591782, f1: 0.45831032574723407\n",
            "epoch: 366, step: 0, Train: label_loss: 0.1198011189699173, precision: 0.32551143200960736, recall: 0.8754045307441949, f1: 0.47456140346921366\n",
            "epoch: 366, step: 1, Train: label_loss: 0.12471352517604828, precision: 0.2894248608534144, recall: 0.8432432432430912, f1: 0.43093922648125094\n",
            "epoch: 366, step: 2, Train: label_loss: 0.11160784959793091, precision: 0.2961586121437239, recall: 0.8415492957744997, f1: 0.43813015578179826\n",
            "epoch: 366, step: 3, Train: label_loss: 0.1212276965379715, precision: 0.3180975911056011, recall: 0.8470394736840712, f1: 0.4625056128924588\n",
            "epoch: 366, step: 4, Train: label_loss: 0.1239740401506424, precision: 0.32754342431759753, recall: 0.8367670364499465, f1: 0.4707980383010291\n",
            "epoch: 366, step: 5, Train: label_loss: 0.12217198312282562, precision: 0.30258302583023966, recall: 0.8482758620688192, f1: 0.4460562102966497\n",
            "epoch: 366, step: 6, Train: label_loss: 0.12754730880260468, precision: 0.313967861557459, recall: 0.8341543513955937, f1: 0.4562191288331462\n",
            "epoch: 366, step: 7, Train: label_loss: 0.14104890823364258, precision: 0.32239747634067367, recall: 0.8162939297123296, f1: 0.46223428308917025\n",
            "epoch: 366, step: 8, Train: label_loss: 0.1171456128358841, precision: 0.3001253132831892, recall: 0.8258620689653748, f1: 0.4402573529020363\n",
            "epoch: 366, step: 9, Train: label_loss: 0.10476599633693695, precision: 0.3256097560975411, recall: 0.8626817447494567, f1: 0.4727755643692025\n",
            "epoch: 366, step: 10, Train: label_loss: 0.11624670773744583, precision: 0.32022126613396923, recall: 0.8416801292405748, f1: 0.46393588597962\n",
            "epoch: 366, step: 11, Train: label_loss: 0.11824420839548111, precision: 0.3347432024168982, recall: 0.890675241157413, f1: 0.48660518221760407\n",
            "epoch: 366, step: 12, Train: label_loss: 0.11157026886940002, precision: 0.3284760170005872, recall: 0.871175523349296, f1: 0.4770723103658341\n",
            "epoch: 366, step: 13, Train: label_loss: 0.11696082353591919, precision: 0.30048959608321296, recall: 0.8494809688579844, f1: 0.4439421337769068\n",
            "epoch: 366, step: 14, Train: label_loss: 0.13399457931518555, precision: 0.3284223449969105, recall: 0.8642972536347553, f1: 0.47597864764688336\n",
            "epoch: 366, step: 15, Train: label_loss: 0.13103441894054413, precision: 0.2967702620353262, recall: 0.8573943661970321, f1: 0.4409234947557817\n",
            "epoch: 366, step: 16, Train: label_loss: 0.12381711602210999, precision: 0.3011083743842179, recall: 0.8288135593218934, f1: 0.44173441730503926\n",
            "epoch: 366, step: 17, Train: label_loss: 0.124642513692379, precision: 0.31640866873063056, recall: 0.8241935483869638, f1: 0.45727069347217303\n",
            "epoch: 366, step: 18, Train: label_loss: 0.11629170179367065, precision: 0.2992656058751347, recall: 0.8445595854920821, f1: 0.4419340261700899\n",
            "epoch: 366, step: 19, Train: label_loss: 0.12335953861474991, precision: 0.33292307692305645, recall: 0.8628389154703567, f1: 0.48046181168268987\n",
            "epoch: 366, step: 20, Train: label_loss: 0.11172932386398315, precision: 0.3180708180707986, recall: 0.8555008210179219, f1: 0.4637294169608894\n",
            "epoch: 366, step: 21, Train: label_loss: 0.11175727844238281, precision: 0.3132236441194203, recall: 0.859531772575107, f1: 0.4591335417205232\n",
            "epoch: 366, step: 22, Train: label_loss: 0.10941432416439056, precision: 0.30558930741188906, recall: 0.8525423728812114, f1: 0.449910554522829\n",
            "epoch: 366, step: 23, Train: label_loss: 0.10565325617790222, precision: 0.31277860326892176, recall: 0.8680412371132231, f1: 0.45985800105330504\n",
            "epoch: 367, step: 0, Train: label_loss: 0.11220178008079529, precision: 0.3162445954292578, recall: 0.8448844884487055, f1: 0.4602247190614463\n",
            "epoch: 367, step: 1, Train: label_loss: 0.10517243295907974, precision: 0.3039999999999813, recall: 0.8192371475952206, f1: 0.44344703766245563\n",
            "epoch: 367, step: 2, Train: label_loss: 0.1142810583114624, precision: 0.3169533169532975, recall: 0.8403908794786904, f1: 0.460303300584629\n",
            "epoch: 367, step: 3, Train: label_loss: 0.09678204357624054, precision: 0.3209500609013203, recall: 0.8725165562912462, f1: 0.46927871768102936\n",
            "epoch: 367, step: 4, Train: label_loss: 0.11044502258300781, precision: 0.3172371638141615, recall: 0.8664440734556149, f1: 0.4644295301620647\n",
            "epoch: 367, step: 5, Train: label_loss: 0.11568920314311981, precision: 0.31300061614292585, recall: 0.8552188552187112, f1: 0.45827695079519093\n",
            "epoch: 367, step: 6, Train: label_loss: 0.09882773458957672, precision: 0.3163636363636172, recall: 0.8613861386137192, f1: 0.462765957407475\n",
            "epoch: 367, step: 7, Train: label_loss: 0.11107237637042999, precision: 0.3420096852300035, recall: 0.8732612055640072, f1: 0.4915180512861758\n",
            "epoch: 367, step: 8, Train: label_loss: 0.11075061559677124, precision: 0.32788868723530984, recall: 0.8885245901637887, f1: 0.47901016346035774\n",
            "epoch: 367, step: 9, Train: label_loss: 0.11289593577384949, precision: 0.3169533169532975, recall: 0.8151658767771224, f1: 0.4564352056208546\n",
            "epoch: 367, step: 10, Train: label_loss: 0.11520640552043915, precision: 0.3021276595744497, recall: 0.8539518900342175, f1: 0.44634036816970385\n",
            "epoch: 367, step: 11, Train: label_loss: 0.11717002093791962, precision: 0.31049382716047463, recall: 0.8583617747438808, f1: 0.4560290117469817\n",
            "epoch: 367, step: 12, Train: label_loss: 0.10653118789196014, precision: 0.3143203883494955, recall: 0.8946459412779111, f1: 0.46519982034764884\n",
            "epoch: 367, step: 13, Train: label_loss: 0.12268391996622086, precision: 0.3100679431747801, recall: 0.8408710217754035, f1: 0.4530685920183557\n",
            "epoch: 367, step: 14, Train: label_loss: 0.109061099588871, precision: 0.31920048455479594, recall: 0.8842281879193147, f1: 0.4690698709000103\n",
            "epoch: 367, step: 15, Train: label_loss: 0.11186502873897552, precision: 0.31398900427609566, recall: 0.8682432432430965, f1: 0.461193360212182\n",
            "epoch: 367, step: 16, Train: label_loss: 0.10660208016633987, precision: 0.31943592887796934, recall: 0.8527004909982238, f1: 0.46476360388537447\n",
            "epoch: 367, step: 17, Train: label_loss: 0.11008745431900024, precision: 0.29981606376454323, recall: 0.8578947368419547, f1: 0.4443434801978346\n",
            "epoch: 367, step: 18, Train: label_loss: 0.12456686794757843, precision: 0.30688158710475466, recall: 0.8347386172005337, f1: 0.44877606523716745\n",
            "epoch: 367, step: 19, Train: label_loss: 0.11126958578824997, precision: 0.32722832722830725, recall: 0.885950413222994, f1: 0.4779313419133042\n",
            "epoch: 367, step: 20, Train: label_loss: 0.10596026480197906, precision: 0.3207547169811125, recall: 0.8682042833606477, f1: 0.46844444440500316\n",
            "epoch: 367, step: 21, Train: label_loss: 0.12688446044921875, precision: 0.31699751861040215, recall: 0.8377049180326495, f1: 0.45994599455958607\n",
            "epoch: 367, step: 22, Train: label_loss: 0.12554459273815155, precision: 0.30056004978218415, recall: 0.8186440677964714, f1: 0.43969048698843904\n",
            "epoch: 367, step: 23, Train: label_loss: 0.10615750402212143, precision: 0.31143911439112093, recall: 0.8701030927833258, f1: 0.4586956521350414\n",
            "epoch: 368, step: 0, Train: label_loss: 0.11232209950685501, precision: 0.29567901234566074, recall: 0.837412587412441, f1: 0.43704379558182715\n",
            "epoch: 368, step: 1, Train: label_loss: 0.10353834927082062, precision: 0.30920245398771107, recall: 0.8470588235292693, f1: 0.4530337078259469\n",
            "epoch: 368, step: 2, Train: label_loss: 0.10345926135778427, precision: 0.3170878459686933, recall: 0.881270903009886, f1: 0.4663716813769703\n",
            "epoch: 368, step: 3, Train: label_loss: 0.12035806477069855, precision: 0.292487684729046, recall: 0.840707964601621, f1: 0.4339881223919961\n",
            "epoch: 368, step: 4, Train: label_loss: 0.10388107597827911, precision: 0.29555149299205996, recall: 0.8553791887123711, f1: 0.4393115941646887\n",
            "epoch: 368, step: 5, Train: label_loss: 0.11807314306497574, precision: 0.31023911710605084, recall: 0.8532883642494344, f1: 0.45503597118387235\n",
            "epoch: 368, step: 6, Train: label_loss: 0.11519476026296616, precision: 0.31386861313866704, recall: 0.8445171849425785, f1: 0.4576496673662168\n",
            "epoch: 368, step: 7, Train: label_loss: 0.11350473761558533, precision: 0.292441140024765, recall: 0.816608996539651, f1: 0.43065693426769885\n",
            "epoch: 368, step: 8, Train: label_loss: 0.1172250509262085, precision: 0.33150517976841365, recall: 0.8745980707394092, f1: 0.48077772863884044\n",
            "epoch: 368, step: 9, Train: label_loss: 0.0941397175192833, precision: 0.3141297756215698, recall: 0.8647746243738121, f1: 0.46085409248755765\n",
            "epoch: 368, step: 10, Train: label_loss: 0.10600761324167252, precision: 0.30165542611892693, recall: 0.8439108061748123, f1: 0.4444444444056074\n",
            "epoch: 368, step: 11, Train: label_loss: 0.1131971925497055, precision: 0.32153941651146356, recall: 0.8314606741571698, f1: 0.46374216647719535\n",
            "epoch: 368, step: 12, Train: label_loss: 0.0986645445227623, precision: 0.3193174893357514, recall: 0.8618421052630161, f1: 0.4659848821303603\n",
            "epoch: 368, step: 13, Train: label_loss: 0.12832669913768768, precision: 0.32258064516127033, recall: 0.8400646203552762, f1: 0.46615867320056276\n",
            "epoch: 368, step: 14, Train: label_loss: 0.10608556866645813, precision: 0.3124616329036027, recall: 0.8441127694857637, f1: 0.45609318992468195\n",
            "epoch: 368, step: 15, Train: label_loss: 0.08688545227050781, precision: 0.33313106796114483, recall: 0.8769968051116809, f1: 0.48284960418169265\n",
            "epoch: 368, step: 16, Train: label_loss: 0.10332221537828445, precision: 0.3143893591293643, recall: 0.8873720136517257, f1: 0.46428571424703907\n",
            "epoch: 368, step: 17, Train: label_loss: 0.11393311619758606, precision: 0.30826140567199084, recall: 0.8333333333331944, f1: 0.45004500446098694\n",
            "epoch: 368, step: 18, Train: label_loss: 0.10923594236373901, precision: 0.31973203410473083, recall: 0.8592471358427398, f1: 0.4660452729298032\n",
            "epoch: 368, step: 19, Train: label_loss: 0.10641211271286011, precision: 0.32922318125768624, recall: 0.8557692307690936, f1: 0.4755120213311566\n",
            "epoch: 368, step: 20, Train: label_loss: 0.10151427984237671, precision: 0.3191105769230577, recall: 0.8924369747897659, f1: 0.4701195218735057\n",
            "epoch: 368, step: 21, Train: label_loss: 0.10775641351938248, precision: 0.3426658551430102, recall: 0.8783151326051671, f1: 0.4929947460191245\n",
            "epoch: 368, step: 22, Train: label_loss: 0.11250150203704834, precision: 0.32236441194391696, recall: 0.8410174880761778, f1: 0.4660792951140815\n",
            "epoch: 368, step: 23, Train: label_loss: 0.12498854845762253, precision: 0.30229007633585475, recall: 0.8407643312100126, f1: 0.4446939921002936\n",
            "epoch: 369, step: 0, Train: label_loss: 0.1165972650051117, precision: 0.31792629606493955, recall: 0.8427152317879398, f1: 0.46167800449532764\n",
            "epoch: 369, step: 1, Train: label_loss: 0.11309332400560379, precision: 0.29673041332508965, recall: 0.8423817863396073, f1: 0.4388686131001188\n",
            "epoch: 369, step: 2, Train: label_loss: 0.11128377914428711, precision: 0.3133047210300237, recall: 0.8690476190474712, f1: 0.4605678233048535\n",
            "epoch: 369, step: 3, Train: label_loss: 0.10961110889911652, precision: 0.32701711491440544, recall: 0.8601286173632057, f1: 0.4738706819795274\n",
            "epoch: 369, step: 4, Train: label_loss: 0.1083901971578598, precision: 0.2942628007402656, recall: 0.842756183745434, f1: 0.43621399173114267\n",
            "epoch: 369, step: 5, Train: label_loss: 0.11461572349071503, precision: 0.3133047210300237, recall: 0.8390804597699771, f1: 0.4562499999603674\n",
            "epoch: 369, step: 6, Train: label_loss: 0.11048896610736847, precision: 0.33496631965705237, recall: 0.8560250391234967, f1: 0.4815140844665701\n",
            "epoch: 369, step: 7, Train: label_loss: 0.09340301156044006, precision: 0.32429174201324146, recall: 0.9026845637582377, f1: 0.4771618624887846\n",
            "epoch: 369, step: 8, Train: label_loss: 0.10975399613380432, precision: 0.31093463653021924, recall: 0.8427152317879398, f1: 0.45426149036665214\n",
            "epoch: 369, step: 9, Train: label_loss: 0.10156270861625671, precision: 0.30958230958229055, recall: 0.8289473684209162, f1: 0.45080500890490804\n",
            "epoch: 369, step: 10, Train: label_loss: 0.10274886339902878, precision: 0.3048780487804692, recall: 0.850340136054277, f1: 0.4488330340724176\n",
            "epoch: 369, step: 11, Train: label_loss: 0.10697177797555923, precision: 0.31249999999998085, recall: 0.8443708609270124, f1: 0.4561717352020303\n",
            "epoch: 369, step: 12, Train: label_loss: 0.09943173825740814, precision: 0.32552552552550595, recall: 0.8756058158318456, f1: 0.47460595442629455\n",
            "epoch: 369, step: 13, Train: label_loss: 0.11911171674728394, precision: 0.296798029556632, recall: 0.8368055555554103, f1: 0.43818181814312446\n",
            "epoch: 369, step: 14, Train: label_loss: 0.1034197062253952, precision: 0.3168622606547056, recall: 0.8396072013091915, f1: 0.4600896860588295\n",
            "epoch: 369, step: 15, Train: label_loss: 0.11385399848222733, precision: 0.29767726161367375, recall: 0.8310580204776739, f1: 0.4383438343445639\n",
            "epoch: 369, step: 16, Train: label_loss: 0.10263407230377197, precision: 0.3105552165954661, recall: 0.8612521150590758, f1: 0.4565022421134683\n",
            "epoch: 369, step: 17, Train: label_loss: 0.11719508469104767, precision: 0.324022346368695, recall: 0.8405797101447922, f1: 0.4677419354436658\n",
            "epoch: 369, step: 18, Train: label_loss: 0.09370355308055878, precision: 0.32273545290939876, recall: 0.883415435139428, f1: 0.4727592266742952\n",
            "epoch: 369, step: 19, Train: label_loss: 0.105680450797081, precision: 0.3157248157247963, recall: 0.8412438625203206, f1: 0.45913354171998894\n",
            "epoch: 369, step: 20, Train: label_loss: 0.11287420988082886, precision: 0.3118872549019417, recall: 0.8627118644066334, f1: 0.45814581454241243\n",
            "epoch: 369, step: 21, Train: label_loss: 0.10986481606960297, precision: 0.32830416415206226, recall: 0.8932676518881948, f1: 0.48014121796594805\n",
            "epoch: 369, step: 22, Train: label_loss: 0.10671860724687576, precision: 0.3367469879517869, recall: 0.901612903225661, f1: 0.4903508771533427\n",
            "epoch: 369, step: 23, Train: label_loss: 0.10742688179016113, precision: 0.3025335320417062, recall: 0.8511530398321067, f1: 0.4463991203570795\n",
            "epoch: 370, step: 0, Train: label_loss: 0.11418341100215912, precision: 0.3018983466013287, recall: 0.851468048359093, f1: 0.44575045204087793\n",
            "epoch: 370, step: 1, Train: label_loss: 0.10073524713516235, precision: 0.3193329215564966, recall: 0.8631051752920095, f1: 0.46618575289110026\n",
            "epoch: 370, step: 2, Train: label_loss: 0.0987311601638794, precision: 0.2904589371980501, recall: 0.8682310469312512, f1: 0.4352941176094517\n",
            "epoch: 370, step: 3, Train: label_loss: 0.10493737459182739, precision: 0.3286413708690129, recall: 0.8510301109348889, f1: 0.47417218539022643\n",
            "epoch: 370, step: 4, Train: label_loss: 0.09725859761238098, precision: 0.31162507608032186, recall: 0.8421052631577561, f1: 0.45490892932525695\n",
            "epoch: 370, step: 5, Train: label_loss: 0.09634052217006683, precision: 0.3179890975166373, recall: 0.8868243243241745, f1: 0.4681230494483976\n",
            "epoch: 370, step: 6, Train: label_loss: 0.1098254919052124, precision: 0.3208232445520387, recall: 0.8603896103894707, f1: 0.4673721339991923\n",
            "epoch: 370, step: 7, Train: label_loss: 0.09569600224494934, precision: 0.33532219570403726, recall: 0.9064516129030795, f1: 0.48954703828806023\n",
            "epoch: 370, step: 8, Train: label_loss: 0.11455851793289185, precision: 0.31812652068124586, recall: 0.8834459459457966, f1: 0.4677996421792727\n",
            "epoch: 370, step: 9, Train: label_loss: 0.10399831831455231, precision: 0.315952824332693, recall: 0.8183279742763957, f1: 0.45588893860732665\n",
            "epoch: 370, step: 10, Train: label_loss: 0.1128464788198471, precision: 0.3078817733989958, recall: 0.8375209380233103, f1: 0.4502476361605602\n",
            "epoch: 370, step: 11, Train: label_loss: 0.1018342673778534, precision: 0.325943678849591, recall: 0.8962108731464751, f1: 0.47803163440724133\n",
            "epoch: 370, step: 12, Train: label_loss: 0.097538061439991, precision: 0.318814277071971, recall: 0.8797996661100367, f1: 0.46802841914385934\n",
            "epoch: 370, step: 13, Train: label_loss: 0.11524336040019989, precision: 0.33778047301392733, recall: 0.8744113029825942, f1: 0.4873140856990389\n",
            "epoch: 370, step: 14, Train: label_loss: 0.11464980989694595, precision: 0.3128048780487614, recall: 0.8650927487350986, f1: 0.4594715628807899\n",
            "epoch: 370, step: 15, Train: label_loss: 0.09489265829324722, precision: 0.30112219451369693, recall: 0.8242320819111221, f1: 0.4410958903717224\n",
            "epoch: 370, step: 16, Train: label_loss: 0.10664413124322891, precision: 0.3266423357664035, recall: 0.8949999999998508, f1: 0.47860962562922904\n",
            "epoch: 370, step: 17, Train: label_loss: 0.11128821223974228, precision: 0.3169533169532975, recall: 0.843137254901823, f1: 0.46071428567453093\n",
            "epoch: 370, step: 18, Train: label_loss: 0.11237227916717529, precision: 0.3020706455541838, recall: 0.8747795414460537, f1: 0.4490719782325112\n",
            "epoch: 370, step: 19, Train: label_loss: 0.11798408627510071, precision: 0.3189655172413597, recall: 0.8561983471072965, f1: 0.4647824135988108\n",
            "epoch: 370, step: 20, Train: label_loss: 0.10192778706550598, precision: 0.3040337146297228, recall: 0.8782608695650646, f1: 0.4516994632891245\n",
            "epoch: 370, step: 21, Train: label_loss: 0.11188973486423492, precision: 0.3154034229828658, recall: 0.8643216080400562, f1: 0.46215853108483185\n",
            "epoch: 370, step: 22, Train: label_loss: 0.1126100942492485, precision: 0.3259396179913539, recall: 0.8532258064514753, f1: 0.47168970125286724\n",
            "epoch: 370, step: 23, Train: label_loss: 0.11922265589237213, precision: 0.32882882882880415, recall: 0.8571428571426895, f1: 0.475311991278373\n",
            "epoch: 371, step: 0, Train: label_loss: 0.1030542254447937, precision: 0.3229548229548032, recall: 0.865793780687256, f1: 0.4704313027616295\n",
            "epoch: 371, step: 1, Train: label_loss: 0.10995198041200638, precision: 0.3184049079754406, recall: 0.8621262458470328, f1: 0.4650537634014249\n",
            "epoch: 371, step: 2, Train: label_loss: 0.12993845343589783, precision: 0.3003095975232012, recall: 0.8479020979019496, f1: 0.44352994966412074\n",
            "epoch: 371, step: 3, Train: label_loss: 0.11301183700561523, precision: 0.3258084197681314, recall: 0.8929765886286132, f1: 0.4774251228932839\n",
            "epoch: 371, step: 4, Train: label_loss: 0.0881432294845581, precision: 0.3521212121211908, recall: 0.8789712556730893, f1: 0.502812635181961\n",
            "epoch: 371, step: 5, Train: label_loss: 0.10133761167526245, precision: 0.3386211104331703, recall: 0.8604651162789363, f1: 0.4859894920785167\n",
            "epoch: 371, step: 6, Train: label_loss: 0.09828991442918777, precision: 0.341240875912388, recall: 0.8738317757007984, f1: 0.49081364825352647\n",
            "epoch: 371, step: 7, Train: label_loss: 0.10489287972450256, precision: 0.31559854897216955, recall: 0.8642384105958834, f1: 0.4623560672769799\n",
            "epoch: 371, step: 8, Train: label_loss: 0.097797691822052, precision: 0.3038204972710549, recall: 0.8774080560418778, f1: 0.4513513513131003\n",
            "epoch: 371, step: 9, Train: label_loss: 0.11486764252185822, precision: 0.29943855271364317, recall: 0.8219178082190373, f1: 0.43895747595532764\n",
            "epoch: 371, step: 10, Train: label_loss: 0.11210289597511292, precision: 0.319214241866156, recall: 0.8455284552844153, f1: 0.46345811047710206\n",
            "epoch: 371, step: 11, Train: label_loss: 0.09781060367822647, precision: 0.3091133004925918, recall: 0.8352745424291455, f1: 0.4512359550167088\n",
            "epoch: 371, step: 12, Train: label_loss: 0.09830024093389511, precision: 0.3217972070430891, recall: 0.868852459016251, f1: 0.4696499778072126\n",
            "epoch: 371, step: 13, Train: label_loss: 0.09994252026081085, precision: 0.3081113801452598, recall: 0.8715753424656041, f1: 0.4552772808200425\n",
            "epoch: 371, step: 14, Train: label_loss: 0.12079458683729172, precision: 0.3210558624923069, recall: 0.8587848932675108, f1: 0.4673815906663317\n",
            "epoch: 371, step: 15, Train: label_loss: 0.11274173855781555, precision: 0.30557256582974246, recall: 0.8693379790939252, f1: 0.45219755320116306\n",
            "epoch: 371, step: 16, Train: label_loss: 0.12114094197750092, precision: 0.31657355679700083, recall: 0.8333333333331971, f1: 0.4588394061678836\n",
            "epoch: 371, step: 17, Train: label_loss: 0.10876418650150299, precision: 0.3070439494280369, recall: 0.8762886597936638, f1: 0.4547481051777583\n",
            "epoch: 371, step: 18, Train: label_loss: 0.10589069873094559, precision: 0.3030303030302843, recall: 0.8333333333331916, f1: 0.44444444440529296\n",
            "epoch: 371, step: 19, Train: label_loss: 0.0988474190235138, precision: 0.3081986834230815, recall: 0.9098939929327013, f1: 0.460438086685449\n",
            "epoch: 371, step: 20, Train: label_loss: 0.10599812865257263, precision: 0.31854590264939503, recall: 0.8420195439738042, f1: 0.46222619575807466\n",
            "epoch: 371, step: 21, Train: label_loss: 0.09677042067050934, precision: 0.29696969696967895, recall: 0.8687943262409806, f1: 0.4426377596729206\n",
            "epoch: 371, step: 22, Train: label_loss: 0.10872528702020645, precision: 0.3228200371057314, recall: 0.8220472440943587, f1: 0.463587921806713\n",
            "epoch: 371, step: 23, Train: label_loss: 0.11009769141674042, precision: 0.299774605559707, recall: 0.8399999999998232, f1: 0.4418604650774628\n",
            "epoch: 372, step: 0, Train: label_loss: 0.09843786805868149, precision: 0.3134418324291553, recall: 0.8813559322032404, f1: 0.46242774562599526\n",
            "epoch: 372, step: 1, Train: label_loss: 0.08738633990287781, precision: 0.296809151113769, recall: 0.8679577464787204, f1: 0.44235082993057845\n",
            "epoch: 372, step: 2, Train: label_loss: 0.09848494827747345, precision: 0.30066145520142507, recall: 0.8710801393726705, f1: 0.4470272686251977\n",
            "epoch: 372, step: 3, Train: label_loss: 0.11892837285995483, precision: 0.3195046439628285, recall: 0.8295819935689984, f1: 0.461332141220428\n",
            "epoch: 372, step: 4, Train: label_loss: 0.10870204865932465, precision: 0.3222691611345611, recall: 0.8668831168829761, f1: 0.4698636163264822\n",
            "epoch: 372, step: 5, Train: label_loss: 0.10342521965503693, precision: 0.31930693069304955, recall: 0.8322580645159947, f1: 0.461538461498341\n",
            "epoch: 372, step: 6, Train: label_loss: 0.10101078450679779, precision: 0.3244228432563594, recall: 0.8826446280990276, f1: 0.47445579738401866\n",
            "epoch: 372, step: 7, Train: label_loss: 0.08964097499847412, precision: 0.33110571081407464, recall: 0.8776167471818231, f1: 0.48081164530645165\n",
            "epoch: 372, step: 8, Train: label_loss: 0.12247736752033234, precision: 0.3142685129439907, recall: 0.8969072164946912, f1: 0.4654480605946098\n",
            "epoch: 372, step: 9, Train: label_loss: 0.1101926788687706, precision: 0.3241082410823909, recall: 0.8499999999998629, f1: 0.4692787176803811\n",
            "epoch: 372, step: 10, Train: label_loss: 0.10262355208396912, precision: 0.3036809815950734, recall: 0.8564013840828968, f1: 0.44836956517870086\n",
            "epoch: 372, step: 11, Train: label_loss: 0.09732368588447571, precision: 0.3113377324534906, recall: 0.8708053691273706, f1: 0.4586831639028288\n",
            "epoch: 372, step: 12, Train: label_loss: 0.09764950722455978, precision: 0.31733653269344225, recall: 0.8743801652891116, f1: 0.4656690140453905\n",
            "epoch: 372, step: 13, Train: label_loss: 0.10541349649429321, precision: 0.3140096618357298, recall: 0.8666666666665221, f1: 0.4609929077623327\n",
            "epoch: 372, step: 14, Train: label_loss: 0.11867630481719971, precision: 0.30055316533495385, recall: 0.8445595854920821, f1: 0.4433363553556232\n",
            "epoch: 372, step: 15, Train: label_loss: 0.10735634714365005, precision: 0.3426097711811786, recall: 0.8656249999998646, f1: 0.4909171466141771\n",
            "epoch: 372, step: 16, Train: label_loss: 0.10719048976898193, precision: 0.316207951070317, recall: 0.8674496644293845, f1: 0.4634692962404979\n",
            "epoch: 372, step: 17, Train: label_loss: 0.11465345323085785, precision: 0.28905755850725556, recall: 0.7865748709120849, f1: 0.4227567067136642\n",
            "epoch: 372, step: 18, Train: label_loss: 0.10464148223400116, precision: 0.32885085574570116, recall: 0.8663446054749007, f1: 0.4767390340761531\n",
            "epoch: 372, step: 19, Train: label_loss: 0.12474171817302704, precision: 0.30797773654914606, recall: 0.8383838383836972, f1: 0.4504748981967555\n",
            "epoch: 372, step: 20, Train: label_loss: 0.11796063184738159, precision: 0.3263931414574203, recall: 0.8610662358641581, f1: 0.4733570159458853\n",
            "epoch: 372, step: 21, Train: label_loss: 0.10222218185663223, precision: 0.3024803387779611, recall: 0.8710801393726705, f1: 0.449034575624023\n",
            "epoch: 372, step: 22, Train: label_loss: 0.11223961412906647, precision: 0.321776155717742, recall: 0.865793780687256, f1: 0.46917960084736887\n",
            "epoch: 372, step: 23, Train: label_loss: 0.10259796679019928, precision: 0.3220466516177335, recall: 0.8441814595659085, f1: 0.4662309367791436\n",
            "epoch: 373, step: 0, Train: label_loss: 0.11080199480056763, precision: 0.3097398669086322, recall: 0.8692699490660662, f1: 0.4567350579451633\n",
            "epoch: 373, step: 1, Train: label_loss: 0.10026706755161285, precision: 0.3159784560143437, recall: 0.8844221105526157, f1: 0.4656084655696368\n",
            "epoch: 373, step: 2, Train: label_loss: 0.10565151274204254, precision: 0.30251071647273103, recall: 0.8606271777001985, f1: 0.44766651559355136\n",
            "epoch: 373, step: 3, Train: label_loss: 0.10130532085895538, precision: 0.3247391037446087, recall: 0.8304552590265571, f1: 0.4669020299683673\n",
            "epoch: 373, step: 4, Train: label_loss: 0.10315106809139252, precision: 0.3343465045592502, recall: 0.8500772797525733, f1: 0.47993019193151476\n",
            "epoch: 373, step: 5, Train: label_loss: 0.1135081946849823, precision: 0.3143032535297536, recall: 0.8434925864908001, f1: 0.4579606439675601\n",
            "epoch: 373, step: 6, Train: label_loss: 0.1095442920923233, precision: 0.3153753026634192, recall: 0.866888519134631, f1: 0.46249445180282794\n",
            "epoch: 373, step: 7, Train: label_loss: 0.10135936737060547, precision: 0.3192401960784118, recall: 0.8697829716192204, f1: 0.46705513218837813\n",
            "epoch: 373, step: 8, Train: label_loss: 0.09123614430427551, precision: 0.3323335332933214, recall: 0.9037520391515654, f1: 0.4859649122413443\n",
            "epoch: 373, step: 9, Train: label_loss: 0.09969476610422134, precision: 0.3107617896009486, recall: 0.8756388415671421, f1: 0.45872378398628283\n",
            "epoch: 373, step: 10, Train: label_loss: 0.09879851341247559, precision: 0.3042424242424058, recall: 0.8776223776222242, f1: 0.45184518448017963\n",
            "epoch: 373, step: 11, Train: label_loss: 0.0987798422574997, precision: 0.3179611650485244, recall: 0.8851351351349855, f1: 0.4678571428182133\n",
            "epoch: 373, step: 12, Train: label_loss: 0.09478374570608139, precision: 0.3365384615384413, recall: 0.9032258064514671, f1: 0.49036777579227764\n",
            "epoch: 373, step: 13, Train: label_loss: 0.10528502613306046, precision: 0.32486388384753023, recall: 0.8846787479405461, f1: 0.47522123889872164\n",
            "epoch: 373, step: 14, Train: label_loss: 0.1294407695531845, precision: 0.307883302296691, recall: 0.823920265780594, f1: 0.4482602801230287\n",
            "epoch: 373, step: 15, Train: label_loss: 0.09423583745956421, precision: 0.3153098420412931, recall: 0.8621262458470328, f1: 0.46174377220273577\n",
            "epoch: 373, step: 16, Train: label_loss: 0.1004815399646759, precision: 0.31569230769228823, recall: 0.8607382550334126, f1: 0.46195407470179856\n",
            "epoch: 373, step: 17, Train: label_loss: 0.09710827469825745, precision: 0.32349397590359497, recall: 0.8803278688523146, f1: 0.47312775326462087\n",
            "epoch: 373, step: 18, Train: label_loss: 0.0952935591340065, precision: 0.3325315694527761, recall: 0.8722397476339318, f1: 0.48149760553247806\n",
            "epoch: 373, step: 19, Train: label_loss: 0.11249779164791107, precision: 0.2934648581997353, recall: 0.835087719298099, f1: 0.43430656930454253\n",
            "epoch: 373, step: 20, Train: label_loss: 0.10015343874692917, precision: 0.3046922608165567, recall: 0.8650519031140371, f1: 0.4506534474603069\n",
            "epoch: 373, step: 21, Train: label_loss: 0.11333291977643967, precision: 0.32526381129731063, recall: 0.8317460317458997, f1: 0.4676483712223686\n",
            "epoch: 373, step: 22, Train: label_loss: 0.11495997756719589, precision: 0.30141190914669724, recall: 0.8293918918917518, f1: 0.44214317870917175\n",
            "epoch: 373, step: 23, Train: label_loss: 0.1175011694431305, precision: 0.30425219941346743, recall: 0.8963282937363075, f1: 0.45429666115532336\n",
            "epoch: 374, step: 0, Train: label_loss: 0.10869398713111877, precision: 0.3107033639143541, recall: 0.8552188552187112, f1: 0.4558097801313448\n",
            "epoch: 374, step: 1, Train: label_loss: 0.10687762498855591, precision: 0.3128457283343385, recall: 0.8525963149077298, f1: 0.4577338129103236\n",
            "epoch: 374, step: 2, Train: label_loss: 0.12170296907424927, precision: 0.32876712328765073, recall: 0.8341232227486833, f1: 0.4716391245686009\n",
            "epoch: 374, step: 3, Train: label_loss: 0.1117970198392868, precision: 0.323257248611948, recall: 0.8343949044584658, f1: 0.46598488212955924\n",
            "epoch: 374, step: 4, Train: label_loss: 0.1119728684425354, precision: 0.32138442521629657, recall: 0.8427876823337369, f1: 0.4653243847474599\n",
            "epoch: 374, step: 5, Train: label_loss: 0.1106756329536438, precision: 0.31426814268140746, recall: 0.8690476190474712, f1: 0.4616079493737761\n",
            "epoch: 374, step: 6, Train: label_loss: 0.10149998962879181, precision: 0.3099697885196187, recall: 0.8799313893652007, f1: 0.45844504017590815\n",
            "epoch: 374, step: 7, Train: label_loss: 0.10219848155975342, precision: 0.3214069132807567, recall: 0.8877721943047089, f1: 0.47195013353171983\n",
            "epoch: 374, step: 8, Train: label_loss: 0.10776035487651825, precision: 0.30121951219510357, recall: 0.85763888888874, f1: 0.4458483754127503\n",
            "epoch: 374, step: 9, Train: label_loss: 0.11530890315771103, precision: 0.33128834355826187, recall: 0.8723747980612483, f1: 0.48021342815036816\n",
            "epoch: 374, step: 10, Train: label_loss: 0.1280304193496704, precision: 0.33312421580926393, recall: 0.850961538461402, f1: 0.4788097384626757\n",
            "epoch: 374, step: 11, Train: label_loss: 0.1016157865524292, precision: 0.32203389830506524, recall: 0.8822553897179299, f1: 0.4718403547279622\n",
            "epoch: 374, step: 12, Train: label_loss: 0.1042826920747757, precision: 0.32070861331702377, recall: 0.8293838862557931, f1: 0.46255506603903546\n",
            "epoch: 374, step: 13, Train: label_loss: 0.11054323613643646, precision: 0.27030378177307685, recall: 0.8014705882351467, f1: 0.4042651830869535\n",
            "epoch: 374, step: 14, Train: label_loss: 0.1030656099319458, precision: 0.3270745003028269, recall: 0.8639999999998617, f1: 0.47451669591793966\n",
            "epoch: 374, step: 15, Train: label_loss: 0.11005745083093643, precision: 0.31115218730743616, recall: 0.8388704318935483, f1: 0.4539325842301505\n",
            "epoch: 374, step: 16, Train: label_loss: 0.1053948849439621, precision: 0.30853658536583484, recall: 0.8461538461537046, f1: 0.4521894548312185\n",
            "epoch: 374, step: 17, Train: label_loss: 0.09290890395641327, precision: 0.3231414868105322, recall: 0.8850574712642224, f1: 0.47342995165159496\n",
            "epoch: 374, step: 18, Train: label_loss: 0.10182008147239685, precision: 0.34100545124165105, recall: 0.8769470404983057, f1: 0.4910597470158969\n",
            "epoch: 374, step: 19, Train: label_loss: 0.10938295722007751, precision: 0.3052631578947179, recall: 0.8456260720410212, f1: 0.4485896268945575\n",
            "epoch: 374, step: 20, Train: label_loss: 0.1104375347495079, precision: 0.30680437424056456, recall: 0.8573853989811786, f1: 0.4519015659566684\n",
            "epoch: 374, step: 21, Train: label_loss: 0.10904888808727264, precision: 0.32608695652171943, recall: 0.891089108910744, f1: 0.47745358086258816\n",
            "epoch: 374, step: 22, Train: label_loss: 0.10978877544403076, precision: 0.2977425259304272, recall: 0.8413793103446825, f1: 0.4398377647202487\n",
            "epoch: 374, step: 23, Train: label_loss: 0.10328318923711777, precision: 0.2879699248120084, recall: 0.8530066815142867, f1: 0.4305789769155584\n",
            "epoch: 375, step: 0, Train: label_loss: 0.1032591313123703, precision: 0.29981606376454323, recall: 0.8548951048949553, f1: 0.44394008166827714\n",
            "epoch: 375, step: 1, Train: label_loss: 0.10794927924871445, precision: 0.30660086366438577, recall: 0.8554216867468406, f1: 0.45140781104194794\n",
            "epoch: 375, step: 2, Train: label_loss: 0.09634905308485031, precision: 0.32451923076921124, recall: 0.8866995073890169, f1: 0.47514298280278855\n",
            "epoch: 375, step: 3, Train: label_loss: 0.09655941277742386, precision: 0.3482252141982651, recall: 0.8794435857803895, f1: 0.4989039894376169\n",
            "epoch: 375, step: 4, Train: label_loss: 0.11276845633983612, precision: 0.3068944478340264, recall: 0.8341625207295466, f1: 0.4487065120034551\n",
            "epoch: 375, step: 5, Train: label_loss: 0.0941021591424942, precision: 0.3082066869300724, recall: 0.840796019900358, f1: 0.45106761561906544\n",
            "epoch: 375, step: 6, Train: label_loss: 0.11125384271144867, precision: 0.3247143716175391, recall: 0.8723747980612483, f1: 0.4732690621865409\n",
            "epoch: 375, step: 7, Train: label_loss: 0.11073775589466095, precision: 0.3188759926694979, recall: 0.8351999999998663, f1: 0.4615384614984286\n",
            "epoch: 375, step: 8, Train: label_loss: 0.09812913835048676, precision: 0.32432432432430486, recall: 0.8667736757623006, f1: 0.47202797198830115\n",
            "epoch: 375, step: 9, Train: label_loss: 0.08928721398115158, precision: 0.3046874999999817, recall: 0.8726333907055296, f1: 0.4516703785807492\n",
            "epoch: 375, step: 10, Train: label_loss: 0.10547686368227005, precision: 0.3274711946634125, recall: 0.8585055643877808, f1: 0.47410008775629536\n",
            "epoch: 375, step: 11, Train: label_loss: 0.11339615285396576, precision: 0.3045592705166988, recall: 0.8820422535209714, f1: 0.4527790329486971\n",
            "epoch: 375, step: 12, Train: label_loss: 0.1131276786327362, precision: 0.2967032967032786, recall: 0.8556338028167507, f1: 0.4406165004150325\n",
            "epoch: 375, step: 13, Train: label_loss: 0.10272333770990372, precision: 0.32650602409636587, recall: 0.8856209150325349, f1: 0.4771126760169344\n",
            "epoch: 375, step: 14, Train: label_loss: 0.12182239443063736, precision: 0.3196319018404712, recall: 0.8457792207790834, f1: 0.4639358859797403\n",
            "epoch: 375, step: 15, Train: label_loss: 0.09728918224573135, precision: 0.32388419782868977, recall: 0.9010067114092447, f1: 0.4764862466336395\n",
            "epoch: 375, step: 16, Train: label_loss: 0.11221344769001007, precision: 0.3234200743494223, recall: 0.8378812199035572, f1: 0.46669646844434837\n",
            "epoch: 375, step: 17, Train: label_loss: 0.12661583721637726, precision: 0.3227016885553269, recall: 0.8417618270797974, f1: 0.4665461120756248\n",
            "epoch: 375, step: 18, Train: label_loss: 0.0917300209403038, precision: 0.32497013142172493, recall: 0.9036544850496837, f1: 0.47803163440744734\n",
            "epoch: 375, step: 19, Train: label_loss: 0.09732076525688171, precision: 0.32170775706552485, recall: 0.8784893267650445, f1: 0.47095070418607127\n",
            "epoch: 375, step: 20, Train: label_loss: 0.12084319442510605, precision: 0.3096107055960882, recall: 0.883680555555402, f1: 0.4585585585200892\n",
            "epoch: 375, step: 21, Train: label_loss: 0.12729769945144653, precision: 0.3003731343283395, recall: 0.8370883882147595, f1: 0.4421052631189865\n",
            "epoch: 375, step: 22, Train: label_loss: 0.1066674143075943, precision: 0.31479217603910054, recall: 0.8714043993230335, f1: 0.46250561289316355\n",
            "epoch: 375, step: 23, Train: label_loss: 0.09501364827156067, precision: 0.31794489947875515, recall: 0.8970588235292233, f1: 0.46948873003277525\n",
            "epoch: 376, step: 0, Train: label_loss: 0.09835083782672882, precision: 0.32728372655775395, recall: 0.8825448613375395, f1: 0.47749338036649175\n",
            "epoch: 376, step: 1, Train: label_loss: 0.09221173822879791, precision: 0.3176328502415267, recall: 0.8694214876031621, f1: 0.4652808491425406\n",
            "epoch: 376, step: 2, Train: label_loss: 0.11286978423595428, precision: 0.30656039239728344, recall: 0.8250825082506889, f1: 0.44702726862384595\n",
            "epoch: 376, step: 3, Train: label_loss: 0.12169687449932098, precision: 0.2894236858771191, recall: 0.7879310344826227, f1: 0.42334414076659466\n",
            "epoch: 376, step: 4, Train: label_loss: 0.09290478378534317, precision: 0.2999999999999819, recall: 0.8601036269428566, f1: 0.44484144703620215\n",
            "epoch: 376, step: 5, Train: label_loss: 0.11173777282238007, precision: 0.32151589242051826, recall: 0.865131578947226, f1: 0.4688057040602733\n",
            "epoch: 376, step: 6, Train: label_loss: 0.11109462380409241, precision: 0.31238447319776264, recall: 0.8325123152707992, f1: 0.45430107522909596\n",
            "epoch: 376, step: 7, Train: label_loss: 0.10016223788261414, precision: 0.32388419782868977, recall: 0.883223684210381, f1: 0.47396293023430375\n",
            "epoch: 376, step: 8, Train: label_loss: 0.1046326607465744, precision: 0.3141809290953353, recall: 0.8552412645589259, f1: 0.4595440321466255\n",
            "epoch: 376, step: 9, Train: label_loss: 0.1037435382604599, precision: 0.33715319662241633, recall: 0.8887122416532768, f1: 0.48885002182278153\n",
            "epoch: 376, step: 10, Train: label_loss: 0.08785183727741241, precision: 0.33333333333331344, recall: 0.8958333333331897, f1: 0.48587570617511816\n",
            "epoch: 376, step: 11, Train: label_loss: 0.10192698985338211, precision: 0.3133414932680347, recall: 0.8393442622949443, f1: 0.4563279857001215\n",
            "epoch: 376, step: 12, Train: label_loss: 0.10908158868551254, precision: 0.30923450789791557, recall: 0.8641765704582572, f1: 0.45548098430118705\n",
            "epoch: 376, step: 13, Train: label_loss: 0.09064825624227524, precision: 0.3140298507462499, recall: 0.8885135135133634, f1: 0.46404940446070836\n",
            "epoch: 376, step: 14, Train: label_loss: 0.11173307150602341, precision: 0.3058752271350511, recall: 0.8573853989811786, f1: 0.45089285710405574\n",
            "epoch: 376, step: 15, Train: label_loss: 0.12687301635742188, precision: 0.3165024630541677, recall: 0.860971524287963, f1: 0.4628545699741566\n",
            "epoch: 376, step: 16, Train: label_loss: 0.09700575470924377, precision: 0.32629674306391276, recall: 0.8898026315788009, f1: 0.4774933803666953\n",
            "epoch: 376, step: 17, Train: label_loss: 0.10968288779258728, precision: 0.3323170731707114, recall: 0.8678343949043203, f1: 0.4805996472262266\n",
            "epoch: 376, step: 18, Train: label_loss: 0.10671348869800568, precision: 0.3070336391437121, recall: 0.8581196581195114, f1: 0.45225225221339677\n",
            "epoch: 376, step: 19, Train: label_loss: 0.0990481898188591, precision: 0.31997571341831693, recall: 0.8768718801995212, f1: 0.46886120992519636\n",
            "epoch: 376, step: 20, Train: label_loss: 0.12357805669307709, precision: 0.3134603564843077, recall: 0.865874363327527, f1: 0.4602888086251888\n",
            "epoch: 376, step: 21, Train: label_loss: 0.0968465656042099, precision: 0.30843373493974047, recall: 0.8797250859105017, f1: 0.45673505794546165\n",
            "epoch: 376, step: 22, Train: label_loss: 0.11602219194173813, precision: 0.3004265691651249, recall: 0.8544194107450859, f1: 0.44454463476759776\n",
            "epoch: 376, step: 23, Train: label_loss: 0.09020775556564331, precision: 0.33234421364982697, recall: 0.8784313725488474, f1: 0.4822389665909049\n",
            "epoch: 377, step: 0, Train: label_loss: 0.08893272280693054, precision: 0.31914893617019335, recall: 0.8808724832213286, f1: 0.4685408299475269\n",
            "epoch: 377, step: 1, Train: label_loss: 0.1048751100897789, precision: 0.2969993876301104, recall: 0.8420138888887426, f1: 0.43911272064950235\n",
            "epoch: 377, step: 2, Train: label_loss: 0.12407584488391876, precision: 0.31809643080774463, recall: 0.8410596026488674, f1: 0.4616083597965733\n",
            "epoch: 377, step: 3, Train: label_loss: 0.1062101423740387, precision: 0.3163390663390469, recall: 0.8526490066223753, f1: 0.46146953401066193\n",
            "epoch: 377, step: 4, Train: label_loss: 0.09614025801420212, precision: 0.32628398791538815, recall: 0.8837970540096752, f1: 0.476610767833475\n",
            "epoch: 377, step: 5, Train: label_loss: 0.09390135854482651, precision: 0.3216232586311132, recall: 0.8719211822658666, f1: 0.4699115043853661\n",
            "epoch: 377, step: 6, Train: label_loss: 0.11250089108943939, precision: 0.3191358024691161, recall: 0.8311897106107988, f1: 0.4611953612444336\n",
            "epoch: 377, step: 7, Train: label_loss: 0.09616567939519882, precision: 0.30315917375453805, recall: 0.8588640275385785, f1: 0.4481365064723959\n",
            "epoch: 377, step: 8, Train: label_loss: 0.11797827482223511, precision: 0.3341493268053651, recall: 0.8652931854198311, f1: 0.48211920525777535\n",
            "epoch: 377, step: 9, Train: label_loss: 0.12295444309711456, precision: 0.3247391037446087, recall: 0.8559870550160427, f1: 0.47085002221197153\n",
            "epoch: 377, step: 10, Train: label_loss: 0.10193124413490295, precision: 0.3106796116504666, recall: 0.8842832469773947, f1: 0.4598114054397014\n",
            "epoch: 377, step: 11, Train: label_loss: 0.10139309614896774, precision: 0.32904411764703867, recall: 0.8605769230767851, f1: 0.47606382974717376\n",
            "epoch: 377, step: 12, Train: label_loss: 0.09181097149848938, precision: 0.29867788461536665, recall: 0.8673647469457474, f1: 0.4443451050132613\n",
            "epoch: 377, step: 13, Train: label_loss: 0.10448300838470459, precision: 0.332934131736507, recall: 0.8924558587478503, f1: 0.48495420842091425\n",
            "epoch: 377, step: 14, Train: label_loss: 0.09543304145336151, precision: 0.3150932050510935, recall: 0.8987993138934993, f1: 0.46660730183151056\n",
            "epoch: 377, step: 15, Train: label_loss: 0.1064608246088028, precision: 0.3135233474833042, recall: 0.8545454545453133, f1: 0.4587400177069148\n",
            "epoch: 377, step: 16, Train: label_loss: 0.11787734180688858, precision: 0.31145510835911383, recall: 0.8809106830121048, f1: 0.4602012808396788\n",
            "epoch: 377, step: 17, Train: label_loss: 0.09932169318199158, precision: 0.3057247259439521, recall: 0.8408710217754035, f1: 0.44841447070672025\n",
            "epoch: 377, step: 18, Train: label_loss: 0.11180998384952545, precision: 0.32595693779902357, recall: 0.8949096880129893, f1: 0.4778605874224567\n",
            "epoch: 377, step: 19, Train: label_loss: 0.09873706102371216, precision: 0.3074096754439493, recall: 0.8494077834177919, f1: 0.45143884888179847\n",
            "epoch: 377, step: 20, Train: label_loss: 0.11207254230976105, precision: 0.3099878197320152, recall: 0.8700854700853213, f1: 0.45711719798547046\n",
            "epoch: 377, step: 21, Train: label_loss: 0.1108163371682167, precision: 0.3310769230769027, recall: 0.8526148969887714, f1: 0.4769503545695932\n",
            "epoch: 377, step: 22, Train: label_loss: 0.11131572723388672, precision: 0.30405405405403535, recall: 0.8490566037734392, f1: 0.4477611939909795\n",
            "epoch: 377, step: 23, Train: label_loss: 0.11014941334724426, precision: 0.3350668647845219, recall: 0.8791423001947604, f1: 0.485207100551703\n",
            "epoch: 378, step: 0, Train: label_loss: 0.10112342983484268, precision: 0.32719459791280986, recall: 0.844690966719359, f1: 0.471681415888912\n",
            "epoch: 378, step: 1, Train: label_loss: 0.10314038395881653, precision: 0.31068560840022785, recall: 0.8369384359399605, f1: 0.4531531531136261\n",
            "epoch: 378, step: 2, Train: label_loss: 0.11078399419784546, precision: 0.30054978619423944, recall: 0.8296795952781062, f1: 0.4412556053420851\n",
            "epoch: 378, step: 3, Train: label_loss: 0.10963889956474304, precision: 0.3142509135200783, recall: 0.8459016393441235, f1: 0.4582593250048643\n",
            "epoch: 378, step: 4, Train: label_loss: 0.09739547967910767, precision: 0.32171253822628, recall: 0.878130217028234, f1: 0.4709042076599049\n",
            "epoch: 378, step: 5, Train: label_loss: 0.11895662546157837, precision: 0.30707692307690415, recall: 0.8400673400671986, f1: 0.4497521405646288\n",
            "epoch: 378, step: 6, Train: label_loss: 0.11369293928146362, precision: 0.31904470300059284, recall: 0.8471544715445777, f1: 0.46352313163281017\n",
            "epoch: 378, step: 7, Train: label_loss: 0.10164102911949158, precision: 0.318459657701692, recall: 0.8756302521006931, f1: 0.4670551321885447\n",
            "epoch: 378, step: 8, Train: label_loss: 0.10689249634742737, precision: 0.3020012128562582, recall: 0.8691099476438273, f1: 0.44824482444413266\n",
            "epoch: 378, step: 9, Train: label_loss: 0.09977684915065765, precision: 0.3079268292682739, recall: 0.8516020236086252, f1: 0.45230631433623164\n",
            "epoch: 378, step: 10, Train: label_loss: 0.10581189393997192, precision: 0.32807762280167807, recall: 0.8868852459014939, f1: 0.47897299686181843\n",
            "epoch: 378, step: 11, Train: label_loss: 0.10844302177429199, precision: 0.31044957472659107, recall: 0.8690476190474712, f1: 0.45747538044461117\n",
            "epoch: 378, step: 12, Train: label_loss: 0.10176803171634674, precision: 0.31729598051155194, recall: 0.8830508474574774, f1: 0.4668458780972663\n",
            "epoch: 378, step: 13, Train: label_loss: 0.11827705800533295, precision: 0.2988220706757409, recall: 0.823931623931483, f1: 0.4385805277133994\n",
            "epoch: 378, step: 14, Train: label_loss: 0.11558471620082855, precision: 0.319461444308426, recall: 0.8501628664493729, f1: 0.46441281134815293\n",
            "epoch: 378, step: 15, Train: label_loss: 0.10109065473079681, precision: 0.3153374233128641, recall: 0.8467874794067797, f1: 0.4595440321463788\n",
            "epoch: 378, step: 16, Train: label_loss: 0.11192162334918976, precision: 0.32920792079205885, recall: 0.8608414239480807, f1: 0.4762757385454327\n",
            "epoch: 378, step: 17, Train: label_loss: 0.0995461642742157, precision: 0.323281061519884, recall: 0.8715447154470127, f1: 0.4716234051518634\n",
            "epoch: 378, step: 18, Train: label_loss: 0.11294341087341309, precision: 0.30308529945551704, recall: 0.8491525423727374, f1: 0.446723138614779\n",
            "epoch: 378, step: 19, Train: label_loss: 0.10582596063613892, precision: 0.3168498168497975, recall: 0.8592715231786656, f1: 0.46297948256541094\n",
            "epoch: 378, step: 20, Train: label_loss: 0.10445353388786316, precision: 0.32383262583381905, recall: 0.8530351437698317, f1: 0.46945054941061837\n",
            "epoch: 378, step: 21, Train: label_loss: 0.10898062586784363, precision: 0.30802469135800564, recall: 0.831666666666528, f1: 0.4495495495100642\n",
            "epoch: 378, step: 22, Train: label_loss: 0.10893703997135162, precision: 0.3084911423335181, recall: 0.8588435374148199, f1: 0.45393258423073585\n",
            "epoch: 378, step: 23, Train: label_loss: 0.11834430694580078, precision: 0.30972117558400075, recall: 0.8562499999998217, f1: 0.4548976203261814\n",
            "epoch: 379, step: 0, Train: label_loss: 0.10602129995822906, precision: 0.3195625759416574, recall: 0.8694214876031621, f1: 0.46734784536269547\n",
            "epoch: 379, step: 1, Train: label_loss: 0.09414045512676239, precision: 0.3183747725894288, recall: 0.8764607679464312, f1: 0.4670818504946745\n",
            "epoch: 379, step: 2, Train: label_loss: 0.12201069295406342, precision: 0.318976279650417, recall: 0.8336052202282489, f1: 0.46139954849265785\n",
            "epoch: 379, step: 3, Train: label_loss: 0.1207360029220581, precision: 0.3050847457626934, recall: 0.8704663212433729, f1: 0.4518153294102028\n",
            "epoch: 379, step: 4, Train: label_loss: 0.12183491885662079, precision: 0.3244084682440645, recall: 0.8282988871222848, f1: 0.46621923933311443\n",
            "epoch: 379, step: 5, Train: label_loss: 0.10956036299467087, precision: 0.3220443349753496, recall: 0.8301587301585983, f1: 0.4640638863838174\n",
            "epoch: 379, step: 6, Train: label_loss: 0.1110655814409256, precision: 0.29095354523225603, recall: 0.856115107913515, f1: 0.43430656930516376\n",
            "epoch: 379, step: 7, Train: label_loss: 0.1112762913107872, precision: 0.3115455100793945, recall: 0.8673469387753626, f1: 0.45842696625320734\n",
            "epoch: 379, step: 8, Train: label_loss: 0.09583209455013275, precision: 0.3269230769230573, recall: 0.8976897689767495, f1: 0.4792951541458413\n",
            "epoch: 379, step: 9, Train: label_loss: 0.11587230861186981, precision: 0.30678282513999333, recall: 0.812191103788993, f1: 0.44534778677136155\n",
            "epoch: 379, step: 10, Train: label_loss: 0.09959062188863754, precision: 0.34861278648972566, recall: 0.8878648233485579, f1: 0.5006496318347374\n",
            "epoch: 379, step: 11, Train: label_loss: 0.10757463425397873, precision: 0.3318965517241175, recall: 0.8637820512819128, f1: 0.47953736650789414\n",
            "epoch: 379, step: 12, Train: label_loss: 0.10892407596111298, precision: 0.32114564290065073, recall: 0.8696369636962261, f1: 0.46906987089959634\n",
            "epoch: 379, step: 13, Train: label_loss: 0.10734740644693375, precision: 0.2986698911728961, recall: 0.8743362831856859, f1: 0.4452456060908891\n",
            "epoch: 379, step: 14, Train: label_loss: 0.10104702413082123, precision: 0.2996960486322006, recall: 0.8633975481609696, f1: 0.4449458483371558\n",
            "epoch: 379, step: 15, Train: label_loss: 0.10144753754138947, precision: 0.3071297989030891, recall: 0.8571428571427113, f1: 0.45222072674442887\n",
            "epoch: 379, step: 16, Train: label_loss: 0.10558529198169708, precision: 0.3091905051734444, recall: 0.8610169491523963, f1: 0.45499328254056737\n",
            "epoch: 379, step: 17, Train: label_loss: 0.10711976140737534, precision: 0.3398294762484568, recall: 0.8624420401853381, f1: 0.48754914805901184\n",
            "epoch: 379, step: 18, Train: label_loss: 0.10503742843866348, precision: 0.32680538555689553, recall: 0.8530351437698317, f1: 0.47256637164132065\n",
            "epoch: 379, step: 19, Train: label_loss: 0.11430142819881439, precision: 0.3310727496917182, recall: 0.8689320388348107, f1: 0.4794642856742878\n",
            "epoch: 379, step: 20, Train: label_loss: 0.10592220723628998, precision: 0.3069427527405416, recall: 0.8689655172412294, f1: 0.45364536449783455\n",
            "epoch: 379, step: 21, Train: label_loss: 0.10842154920101166, precision: 0.30773918342472223, recall: 0.8662092624355289, f1: 0.45413669060875655\n",
            "epoch: 379, step: 22, Train: label_loss: 0.1268734186887741, precision: 0.30726939523516755, recall: 0.8613013698628661, f1: 0.4529491219783076\n",
            "epoch: 379, step: 23, Train: label_loss: 0.10906563699245453, precision: 0.3093093093092861, recall: 0.8691983122361036, f1: 0.4562569213344351\n",
            "epoch: 380, step: 0, Train: label_loss: 0.11714449524879456, precision: 0.3066095471236042, recall: 0.8448566610453887, f1: 0.44993264477453554\n",
            "epoch: 380, step: 1, Train: label_loss: 0.1229645237326622, precision: 0.28905755850725556, recall: 0.7852233676974595, f1: 0.42256125747334033\n",
            "epoch: 380, step: 2, Train: label_loss: 0.09165987372398376, precision: 0.3343337334933773, recall: 0.8869426751590944, f1: 0.4856146468651643\n",
            "epoch: 380, step: 3, Train: label_loss: 0.11569778621196747, precision: 0.3228004956629292, recall: 0.8309409888355931, f1: 0.4649709950511344\n",
            "epoch: 380, step: 4, Train: label_loss: 0.11802928149700165, precision: 0.30486284289274906, recall: 0.8016393442621637, f1: 0.4417344173042118\n",
            "epoch: 380, step: 5, Train: label_loss: 0.10469836741685867, precision: 0.3078817733989958, recall: 0.8403361344536402, f1: 0.45065344745958463\n",
            "epoch: 380, step: 6, Train: label_loss: 0.10473666340112686, precision: 0.3393501805053947, recall: 0.8909952606633663, f1: 0.49150326793386495\n",
            "epoch: 380, step: 7, Train: label_loss: 0.09242374449968338, precision: 0.32931968693556113, recall: 0.8766025641024235, f1: 0.47877461702808977\n",
            "epoch: 380, step: 8, Train: label_loss: 0.11916075646877289, precision: 0.31513647642677944, recall: 0.8509212730316832, f1: 0.45993662286680703\n",
            "epoch: 380, step: 9, Train: label_loss: 0.10396275669336319, precision: 0.3284132841328211, recall: 0.8739770867429011, f1: 0.47742512289274985\n",
            "epoch: 380, step: 10, Train: label_loss: 0.11891115456819534, precision: 0.2897832817337282, recall: 0.8372093023254316, f1: 0.43054277825062603\n",
            "epoch: 380, step: 11, Train: label_loss: 0.11285269260406494, precision: 0.29815950920243567, recall: 0.8408304498268441, f1: 0.4402173912656581\n",
            "epoch: 380, step: 12, Train: label_loss: 0.10567251592874527, precision: 0.3130644190246651, recall: 0.8888888888887369, f1: 0.46304541403089117\n",
            "epoch: 380, step: 13, Train: label_loss: 0.10429990291595459, precision: 0.3130644190246651, recall: 0.8873720136517257, f1: 0.46283934130541715\n",
            "epoch: 380, step: 14, Train: label_loss: 0.10510185360908508, precision: 0.32579462102687495, recall: 0.8638573743920803, f1: 0.4731469151843317\n",
            "epoch: 380, step: 15, Train: label_loss: 0.10637406259775162, precision: 0.31843233312919056, recall: 0.8652246256238161, f1: 0.46553267677352\n",
            "epoch: 380, step: 16, Train: label_loss: 0.1027173399925232, precision: 0.31892878880095443, recall: 0.859016393442482, f1: 0.4651575676479975\n",
            "epoch: 380, step: 17, Train: label_loss: 0.10706058144569397, precision: 0.2967702620353262, recall: 0.8589065255730407, f1: 0.44112318836758696\n",
            "epoch: 380, step: 18, Train: label_loss: 0.12008543312549591, precision: 0.31083591331267424, recall: 0.8270181219109016, f1: 0.4518451844787008\n",
            "epoch: 380, step: 19, Train: label_loss: 0.0884023904800415, precision: 0.3055555555555371, recall: 0.8709122203096608, f1: 0.45239159584885524\n",
            "epoch: 380, step: 20, Train: label_loss: 0.10230547189712524, precision: 0.3155339805825051, recall: 0.8580858085807164, f1: 0.46140195204582646\n",
            "epoch: 380, step: 21, Train: label_loss: 0.10200931131839752, precision: 0.3327228327228124, recall: 0.8637083993659487, f1: 0.4803878360109297\n",
            "epoch: 380, step: 22, Train: label_loss: 0.11051978170871735, precision: 0.30623471882638714, recall: 0.8363939899831658, f1: 0.4483221476117305\n",
            "epoch: 380, step: 23, Train: label_loss: 0.10511110723018646, precision: 0.32153614457828905, recall: 0.8678861788616122, f1: 0.4692307691912673\n",
            "epoch: 381, step: 0, Train: label_loss: 0.10675472766160965, precision: 0.3267813267813067, recall: 0.8417721518986009, f1: 0.47079646013666065\n",
            "epoch: 381, step: 1, Train: label_loss: 0.104736328125, precision: 0.3288260602335385, recall: 0.855999999999863, f1: 0.47513321487992727\n",
            "epoch: 381, step: 2, Train: label_loss: 0.09724375605583191, precision: 0.3234761617380613, recall: 0.885950413222994, f1: 0.4739168876707639\n",
            "epoch: 381, step: 3, Train: label_loss: 0.11460529267787933, precision: 0.31916204559455824, recall: 0.8477905073648366, f1: 0.4637421664776763\n",
            "epoch: 381, step: 4, Train: label_loss: 0.09612146764993668, precision: 0.309422492401197, recall: 0.8730703259003647, f1: 0.4569120286866335\n",
            "epoch: 381, step: 5, Train: label_loss: 0.11578242480754852, precision: 0.30448127685694876, recall: 0.8478632478631029, f1: 0.4480578138725496\n",
            "epoch: 381, step: 6, Train: label_loss: 0.106744185090065, precision: 0.304907975460104, recall: 0.8524871355058572, f1: 0.44916403068867045\n",
            "epoch: 381, step: 7, Train: label_loss: 0.1189979761838913, precision: 0.30397022332504314, recall: 0.8333333333331916, f1: 0.4454545454153373\n",
            "epoch: 381, step: 8, Train: label_loss: 0.11985333263874054, precision: 0.3071161048688947, recall: 0.8132231404957333, f1: 0.44585410054919816\n",
            "epoch: 381, step: 9, Train: label_loss: 0.09035241603851318, precision: 0.3127646702964118, recall: 0.8762711864405294, f1: 0.46098974583724767\n",
            "epoch: 381, step: 10, Train: label_loss: 0.09971529990434647, precision: 0.30982519590112656, recall: 0.8741496598637969, f1: 0.45749888736674776\n",
            "epoch: 381, step: 11, Train: label_loss: 0.12100160121917725, precision: 0.3304293714996683, recall: 0.8362204724408131, f1: 0.47368421048567144\n",
            "epoch: 381, step: 12, Train: label_loss: 0.09890265017747879, precision: 0.3054367745876417, recall: 0.8488964346348303, f1: 0.4492362982539443\n",
            "epoch: 381, step: 13, Train: label_loss: 0.0970737487077713, precision: 0.2999392835458227, recall: 0.8546712802766687, f1: 0.4440449437817263\n",
            "epoch: 381, step: 14, Train: label_loss: 0.09858929365873337, precision: 0.32379793061470946, recall: 0.8622366288491309, f1: 0.47079646013725446\n",
            "epoch: 381, step: 15, Train: label_loss: 0.11754447221755981, precision: 0.305385556915526, recall: 0.8344481605349775, f1: 0.4471326164481872\n",
            "epoch: 381, step: 16, Train: label_loss: 0.11645437777042389, precision: 0.29613733905577583, recall: 0.8429319371726277, f1: 0.43829401085077413\n",
            "epoch: 381, step: 17, Train: label_loss: 0.10932505130767822, precision: 0.32555282555280557, recall: 0.8745874587457302, f1: 0.47448522825048434\n",
            "epoch: 381, step: 18, Train: label_loss: 0.12600933015346527, precision: 0.3322903629536713, recall: 0.8362204724408131, f1: 0.4755933721043528\n",
            "epoch: 381, step: 19, Train: label_loss: 0.10179313272237778, precision: 0.3087783916513009, recall: 0.8453781512603621, f1: 0.45233812945717017\n",
            "epoch: 381, step: 20, Train: label_loss: 0.12700265645980835, precision: 0.305396825396806, recall: 0.7833876221497095, f1: 0.43947007762062895\n",
            "epoch: 381, step: 21, Train: label_loss: 0.10895024240016937, precision: 0.3160173160172965, recall: 0.8474295190711695, f1: 0.46036036032075023\n",
            "epoch: 381, step: 22, Train: label_loss: 0.12244494259357452, precision: 0.3029150823827438, recall: 0.7697262479869935, f1: 0.4347430649889892\n",
            "epoch: 381, step: 23, Train: label_loss: 0.11357123404741287, precision: 0.2871137905048766, recall: 0.8282608695650373, f1: 0.426412982614212\n",
            "epoch: 382, step: 0, Train: label_loss: 0.11472269892692566, precision: 0.3136167590880891, recall: 0.8357963875203881, f1: 0.4560931899244363\n",
            "epoch: 382, step: 1, Train: label_loss: 0.12054918706417084, precision: 0.2931776275353231, recall: 0.8339160839159381, f1: 0.43383356067088263\n",
            "epoch: 382, step: 2, Train: label_loss: 0.1107248067855835, precision: 0.30098280098278246, recall: 0.8361774744025876, f1: 0.44263775967196556\n",
            "epoch: 382, step: 3, Train: label_loss: 0.12316849827766418, precision: 0.291640477686971, recall: 0.8055555555554157, f1: 0.42824180891339875\n",
            "epoch: 382, step: 4, Train: label_loss: 0.11258694529533386, precision: 0.30984204131225335, recall: 0.8443708609270124, f1: 0.4533333332940166\n",
            "epoch: 382, step: 5, Train: label_loss: 0.10838226974010468, precision: 0.2941903584672253, recall: 0.835087719298099, f1: 0.4351005484075006\n",
            "epoch: 382, step: 6, Train: label_loss: 0.12816432118415833, precision: 0.3124215809284622, recall: 0.8299999999998616, f1: 0.4539653600331476\n",
            "epoch: 382, step: 7, Train: label_loss: 0.11137307435274124, precision: 0.3079306071870937, recall: 0.8187808896209524, f1: 0.44754615034294876\n",
            "epoch: 382, step: 8, Train: label_loss: 0.10968105494976044, precision: 0.31462060456506385, recall: 0.8333333333331971, f1: 0.4567845946757971\n",
            "epoch: 382, step: 9, Train: label_loss: 0.09061779081821442, precision: 0.32797619047617094, recall: 0.9062499999998509, f1: 0.4816433566042906\n",
            "epoch: 382, step: 10, Train: label_loss: 0.12045739591121674, precision: 0.3248919085855266, recall: 0.8362480127184679, f1: 0.4679715302087659\n",
            "epoch: 382, step: 11, Train: label_loss: 0.10796793550252914, precision: 0.31339563862926395, recall: 0.8397328881467713, f1: 0.4564428311763465\n",
            "epoch: 382, step: 12, Train: label_loss: 0.10911989212036133, precision: 0.3041079092581052, recall: 0.8581314878891249, f1: 0.4490719782320316\n",
            "epoch: 382, step: 13, Train: label_loss: 0.11710318922996521, precision: 0.3370233702336816, recall: 0.868462757527596, f1: 0.4856003544124879\n",
            "epoch: 382, step: 14, Train: label_loss: 0.11461041122674942, precision: 0.3149411035337684, recall: 0.8452579034940356, f1: 0.4588979222729615\n",
            "epoch: 382, step: 15, Train: label_loss: 0.1147841066122055, precision: 0.3158866995073697, recall: 0.8368678629688683, f1: 0.45864997760880827\n",
            "epoch: 382, step: 16, Train: label_loss: 0.12127663195133209, precision: 0.30593325092705154, recall: 0.8404074702884821, f1: 0.44857272311443064\n",
            "epoch: 382, step: 17, Train: label_loss: 0.11637243628501892, precision: 0.30336391437307014, recall: 0.8747795414460537, f1: 0.4504995458291142\n",
            "epoch: 382, step: 18, Train: label_loss: 0.10468258708715439, precision: 0.30627306273060845, recall: 0.841216216216074, f1: 0.4490532010428818\n",
            "epoch: 382, step: 19, Train: label_loss: 0.11033712327480316, precision: 0.3199268738573845, recall: 0.8749999999998541, f1: 0.4685408299473604\n",
            "epoch: 382, step: 20, Train: label_loss: 0.1020202711224556, precision: 0.3262454434993726, recall: 0.864734299516769, f1: 0.47375385968669054\n",
            "epoch: 382, step: 21, Train: label_loss: 0.12604071199893951, precision: 0.324938574938555, recall: 0.8477564102562744, f1: 0.4698046180771254\n",
            "epoch: 382, step: 22, Train: label_loss: 0.1160682663321495, precision: 0.3260598503740445, recall: 0.8301587301585983, f1: 0.46821844221550535\n",
            "epoch: 382, step: 23, Train: label_loss: 0.13549576699733734, precision: 0.3088569265707563, recall: 0.8143712574848674, f1: 0.4478594950204514\n",
            "epoch: 383, step: 0, Train: label_loss: 0.11517331004142761, precision: 0.3069427527405416, recall: 0.8689655172412294, f1: 0.45364536449783455\n",
            "epoch: 383, step: 1, Train: label_loss: 0.10454784333705902, precision: 0.3048855905998574, recall: 0.8355932203388413, f1: 0.44676030807134376\n",
            "epoch: 383, step: 2, Train: label_loss: 0.10904933512210846, precision: 0.3168498168497975, recall: 0.8649999999998558, f1: 0.46380697047009767\n",
            "epoch: 383, step: 3, Train: label_loss: 0.09885837137699127, precision: 0.3237063778579829, recall: 0.8790849673201178, f1: 0.47317502194830546\n",
            "epoch: 383, step: 4, Train: label_loss: 0.1135345846414566, precision: 0.3079754601226805, recall: 0.8581196581195114, f1: 0.453273137658605\n",
            "epoch: 383, step: 5, Train: label_loss: 0.11596822738647461, precision: 0.2982349360924955, recall: 0.864197530864045, f1: 0.44343891398896174\n",
            "epoch: 383, step: 6, Train: label_loss: 0.11813215166330338, precision: 0.30918176139910625, recall: 0.8208955223879235, f1: 0.44918330304551063\n",
            "epoch: 383, step: 7, Train: label_loss: 0.10097245126962662, precision: 0.33696969696967655, recall: 0.8895999999998576, f1: 0.48879120875131554\n",
            "epoch: 383, step: 8, Train: label_loss: 0.1058947741985321, precision: 0.32865853658534583, recall: 0.8707592891759497, f1: 0.4772023018636687\n",
            "epoch: 383, step: 9, Train: label_loss: 0.11059384047985077, precision: 0.29900744416871594, recall: 0.8324697754748129, f1: 0.43998174345719465\n",
            "epoch: 383, step: 10, Train: label_loss: 0.11661335825920105, precision: 0.34008594229586614, recall: 0.849693251533612, f1: 0.48575186317701713\n",
            "epoch: 383, step: 11, Train: label_loss: 0.09765943884849548, precision: 0.31563065781530986, recall: 0.8531810766719652, f1: 0.4607929515023856\n",
            "epoch: 383, step: 12, Train: label_loss: 0.10371076315641403, precision: 0.3150183150182958, recall: 0.8643216080400562, f1: 0.46174496640375884\n",
            "epoch: 383, step: 13, Train: label_loss: 0.10368552803993225, precision: 0.321559074299615, recall: 0.8698517298186376, f1: 0.46954201863551426\n",
            "epoch: 383, step: 14, Train: label_loss: 0.13678137958049774, precision: 0.285175879396967, recall: 0.8121645796062947, f1: 0.42212924217441655\n",
            "epoch: 383, step: 15, Train: label_loss: 0.11656045913696289, precision: 0.319461444308426, recall: 0.8613861386137192, f1: 0.4660714285319177\n",
            "epoch: 383, step: 16, Train: label_loss: 0.12159742414951324, precision: 0.3112623762376045, recall: 0.8397328881467713, f1: 0.45417607219526257\n",
            "epoch: 383, step: 17, Train: label_loss: 0.10763974487781525, precision: 0.3240460327074304, recall: 0.8642972536347553, f1: 0.4713656387268125\n",
            "epoch: 383, step: 18, Train: label_loss: 0.1149074137210846, precision: 0.3228004956629292, recall: 0.8403225806450257, f1: 0.46642793192046567\n",
            "epoch: 383, step: 19, Train: label_loss: 0.10306615382432938, precision: 0.3232077764276839, recall: 0.8941176470586731, f1: 0.4747880410140563\n",
            "epoch: 383, step: 20, Train: label_loss: 0.10358881950378418, precision: 0.3254688445250862, recall: 0.8907284768210445, f1: 0.4767390340768418\n",
            "epoch: 383, step: 21, Train: label_loss: 0.1242818683385849, precision: 0.30717351318207803, recall: 0.8564102564101099, f1: 0.45216606494304884\n",
            "epoch: 383, step: 22, Train: label_loss: 0.10873260349035263, precision: 0.3357531760435368, recall: 0.8951612903224362, f1: 0.48834139899240003\n",
            "epoch: 383, step: 23, Train: label_loss: 0.13388115167617798, precision: 0.3055344958301512, recall: 0.8343685300205312, f1: 0.44728079907280954\n",
            "epoch: 384, step: 0, Train: label_loss: 0.09580451995134354, precision: 0.32429174201324146, recall: 0.8819672131146095, f1: 0.4742177170166169\n",
            "epoch: 384, step: 1, Train: label_loss: 0.10501372814178467, precision: 0.3211678832116593, recall: 0.8698517298186376, f1: 0.4691248333679443\n",
            "epoch: 384, step: 2, Train: label_loss: 0.11233390867710114, precision: 0.30238240684176526, recall: 0.8534482758619217, f1: 0.44654939103033736\n",
            "epoch: 384, step: 3, Train: label_loss: 0.11611250042915344, precision: 0.30326876513315354, recall: 0.859348198970693, f1: 0.4483221476124051\n",
            "epoch: 384, step: 4, Train: label_loss: 0.10709437727928162, precision: 0.31034482758618775, recall: 0.842809364548354, f1: 0.4536453644970732\n",
            "epoch: 384, step: 5, Train: label_loss: 0.11618036031723022, precision: 0.30476765238380776, recall: 0.8588435374148199, f1: 0.4498886413866865\n",
            "epoch: 384, step: 6, Train: label_loss: 0.10923131555318832, precision: 0.3065015479875971, recall: 0.8208955223879235, f1: 0.44634806127687\n",
            "epoch: 384, step: 7, Train: label_loss: 0.10030756890773773, precision: 0.3361858190708841, recall: 0.8702531645568242, f1: 0.4850088183019072\n",
            "epoch: 384, step: 8, Train: label_loss: 0.09679721295833588, precision: 0.3140794223826526, recall: 0.8938356164382031, f1: 0.4648263579312008\n",
            "epoch: 384, step: 9, Train: label_loss: 0.11347749829292297, precision: 0.3187960687960492, recall: 0.8522167487683329, f1: 0.46401430483293066\n",
            "epoch: 384, step: 10, Train: label_loss: 0.12235365062952042, precision: 0.3045089561457502, recall: 0.8327702702701295, f1: 0.4459520578531038\n",
            "epoch: 384, step: 11, Train: label_loss: 0.11361545324325562, precision: 0.316207951070317, recall: 0.8602329450913709, f1: 0.46243291588193886\n",
            "epoch: 384, step: 12, Train: label_loss: 0.10412853956222534, precision: 0.31268973891922813, recall: 0.845648604269155, f1: 0.4565602836484876\n",
            "epoch: 384, step: 13, Train: label_loss: 0.1105513796210289, precision: 0.3013530135301168, recall: 0.8506944444442966, f1: 0.4450499545480676\n",
            "epoch: 384, step: 14, Train: label_loss: 0.09124119579792023, precision: 0.3212996389891503, recall: 0.8841059602647542, f1: 0.47131509263517424\n",
            "epoch: 384, step: 15, Train: label_loss: 0.10997529327869415, precision: 0.30048959608321296, recall: 0.8494809688579844, f1: 0.4439421337769068\n",
            "epoch: 384, step: 16, Train: label_loss: 0.11882912367582321, precision: 0.33414485696893886, recall: 0.8783999999998594, f1: 0.4841269840870149\n",
            "epoch: 384, step: 17, Train: label_loss: 0.10930091142654419, precision: 0.34155363748456585, recall: 0.8642745709827044, f1: 0.48961555453292754\n",
            "epoch: 384, step: 18, Train: label_loss: 0.10522964596748352, precision: 0.3265306122448778, recall: 0.8543689320386967, f1: 0.47248322143645743\n",
            "epoch: 384, step: 19, Train: label_loss: 0.10563310235738754, precision: 0.3150431565967747, recall: 0.8502495840264808, f1: 0.4597390912785447\n",
            "epoch: 384, step: 20, Train: label_loss: 0.10676896572113037, precision: 0.3122311001843692, recall: 0.8452579034940356, f1: 0.4560143626176537\n",
            "epoch: 384, step: 21, Train: label_loss: 0.11156993359327316, precision: 0.3110018438844308, recall: 0.8281505728312883, f1: 0.45218945483068435\n",
            "epoch: 384, step: 22, Train: label_loss: 0.11144810914993286, precision: 0.3030303030302843, recall: 0.8085808580856751, f1: 0.4408457039639008\n",
            "epoch: 384, step: 23, Train: label_loss: 0.11724816262722015, precision: 0.3025335320417062, recall: 0.8787878787876886, f1: 0.4501108647068588\n",
            "epoch: 385, step: 0, Train: label_loss: 0.12284228950738907, precision: 0.31338679827265187, recall: 0.8341543513955937, f1: 0.4556053811261757\n",
            "epoch: 385, step: 1, Train: label_loss: 0.11031226068735123, precision: 0.33272616879172234, recall: 0.8602825745681537, f1: 0.4798598948809262\n",
            "epoch: 385, step: 2, Train: label_loss: 0.1163715347647667, precision: 0.3223844282238247, recall: 0.8731466227346172, f1: 0.4709018213732752\n",
            "epoch: 385, step: 3, Train: label_loss: 0.09739771485328674, precision: 0.3152173913043288, recall: 0.8699999999998549, f1: 0.46276595740772264\n",
            "epoch: 385, step: 4, Train: label_loss: 0.09633022546768188, precision: 0.3309265944644807, recall: 0.9016393442621472, f1: 0.48415492953814193\n",
            "epoch: 385, step: 5, Train: label_loss: 0.13058915734291077, precision: 0.3206349206349003, recall: 0.8292282430212102, f1: 0.4624542124139519\n",
            "epoch: 385, step: 6, Train: label_loss: 0.10041020810604095, precision: 0.32987804878046767, recall: 0.861464968152729, f1: 0.4770723103655567\n",
            "epoch: 385, step: 7, Train: label_loss: 0.11849716305732727, precision: 0.3004926108374199, recall: 0.8413793103446825, f1: 0.44283121593214053\n",
            "epoch: 385, step: 8, Train: label_loss: 0.10194222629070282, precision: 0.3119658119657929, recall: 0.8661016949151074, f1: 0.45870736082278096\n",
            "epoch: 385, step: 9, Train: label_loss: 0.10891906172037125, precision: 0.30651105651103766, recall: 0.8443316412858131, f1: 0.4497521405647549\n",
            "epoch: 385, step: 10, Train: label_loss: 0.11179591715335846, precision: 0.31257706535139873, recall: 0.8352553542008508, f1: 0.4549125167840146\n",
            "epoch: 385, step: 11, Train: label_loss: 0.10135175287723541, precision: 0.30102967898241667, recall: 0.8704028021014237, f1: 0.44734473443521927\n",
            "epoch: 385, step: 12, Train: label_loss: 0.1164766252040863, precision: 0.33149847094799195, recall: 0.8630573248406268, f1: 0.4790101634596372\n",
            "epoch: 385, step: 13, Train: label_loss: 0.12101995199918747, precision: 0.31792975970423176, recall: 0.8417618270797974, f1: 0.4615384614986219\n",
            "epoch: 385, step: 14, Train: label_loss: 0.10325586795806885, precision: 0.31219806763283137, recall: 0.8703703703702238, f1: 0.4595555555166539\n",
            "epoch: 385, step: 15, Train: label_loss: 0.1155540943145752, precision: 0.2987577639751367, recall: 0.8307426597580603, f1: 0.4394700776220839\n",
            "epoch: 385, step: 16, Train: label_loss: 0.11872802674770355, precision: 0.30816077953713106, recall: 0.8620102214649298, f1: 0.4540152534380556\n",
            "epoch: 385, step: 17, Train: label_loss: 0.12220257520675659, precision: 0.30721393034823957, recall: 0.8401360544216258, f1: 0.44990892527950743\n",
            "epoch: 385, step: 18, Train: label_loss: 0.14058364927768707, precision: 0.30581613508440864, recall: 0.8402061855668659, f1: 0.4484181567696339\n",
            "epoch: 385, step: 19, Train: label_loss: 0.10762591660022736, precision: 0.3238498789346051, recall: 0.8727569331156814, f1: 0.47240618097593196\n",
            "epoch: 385, step: 20, Train: label_loss: 0.1068313717842102, precision: 0.30759878419451014, recall: 0.8664383561642351, f1: 0.4540152534381834\n",
            "epoch: 385, step: 21, Train: label_loss: 0.11971874535083771, precision: 0.3127698951264458, recall: 0.8449999999998591, f1: 0.45655110306723384\n",
            "epoch: 385, step: 22, Train: label_loss: 0.09977185726165771, precision: 0.32345828295040363, recall: 0.8629032258063124, f1: 0.4705364995205426\n",
            "epoch: 385, step: 23, Train: label_loss: 0.11217385530471802, precision: 0.3173652694610541, recall: 0.8617886178860037, f1: 0.46389496713785083\n",
            "epoch: 386, step: 0, Train: label_loss: 0.11551038920879364, precision: 0.3211233211233015, recall: 0.8637110016418942, f1: 0.46817979524304293\n",
            "epoch: 386, step: 1, Train: label_loss: 0.1173441931605339, precision: 0.298288508557439, recall: 0.8516579406630276, f1: 0.441828881808528\n",
            "epoch: 386, step: 2, Train: label_loss: 0.11084867268800735, precision: 0.31015719467954594, recall: 0.8799313893652007, f1: 0.4586499776100564\n",
            "epoch: 386, step: 3, Train: label_loss: 0.10060535371303558, precision: 0.31607795371496245, recall: 0.8678929765884835, f1: 0.4633928571036768\n",
            "epoch: 386, step: 4, Train: label_loss: 0.11320473253726959, precision: 0.3238153098420216, recall: 0.8596774193547, f1: 0.4704324801014269\n",
            "epoch: 386, step: 5, Train: label_loss: 0.1073998361825943, precision: 0.3353365384615183, recall: 0.8871224165340401, f1: 0.4866986480194554\n",
            "epoch: 386, step: 6, Train: label_loss: 0.12190023064613342, precision: 0.3180124223602287, recall: 0.82580645161277, f1: 0.45919282507192083\n",
            "epoch: 386, step: 7, Train: label_loss: 0.11172943562269211, precision: 0.29796421961750164, recall: 0.8298969072163522, f1: 0.4384929641008912\n",
            "epoch: 386, step: 8, Train: label_loss: 0.10141805559396744, precision: 0.3101538461538271, recall: 0.8456375838924755, f1: 0.4538496172502009\n",
            "epoch: 386, step: 9, Train: label_loss: 0.11267191171646118, precision: 0.30811470408783964, recall: 0.8487394957981766, f1: 0.45210384955801425\n",
            "epoch: 386, step: 10, Train: label_loss: 0.1170293539762497, precision: 0.30940594059404025, recall: 0.8278145695362867, f1: 0.45045045041080006\n",
            "epoch: 386, step: 11, Train: label_loss: 0.10851101577281952, precision: 0.3367907260524505, recall: 0.8775834658186203, f1: 0.48677248673235957\n",
            "epoch: 386, step: 12, Train: label_loss: 0.11208070814609528, precision: 0.3201460742543932, recall: 0.8679867986797247, f1: 0.46776345038299877\n",
            "epoch: 386, step: 13, Train: label_loss: 0.10790122300386429, precision: 0.2958179581795636, recall: 0.8336221837086942, f1: 0.4366772582454551\n",
            "epoch: 386, step: 14, Train: label_loss: 0.10996487736701965, precision: 0.3040581465778132, recall: 0.8822495606325338, f1: 0.4522522522140889\n",
            "epoch: 386, step: 15, Train: label_loss: 0.10812697559595108, precision: 0.3323152107513542, recall: 0.8621236133120662, f1: 0.4797178130109414\n",
            "epoch: 386, step: 16, Train: label_loss: 0.1104653850197792, precision: 0.319606637984, recall: 0.8609271523177382, f1: 0.4661586732011702\n",
            "epoch: 386, step: 17, Train: label_loss: 0.12117068469524384, precision: 0.308581862446725, recall: 0.8786828422875427, f1: 0.4567567567182442\n",
            "epoch: 386, step: 18, Train: label_loss: 0.11949275434017181, precision: 0.3035279805352613, recall: 0.8739054290716507, f1: 0.4505643340474713\n",
            "epoch: 386, step: 19, Train: label_loss: 0.11586059629917145, precision: 0.3041871921182079, recall: 0.8458904109587592, f1: 0.44746376807699423\n",
            "epoch: 386, step: 20, Train: label_loss: 0.11918305605649948, precision: 0.3038130381303626, recall: 0.8415672913116112, f1: 0.44645277899396796\n",
            "epoch: 386, step: 21, Train: label_loss: 0.10801497846841812, precision: 0.3562386980108284, recall: 0.8847305389220231, f1: 0.5079501503672755\n",
            "epoch: 386, step: 22, Train: label_loss: 0.11345532536506653, precision: 0.29724770642200016, recall: 0.8466898954702357, f1: 0.4400181077025542\n",
            "epoch: 386, step: 23, Train: label_loss: 0.10137230157852173, precision: 0.34782608695649564, recall: 0.8705440900561218, f1: 0.4970540974417425\n",
            "epoch: 387, step: 0, Train: label_loss: 0.1008477658033371, precision: 0.32078963602712396, recall: 0.8387096774192195, f1: 0.4640785363276276\n",
            "epoch: 387, step: 1, Train: label_loss: 0.11129368841648102, precision: 0.3205596107055766, recall: 0.8639344262293666, f1: 0.46761313216988615\n",
            "epoch: 387, step: 2, Train: label_loss: 0.11010091006755829, precision: 0.31640146878823033, recall: 0.8311897106107988, f1: 0.45833333329335396\n",
            "epoch: 387, step: 3, Train: label_loss: 0.11441473662853241, precision: 0.3189812007276944, recall: 0.8795986622072107, f1: 0.4681797952434961\n",
            "epoch: 387, step: 4, Train: label_loss: 0.10000000894069672, precision: 0.327848872638615, recall: 0.8553259141493075, f1: 0.4740088105325829\n",
            "epoch: 387, step: 5, Train: label_loss: 0.0966271311044693, precision: 0.3056397816858517, recall: 0.855687606111909, f1: 0.4504021447332944\n",
            "epoch: 387, step: 6, Train: label_loss: 0.107811838388443, precision: 0.3052695336159718, recall: 0.8734835355284447, f1: 0.4524236983457789\n",
            "epoch: 387, step: 7, Train: label_loss: 0.09896956384181976, precision: 0.3124231242312231, recall: 0.8610169491523963, f1: 0.4584837544735222\n",
            "epoch: 387, step: 8, Train: label_loss: 0.10451007634401321, precision: 0.32129742962054336, recall: 0.8578431372547617, f1: 0.4674977737804357\n",
            "epoch: 387, step: 9, Train: label_loss: 0.10434417426586151, precision: 0.30862697448357784, recall: 0.8639455782311455, f1: 0.45478961500146015\n",
            "epoch: 387, step: 10, Train: label_loss: 0.09727142006158829, precision: 0.30978260869563345, recall: 0.8709677419353359, f1: 0.4570155901616992\n",
            "epoch: 387, step: 11, Train: label_loss: 0.09996367990970612, precision: 0.3083941605839228, recall: 0.8593220338981594, f1: 0.4538943598536585\n",
            "epoch: 387, step: 12, Train: label_loss: 0.12526792287826538, precision: 0.2912621359223124, recall: 0.8633093525178303, f1: 0.435571687802525\n",
            "epoch: 387, step: 13, Train: label_loss: 0.12183944880962372, precision: 0.33578431372546963, recall: 0.8712241653416738, f1: 0.48474126488682\n",
            "epoch: 387, step: 14, Train: label_loss: 0.10171276330947876, precision: 0.3138330286410534, recall: 0.8612040133777823, f1: 0.4600267976383436\n",
            "epoch: 387, step: 15, Train: label_loss: 0.11842319369316101, precision: 0.3103448275861881, recall: 0.878424657534096, f1: 0.4586499776100136\n",
            "epoch: 387, step: 16, Train: label_loss: 0.11364834010601044, precision: 0.3269468479604248, recall: 0.8463999999998645, f1: 0.4716897012526688\n",
            "epoch: 387, step: 17, Train: label_loss: 0.11306412518024445, precision: 0.3189122373300174, recall: 0.8514851485147109, f1: 0.46402877693872846\n",
            "epoch: 387, step: 18, Train: label_loss: 0.1256246715784073, precision: 0.30545454545452694, recall: 0.8719723183389494, f1: 0.45242369834573565\n",
            "epoch: 387, step: 19, Train: label_loss: 0.12453445792198181, precision: 0.30506406345330656, recall: 0.88028169014069, f1: 0.4531037607229477\n",
            "epoch: 387, step: 20, Train: label_loss: 0.12146304547786713, precision: 0.31578947368419097, recall: 0.8360655737703547, f1: 0.45842696625229457\n",
            "epoch: 387, step: 21, Train: label_loss: 0.09923027455806732, precision: 0.32628398791538815, recall: 0.8723747980612483, f1: 0.4749340368996501\n",
            "epoch: 387, step: 22, Train: label_loss: 0.12891104817390442, precision: 0.32620993086107314, recall: 0.7947932618681783, f1: 0.4625668448784812\n",
            "epoch: 387, step: 23, Train: label_loss: 0.12205751240253448, precision: 0.295180722891544, recall: 0.8183716075154868, f1: 0.43386828994438736\n",
            "epoch: 388, step: 0, Train: label_loss: 0.11888884007930756, precision: 0.28348909657319105, recall: 0.8139534883719474, f1: 0.42051756003558033\n",
            "epoch: 388, step: 1, Train: label_loss: 0.14957532286643982, precision: 0.30437580437578476, recall: 0.7922948073700515, f1: 0.43979544393940073\n",
            "epoch: 388, step: 2, Train: label_loss: 0.11761653423309326, precision: 0.3100917431192471, recall: 0.8380165289254813, f1: 0.4526785713891027\n",
            "epoch: 388, step: 3, Train: label_loss: 0.11382453888654709, precision: 0.3113440197287108, recall: 0.8402662229615906, f1: 0.45434098061727657\n",
            "epoch: 388, step: 4, Train: label_loss: 0.13500800728797913, precision: 0.3092189500640007, recall: 0.7853658536584088, f1: 0.44372990349639807\n",
            "epoch: 388, step: 5, Train: label_loss: 0.11918849498033524, precision: 0.3113207547169615, recall: 0.8009708737862781, f1: 0.44836956517704024\n",
            "epoch: 388, step: 6, Train: label_loss: 0.1462801694869995, precision: 0.3082901554403945, recall: 0.7752442996741408, f1: 0.4411492121927948\n",
            "epoch: 388, step: 7, Train: label_loss: 0.11638207733631134, precision: 0.3335388409370941, recall: 0.8669871794870405, f1: 0.48174532498209105\n",
            "epoch: 388, step: 8, Train: label_loss: 0.11899881064891815, precision: 0.2851828890266407, recall: 0.8041958041956635, f1: 0.42105263154025807\n",
            "epoch: 388, step: 9, Train: label_loss: 0.12288245558738708, precision: 0.3163841807909406, recall: 0.8275862068964158, f1: 0.4577656675348748\n",
            "epoch: 388, step: 10, Train: label_loss: 0.12816251814365387, precision: 0.32316313823161125, recall: 0.8370967741934133, f1: 0.46630727758780055\n",
            "epoch: 388, step: 11, Train: label_loss: 0.11845376342535019, precision: 0.31523750771126985, recall: 0.8390804597699771, f1: 0.4582959640858167\n",
            "epoch: 388, step: 12, Train: label_loss: 0.11221763491630554, precision: 0.28271604938269856, recall: 0.8282097649184759, f1: 0.4215370455211513\n",
            "epoch: 388, step: 13, Train: label_loss: 0.10824545472860336, precision: 0.31512868801002414, recall: 0.8422818791944895, f1: 0.458656920928809\n",
            "epoch: 388, step: 14, Train: label_loss: 0.11615137755870819, precision: 0.31854590264939503, recall: 0.8517298187807493, f1: 0.46367713000518024\n",
            "epoch: 388, step: 15, Train: label_loss: 0.13337653875350952, precision: 0.3262366938008562, recall: 0.8389694041866603, f1: 0.4697926059109466\n",
            "epoch: 388, step: 16, Train: label_loss: 0.11944934725761414, precision: 0.3312616532007252, recall: 0.8487261146495463, f1: 0.476531068354745\n",
            "epoch: 388, step: 17, Train: label_loss: 0.11717718094587326, precision: 0.3121175030599564, recall: 0.858585858585714, f1: 0.45780969475439015\n",
            "epoch: 388, step: 18, Train: label_loss: 0.11232610791921616, precision: 0.31904470300059284, recall: 0.8499184339313458, f1: 0.46393588597986124\n",
            "epoch: 388, step: 19, Train: label_loss: 0.122653529047966, precision: 0.3022670025188726, recall: 0.8318890814556616, f1: 0.44341801381767515\n",
            "epoch: 388, step: 20, Train: label_loss: 0.11562749743461609, precision: 0.3316892725030622, recall: 0.8580542264751422, f1: 0.47843485989749435\n",
            "epoch: 388, step: 21, Train: label_loss: 0.1375792771577835, precision: 0.3036159600997317, recall: 0.84402079722689, f1: 0.4465841356786064\n",
            "epoch: 388, step: 22, Train: label_loss: 0.1633313149213791, precision: 0.2895579756566118, recall: 0.7766323024053647, f1: 0.42183854405745574\n",
            "epoch: 388, step: 23, Train: label_loss: 0.1440444439649582, precision: 0.3121069182389692, recall: 0.7924151696605205, f1: 0.44782853915850207\n",
            "epoch: 389, step: 0, Train: label_loss: 0.1550089567899704, precision: 0.30857142857140896, recall: 0.8059701492535977, f1: 0.44628099169545454\n",
            "epoch: 389, step: 1, Train: label_loss: 0.1492483913898468, precision: 0.3168380462724732, recall: 0.7900641025639759, f1: 0.4522935779407486\n",
            "epoch: 389, step: 2, Train: label_loss: 0.1461169570684433, precision: 0.3083280356007433, recall: 0.8151260504200311, f1: 0.4474169741298753\n",
            "epoch: 389, step: 3, Train: label_loss: 0.131953626871109, precision: 0.3071608040200812, recall: 0.8042763157893413, f1: 0.4445454545054167\n",
            "epoch: 389, step: 4, Train: label_loss: 0.1427481472492218, precision: 0.3006289308175911, recall: 0.8020134228186573, f1: 0.4373284537571874\n",
            "epoch: 389, step: 5, Train: label_loss: 0.1327836811542511, precision: 0.31371321227299226, recall: 0.8159609120519843, f1: 0.453188602402176\n",
            "epoch: 389, step: 6, Train: label_loss: 0.13563188910484314, precision: 0.3300553165334769, recall: 0.864734299516769, f1: 0.4777580070774084\n",
            "epoch: 389, step: 7, Train: label_loss: 0.14207857847213745, precision: 0.2949194547707376, recall: 0.8469750889678208, f1: 0.4374999999616463\n",
            "epoch: 389, step: 8, Train: label_loss: 0.1357598900794983, precision: 0.318633540372651, recall: 0.8194888178912428, f1: 0.4588550983496242\n",
            "epoch: 389, step: 9, Train: label_loss: 0.1418432742357254, precision: 0.32051282051279995, recall: 0.7961783439489177, f1: 0.4570383911838931\n",
            "epoch: 389, step: 10, Train: label_loss: 0.13235649466514587, precision: 0.32012578616350185, recall: 0.8249594813612925, f1: 0.46125962841459267\n",
            "epoch: 389, step: 11, Train: label_loss: 0.13167804479599, precision: 0.29308176100627087, recall: 0.8277087033746309, f1: 0.4328843473835382\n",
            "epoch: 389, step: 12, Train: label_loss: 0.13785386085510254, precision: 0.29574861367835514, recall: 0.8275862068964089, f1: 0.43576940531750025\n",
            "epoch: 389, step: 13, Train: label_loss: 0.14216198027133942, precision: 0.3242236024844519, recall: 0.8571428571427163, f1: 0.4704821991489561\n",
            "epoch: 389, step: 14, Train: label_loss: 0.12811784446239471, precision: 0.3117206982543447, recall: 0.8116883116881799, f1: 0.45045045041031306\n",
            "epoch: 389, step: 15, Train: label_loss: 0.13065311312675476, precision: 0.3129381771828991, recall: 0.8049180327867532, f1: 0.4506654428233424\n",
            "epoch: 389, step: 16, Train: label_loss: 0.141969233751297, precision: 0.293971410814152, recall: 0.825479930191828, f1: 0.433547204360865\n",
            "epoch: 389, step: 17, Train: label_loss: 0.13968709111213684, precision: 0.30847673677499626, recall: 0.7908496732024851, f1: 0.44383310404028303\n",
            "epoch: 389, step: 18, Train: label_loss: 0.12165095657110214, precision: 0.3168927250308066, recall: 0.859531772575107, f1: 0.4630630630236594\n",
            "epoch: 389, step: 19, Train: label_loss: 0.1268487423658371, precision: 0.3201238390092681, recall: 0.843393148450107, f1: 0.46409335723116635\n",
            "epoch: 389, step: 20, Train: label_loss: 0.1145729273557663, precision: 0.31115218730743616, recall: 0.8473154362414685, f1: 0.4551599819345313\n",
            "epoch: 389, step: 21, Train: label_loss: 0.11539915204048157, precision: 0.3161720169593994, recall: 0.8671096345513509, f1: 0.46338215708463304\n",
            "epoch: 389, step: 22, Train: label_loss: 0.12051686644554138, precision: 0.2911084043848787, recall: 0.8659420289853503, f1: 0.4357338194700497\n",
            "epoch: 389, step: 23, Train: label_loss: 0.09183645248413086, precision: 0.32686567164176666, recall: 0.8742514970058135, f1: 0.4758283541156832\n",
            "epoch: 390, step: 0, Train: label_loss: 0.1156008318066597, precision: 0.2976117575015127, recall: 0.8422876949738575, f1: 0.43981900448626304\n",
            "epoch: 390, step: 1, Train: label_loss: 0.12972001731395721, precision: 0.3064220183486051, recall: 0.8578767123286202, f1: 0.45155475435504705\n",
            "epoch: 390, step: 2, Train: label_loss: 0.12022113054990768, precision: 0.3279503105589858, recall: 0.8341232227486833, f1: 0.47079803830095135\n",
            "epoch: 390, step: 3, Train: label_loss: 0.11530677229166031, precision: 0.3160463697376256, recall: 0.8662207357858083, f1: 0.46312025029605675\n",
            "epoch: 390, step: 4, Train: label_loss: 0.10461954772472382, precision: 0.3196374622356302, recall: 0.8772802653398213, f1: 0.46855624442493915\n",
            "epoch: 390, step: 5, Train: label_loss: 0.10481667518615723, precision: 0.3074096754439493, recall: 0.8283828382836916, f1: 0.44841447070634827\n",
            "epoch: 390, step: 6, Train: label_loss: 0.10620523244142532, precision: 0.3100490196078241, recall: 0.8489932885904615, f1: 0.45421903048141626\n",
            "epoch: 390, step: 7, Train: label_loss: 0.10986978560686111, precision: 0.32555282555280557, recall: 0.8576051779933886, f1: 0.4719501335308615\n",
            "epoch: 390, step: 8, Train: label_loss: 0.118685781955719, precision: 0.33006134969323125, recall: 0.8649517684886069, f1: 0.4777975132814669\n",
            "epoch: 390, step: 9, Train: label_loss: 0.11478910595178604, precision: 0.2994522215459343, recall: 0.8646748681896547, f1: 0.4448462929093057\n",
            "epoch: 390, step: 10, Train: label_loss: 0.10175379365682602, precision: 0.318814277071971, recall: 0.875415282391881, f1: 0.46740576492756036\n",
            "epoch: 390, step: 11, Train: label_loss: 0.10888339579105377, precision: 0.3049601959583402, recall: 0.8455008488962911, f1: 0.4482448244434457\n",
            "epoch: 390, step: 12, Train: label_loss: 0.11557026207447052, precision: 0.3223844282238247, recall: 0.8745874587457302, f1: 0.47111111107171066\n",
            "epoch: 390, step: 13, Train: label_loss: 0.12501344084739685, precision: 0.30445699937223447, recall: 0.8096828046743222, f1: 0.4425182481354237\n",
            "epoch: 390, step: 14, Train: label_loss: 0.10135036706924438, precision: 0.31234718826403957, recall: 0.8573825503354265, f1: 0.4578853046203127\n",
            "epoch: 390, step: 15, Train: label_loss: 0.11908240616321564, precision: 0.326315789473664, recall: 0.8351822503960641, f1: 0.4692787176799471\n",
            "epoch: 390, step: 16, Train: label_loss: 0.12145885825157166, precision: 0.32988435788190323, recall: 0.8856209150325349, f1: 0.4807095343284801\n",
            "epoch: 390, step: 17, Train: label_loss: 0.1137775182723999, precision: 0.3199513381994939, recall: 0.8497576736670678, f1: 0.4648696420282678\n",
            "epoch: 390, step: 18, Train: label_loss: 0.1099429652094841, precision: 0.3100917431192471, recall: 0.84782608695638, f1: 0.45409762647216223\n",
            "epoch: 390, step: 19, Train: label_loss: 0.131556898355484, precision: 0.3139240506328915, recall: 0.8051948051946745, f1: 0.45173041890312776\n",
            "epoch: 390, step: 20, Train: label_loss: 0.11637234687805176, precision: 0.30933496034165286, recall: 0.8756476683936311, f1: 0.45716862034009814\n",
            "epoch: 390, step: 21, Train: label_loss: 0.12648725509643555, precision: 0.2952853598014705, recall: 0.8499999999998481, f1: 0.4383057089856303\n",
            "epoch: 390, step: 22, Train: label_loss: 0.12164553999900818, precision: 0.3394607843137047, recall: 0.8835725677829531, f1: 0.49048251434674967\n",
            "epoch: 390, step: 23, Train: label_loss: 0.1240440160036087, precision: 0.3141361256544268, recall: 0.8768267223380216, f1: 0.46255506604040547\n",
            "epoch: 391, step: 0, Train: label_loss: 0.09564570337533951, precision: 0.322935779816494, recall: 0.8712871287127274, f1: 0.47121820611846493\n",
            "epoch: 391, step: 1, Train: label_loss: 0.1119953989982605, precision: 0.3253676470588036, recall: 0.8468899521529749, f1: 0.4701195218722052\n",
            "epoch: 391, step: 2, Train: label_loss: 0.11987775564193726, precision: 0.3201701093559951, recall: 0.8569105691055516, f1: 0.46616541349418983\n",
            "epoch: 391, step: 3, Train: label_loss: 0.09932126104831696, precision: 0.2926682692307516, recall: 0.8806509945748859, f1: 0.4393324311758681\n",
            "epoch: 391, step: 4, Train: label_loss: 0.11213605105876923, precision: 0.3252937538651623, recall: 0.8375796178342615, f1: 0.46859688191957266\n",
            "epoch: 391, step: 5, Train: label_loss: 0.1111244410276413, precision: 0.30378177309359555, recall: 0.8139534883719578, f1: 0.44243792321094094\n",
            "epoch: 391, step: 6, Train: label_loss: 0.11509586870670319, precision: 0.3066095471236042, recall: 0.8505942275041, f1: 0.4507422401769328\n",
            "epoch: 391, step: 7, Train: label_loss: 0.10080873966217041, precision: 0.3135233474833042, recall: 0.8645484949831329, f1: 0.46016911433561963\n",
            "epoch: 391, step: 8, Train: label_loss: 0.1099979355931282, precision: 0.3093788063337205, recall: 0.8773747841103838, f1: 0.4574515983405209\n",
            "epoch: 391, step: 9, Train: label_loss: 0.10796889662742615, precision: 0.3147581139007768, recall: 0.8624161073824056, f1: 0.4611933602120143\n",
            "epoch: 391, step: 10, Train: label_loss: 0.09527774900197983, precision: 0.3311298076922878, recall: 0.8746031746030357, f1: 0.48038360937598396\n",
            "epoch: 391, step: 11, Train: label_loss: 0.1085529774427414, precision: 0.313967861557459, recall: 0.8076311605722086, f1: 0.45215843342649076\n",
            "epoch: 391, step: 12, Train: label_loss: 0.13031311333179474, precision: 0.3168927250308066, recall: 0.8250401284107824, f1: 0.4579064587571874\n",
            "epoch: 391, step: 13, Train: label_loss: 0.11409943550825119, precision: 0.33211233211231184, recall: 0.8788368336024428, f1: 0.4820558262782706\n",
            "epoch: 391, step: 14, Train: label_loss: 0.11179882287979126, precision: 0.32400497512435794, recall: 0.8444084278766865, f1: 0.46831460670144964\n",
            "epoch: 391, step: 15, Train: label_loss: 0.10644309222698212, precision: 0.316463414634127, recall: 0.8708053691273706, f1: 0.4642218246477994\n",
            "epoch: 391, step: 16, Train: label_loss: 0.12175487726926804, precision: 0.3161131611315919, recall: 0.8538205980065027, f1: 0.46140035902694776\n",
            "epoch: 391, step: 17, Train: label_loss: 0.11317966878414154, precision: 0.31591737545563087, recall: 0.8637873754151388, f1: 0.46263345191803823\n",
            "epoch: 391, step: 18, Train: label_loss: 0.11415921151638031, precision: 0.3031618102913637, recall: 0.8548951048949553, f1: 0.447597253965885\n",
            "epoch: 391, step: 19, Train: label_loss: 0.1264055371284485, precision: 0.2875078468298627, recall: 0.8163992869873767, f1: 0.42525533886580175\n",
            "epoch: 391, step: 20, Train: label_loss: 0.12086795270442963, precision: 0.3153042409342154, recall: 0.8396072013091915, f1: 0.4584450401747409\n",
            "epoch: 391, step: 21, Train: label_loss: 0.1160169392824173, precision: 0.30514705882351073, recall: 0.8556701030926365, f1: 0.44986449860619165\n",
            "epoch: 391, step: 22, Train: label_loss: 0.10358171164989471, precision: 0.31257557436515643, recall: 0.8703703703702238, f1: 0.45996441277246397\n",
            "epoch: 391, step: 23, Train: label_loss: 0.11648879945278168, precision: 0.3080959520239649, recall: 0.8422131147539258, f1: 0.45115257954360627\n",
            "epoch: 392, step: 0, Train: label_loss: 0.08621345460414886, precision: 0.326347305389202, recall: 0.8776167471818231, f1: 0.47577477080286795\n",
            "epoch: 392, step: 1, Train: label_loss: 0.11300919204950333, precision: 0.30360415394011586, recall: 0.8613518197572163, f1: 0.44896115623965005\n",
            "epoch: 392, step: 2, Train: label_loss: 0.10091236233711243, precision: 0.3156626506023906, recall: 0.870431893687563, f1: 0.46330680809529173\n",
            "epoch: 392, step: 3, Train: label_loss: 0.09266893565654755, precision: 0.33456108041741345, recall: 0.8410493827159196, f1: 0.47870004387667386\n",
            "epoch: 392, step: 4, Train: label_loss: 0.1093314066529274, precision: 0.30914634146339576, recall: 0.8578680203044233, f1: 0.45450470637069507\n",
            "epoch: 392, step: 5, Train: label_loss: 0.09893882274627686, precision: 0.3095673369896216, recall: 0.8668941979520705, f1: 0.45621912883410326\n",
            "epoch: 392, step: 6, Train: label_loss: 0.12086205184459686, precision: 0.3098330241187192, recall: 0.8146341463413309, f1: 0.4489247311428321\n",
            "epoch: 392, step: 7, Train: label_loss: 0.10620931535959244, precision: 0.3329275715155001, recall: 0.8587127158554382, f1: 0.47982456136320084\n",
            "epoch: 392, step: 8, Train: label_loss: 0.11423064768314362, precision: 0.3108108108107917, recall: 0.8308702791460048, f1: 0.45239159584768357\n",
            "epoch: 392, step: 9, Train: label_loss: 0.11025499552488327, precision: 0.3221271393642835, recall: 0.8527508090613506, f1: 0.4676131321695631\n",
            "epoch: 392, step: 10, Train: label_loss: 0.1154291033744812, precision: 0.31860036832410565, recall: 0.8664440734556149, f1: 0.4658886893681845\n",
            "epoch: 392, step: 11, Train: label_loss: 0.09748682379722595, precision: 0.30175015087505724, recall: 0.863557858376362, f1: 0.44722719137481953\n",
            "epoch: 392, step: 12, Train: label_loss: 0.12617932260036469, precision: 0.29393753827309893, recall: 0.8540925266902394, f1: 0.4373576309413626\n",
            "epoch: 392, step: 13, Train: label_loss: 0.11809737235307693, precision: 0.32526381129731063, recall: 0.841091492776751, f1: 0.46911369736349756\n",
            "epoch: 392, step: 14, Train: label_loss: 0.09557530283927917, precision: 0.32870090634439103, recall: 0.8788368336024428, f1: 0.4784520668029039\n",
            "epoch: 392, step: 15, Train: label_loss: 0.1023922711610794, precision: 0.31268973891922813, recall: 0.8554817275746086, f1: 0.45798132499410243\n",
            "epoch: 392, step: 16, Train: label_loss: 0.10659969598054886, precision: 0.3072252580449115, recall: 0.8784722222220697, f1: 0.45524066572854627\n",
            "epoch: 392, step: 17, Train: label_loss: 0.11442434787750244, precision: 0.30030769230767385, recall: 0.874551971326008, f1: 0.44709115891746987\n",
            "epoch: 392, step: 18, Train: label_loss: 0.13571207225322723, precision: 0.28987341772150066, recall: 0.8077601410933319, f1: 0.4266418257645377\n",
            "epoch: 392, step: 19, Train: label_loss: 0.10624327510595322, precision: 0.33292533659728685, recall: 0.8607594936707498, f1: 0.4801412179650298\n",
            "epoch: 392, step: 20, Train: label_loss: 0.11101095378398895, precision: 0.2897657213316714, recall: 0.8159722222220805, f1: 0.42766151042534273\n",
            "epoch: 392, step: 21, Train: label_loss: 0.11410439014434814, precision: 0.3174123337363774, recall: 0.8620689655170998, f1: 0.46398585943918913\n",
            "epoch: 392, step: 22, Train: label_loss: 0.10232234001159668, precision: 0.32360097323599, recall: 0.8692810457514919, f1: 0.47163120563418\n",
            "epoch: 392, step: 23, Train: label_loss: 0.111145980656147, precision: 0.3191811978771555, recall: 0.8403193612772774, f1: 0.46263736259741206\n",
            "epoch: 393, step: 0, Train: label_loss: 0.10779598355293274, precision: 0.30896805896803997, recall: 0.8468013468012042, f1: 0.4527452744882393\n",
            "epoch: 393, step: 1, Train: label_loss: 0.10973990708589554, precision: 0.31459987782527093, recall: 0.8428805237314495, f1: 0.45818505334115744\n",
            "epoch: 393, step: 2, Train: label_loss: 0.11422866582870483, precision: 0.329238329238309, recall: 0.8454258675077531, f1: 0.4739168876696043\n",
            "epoch: 393, step: 3, Train: label_loss: 0.08746452629566193, precision: 0.3167366526694471, recall: 0.8934010152282752, f1: 0.46767050483288025\n",
            "epoch: 393, step: 4, Train: label_loss: 0.10550161451101303, precision: 0.31566118220595274, recall: 0.8604651162789267, f1: 0.4618814087881506\n",
            "epoch: 393, step: 5, Train: label_loss: 0.12301705777645111, precision: 0.31868811881186143, recall: 0.8498349834982095, f1: 0.4635463545957523\n",
            "epoch: 393, step: 6, Train: label_loss: 0.1193314865231514, precision: 0.30834340991533804, recall: 0.8732876712327271, f1: 0.45576407502841265\n",
            "epoch: 393, step: 7, Train: label_loss: 0.10673348605632782, precision: 0.29296636085625116, recall: 0.837412587412441, f1: 0.43407340277080325\n",
            "epoch: 393, step: 8, Train: label_loss: 0.11031274497509003, precision: 0.3119999999999808, recall: 0.8578680203044233, f1: 0.45758122739766793\n",
            "epoch: 393, step: 9, Train: label_loss: 0.10164910554885864, precision: 0.29194427619622704, recall: 0.8530973451325923, f1: 0.4350180505034856\n",
            "epoch: 393, step: 10, Train: label_loss: 0.10024628043174744, precision: 0.3493902439024177, recall: 0.8815384615383258, f1: 0.5004366811820083\n",
            "epoch: 393, step: 11, Train: label_loss: 0.10555467009544373, precision: 0.3270745003028269, recall: 0.891089108910744, f1: 0.4785112981441056\n",
            "epoch: 393, step: 12, Train: label_loss: 0.10939007997512817, precision: 0.33373277411621727, recall: 0.9056910569104217, f1: 0.48774080556480814\n",
            "epoch: 393, step: 13, Train: label_loss: 0.0965304970741272, precision: 0.3204353083433905, recall: 0.8745874587457302, f1: 0.4690265486332764\n",
            "epoch: 393, step: 14, Train: label_loss: 0.10452002286911011, precision: 0.31231049120677307, recall: 0.8612040133777823, f1: 0.4583889630227582\n",
            "epoch: 393, step: 15, Train: label_loss: 0.12165430188179016, precision: 0.3133498145858892, recall: 0.8380165289254813, f1: 0.45614035083753474\n",
            "epoch: 393, step: 16, Train: label_loss: 0.11222481727600098, precision: 0.3134698944754616, recall: 0.8473154362414685, f1: 0.4576347983293604\n",
            "epoch: 393, step: 17, Train: label_loss: 0.1134854406118393, precision: 0.3142857142856952, recall: 0.8559602649005205, f1: 0.4597598932465765\n",
            "epoch: 393, step: 18, Train: label_loss: 0.10471135377883911, precision: 0.31746987951805317, recall: 0.8917089678509489, f1: 0.4682363393659439\n",
            "epoch: 393, step: 19, Train: label_loss: 0.10486702620983124, precision: 0.3099022004889786, recall: 0.8352553542008508, f1: 0.4520731163224979\n",
            "epoch: 393, step: 20, Train: label_loss: 0.09684421867132187, precision: 0.32951116475556247, recall: 0.866666666666529, f1: 0.4774814166631455\n",
            "epoch: 393, step: 21, Train: label_loss: 0.11523644626140594, precision: 0.3106200122774518, recall: 0.8308702791460048, f1: 0.45218945483076567\n",
            "epoch: 393, step: 22, Train: label_loss: 0.11414273083209991, precision: 0.31318681318679403, recall: 0.8739352640543655, f1: 0.46112359546673265\n",
            "epoch: 393, step: 23, Train: label_loss: 0.11284837871789932, precision: 0.28647014361297907, recall: 0.8150537634406849, f1: 0.42393736014043704\n",
            "epoch: 394, step: 0, Train: label_loss: 0.11291944235563278, precision: 0.3013365735115248, recall: 0.8747795414460537, f1: 0.448260280124521\n",
            "epoch: 394, step: 1, Train: label_loss: 0.09907887130975723, precision: 0.3246987951807033, recall: 0.886513157894591, f1: 0.47530864193602435\n",
            "epoch: 394, step: 2, Train: label_loss: 0.10763406753540039, precision: 0.32538226299692197, recall: 0.8764415156505969, f1: 0.47457627114691026\n",
            "epoch: 394, step: 3, Train: label_loss: 0.09448402374982834, precision: 0.3398413666869835, recall: 0.8785488958989149, f1: 0.49010118781718864\n",
            "epoch: 394, step: 4, Train: label_loss: 0.09343234449625015, precision: 0.31419939577037376, recall: 0.8681135225374176, f1: 0.4614019520461155\n",
            "epoch: 394, step: 5, Train: label_loss: 0.10030747950077057, precision: 0.3226392251815785, recall: 0.8809917355370444, f1: 0.472308373908436\n",
            "epoch: 394, step: 6, Train: label_loss: 0.09693741798400879, precision: 0.3353621424223776, recall: 0.8582554517132619, f1: 0.4822757111192906\n",
            "epoch: 394, step: 7, Train: label_loss: 0.09081969410181046, precision: 0.3196125907990121, recall: 0.8613376835235136, f1: 0.46622516552339394\n",
            "epoch: 394, step: 8, Train: label_loss: 0.10416923463344574, precision: 0.3209951456310485, recall: 0.8629690048938232, f1: 0.46793454219838365\n",
            "epoch: 394, step: 9, Train: label_loss: 0.1079268753528595, precision: 0.31795817958177625, recall: 0.8517298187807493, f1: 0.4630541871524889\n",
            "epoch: 394, step: 10, Train: label_loss: 0.10432955622673035, precision: 0.32110643415512197, recall: 0.8914858096826558, f1: 0.47214854107507936\n",
            "epoch: 394, step: 11, Train: label_loss: 0.11590594053268433, precision: 0.27611940298505744, recall: 0.8117001828152081, f1: 0.41206496515929764\n",
            "epoch: 394, step: 12, Train: label_loss: 0.10724443942308426, precision: 0.30697961704754123, recall: 0.838111298482152, f1: 0.4493670885683113\n",
            "epoch: 394, step: 13, Train: label_loss: 0.09347718954086304, precision: 0.3277411623726586, recall: 0.8937908496730566, f1: 0.47961420425705587\n",
            "epoch: 394, step: 14, Train: label_loss: 0.11430160701274872, precision: 0.3121529919802398, recall: 0.8532883642494344, f1: 0.45709123753978076\n",
            "epoch: 394, step: 15, Train: label_loss: 0.11016662418842316, precision: 0.3222016079158737, recall: 0.8416801292405748, f1: 0.46601073341251287\n",
            "epoch: 394, step: 16, Train: label_loss: 0.10049831122159958, precision: 0.30348557692305866, recall: 0.8752166377814774, f1: 0.45069165547265605\n",
            "epoch: 394, step: 17, Train: label_loss: 0.12395845353603363, precision: 0.31553100061385414, recall: 0.8481848184817081, f1: 0.45995525723112757\n",
            "epoch: 394, step: 18, Train: label_loss: 0.116608165204525, precision: 0.29516227801590356, recall: 0.8576512455514488, f1: 0.43917995440377716\n",
            "epoch: 394, step: 19, Train: label_loss: 0.09656502306461334, precision: 0.29468599033814646, recall: 0.8714285714284158, f1: 0.4404332129585808\n",
            "epoch: 394, step: 20, Train: label_loss: 0.09088286012411118, precision: 0.3395657418576393, recall: 0.8824451410656924, f1: 0.4904181184267241\n",
            "epoch: 394, step: 21, Train: label_loss: 0.11003100872039795, precision: 0.3325227963525634, recall: 0.8794212218648103, f1: 0.4825760917113521\n",
            "epoch: 394, step: 22, Train: label_loss: 0.11695078015327454, precision: 0.3118749999999805, recall: 0.8061389337640054, f1: 0.4497521405636073\n",
            "epoch: 394, step: 23, Train: label_loss: 0.11391863226890564, precision: 0.3042168674698566, recall: 0.8469601677147072, f1: 0.44764542932394535\n",
            "epoch: 395, step: 0, Train: label_loss: 0.09174834191799164, precision: 0.3285285285285088, recall: 0.9011532125204446, f1: 0.4815140844678422\n",
            "epoch: 395, step: 1, Train: label_loss: 0.110407754778862, precision: 0.3199505867819444, recall: 0.8395461912478379, f1: 0.4633273702641137\n",
            "epoch: 395, step: 2, Train: label_loss: 0.08769851922988892, precision: 0.3127646702964118, recall: 0.868907563025064, f1: 0.45996441277242217\n",
            "epoch: 395, step: 3, Train: label_loss: 0.10812787711620331, precision: 0.31318016928655906, recall: 0.8720538720537252, f1: 0.4608540924877665\n",
            "epoch: 395, step: 4, Train: label_loss: 0.10106486827135086, precision: 0.31057401812686947, recall: 0.8741496598637969, f1: 0.4583147569831196\n",
            "epoch: 395, step: 5, Train: label_loss: 0.10081201791763306, precision: 0.32531569452794196, recall: 0.8754045307441949, f1: 0.47435335375264903\n",
            "epoch: 395, step: 6, Train: label_loss: 0.10056814551353455, precision: 0.321665660832811, recall: 0.8853820598005173, f1: 0.4718902168710009\n",
            "epoch: 395, step: 7, Train: label_loss: 0.10792695730924606, precision: 0.318654434250745, recall: 0.8403225806450257, f1: 0.4620842571662975\n",
            "epoch: 395, step: 8, Train: label_loss: 0.08887070417404175, precision: 0.30764599638769974, recall: 0.8720136518769842, f1: 0.45482866039754066\n",
            "epoch: 395, step: 9, Train: label_loss: 0.10219709575176239, precision: 0.3202889825406189, recall: 0.8764415156505969, f1: 0.4691358024298929\n",
            "epoch: 395, step: 10, Train: label_loss: 0.09317980706691742, precision: 0.31246200607900837, recall: 0.8566666666665238, f1: 0.45790645875812014\n",
            "epoch: 395, step: 11, Train: label_loss: 0.10202058404684067, precision: 0.3122743682310281, recall: 0.8621262458470328, f1: 0.45848056533194465\n",
            "epoch: 395, step: 12, Train: label_loss: 0.10801714658737183, precision: 0.3265179677818881, recall: 0.83254344391772, f1: 0.46906987089851826\n",
            "epoch: 395, step: 13, Train: label_loss: 0.1095164567232132, precision: 0.32620647525960134, recall: 0.878289473684066, f1: 0.47572383069542856\n",
            "epoch: 395, step: 14, Train: label_loss: 0.09465843439102173, precision: 0.3317161916312716, recall: 0.8751999999998599, f1: 0.48109058923010534\n",
            "epoch: 395, step: 15, Train: label_loss: 0.11104558408260345, precision: 0.3135233474833042, recall: 0.8762711864405294, f1: 0.46181330947431964\n",
            "epoch: 395, step: 16, Train: label_loss: 0.1155676320195198, precision: 0.3210558624923069, recall: 0.8644628099172125, f1: 0.4682184422165063\n",
            "epoch: 395, step: 17, Train: label_loss: 0.11200162768363953, precision: 0.29767726161367375, recall: 0.855887521968215, f1: 0.44172335597073825\n",
            "epoch: 395, step: 18, Train: label_loss: 0.10679395496845245, precision: 0.2969325153374051, recall: 0.8491228070173948, f1: 0.4399999999615674\n",
            "epoch: 395, step: 19, Train: label_loss: 0.09985476732254028, precision: 0.30891330891329005, recall: 0.8830715532284671, f1: 0.4577114427476291\n",
            "epoch: 395, step: 20, Train: label_loss: 0.110242560505867, precision: 0.3239951278927939, recall: 0.8721311475408405, f1: 0.47246891647910816\n",
            "epoch: 395, step: 21, Train: label_loss: 0.10156543552875519, precision: 0.3194868662186732, recall: 0.8531810766719652, f1: 0.4648888888492039\n",
            "epoch: 395, step: 22, Train: label_loss: 0.11143913120031357, precision: 0.3128457283343385, recall: 0.8330605564646754, f1: 0.45487041997813715\n",
            "epoch: 395, step: 23, Train: label_loss: 0.10619775950908661, precision: 0.3074626865671412, recall: 0.8655462184872131, f1: 0.45374449335333833\n",
            "epoch: 396, step: 0, Train: label_loss: 0.1018558144569397, precision: 0.3203647416413179, recall: 0.881270903009886, f1: 0.469906375350955\n",
            "epoch: 396, step: 1, Train: label_loss: 0.09954246133565903, precision: 0.3090024330900055, recall: 0.8624787775889876, f1: 0.4549932825406095\n",
            "epoch: 396, step: 2, Train: label_loss: 0.09722043573856354, precision: 0.33109756097558957, recall: 0.8701923076921682, f1: 0.47968197875861357\n",
            "epoch: 396, step: 3, Train: label_loss: 0.09725058823823929, precision: 0.32322619769555344, recall: 0.8666666666665257, f1: 0.47084805649749023\n",
            "epoch: 396, step: 4, Train: label_loss: 0.11336157470941544, precision: 0.29661538461536635, recall: 0.8382608695650715, f1: 0.4381818181431678\n",
            "epoch: 396, step: 5, Train: label_loss: 0.10643548518419266, precision: 0.3239780353874116, recall: 0.862012987012847, f1: 0.47095343676734386\n",
            "epoch: 396, step: 6, Train: label_loss: 0.09606583416461945, precision: 0.32992788461536476, recall: 0.8869143780289358, f1: 0.4809461234821157\n",
            "epoch: 396, step: 7, Train: label_loss: 0.11515676230192184, precision: 0.34700122399018685, recall: 0.8915094339621239, f1: 0.4995594713252593\n",
            "epoch: 396, step: 8, Train: label_loss: 0.10137799382209778, precision: 0.3079249848759644, recall: 0.8627118644066334, f1: 0.45385644222601335\n",
            "epoch: 396, step: 9, Train: label_loss: 0.12284082174301147, precision: 0.31488314883146895, recall: 0.8533333333331911, f1: 0.46001796941251255\n",
            "epoch: 396, step: 10, Train: label_loss: 0.1110009104013443, precision: 0.3070336391437121, recall: 0.8508474576269743, f1: 0.45123595501716834\n",
            "epoch: 396, step: 11, Train: label_loss: 0.10311728715896606, precision: 0.3337400854179174, recall: 0.8766025641024235, f1: 0.4834290764072097\n",
            "epoch: 396, step: 12, Train: label_loss: 0.09345079958438873, precision: 0.33596597812877665, recall: 0.8708661417321463, f1: 0.484875054760306\n",
            "epoch: 396, step: 13, Train: label_loss: 0.09520035982131958, precision: 0.30736457699328623, recall: 0.8603066439521532, f1: 0.45291479816744956\n",
            "epoch: 396, step: 14, Train: label_loss: 0.09658132493495941, precision: 0.3150932050510935, recall: 0.8866328257189701, f1: 0.4649511978317209\n",
            "epoch: 396, step: 15, Train: label_loss: 0.10455161333084106, precision: 0.3192771084337157, recall: 0.8818635607319664, f1: 0.4688191065509318\n",
            "epoch: 396, step: 16, Train: label_loss: 0.11400049924850464, precision: 0.3266423357664035, recall: 0.8774509803920134, f1: 0.47606382974765477\n",
            "epoch: 396, step: 17, Train: label_loss: 0.09692059457302094, precision: 0.32313341493266073, recall: 0.8684210526314361, f1: 0.4710080285063702\n",
            "epoch: 396, step: 18, Train: label_loss: 0.10675808042287827, precision: 0.31292100428656994, recall: 0.8690476190474712, f1: 0.4601530841573354\n",
            "epoch: 396, step: 19, Train: label_loss: 0.09500359743833542, precision: 0.29981938591208307, recall: 0.8845470692716012, f1: 0.4478417265808519\n",
            "epoch: 396, step: 20, Train: label_loss: 0.10032664984464645, precision: 0.3283492822966311, recall: 0.888349514562963, f1: 0.4794759824933013\n",
            "epoch: 396, step: 21, Train: label_loss: 0.11674067378044128, precision: 0.3018518518518332, recall: 0.8445595854920821, f1: 0.44474761251232436\n",
            "epoch: 396, step: 22, Train: label_loss: 0.11099962890148163, precision: 0.30736457699328623, recall: 0.8603066439521532, f1: 0.45291479816744956\n",
            "epoch: 396, step: 23, Train: label_loss: 0.09697701036930084, precision: 0.3106796116504622, recall: 0.8776371308015026, f1: 0.4589078874406471\n",
            "epoch: 397, step: 0, Train: label_loss: 0.09873592853546143, precision: 0.3319200484554614, recall: 0.8562499999998662, f1: 0.4783937144948326\n",
            "epoch: 397, step: 1, Train: label_loss: 0.0912688672542572, precision: 0.3190220632080907, recall: 0.8901830282860415, f1: 0.46971027212968314\n",
            "epoch: 397, step: 2, Train: label_loss: 0.10147018730640411, precision: 0.2986069049060994, recall: 0.8441780821916363, f1: 0.441163310923325\n",
            "epoch: 397, step: 3, Train: label_loss: 0.08521070331335068, precision: 0.3104477611940113, recall: 0.8724832214763636, f1: 0.45794804047203486\n",
            "epoch: 397, step: 4, Train: label_loss: 0.11081806570291519, precision: 0.30651105651103766, recall: 0.8414839797637703, f1: 0.4493471408883278\n",
            "epoch: 397, step: 5, Train: label_loss: 0.09871366620063782, precision: 0.31591591591589696, recall: 0.8840336134452295, f1: 0.46548672562488347\n",
            "epoch: 397, step: 6, Train: label_loss: 0.1273731291294098, precision: 0.3130056004978025, recall: 0.8192182410422117, f1: 0.4529491219770633\n",
            "epoch: 397, step: 7, Train: label_loss: 0.11045153439044952, precision: 0.30314465408803126, recall: 0.8087248322146293, f1: 0.44098810609021544\n",
            "epoch: 397, step: 8, Train: label_loss: 0.09915474057197571, precision: 0.306707317073152, recall: 0.8568994889266002, f1: 0.45172878307743797\n",
            "epoch: 397, step: 9, Train: label_loss: 0.09588850289583206, precision: 0.3110976349302419, recall: 0.8709677419353359, f1: 0.4584450401756528\n",
            "epoch: 397, step: 10, Train: label_loss: 0.10180498659610748, precision: 0.3039568345323559, recall: 0.8651877133104325, f1: 0.44986690324453416\n",
            "epoch: 397, step: 11, Train: label_loss: 0.09038426727056503, precision: 0.3277411623726586, recall: 0.8937908496730566, f1: 0.47961420425705587\n",
            "epoch: 397, step: 12, Train: label_loss: 0.10919611155986786, precision: 0.30910201588269337, recall: 0.8634812286687945, f1: 0.4552406657281168\n",
            "epoch: 397, step: 13, Train: label_loss: 0.10890071094036102, precision: 0.3369963369963164, recall: 0.8860353130014629, f1: 0.48827952229528293\n",
            "epoch: 397, step: 14, Train: label_loss: 0.11429260671138763, precision: 0.29524397776403366, recall: 0.8415492957744997, f1: 0.43712848647270985\n",
            "epoch: 397, step: 15, Train: label_loss: 0.10621277987957001, precision: 0.32244404113730657, recall: 0.8795379537952344, f1: 0.47189021687083604\n",
            "epoch: 397, step: 16, Train: label_loss: 0.09576080739498138, precision: 0.3180987202924852, recall: 0.8599670510706985, f1: 0.4644128113484374\n",
            "epoch: 397, step: 17, Train: label_loss: 0.09974141418933868, precision: 0.308581862446725, recall: 0.84782608695638, f1: 0.45247657291933246\n",
            "epoch: 397, step: 18, Train: label_loss: 0.10419526696205139, precision: 0.31391784181481824, recall: 0.8533333333331911, f1: 0.45898700130532527\n",
            "epoch: 397, step: 19, Train: label_loss: 0.11034267395734787, precision: 0.3408536585365646, recall: 0.8599999999998676, f1: 0.48820960694620175\n",
            "epoch: 397, step: 20, Train: label_loss: 0.11194518953561783, precision: 0.309361438313682, recall: 0.8529914529913071, f1: 0.4540491355386937\n",
            "epoch: 397, step: 21, Train: label_loss: 0.11268278956413269, precision: 0.32254123396454965, recall: 0.8543689320386967, f1: 0.46829268288699766\n",
            "epoch: 397, step: 22, Train: label_loss: 0.09440578520298004, precision: 0.30165542611892693, recall: 0.866197183098439, f1: 0.4474761254732393\n",
            "epoch: 397, step: 23, Train: label_loss: 0.12125655263662338, precision: 0.3297791317593047, recall: 0.8375241779495478, f1: 0.47322404367525533\n",
            "epoch: 398, step: 0, Train: label_loss: 0.10542935132980347, precision: 0.3101767215112547, recall: 0.8583473861718619, f1: 0.45568487014896614\n",
            "epoch: 398, step: 1, Train: label_loss: 0.12879811227321625, precision: 0.2923864363403524, recall: 0.7772108843536093, f1: 0.42491864245209776\n",
            "epoch: 398, step: 2, Train: label_loss: 0.14191606640815735, precision: 0.30749842470067373, recall: 0.8133333333331977, f1: 0.4462734338878978\n",
            "epoch: 398, step: 3, Train: label_loss: 0.12932826578617096, precision: 0.32196969696967664, recall: 0.8133971291864731, f1: 0.4613297150203839\n",
            "epoch: 398, step: 4, Train: label_loss: 0.13180230557918549, precision: 0.30377358490564127, recall: 0.8076923076921726, f1: 0.441499085883455\n",
            "epoch: 398, step: 5, Train: label_loss: 0.1170293316245079, precision: 0.298156389065461, recall: 0.7949152542371534, f1: 0.4336569578890892\n",
            "epoch: 398, step: 6, Train: label_loss: 0.13120236992835999, precision: 0.3102352193261087, recall: 0.7973856209149023, f1: 0.4466819221564274\n",
            "epoch: 398, step: 7, Train: label_loss: 0.1304139941930771, precision: 0.30501930501928537, recall: 0.7559808612438985, f1: 0.434662998583477\n",
            "epoch: 398, step: 8, Train: label_loss: 0.14125335216522217, precision: 0.2848874598070556, recall: 0.7785588752195468, f1: 0.417137476420246\n",
            "epoch: 398, step: 9, Train: label_loss: 0.13269725441932678, precision: 0.3030108904548172, recall: 0.7567999999998789, f1: 0.43275388833973105\n",
            "epoch: 398, step: 10, Train: label_loss: 0.12291289865970612, precision: 0.2900188323916955, recall: 0.802083333333194, f1: 0.426002766212682\n",
            "epoch: 398, step: 11, Train: label_loss: 0.14764486253261566, precision: 0.28552887735235005, recall: 0.7260726072606062, f1: 0.40987424308939324\n",
            "epoch: 398, step: 12, Train: label_loss: 0.12875932455062866, precision: 0.2980216975111488, recall: 0.7861952861951538, f1: 0.43220731138998997\n",
            "epoch: 398, step: 13, Train: label_loss: 0.1364077478647232, precision: 0.30686830497792644, recall: 0.7944535073408165, f1: 0.4427272726870328\n",
            "epoch: 398, step: 14, Train: label_loss: 0.11589650809764862, precision: 0.32341772151896686, recall: 0.8162939297123296, f1: 0.46328195825486645\n",
            "epoch: 398, step: 15, Train: label_loss: 0.1262759268283844, precision: 0.2993749999999813, recall: 0.8104906937392875, f1: 0.4372432678747584\n",
            "epoch: 398, step: 16, Train: label_loss: 0.12661035358905792, precision: 0.2984126984126795, recall: 0.8006814310049742, f1: 0.43478260865605367\n",
            "epoch: 398, step: 17, Train: label_loss: 0.13179421424865723, precision: 0.2981445937299873, recall: 0.7831932773107927, f1: 0.4318813716004282\n",
            "epoch: 398, step: 18, Train: label_loss: 0.13786742091178894, precision: 0.31630769230767286, recall: 0.8412438625203206, f1: 0.45974955273304996\n",
            "epoch: 398, step: 19, Train: label_loss: 0.12173740565776825, precision: 0.31186868686866714, recall: 0.8151815181516806, f1: 0.4511415524713458\n",
            "epoch: 398, step: 20, Train: label_loss: 0.12241852283477783, precision: 0.31238332296202165, recall: 0.8256578947367063, f1: 0.45327313765764676\n",
            "epoch: 398, step: 21, Train: label_loss: 0.1310001164674759, precision: 0.30744949494947554, recall: 0.8184873949578456, f1: 0.44699403392079157\n",
            "epoch: 398, step: 22, Train: label_loss: 0.137764573097229, precision: 0.3065739570164155, recall: 0.8137583892616084, f1: 0.4453627180501971\n",
            "epoch: 398, step: 23, Train: label_loss: 0.12965187430381775, precision: 0.31172839506170436, recall: 0.8312757201644381, f1: 0.4534231200500665\n",
            "epoch: 399, step: 0, Train: label_loss: 0.12951144576072693, precision: 0.2942271880819184, recall: 0.8186528497407912, f1: 0.4328767122898306\n",
            "epoch: 399, step: 1, Train: label_loss: 0.12969055771827698, precision: 0.33876017532872016, recall: 0.8184568835097097, f1: 0.4791851195333941\n",
            "epoch: 399, step: 2, Train: label_loss: 0.11631643772125244, precision: 0.32884262094302946, recall: 0.8703403565638783, f1: 0.47733333329348593\n",
            "epoch: 399, step: 3, Train: label_loss: 0.10940389335155487, precision: 0.3125778331257589, recall: 0.8325041459368436, f1: 0.4545043005487685\n",
            "epoch: 399, step: 4, Train: label_loss: 0.12609100341796875, precision: 0.2993749999999813, recall: 0.8118644067795233, f1: 0.43744292233502396\n",
            "epoch: 399, step: 5, Train: label_loss: 0.11062011122703552, precision: 0.31188118811879256, recall: 0.8289473684209162, f1: 0.4532374100321728\n",
            "epoch: 399, step: 6, Train: label_loss: 0.12324400991201401, precision: 0.31962616822427914, recall: 0.8341463414632789, f1: 0.46216216212206396\n",
            "epoch: 399, step: 7, Train: label_loss: 0.1370728611946106, precision: 0.3082278481012463, recall: 0.8062913907283432, f1: 0.44597069593064054\n",
            "epoch: 399, step: 8, Train: label_loss: 0.12780898809432983, precision: 0.30044843049325426, recall: 0.7713815789472415, f1: 0.4324573535787918\n",
            "epoch: 399, step: 9, Train: label_loss: 0.11140646040439606, precision: 0.322180916976436, recall: 0.8681135225374176, f1: 0.46995029367940927\n",
            "epoch: 399, step: 10, Train: label_loss: 0.12063536047935486, precision: 0.3162128712871091, recall: 0.8295454545453198, f1: 0.45788530461949367\n",
            "epoch: 399, step: 11, Train: label_loss: 0.11192730069160461, precision: 0.31412639405202514, recall: 0.8257328990226668, f1: 0.4551166965489006\n",
            "epoch: 399, step: 12, Train: label_loss: 0.11531049013137817, precision: 0.3158544108574759, recall: 0.8421052631577561, f1: 0.4593988335179348\n",
            "epoch: 399, step: 13, Train: label_loss: 0.12878713011741638, precision: 0.2956411876184273, recall: 0.8110918544192701, f1: 0.43333333329413887\n",
            "epoch: 399, step: 14, Train: label_loss: 0.12250523269176483, precision: 0.2985074626865486, recall: 0.8205128205126802, f1: 0.4377564979088568\n",
            "epoch: 399, step: 15, Train: label_loss: 0.1072094738483429, precision: 0.31403940886697573, recall: 0.8457711442784667, f1: 0.45801526713604085\n",
            "epoch: 399, step: 16, Train: label_loss: 0.12236558645963669, precision: 0.3246670894102521, recall: 0.82580645161277, f1: 0.46609012285430124\n",
            "epoch: 399, step: 17, Train: label_loss: 0.10410867631435394, precision: 0.30067775723966106, recall: 0.8370497427099765, f1: 0.4424297370417617\n",
            "epoch: 399, step: 18, Train: label_loss: 0.11809614300727844, precision: 0.31053952321202566, recall: 0.803571428571298, f1: 0.44796380086472865\n",
            "epoch: 399, step: 19, Train: label_loss: 0.12894286215305328, precision: 0.30730793254214195, recall: 0.8324873096445291, f1: 0.4489051094496254\n",
            "epoch: 399, step: 20, Train: label_loss: 0.1059589833021164, precision: 0.30601092896173004, recall: 0.8765217391302823, f1: 0.4536453644980506\n",
            "epoch: 399, step: 21, Train: label_loss: 0.100617915391922, precision: 0.31158536585363955, recall: 0.8646362098137285, f1: 0.45809054231870017\n",
            "epoch: 399, step: 22, Train: label_loss: 0.11888326704502106, precision: 0.29840686274507977, recall: 0.8499127399649475, f1: 0.4417233559705632\n",
            "epoch: 399, step: 23, Train: label_loss: 0.10883498936891556, precision: 0.3028919330288963, recall: 0.8240165631468274, f1: 0.4429604896657071\n",
            "epoch: 400, step: 0, Train: label_loss: 0.1151142343878746, precision: 0.31149567367117975, recall: 0.83999999999986, f1: 0.4544634805736567\n",
            "epoch: 400, step: 1, Train: label_loss: 0.11210697889328003, precision: 0.3196004993757603, recall: 0.8407224958947715, f1: 0.4631388511585961\n",
            "epoch: 400, step: 2, Train: label_loss: 0.11247207224369049, precision: 0.2924120913016476, recall: 0.815834767641856, f1: 0.4305177111327762\n",
            "epoch: 400, step: 3, Train: label_loss: 0.10781789571046829, precision: 0.31223628691981237, recall: 0.8779661016947664, f1: 0.46064917737343875\n",
            "epoch: 400, step: 4, Train: label_loss: 0.11790972203016281, precision: 0.2988792029887734, recall: 0.8094435075883963, f1: 0.4365620736304207\n",
            "epoch: 400, step: 5, Train: label_loss: 0.1142129898071289, precision: 0.30783466995679776, recall: 0.831666666666528, f1: 0.4493471408880359\n",
            "epoch: 400, step: 6, Train: label_loss: 0.11389294266700745, precision: 0.3146896127842462, recall: 0.8590604026844195, f1: 0.46063877638896356\n",
            "epoch: 400, step: 7, Train: label_loss: 0.11951872706413269, precision: 0.31467661691540333, recall: 0.8135048231509946, f1: 0.45381165915255944\n",
            "epoch: 400, step: 8, Train: label_loss: 0.11794731020927429, precision: 0.31064356435641644, recall: 0.8366666666665271, f1: 0.4530685920182313\n",
            "epoch: 400, step: 9, Train: label_loss: 0.09942626953125, precision: 0.32722832722830725, recall: 0.8673139158574648, f1: 0.4751773049247179\n",
            "epoch: 400, step: 10, Train: label_loss: 0.11584782600402832, precision: 0.3184634448574772, recall: 0.806907378335823, f1: 0.45668591732943625\n",
            "epoch: 400, step: 11, Train: label_loss: 0.10867538303136826, precision: 0.3096259963212563, recall: 0.867697594501569, f1: 0.4563940352074654\n",
            "epoch: 400, step: 12, Train: label_loss: 0.11688092350959778, precision: 0.3103233830845578, recall: 0.8573883161510554, f1: 0.4557077625180103\n",
            "epoch: 400, step: 13, Train: label_loss: 0.10741595923900604, precision: 0.3150183150182958, recall: 0.8528925619833301, f1: 0.4600980828852185\n",
            "epoch: 400, step: 14, Train: label_loss: 0.10239711403846741, precision: 0.32623250152158695, recall: 0.8631239935586371, f1: 0.47349823317569456\n",
            "epoch: 400, step: 15, Train: label_loss: 0.11880062520503998, precision: 0.3104294478527417, recall: 0.8532883642494344, f1: 0.4552406657278211\n",
            "epoch: 400, step: 16, Train: label_loss: 0.10764655470848083, precision: 0.31569230769228823, recall: 0.8549999999998574, f1: 0.46112359546618753\n",
            "epoch: 400, step: 17, Train: label_loss: 0.1107519343495369, precision: 0.30159705159703304, recall: 0.8421955403086033, f1: 0.44414292171599107\n",
            "epoch: 400, step: 18, Train: label_loss: 0.10821439325809479, precision: 0.32333129210040884, recall: 0.8627450980390746, f1: 0.4703786191139745\n",
            "epoch: 400, step: 19, Train: label_loss: 0.12175662815570831, precision: 0.3281733746129828, recall: 0.8333333333332023, f1: 0.4709018213721214\n",
            "epoch: 400, step: 20, Train: label_loss: 0.1092136949300766, precision: 0.3059472716124889, recall: 0.8633217993078091, f1: 0.4517881393909267\n",
            "epoch: 400, step: 21, Train: label_loss: 0.11206682026386261, precision: 0.29999999999998156, recall: 0.8578947368419547, f1: 0.4445454545070215\n",
            "epoch: 400, step: 22, Train: label_loss: 0.11192244291305542, precision: 0.30233990147781387, recall: 0.821070234113575, f1: 0.44194419438006255\n",
            "epoch: 400, step: 23, Train: label_loss: 0.1174769252538681, precision: 0.3297546012269686, recall: 0.8382066276801484, f1: 0.4733076499319057\n",
            "epoch: 401, step: 0, Train: label_loss: 0.11015907675027847, precision: 0.32447466007414555, recall: 0.8663366336632233, f1: 0.4721223021185838\n",
            "epoch: 401, step: 1, Train: label_loss: 0.11861896514892578, precision: 0.29684601113170705, recall: 0.8149405772494371, f1: 0.435176790531988\n",
            "epoch: 401, step: 2, Train: label_loss: 0.11729366332292557, precision: 0.29171894604766047, recall: 0.8129370629369208, f1: 0.4293628808475184\n",
            "epoch: 401, step: 3, Train: label_loss: 0.11957278847694397, precision: 0.2956411876184273, recall: 0.7799999999998699, f1: 0.42876775076174817\n",
            "epoch: 401, step: 4, Train: label_loss: 0.11714721471071243, precision: 0.31383647798740166, recall: 0.8048387096772894, f1: 0.45158371036683126\n",
            "epoch: 401, step: 5, Train: label_loss: 0.13311342895030975, precision: 0.2854418308963582, recall: 0.7558922558921286, f1: 0.41439778491632745\n",
            "epoch: 401, step: 6, Train: label_loss: 0.12469007819890976, precision: 0.3039950062421783, recall: 0.8198653198651817, f1: 0.4435336975925527\n",
            "epoch: 401, step: 7, Train: label_loss: 0.11571388691663742, precision: 0.3150684931506653, recall: 0.820097244732444, f1: 0.45524066572683713\n",
            "epoch: 401, step: 8, Train: label_loss: 0.11848479509353638, precision: 0.30541871921180386, recall: 0.8493150684930052, f1: 0.4492753622798925\n",
            "epoch: 401, step: 9, Train: label_loss: 0.13267777860164642, precision: 0.30622617534940877, recall: 0.8155668358712663, f1: 0.4452655888748162\n",
            "epoch: 401, step: 10, Train: label_loss: 0.13856318593025208, precision: 0.30744336569577296, recall: 0.7575757575756367, f1: 0.43738489866975694\n",
            "epoch: 401, step: 11, Train: label_loss: 0.14703209698200226, precision: 0.30715642811904326, recall: 0.8029801324501982, f1: 0.44434264769241155\n",
            "epoch: 401, step: 12, Train: label_loss: 0.1283566653728485, precision: 0.32318210068363434, recall: 0.8510638297870947, f1: 0.46846846842853096\n",
            "epoch: 401, step: 13, Train: label_loss: 0.10037017613649368, precision: 0.31854590264939503, recall: 0.8475409836064184, f1: 0.4630541871523667\n",
            "epoch: 401, step: 14, Train: label_loss: 0.11247091740369797, precision: 0.3157240522063197, recall: 0.8273615635177805, f1: 0.4570400359473802\n",
            "epoch: 401, step: 15, Train: label_loss: 0.11242154985666275, precision: 0.3199498117942083, recall: 0.803149606299086, f1: 0.45760430682327874\n",
            "epoch: 401, step: 16, Train: label_loss: 0.11823438853025436, precision: 0.30527638190952855, recall: 0.8154362416106014, f1: 0.4442413162308869\n",
            "epoch: 401, step: 17, Train: label_loss: 0.09761451929807663, precision: 0.33556638246039366, recall: 0.8622848200311639, f1: 0.4831214379254298\n",
            "epoch: 401, step: 18, Train: label_loss: 0.11064828932285309, precision: 0.3070283600493029, recall: 0.8645833333331832, f1: 0.4531392174317099\n",
            "epoch: 401, step: 19, Train: label_loss: 0.13495591282844543, precision: 0.29890955740857605, recall: 0.7664473684209265, f1: 0.4300876787782333\n",
            "epoch: 401, step: 20, Train: label_loss: 0.11302685737609863, precision: 0.2973796465569593, recall: 0.8531468531467039, f1: 0.44103027560554947\n",
            "epoch: 401, step: 21, Train: label_loss: 0.1250825971364975, precision: 0.3102803738317564, recall: 0.8440677966100264, f1: 0.45375854210188005\n",
            "epoch: 401, step: 22, Train: label_loss: 0.12962749600410461, precision: 0.29668956901934435, recall: 0.8246527777776346, f1: 0.4363803398783614\n",
            "epoch: 401, step: 23, Train: label_loss: 0.12063835561275482, precision: 0.3116981132075236, recall: 0.8360323886637984, f1: 0.45409565691475584\n",
            "epoch: 402, step: 0, Train: label_loss: 0.09268088638782501, precision: 0.3101991550995588, recall: 0.8892733564012302, f1: 0.45995525723230585\n",
            "epoch: 402, step: 1, Train: label_loss: 0.1286153793334961, precision: 0.322641509433942, recall: 0.8341463414632789, f1: 0.46530612240871344\n",
            "epoch: 402, step: 2, Train: label_loss: 0.12070787698030472, precision: 0.31292517006800785, recall: 0.833607907742861, f1: 0.45503597118329264\n",
            "epoch: 402, step: 3, Train: label_loss: 0.11660680174827576, precision: 0.31511056511054575, recall: 0.8694915254235813, f1: 0.46257889987073764\n",
            "epoch: 402, step: 4, Train: label_loss: 0.10680514574050903, precision: 0.31843233312919056, recall: 0.8595041322312629, f1: 0.46470062551904256\n",
            "epoch: 402, step: 5, Train: label_loss: 0.11094367504119873, precision: 0.3021806853582366, recall: 0.8434782608694185, f1: 0.4449541284014879\n",
            "epoch: 402, step: 6, Train: label_loss: 0.1226985976099968, precision: 0.3217391304347626, recall: 0.834138486312265, f1: 0.4643657552264806\n",
            "epoch: 402, step: 7, Train: label_loss: 0.11703191697597504, precision: 0.3162128712871091, recall: 0.855946398659823, f1: 0.46181653859589605\n",
            "epoch: 402, step: 8, Train: label_loss: 0.10120979696512222, precision: 0.3222222222222023, recall: 0.8259493670884769, f1: 0.46358792180682956\n",
            "epoch: 402, step: 9, Train: label_loss: 0.11332323402166367, precision: 0.3228974831184578, recall: 0.8497576736670678, f1: 0.46797153020916166\n",
            "epoch: 402, step: 10, Train: label_loss: 0.12339846789836884, precision: 0.28816676885344644, recall: 0.8318584070794988, f1: 0.4280510017832367\n",
            "epoch: 402, step: 11, Train: label_loss: 0.12966158986091614, precision: 0.30572851805726614, recall: 0.8307952622672028, f1: 0.44697314515862846\n",
            "epoch: 402, step: 12, Train: label_loss: 0.11274024844169617, precision: 0.30291970802917867, recall: 0.834170854271217, f1: 0.4444444444053186\n",
            "epoch: 402, step: 13, Train: label_loss: 0.10575059801340103, precision: 0.3077866339668726, recall: 0.8408710217754035, f1: 0.4506283662084845\n",
            "epoch: 402, step: 14, Train: label_loss: 0.11099065095186234, precision: 0.3059472716124889, recall: 0.8471986417655607, f1: 0.4495495495105245\n",
            "epoch: 402, step: 15, Train: label_loss: 0.11126498132944107, precision: 0.3093167701863162, recall: 0.8426395939084868, f1: 0.45252158106017626\n",
            "epoch: 402, step: 16, Train: label_loss: 0.09668928384780884, precision: 0.31143552311433625, recall: 0.8476821192051576, f1: 0.4555160141955364\n",
            "epoch: 402, step: 17, Train: label_loss: 0.11288076639175415, precision: 0.2823529411764531, recall: 0.8042328042326623, f1: 0.4179651695306983\n",
            "epoch: 402, step: 18, Train: label_loss: 0.10700199007987976, precision: 0.31479217603910054, recall: 0.8387622149835767, f1: 0.45777777773805295\n",
            "epoch: 402, step: 19, Train: label_loss: 0.10413654893636703, precision: 0.3207660083781974, recall: 0.8786885245900198, f1: 0.46996931166616923\n",
            "epoch: 402, step: 20, Train: label_loss: 0.11747615039348602, precision: 0.33836477987419256, recall: 0.8289676425268367, f1: 0.48057168374619375\n",
            "epoch: 402, step: 21, Train: label_loss: 0.11251145601272583, precision: 0.3087783916513009, recall: 0.8453781512603621, f1: 0.45233812945717017\n",
            "epoch: 402, step: 22, Train: label_loss: 0.11866463720798492, precision: 0.3189920098340308, recall: 0.8494271685759657, f1: 0.46380697046964675\n",
            "epoch: 402, step: 23, Train: label_loss: 0.12111537158489227, precision: 0.31555221637863895, recall: 0.839999999999832, f1: 0.45876570176254283\n",
            "epoch: 403, step: 0, Train: label_loss: 0.1234448179602623, precision: 0.32885085574570116, recall: 0.8705501618121568, f1: 0.47737355807905635\n",
            "epoch: 403, step: 1, Train: label_loss: 0.10831937193870544, precision: 0.31257557436515643, recall: 0.8762711864405294, f1: 0.46078431368669015\n",
            "epoch: 403, step: 2, Train: label_loss: 0.1015017107129097, precision: 0.31914893617019335, recall: 0.8467741935482505, f1: 0.463576158900596\n",
            "epoch: 403, step: 3, Train: label_loss: 0.11847987771034241, precision: 0.3228395061728196, recall: 0.8545751633985531, f1: 0.4686379927916969\n",
            "epoch: 403, step: 4, Train: label_loss: 0.09384755790233612, precision: 0.33091349062308945, recall: 0.8794212218648103, f1: 0.4808791208393474\n",
            "epoch: 403, step: 5, Train: label_loss: 0.10148081928491592, precision: 0.31588447653427704, recall: 0.8928571428569909, f1: 0.4666666666280176\n",
            "epoch: 403, step: 6, Train: label_loss: 0.1130162701010704, precision: 0.3189920098340308, recall: 0.8737373737372266, f1: 0.4673570463362806\n",
            "epoch: 403, step: 7, Train: label_loss: 0.10722418874502182, precision: 0.31637032495399653, recall: 0.8445171849425785, f1: 0.46030330058475044\n",
            "epoch: 403, step: 8, Train: label_loss: 0.10884210467338562, precision: 0.30907960199003054, recall: 0.8201320132011848, f1: 0.4489611562384301\n",
            "epoch: 403, step: 9, Train: label_loss: 0.09742681682109833, precision: 0.3188667872211984, recall: 0.8700657894735411, f1: 0.4666960740674545\n",
            "epoch: 403, step: 10, Train: label_loss: 0.09628541022539139, precision: 0.3361858190708841, recall: 0.8688783570298785, f1: 0.48479506386453125\n",
            "epoch: 403, step: 11, Train: label_loss: 0.10019613802433014, precision: 0.3260606060605863, recall: 0.8539682539681184, f1: 0.47192982452136895\n",
            "epoch: 403, step: 12, Train: label_loss: 0.09836377203464508, precision: 0.3049300060864087, recall: 0.8637931034481269, f1: 0.45074224017731673\n",
            "epoch: 403, step: 13, Train: label_loss: 0.1150055080652237, precision: 0.32127529123235304, recall: 0.8576104746316108, f1: 0.4674397858657489\n",
            "epoch: 403, step: 14, Train: label_loss: 0.09907300770282745, precision: 0.3104294478527417, recall: 0.8489932885904615, f1: 0.4546271338331645\n",
            "epoch: 403, step: 15, Train: label_loss: 0.11631564795970917, precision: 0.3101538461538271, recall: 0.8630136986299891, f1: 0.4563150746554946\n",
            "epoch: 403, step: 16, Train: label_loss: 0.11057116091251373, precision: 0.3221271393642835, recall: 0.8639344262293666, f1: 0.4692787176807839\n",
            "epoch: 403, step: 17, Train: label_loss: 0.11101023107767105, precision: 0.29232643118146817, recall: 0.8347826086955069, f1: 0.43301759130119066\n",
            "epoch: 403, step: 18, Train: label_loss: 0.11075763404369354, precision: 0.3202694427433974, recall: 0.8658940397349559, f1: 0.4675905229824421\n",
            "epoch: 403, step: 19, Train: label_loss: 0.12001831829547882, precision: 0.2942271880819184, recall: 0.8330404217924722, f1: 0.43486238528248433\n",
            "epoch: 403, step: 20, Train: label_loss: 0.11857625842094421, precision: 0.3101109741060228, recall: 0.8510998307951182, f1: 0.4545865340773951\n",
            "epoch: 403, step: 21, Train: label_loss: 0.12447366118431091, precision: 0.2829601990049575, recall: 0.7858376511224894, f1: 0.4160951074141629\n",
            "epoch: 403, step: 22, Train: label_loss: 0.12059685587882996, precision: 0.29956763434216804, recall: 0.8376511226250711, f1: 0.44131028203576705\n",
            "epoch: 403, step: 23, Train: label_loss: 0.1275632083415985, precision: 0.32549317147190243, recall: 0.8428290766206595, f1: 0.4696223316510495\n",
            "epoch: 404, step: 0, Train: label_loss: 0.10265837609767914, precision: 0.3359853121174825, recall: 0.8686708860758119, f1: 0.4845542806305193\n",
            "epoch: 404, step: 1, Train: label_loss: 0.10336203873157501, precision: 0.2978075517661207, recall: 0.8578947368419547, f1: 0.4421338155132404\n",
            "epoch: 404, step: 2, Train: label_loss: 0.09019452333450317, precision: 0.3355461677730636, recall: 0.8797468354428987, f1: 0.4858016600735702\n",
            "epoch: 404, step: 3, Train: label_loss: 0.09250741451978683, precision: 0.32134146341461456, recall: 0.8569105691055516, f1: 0.4674057649270297\n",
            "epoch: 404, step: 4, Train: label_loss: 0.11570488661527634, precision: 0.3006172839505987, recall: 0.8411053540585766, f1: 0.4429286038720334\n",
            "epoch: 404, step: 5, Train: label_loss: 0.11047035455703735, precision: 0.30624620982411727, recall: 0.8647260273971121, f1: 0.4523063143366128\n",
            "epoch: 404, step: 6, Train: label_loss: 0.10310095548629761, precision: 0.296048632218827, recall: 0.855887521968215, f1: 0.4399277325724294\n",
            "epoch: 404, step: 7, Train: label_loss: 0.10442604124546051, precision: 0.3208459214501317, recall: 0.8791390728475365, f1: 0.4701195218731319\n",
            "epoch: 404, step: 8, Train: label_loss: 0.09830699861049652, precision: 0.30476765238380776, recall: 0.8603066439521532, f1: 0.4500891265210429\n",
            "epoch: 404, step: 9, Train: label_loss: 0.09800013899803162, precision: 0.3034188034187849, recall: 0.8643478260868062, f1: 0.44916403068901517\n",
            "epoch: 404, step: 10, Train: label_loss: 0.12100154161453247, precision: 0.30370370370368494, recall: 0.8310810810809406, f1: 0.44484629290831756\n",
            "epoch: 404, step: 11, Train: label_loss: 0.10448500514030457, precision: 0.3156596794081186, recall: 0.8379705400980625, f1: 0.45857590681197713\n",
            "epoch: 404, step: 12, Train: label_loss: 0.1105196624994278, precision: 0.29622871046226906, recall: 0.855887521968215, f1: 0.44012652504083677\n",
            "epoch: 404, step: 13, Train: label_loss: 0.11479274928569794, precision: 0.3267570900123103, recall: 0.8660130718952833, f1: 0.47448522825024003\n",
            "epoch: 404, step: 14, Train: label_loss: 0.10766899585723877, precision: 0.3393829401088724, recall: 0.8890649762280682, f1: 0.49124343253439884\n",
            "epoch: 404, step: 15, Train: label_loss: 0.11234286427497864, precision: 0.3161764705882159, recall: 0.8528925619833301, f1: 0.46133214122111416\n",
            "epoch: 404, step: 16, Train: label_loss: 0.10383531451225281, precision: 0.31807228915660735, recall: 0.8770764119599871, f1: 0.46684350128715707\n",
            "epoch: 404, step: 17, Train: label_loss: 0.10701602697372437, precision: 0.34060606060603993, recall: 0.875389408099552, f1: 0.4904013961201864\n",
            "epoch: 404, step: 18, Train: label_loss: 0.10452085733413696, precision: 0.3161448741559045, recall: 0.8470394736840712, f1: 0.4604380866836647\n",
            "epoch: 404, step: 19, Train: label_loss: 0.11272686719894409, precision: 0.3224615384615186, recall: 0.8534201954396003, f1: 0.46806610089807127\n",
            "epoch: 404, step: 20, Train: label_loss: 0.09744271636009216, precision: 0.29308252427182685, recall: 0.8414634146339997, f1: 0.43474347430907684\n",
            "epoch: 404, step: 21, Train: label_loss: 0.08938875794410706, precision: 0.3185893604303456, recall: 0.9064625850338593, f1: 0.4714727996076467\n",
            "epoch: 404, step: 22, Train: label_loss: 0.11046463996171951, precision: 0.30933496034165286, recall: 0.8651877133104325, f1: 0.4557303370398095\n",
            "epoch: 404, step: 23, Train: label_loss: 0.10409698635339737, precision: 0.3523238380809331, recall: 0.8736059479552278, f1: 0.5021367520957388\n",
            "epoch: 405, step: 0, Train: label_loss: 0.09540753066539764, precision: 0.31944444444442516, recall: 0.8729372937292288, f1: 0.4677276745849587\n",
            "epoch: 405, step: 1, Train: label_loss: 0.10264282673597336, precision: 0.3258084197681314, recall: 0.847619047618913, f1: 0.4706919347328737\n",
            "epoch: 405, step: 2, Train: label_loss: 0.09969654679298401, precision: 0.3158834027364476, recall: 0.8849999999998525, f1: 0.4655852695797773\n",
            "epoch: 405, step: 3, Train: label_loss: 0.10702252388000488, precision: 0.3094801223241401, recall: 0.8709122203096608, f1: 0.45667870032228086\n",
            "epoch: 405, step: 4, Train: label_loss: 0.09043106436729431, precision: 0.3097238895558037, recall: 0.8730964467003598, f1: 0.4572441293365792\n",
            "epoch: 405, step: 5, Train: label_loss: 0.1041145995259285, precision: 0.3337393422655095, recall: 0.8796147672550755, f1: 0.48388520967310167\n",
            "epoch: 405, step: 6, Train: label_loss: 0.09947788715362549, precision: 0.2932515337423133, recall: 0.8298611111109669, f1: 0.4333635539051644\n",
            "epoch: 405, step: 7, Train: label_loss: 0.10655714571475983, precision: 0.32101756511203383, recall: 0.864600326264133, f1: 0.4681978798191261\n",
            "epoch: 405, step: 8, Train: label_loss: 0.10256465524435043, precision: 0.32313341493266073, recall: 0.8741721854303188, f1: 0.47184986591229106\n",
            "epoch: 405, step: 9, Train: label_loss: 0.09497426450252533, precision: 0.32396891811115813, recall: 0.8988391376449587, f1: 0.47627416516311794\n",
            "epoch: 405, step: 10, Train: label_loss: 0.1162535697221756, precision: 0.33252866626431304, recall: 0.9047619047617561, f1: 0.4863195056976333\n",
            "epoch: 405, step: 11, Train: label_loss: 0.11489275097846985, precision: 0.3084911423335181, recall: 0.8752166377814774, f1: 0.4561878951737053\n",
            "epoch: 405, step: 12, Train: label_loss: 0.10490298271179199, precision: 0.29920780012185866, recall: 0.8736654804268907, f1: 0.44575578752436895\n",
            "epoch: 405, step: 13, Train: label_loss: 0.11421206593513489, precision: 0.32720588235292114, recall: 0.8516746411481895, f1: 0.4727755643688849\n",
            "epoch: 405, step: 14, Train: label_loss: 0.10958395898342133, precision: 0.30708180708178834, recall: 0.8554421768706028, f1: 0.45193171604374377\n",
            "epoch: 405, step: 15, Train: label_loss: 0.11736216396093369, precision: 0.31368937998770324, recall: 0.8646362098137285, f1: 0.4603603603212498\n",
            "epoch: 405, step: 16, Train: label_loss: 0.11092869937419891, precision: 0.3119266055045681, recall: 0.8528428093644058, f1: 0.4567845946763715\n",
            "epoch: 405, step: 17, Train: label_loss: 0.09953253716230392, precision: 0.3016928657799092, recall: 0.851535836177329, f1: 0.44553571424704075\n",
            "epoch: 405, step: 18, Train: label_loss: 0.1071503609418869, precision: 0.33493686109438753, recall: 0.8716744913926647, f1: 0.4839270199424754\n",
            "epoch: 405, step: 19, Train: label_loss: 0.11328569054603577, precision: 0.3176328502415267, recall: 0.8885135135133634, f1: 0.46797153021026977\n",
            "epoch: 405, step: 20, Train: label_loss: 0.1132000982761383, precision: 0.33394947627847604, recall: 0.8522012578615011, f1: 0.47985834435967945\n",
            "epoch: 405, step: 21, Train: label_loss: 0.0960659384727478, precision: 0.30565583634173854, recall: 0.8896672504376725, f1: 0.45499328254138427\n",
            "epoch: 405, step: 22, Train: label_loss: 0.11626477539539337, precision: 0.3096853793954158, recall: 0.8297520661155653, f1: 0.4510332434464493\n",
            "epoch: 405, step: 23, Train: label_loss: 0.11871939152479172, precision: 0.33182161753587813, recall: 0.8590998043051157, f1: 0.4787350054123118\n",
            "epoch: 406, step: 0, Train: label_loss: 0.0964256301522255, precision: 0.31862152357918266, recall: 0.8682042833606477, f1: 0.466165413494515\n",
            "epoch: 406, step: 1, Train: label_loss: 0.09979376196861267, precision: 0.2992656058751347, recall: 0.8218487394956602, f1: 0.43876177654225107\n",
            "epoch: 406, step: 2, Train: label_loss: 0.11573778092861176, precision: 0.2883211678831941, recall: 0.8315789473682751, f1: 0.4281842818045456\n",
            "epoch: 406, step: 3, Train: label_loss: 0.1087491363286972, precision: 0.3141809290953353, recall: 0.8412438625203206, f1: 0.4574988873657929\n",
            "epoch: 406, step: 4, Train: label_loss: 0.10661956667900085, precision: 0.3244390539720846, recall: 0.855999999999863, f1: 0.4705364995203437\n",
            "epoch: 406, step: 5, Train: label_loss: 0.10031161457300186, precision: 0.3246359223300774, recall: 0.8629032258063124, f1: 0.4717813050748692\n",
            "epoch: 406, step: 6, Train: label_loss: 0.09697659313678741, precision: 0.31746031746029807, recall: 0.8482871125610361, f1: 0.4620168813463768\n",
            "epoch: 406, step: 7, Train: label_loss: 0.11169800162315369, precision: 0.29768605378359614, recall: 0.8040540540539182, f1: 0.4345047922927906\n",
            "epoch: 406, step: 8, Train: label_loss: 0.1061779111623764, precision: 0.31230863441516765, recall: 0.8457711442784667, f1: 0.45617173520207155\n",
            "epoch: 406, step: 9, Train: label_loss: 0.11029009521007538, precision: 0.305846153846135, recall: 0.8352941176469184, f1: 0.4477477477084705\n",
            "epoch: 406, step: 10, Train: label_loss: 0.10842563211917877, precision: 0.3136167590880891, recall: 0.8497495826375876, f1: 0.4581458145420358\n",
            "epoch: 406, step: 11, Train: label_loss: 0.10675787925720215, precision: 0.32022126613396923, recall: 0.8540983606555976, f1: 0.46580241390754346\n",
            "epoch: 406, step: 12, Train: label_loss: 0.10957594960927963, precision: 0.33780487804875986, recall: 0.8821656050954009, f1: 0.48853615516273385\n",
            "epoch: 406, step: 13, Train: label_loss: 0.11943106353282928, precision: 0.3146896127842462, recall: 0.8462809917353973, f1: 0.45878136196761027\n",
            "epoch: 406, step: 14, Train: label_loss: 0.1081802248954773, precision: 0.31192093885112343, recall: 0.8573853989811786, f1: 0.4574275361927231\n",
            "epoch: 406, step: 15, Train: label_loss: 0.11348538100719452, precision: 0.28606811145509065, recall: 0.8279569892471634, f1: 0.4252185917703509\n",
            "epoch: 406, step: 16, Train: label_loss: 0.11479682475328445, precision: 0.3115055079559173, recall: 0.8641765704582572, f1: 0.45793972105862363\n",
            "epoch: 406, step: 17, Train: label_loss: 0.11742544919252396, precision: 0.3084112149532518, recall: 0.8375634517765079, f1: 0.45081967209176704\n",
            "epoch: 406, step: 18, Train: label_loss: 0.10603083670139313, precision: 0.3418181818181611, recall: 0.8730650154797409, f1: 0.4912891985657898\n",
            "epoch: 406, step: 19, Train: label_loss: 0.11825902760028839, precision: 0.297495418448363, recall: 0.8619469026547146, f1: 0.4423251589082223\n",
            "epoch: 406, step: 20, Train: label_loss: 0.12159664183855057, precision: 0.301538461538443, recall: 0.8433734939757583, f1: 0.44424297366922716\n",
            "epoch: 406, step: 21, Train: label_loss: 0.11754327267408371, precision: 0.33206590621037185, recall: 0.8278041074248297, f1: 0.4739936679826097\n",
            "epoch: 406, step: 22, Train: label_loss: 0.11657358705997467, precision: 0.31163954943677646, recall: 0.811074918566643, f1: 0.4502712476994558\n",
            "epoch: 406, step: 23, Train: label_loss: 0.11043386161327362, precision: 0.3042505592840936, recall: 0.8499999999998229, f1: 0.4481054365344399\n",
            "epoch: 407, step: 0, Train: label_loss: 0.10130699723958969, precision: 0.31815421979354475, recall: 0.8632619439866781, f1: 0.4649511978310559\n",
            "epoch: 407, step: 1, Train: label_loss: 0.1092660203576088, precision: 0.30854333128455386, recall: 0.8366666666665271, f1: 0.45083071392556806\n",
            "epoch: 407, step: 2, Train: label_loss: 0.10875982791185379, precision: 0.3100917431192471, recall: 0.8464106844739822, f1: 0.4538943598532816\n",
            "epoch: 407, step: 3, Train: label_loss: 0.12157867103815079, precision: 0.3079732197200056, recall: 0.8349834983496971, f1: 0.4499777678574334\n",
            "epoch: 407, step: 4, Train: label_loss: 0.09650392830371857, precision: 0.32848484848482856, recall: 0.8770226537215409, f1: 0.47795414458112156\n",
            "epoch: 407, step: 5, Train: label_loss: 0.10468731075525284, precision: 0.29726443768995153, recall: 0.8685612788630783, f1: 0.44293478257066227\n",
            "epoch: 407, step: 6, Train: label_loss: 0.11509895324707031, precision: 0.3256823821339748, recall: 0.8550488599347141, f1: 0.47169811316755517\n",
            "epoch: 407, step: 7, Train: label_loss: 0.1039840579032898, precision: 0.3290986085904217, recall: 0.8676236044655713, f1: 0.4771929824162235\n",
            "epoch: 407, step: 8, Train: label_loss: 0.11213217675685883, precision: 0.3166564978645322, recall: 0.8606965174127925, f1: 0.462979482565452\n",
            "epoch: 407, step: 9, Train: label_loss: 0.09654387086629868, precision: 0.2996323529411581, recall: 0.8387650085761854, f1: 0.4415349886744927\n",
            "epoch: 407, step: 10, Train: label_loss: 0.09980307519435883, precision: 0.31795817958177625, recall: 0.8674496644293845, f1: 0.46534653461416714\n",
            "epoch: 407, step: 11, Train: label_loss: 0.10517533123493195, precision: 0.3155688622754302, recall: 0.8872053872052378, f1: 0.46554770314146476\n",
            "epoch: 407, step: 12, Train: label_loss: 0.11301375180482864, precision: 0.30745906610064844, recall: 0.871134020618407, f1: 0.45450470637107776\n",
            "epoch: 407, step: 13, Train: label_loss: 0.11945613473653793, precision: 0.2881880024736989, recall: 0.8048359240067694, f1: 0.42440801453308147\n",
            "epoch: 407, step: 14, Train: label_loss: 0.12212494015693665, precision: 0.30887792848333484, recall: 0.8477157360404657, f1: 0.4527790329477071\n",
            "epoch: 407, step: 15, Train: label_loss: 0.10484416037797928, precision: 0.3273625694873176, recall: 0.8412698412697077, f1: 0.4713205868871504\n",
            "epoch: 407, step: 16, Train: label_loss: 0.10877315700054169, precision: 0.3263931414574203, recall: 0.8582930756842417, f1: 0.4729370008473485\n",
            "epoch: 407, step: 17, Train: label_loss: 0.10158504545688629, precision: 0.3093788063337205, recall: 0.8624787775889876, f1: 0.4554011653577808\n",
            "epoch: 407, step: 18, Train: label_loss: 0.107177734375, precision: 0.3365558912386504, recall: 0.8813291139239111, f1: 0.48710100564426434\n",
            "epoch: 407, step: 19, Train: label_loss: 0.10620717704296112, precision: 0.291309669522626, recall: 0.8439716312055241, f1: 0.4331210190700898\n",
            "epoch: 407, step: 20, Train: label_loss: 0.10921741276979446, precision: 0.2949816401468608, recall: 0.8397212543552544, f1: 0.4365942028600347\n",
            "epoch: 407, step: 21, Train: label_loss: 0.11390779912471771, precision: 0.3158544108574759, recall: 0.8504983388702906, f1: 0.46063877638871475\n",
            "epoch: 407, step: 22, Train: label_loss: 0.10099783539772034, precision: 0.34412470023978753, recall: 0.8913043478259485, f1: 0.4965397923473086\n",
            "epoch: 407, step: 23, Train: label_loss: 0.1000133827328682, precision: 0.3204747774480474, recall: 0.8622754491016243, f1: 0.467279610560766\n",
            "epoch: 408, step: 0, Train: label_loss: 0.11167529970407486, precision: 0.34051724137928935, recall: 0.8627145085802086, f1: 0.4883002207099263\n",
            "epoch: 408, step: 1, Train: label_loss: 0.0972415953874588, precision: 0.3226002430133461, recall: 0.8606158833061813, f1: 0.4692885549757625\n",
            "epoch: 408, step: 2, Train: label_loss: 0.10211531072854996, precision: 0.3251349730053794, recall: 0.9018302828617467, f1: 0.47795414458181495\n",
            "epoch: 408, step: 3, Train: label_loss: 0.10696408152580261, precision: 0.31215970961885586, recall: 0.8790459965926951, f1: 0.46071428567556816\n",
            "epoch: 408, step: 4, Train: label_loss: 0.12141051888465881, precision: 0.292079207920774, recall: 0.8237347294937479, f1: 0.43124714477629594\n",
            "epoch: 408, step: 5, Train: label_loss: 0.11460007727146149, precision: 0.32575291948369234, recall: 0.868852459016251, f1: 0.4738489047434837\n",
            "epoch: 408, step: 6, Train: label_loss: 0.09963167458772659, precision: 0.323281061519884, recall: 0.8715447154470127, f1: 0.4716234051518634\n",
            "epoch: 408, step: 7, Train: label_loss: 0.1085272878408432, precision: 0.329238329238309, recall: 0.8589743589742213, f1: 0.47602131434710715\n",
            "epoch: 408, step: 8, Train: label_loss: 0.10521285235881805, precision: 0.30812151270921834, recall: 0.8201320132011848, f1: 0.44794952677413685\n",
            "epoch: 408, step: 9, Train: label_loss: 0.1053171455860138, precision: 0.32254123396454965, recall: 0.8502415458935828, f1: 0.46767050483164935\n",
            "epoch: 408, step: 10, Train: label_loss: 0.10678140074014664, precision: 0.32234432234430266, recall: 0.8627450980390746, f1: 0.4693333332936884\n",
            "epoch: 408, step: 11, Train: label_loss: 0.11881659924983978, precision: 0.2942249240121402, recall: 0.8536155202820364, f1: 0.43761301985333645\n",
            "epoch: 408, step: 12, Train: label_loss: 0.08681341260671616, precision: 0.3052884615384432, recall: 0.8850174216026332, f1: 0.45397676493054195\n",
            "epoch: 408, step: 13, Train: label_loss: 0.12243832647800446, precision: 0.33106435643562304, recall: 0.8398744113028508, f1: 0.47492232574723714\n",
            "epoch: 408, step: 14, Train: label_loss: 0.10197438299655914, precision: 0.31147540983604666, recall: 0.8769230769229269, f1: 0.45967741931611705\n",
            "epoch: 408, step: 15, Train: label_loss: 0.09641830623149872, precision: 0.3256797583081374, recall: 0.8879736408565259, f1: 0.4765694075645808\n",
            "epoch: 408, step: 16, Train: label_loss: 0.10808680951595306, precision: 0.33435582822083837, recall: 0.8706070287538544, f1: 0.4831560283286543\n",
            "epoch: 408, step: 17, Train: label_loss: 0.10838799178600311, precision: 0.3111111111110924, recall: 0.8824531516182482, f1: 0.4600355239401018\n",
            "epoch: 408, step: 18, Train: label_loss: 0.1076873242855072, precision: 0.31068560840022785, recall: 0.8468013468012042, f1: 0.4545865340772691\n",
            "epoch: 408, step: 19, Train: label_loss: 0.11451871693134308, precision: 0.3171028606207963, recall: 0.866888519134631, f1: 0.4643493760748216\n",
            "epoch: 408, step: 20, Train: label_loss: 0.10778052359819412, precision: 0.3074074074073884, recall: 0.8455008488962911, f1: 0.4508827523374919\n",
            "epoch: 408, step: 21, Train: label_loss: 0.11385077238082886, precision: 0.30924678505815617, recall: 0.8782608695650646, f1: 0.45742753619332266\n",
            "epoch: 408, step: 22, Train: label_loss: 0.10282929241657257, precision: 0.3056057866184264, recall: 0.8651877133104325, f1: 0.4516703785805353\n",
            "epoch: 408, step: 23, Train: label_loss: 0.10514882206916809, precision: 0.3038922155688395, recall: 0.8388429752064382, f1: 0.4461538461147544\n",
            "epoch: 409, step: 0, Train: label_loss: 0.10361701250076294, precision: 0.32336790726050496, recall: 0.8562197092082623, f1: 0.46944198401684856\n",
            "epoch: 409, step: 1, Train: label_loss: 0.090752974152565, precision: 0.31600955794502295, recall: 0.8875838926173006, f1: 0.46607929511542\n",
            "epoch: 409, step: 2, Train: label_loss: 0.10143842548131943, precision: 0.34936861094405597, recall: 0.8697604790417859, f1: 0.498498498457566\n",
            "epoch: 409, step: 3, Train: label_loss: 0.09929682314395905, precision: 0.29981606376454323, recall: 0.8246205733556787, f1: 0.43974820139970106\n",
            "epoch: 409, step: 4, Train: label_loss: 0.08977893739938736, precision: 0.3254156769596006, recall: 0.9028006589784344, f1: 0.4783937144961455\n",
            "epoch: 409, step: 5, Train: label_loss: 0.10249509662389755, precision: 0.3026796589524785, recall: 0.8568965517239902, f1: 0.44734473443482875\n",
            "epoch: 409, step: 6, Train: label_loss: 0.10843245685100555, precision: 0.3323076923076719, recall: 0.8598726114648312, f1: 0.4793608521568192\n",
            "epoch: 409, step: 7, Train: label_loss: 0.10082898288965225, precision: 0.3117359413202743, recall: 0.8600337268126711, f1: 0.45760430682497105\n",
            "epoch: 409, step: 8, Train: label_loss: 0.10191716253757477, precision: 0.31257706535139873, recall: 0.8492462311556366, f1: 0.45696259572448483\n",
            "epoch: 409, step: 9, Train: label_loss: 0.10777203738689423, precision: 0.2908756889160875, recall: 0.8543165467624362, f1: 0.4339881223923973\n",
            "epoch: 409, step: 10, Train: label_loss: 0.11864074319601059, precision: 0.33210784313723457, recall: 0.8548895899052279, f1: 0.4783759928987562\n",
            "epoch: 409, step: 11, Train: label_loss: 0.1008823812007904, precision: 0.30138637733572626, recall: 0.8771929824559864, f1: 0.44863167335803605\n",
            "epoch: 409, step: 12, Train: label_loss: 0.10658255219459534, precision: 0.31997571341831693, recall: 0.881270903009886, f1: 0.46948775051766756\n",
            "epoch: 409, step: 13, Train: label_loss: 0.11694546043872833, precision: 0.30098887515449313, recall: 0.8324786324784901, f1: 0.4421243758120656\n",
            "epoch: 409, step: 14, Train: label_loss: 0.10854525864124298, precision: 0.31453096259961283, recall: 0.8665540540539076, f1: 0.46153846149934247\n",
            "epoch: 409, step: 15, Train: label_loss: 0.106206014752388, precision: 0.3341523341523136, recall: 0.8676236044655713, f1: 0.48248337024805804\n",
            "epoch: 409, step: 16, Train: label_loss: 0.09321556240320206, precision: 0.33010296789822346, recall: 0.8692185007973094, f1: 0.4784899033841174\n",
            "epoch: 409, step: 17, Train: label_loss: 0.12120296061038971, precision: 0.3112623762376045, recall: 0.8642611683847312, f1: 0.45768880796830275\n",
            "epoch: 409, step: 18, Train: label_loss: 0.10650141537189484, precision: 0.30402930402928546, recall: 0.8483816013627175, f1: 0.4476404493993182\n",
            "epoch: 409, step: 19, Train: label_loss: 0.11436043679714203, precision: 0.3004291845493378, recall: 0.8536585365852171, f1: 0.4444444444058937\n",
            "epoch: 409, step: 20, Train: label_loss: 0.1084369346499443, precision: 0.30958230958229055, recall: 0.8208469055373255, f1: 0.4495985726631313\n",
            "epoch: 409, step: 21, Train: label_loss: 0.10329581797122955, precision: 0.2975903614457652, recall: 0.8606271777001985, f1: 0.44225604293402326\n",
            "epoch: 409, step: 22, Train: label_loss: 0.1289673000574112, precision: 0.3268628678772494, recall: 0.8246445497629028, f1: 0.46816143493688\n",
            "epoch: 409, step: 23, Train: label_loss: 0.11782075464725494, precision: 0.32008995502246473, recall: 0.8804123711338391, f1: 0.46948873003230845\n",
            "epoch: 410, step: 0, Train: label_loss: 0.12420672178268433, precision: 0.3079306071870937, recall: 0.8255813953487, f1: 0.4485559566390877\n",
            "epoch: 410, step: 1, Train: label_loss: 0.1195841059088707, precision: 0.31164807930605254, recall: 0.8341625207295466, f1: 0.45376635088502987\n",
            "epoch: 410, step: 2, Train: label_loss: 0.11346900463104248, precision: 0.3267813267813067, recall: 0.8580645161288938, f1: 0.47330960850093623\n",
            "epoch: 410, step: 3, Train: label_loss: 0.10527528077363968, precision: 0.31468110709986075, recall: 0.8894557823127738, f1: 0.4648888888502399\n",
            "epoch: 410, step: 4, Train: label_loss: 0.12198147922754288, precision: 0.31815421979354475, recall: 0.8492706645055349, f1: 0.46289752646207466\n",
            "epoch: 410, step: 5, Train: label_loss: 0.10796602070331573, precision: 0.3153042409342154, recall: 0.8465346534652067, f1: 0.4594715628802507\n",
            "epoch: 410, step: 6, Train: label_loss: 0.11629970371723175, precision: 0.3135333741579722, recall: 0.8462809917353973, f1: 0.45755138512583493\n",
            "epoch: 410, step: 7, Train: label_loss: 0.10362233221530914, precision: 0.32623250152158695, recall: 0.8659127625200539, f1: 0.47391688767019596\n",
            "epoch: 410, step: 8, Train: label_loss: 0.1068493127822876, precision: 0.2994522215459343, recall: 0.8677248677247146, f1: 0.4452488687400928\n",
            "epoch: 410, step: 9, Train: label_loss: 0.10078002512454987, precision: 0.3252866626433117, recall: 0.886513157894591, f1: 0.4759381898061573\n",
            "epoch: 410, step: 10, Train: label_loss: 0.10756561905145645, precision: 0.35096153846151734, recall: 0.9040247678017176, f1: 0.5056277055873724\n",
            "epoch: 410, step: 11, Train: label_loss: 0.10307131707668304, precision: 0.32809667673714027, recall: 0.8887070376430624, f1: 0.47925860543276866\n",
            "epoch: 410, step: 12, Train: label_loss: 0.10303620994091034, precision: 0.30079803560464696, recall: 0.8404802744423944, f1: 0.44303797464468475\n",
            "epoch: 410, step: 13, Train: label_loss: 0.1050468161702156, precision: 0.31310679611648584, recall: 0.8989547038325959, f1: 0.4644464446061039\n",
            "epoch: 410, step: 14, Train: label_loss: 0.1129128485918045, precision: 0.30992736077479965, recall: 0.8782161234989917, f1: 0.4581655480598315\n",
            "epoch: 410, step: 15, Train: label_loss: 0.11255943775177002, precision: 0.31926605504585204, recall: 0.8642384105958834, f1: 0.4662795890628379\n",
            "epoch: 410, step: 16, Train: label_loss: 0.11492300778627396, precision: 0.31459987782527093, recall: 0.8554817275746086, f1: 0.46002679763817766\n",
            "epoch: 410, step: 17, Train: label_loss: 0.12431099265813828, precision: 0.2971813725490014, recall: 0.8434782608694185, f1: 0.43951064789980676\n",
            "epoch: 410, step: 18, Train: label_loss: 0.11168058216571808, precision: 0.32465172622650973, recall: 0.8673139158574648, f1: 0.4724548258748215\n",
            "epoch: 410, step: 19, Train: label_loss: 0.1011272668838501, precision: 0.2963636363636184, recall: 0.8504347826085477, f1: 0.43955056175938484\n",
            "epoch: 410, step: 20, Train: label_loss: 0.10340623557567596, precision: 0.3104715248009608, recall: 0.8366336633661985, f1: 0.4528807502954502\n",
            "epoch: 410, step: 21, Train: label_loss: 0.11293938755989075, precision: 0.3112864077669714, recall: 0.8636363636362182, f1: 0.45762711860507743\n",
            "epoch: 410, step: 22, Train: label_loss: 0.11375027894973755, precision: 0.32124999999997994, recall: 0.8197767145134258, f1: 0.4616075437403742\n",
            "epoch: 410, step: 23, Train: label_loss: 0.1055947095155716, precision: 0.3188946975354504, recall: 0.8786008230450867, f1: 0.46794520544032375\n",
            "epoch: 411, step: 0, Train: label_loss: 0.09562666714191437, precision: 0.3182912154031096, recall: 0.8831385642736421, f1: 0.46793454219895825\n",
            "epoch: 411, step: 1, Train: label_loss: 0.12404219806194305, precision: 0.2975460122699204, recall: 0.8376511226250711, f1: 0.4391127206493728\n",
            "epoch: 411, step: 2, Train: label_loss: 0.09978479146957397, precision: 0.32531569452794196, recall: 0.869774919614008, f1: 0.47352297589031433\n",
            "epoch: 411, step: 3, Train: label_loss: 0.09694631397724152, precision: 0.33979406420349245, recall: 0.8961661341851603, f1: 0.49275362314849447\n",
            "epoch: 411, step: 4, Train: label_loss: 0.10418283194303513, precision: 0.332527206771443, recall: 0.8744038155801471, f1: 0.48182216377957215\n",
            "epoch: 411, step: 5, Train: label_loss: 0.09704294800758362, precision: 0.3069069069068885, recall: 0.8780068728520828, f1: 0.45482866039771164\n",
            "epoch: 411, step: 6, Train: label_loss: 0.10590516775846481, precision: 0.31368937998770324, recall: 0.8502495840264808, f1: 0.4582959640861448\n",
            "epoch: 411, step: 7, Train: label_loss: 0.11305546015501022, precision: 0.29259259259257453, recall: 0.8359788359786885, f1: 0.43347050750613325\n",
            "epoch: 411, step: 8, Train: label_loss: 0.11007978022098541, precision: 0.3218390804597506, recall: 0.8764415156505969, f1: 0.47079646013766013\n",
            "epoch: 411, step: 9, Train: label_loss: 0.10187209397554398, precision: 0.2986069049060994, recall: 0.8384353741495172, f1: 0.44037516744671534\n",
            "epoch: 411, step: 10, Train: label_loss: 0.11666886508464813, precision: 0.28891656288914763, recall: 0.8270944741531502, f1: 0.4282418089140568\n",
            "epoch: 411, step: 11, Train: label_loss: 0.11520972102880478, precision: 0.3109605911329858, recall: 0.8473154362414685, f1: 0.45495495491563537\n",
            "epoch: 411, step: 12, Train: label_loss: 0.10997940599918365, precision: 0.3247549019607644, recall: 0.8466453674120052, f1: 0.4694419840165704\n",
            "epoch: 411, step: 13, Train: label_loss: 0.09649033844470978, precision: 0.3288672350791517, recall: 0.8681672025722076, f1: 0.4770318020802481\n",
            "epoch: 411, step: 14, Train: label_loss: 0.11345836520195007, precision: 0.3207317073170536, recall: 0.8637110016418942, f1: 0.4677634503828761\n",
            "epoch: 411, step: 15, Train: label_loss: 0.10289396345615387, precision: 0.3141646489103926, recall: 0.8494271685759657, f1: 0.45868316390221026\n",
            "epoch: 411, step: 16, Train: label_loss: 0.08742509037256241, precision: 0.31063829787232156, recall: 0.8675721561967966, f1: 0.45747538044456876\n",
            "epoch: 411, step: 17, Train: label_loss: 0.10282497107982635, precision: 0.30146163215588906, recall: 0.8669001751311967, f1: 0.44735652955950134\n",
            "epoch: 411, step: 18, Train: label_loss: 0.12655405700206757, precision: 0.31308121512707293, recall: 0.8402662229615906, f1: 0.45618789517269087\n",
            "epoch: 411, step: 19, Train: label_loss: 0.11903436481952667, precision: 0.33188315724050144, recall: 0.8462757527732414, f1: 0.47678571424520294\n",
            "epoch: 411, step: 20, Train: label_loss: 0.11358930170536041, precision: 0.3153320918683851, recall: 0.8193548387095452, f1: 0.45540116535650776\n",
            "epoch: 411, step: 21, Train: label_loss: 0.10262436419725418, precision: 0.3106617647058633, recall: 0.8564189189187742, f1: 0.4559352517594538\n",
            "epoch: 411, step: 22, Train: label_loss: 0.10454721748828888, precision: 0.32026537997585525, recall: 0.880597014925227, f1: 0.46970367090290555\n",
            "epoch: 411, step: 23, Train: label_loss: 0.10011839866638184, precision: 0.31872213967308183, recall: 0.8809034907595727, f1: 0.4680851063439084\n",
            "epoch: 412, step: 0, Train: label_loss: 0.1026720181107521, precision: 0.3386503067484455, recall: 0.8706624605676859, f1: 0.4876325087935561\n",
            "epoch: 412, step: 1, Train: label_loss: 0.10934396833181381, precision: 0.31104294478525696, recall: 0.8622448979590369, f1: 0.45716862033971356\n",
            "epoch: 412, step: 2, Train: label_loss: 0.09659899771213531, precision: 0.3359374999999798, recall: 0.9059967585087672, f1: 0.49013590526518236\n",
            "epoch: 412, step: 3, Train: label_loss: 0.08821143209934235, precision: 0.3177966101694723, recall: 0.8898305084744254, f1: 0.46833184652674353\n",
            "epoch: 412, step: 4, Train: label_loss: 0.11367100477218628, precision: 0.30499075785580376, recall: 0.8333333333331929, f1: 0.4465493910297432\n",
            "epoch: 412, step: 5, Train: label_loss: 0.10094629228115082, precision: 0.31920048455479594, recall: 0.875415282391881, f1: 0.46782068349386463\n",
            "epoch: 412, step: 6, Train: label_loss: 0.09407632052898407, precision: 0.3108839446782735, recall: 0.8747884940776861, f1: 0.4587400177074979\n",
            "epoch: 412, step: 7, Train: label_loss: 0.10510699450969696, precision: 0.33312883435580776, recall: 0.8729903536976088, f1: 0.48223801061716814\n",
            "epoch: 412, step: 8, Train: label_loss: 0.0998300313949585, precision: 0.3333333333333132, recall: 0.894822006472347, f1: 0.4857268335133285\n",
            "epoch: 412, step: 9, Train: label_loss: 0.0955173596739769, precision: 0.3126131563065593, recall: 0.8764805414550124, f1: 0.4608540924878926\n",
            "epoch: 412, step: 10, Train: label_loss: 0.10728571563959122, precision: 0.2979368932038654, recall: 0.8583916083914582, f1: 0.4423423423040484\n",
            "epoch: 412, step: 11, Train: label_loss: 0.10772164165973663, precision: 0.32340425531912925, recall: 0.8636363636362234, f1: 0.4705882352544322\n",
            "epoch: 412, step: 12, Train: label_loss: 0.10208216309547424, precision: 0.3270858524788194, recall: 0.871175523349296, f1: 0.47560439556466255\n",
            "epoch: 412, step: 13, Train: label_loss: 0.10242440551519394, precision: 0.31559633027521006, recall: 0.858569051580556, f1: 0.4615384614991125\n",
            "epoch: 412, step: 14, Train: label_loss: 0.11016480624675751, precision: 0.29533050333533684, recall: 0.866548042704472, f1: 0.44052464944191866\n",
            "epoch: 412, step: 15, Train: label_loss: 0.1103343814611435, precision: 0.3253382533825138, recall: 0.8532258064514753, f1: 0.4710596615806481\n",
            "epoch: 412, step: 16, Train: label_loss: 0.10600227117538452, precision: 0.296092796092778, recall: 0.8420138888887426, f1: 0.4381210478386102\n",
            "epoch: 412, step: 17, Train: label_loss: 0.11063668876886368, precision: 0.30975609756095673, recall: 0.8788927335638617, f1: 0.458070333595326\n",
            "epoch: 412, step: 18, Train: label_loss: 0.10676376521587372, precision: 0.31479217603910054, recall: 0.8655462184872494, f1: 0.4616763782665372\n",
            "epoch: 412, step: 19, Train: label_loss: 0.10891473293304443, precision: 0.32549728752258433, recall: 0.8737864077668488, f1: 0.47430830035566596\n",
            "epoch: 412, step: 20, Train: label_loss: 0.10181780904531479, precision: 0.30400485436891356, recall: 0.8564102564101099, f1: 0.44872369006429097\n",
            "epoch: 412, step: 21, Train: label_loss: 0.11506204307079315, precision: 0.29520295202950214, recall: 0.8177172061327397, f1: 0.43380027108615166\n",
            "epoch: 412, step: 22, Train: label_loss: 0.11468040198087692, precision: 0.31575682382132036, recall: 0.8303425774876296, f1: 0.4575280898476788\n",
            "epoch: 412, step: 23, Train: label_loss: 0.10439838469028473, precision: 0.33660377358488025, recall: 0.8446969696968096, f1: 0.48138154340226325\n",
            "epoch: 413, step: 0, Train: label_loss: 0.10508771240711212, precision: 0.3256519102486158, recall: 0.8731707317071751, f1: 0.47438162540208356\n",
            "epoch: 413, step: 1, Train: label_loss: 0.11286978423595428, precision: 0.3310893512851694, recall: 0.8453124999998679, f1: 0.4758135443746391\n",
            "epoch: 413, step: 2, Train: label_loss: 0.11120641231536865, precision: 0.3188228080931748, recall: 0.8681135225374176, f1: 0.46636771296515067\n",
            "epoch: 413, step: 3, Train: label_loss: 0.09012949466705322, precision: 0.3317220543806446, recall: 0.8926829268291231, f1: 0.4837004404890868\n",
            "epoch: 413, step: 4, Train: label_loss: 0.10397495329380035, precision: 0.3036263060848, recall: 0.8430034129691394, f1: 0.4464527789940105\n",
            "epoch: 413, step: 5, Train: label_loss: 0.10374937951564789, precision: 0.31223628691981237, recall: 0.8794567062816843, f1: 0.46085409248797715\n",
            "epoch: 413, step: 6, Train: label_loss: 0.09951511770486832, precision: 0.31207847946043454, recall: 0.865646258503254, f1: 0.45876520951485816\n",
            "epoch: 413, step: 7, Train: label_loss: 0.08262777328491211, precision: 0.3170441001191706, recall: 0.9001692047375803, f1: 0.46892904359298954\n",
            "epoch: 413, step: 8, Train: label_loss: 0.10643039643764496, precision: 0.31498470948010304, recall: 0.8583333333331902, f1: 0.46085011181750446\n",
            "epoch: 413, step: 9, Train: label_loss: 0.09006188064813614, precision: 0.32628398791538815, recall: 0.8598726114648312, f1: 0.47306176080107537\n",
            "epoch: 413, step: 10, Train: label_loss: 0.09995020925998688, precision: 0.3297491039426326, recall: 0.9034369885432236, f1: 0.48315098464349193\n",
            "epoch: 413, step: 11, Train: label_loss: 0.11068050563335419, precision: 0.28971393791842426, recall: 0.8469750889678208, f1: 0.4317460317080098\n",
            "epoch: 413, step: 12, Train: label_loss: 0.10166246443986893, precision: 0.30764599638769974, recall: 0.882556131260642, f1: 0.45624999996162546\n",
            "epoch: 413, step: 13, Train: label_loss: 0.09565088152885437, precision: 0.3347483323225995, recall: 0.857142857142724, f1: 0.4814653292225372\n",
            "epoch: 413, step: 14, Train: label_loss: 0.10212209075689316, precision: 0.33174224343673436, recall: 0.8867623604464295, f1: 0.48284845849268077\n",
            "epoch: 413, step: 15, Train: label_loss: 0.11433431506156921, precision: 0.3147581139007768, recall: 0.8524046434492781, f1: 0.4597495527333771\n",
            "epoch: 413, step: 16, Train: label_loss: 0.11510251462459564, precision: 0.31637032495399653, recall: 0.8514851485147109, f1: 0.46133214122107313\n",
            "epoch: 413, step: 17, Train: label_loss: 0.10698656737804413, precision: 0.3265807243707596, recall: 0.8636363636362234, f1: 0.47394209350134064\n",
            "epoch: 413, step: 18, Train: label_loss: 0.10157206654548645, precision: 0.30398069963809987, recall: 0.855687606111909, f1: 0.44859813080239824\n",
            "epoch: 413, step: 19, Train: label_loss: 0.09875793009996414, precision: 0.3202694427433974, recall: 0.8658940397349559, f1: 0.4675905229824421\n",
            "epoch: 413, step: 20, Train: label_loss: 0.09845499694347382, precision: 0.3154689403166677, recall: 0.861896838602186, f1: 0.4618814087881919\n",
            "epoch: 413, step: 21, Train: label_loss: 0.10318974405527115, precision: 0.2979242979242797, recall: 0.8501742160277264, f1: 0.44122965638105854\n",
            "epoch: 413, step: 22, Train: label_loss: 0.11184798926115036, precision: 0.30360415394011586, recall: 0.8780918727913642, f1: 0.45120290509114536\n",
            "epoch: 413, step: 23, Train: label_loss: 0.09679935872554779, precision: 0.32005899705012386, recall: 0.8930041152261537, f1: 0.47122692721408865\n",
            "epoch: 414, step: 0, Train: label_loss: 0.09429684281349182, precision: 0.3269704433497336, recall: 0.8592233009707347, f1: 0.47368421048634046\n",
            "epoch: 414, step: 1, Train: label_loss: 0.10437731444835663, precision: 0.30577507598782333, recall: 0.8687392055266202, f1: 0.4523381294578494\n",
            "epoch: 414, step: 2, Train: label_loss: 0.1096767783164978, precision: 0.3202179176755254, recall: 0.861563517915169, f1: 0.46690202996927654\n",
            "epoch: 414, step: 3, Train: label_loss: 0.11928468942642212, precision: 0.3129584352078048, recall: 0.8677966101693444, f1: 0.46001796941293077\n",
            "epoch: 414, step: 4, Train: label_loss: 0.11893986910581589, precision: 0.3153320918683851, recall: 0.8382838283826999, f1: 0.4582769507946943\n",
            "epoch: 414, step: 5, Train: label_loss: 0.10622614622116089, precision: 0.2965009208102949, recall: 0.8655913978493072, f1: 0.44170096018142924\n",
            "epoch: 414, step: 6, Train: label_loss: 0.07904614508152008, precision: 0.33729922665078305, recall: 0.9130434782607225, f1: 0.49261511724987245\n",
            "epoch: 414, step: 7, Train: label_loss: 0.10081657022237778, precision: 0.3190591073582437, recall: 0.8860971524286623, f1: 0.46917960084794536\n",
            "epoch: 414, step: 8, Train: label_loss: 0.0767030268907547, precision: 0.32934131736524974, recall: 0.8957654723125577, f1: 0.48161120836695076\n",
            "epoch: 414, step: 9, Train: label_loss: 0.10984517633914948, precision: 0.3275135460565727, recall: 0.8932676518881948, f1: 0.47929515414571844\n",
            "epoch: 414, step: 10, Train: label_loss: 0.09404624998569489, precision: 0.30847865303666216, recall: 0.8952879581150269, f1: 0.4588550983518228\n",
            "epoch: 414, step: 11, Train: label_loss: 0.10890178382396698, precision: 0.3366583541146922, recall: 0.8490566037734514, f1: 0.48214285710215143\n",
            "epoch: 414, step: 12, Train: label_loss: 0.09806758910417557, precision: 0.32684114424830635, recall: 0.8788870703762882, f1: 0.4764862466330212\n",
            "epoch: 414, step: 13, Train: label_loss: 0.10451318323612213, precision: 0.32749244712988956, recall: 0.8784440842786257, f1: 0.4771126760167323\n",
            "epoch: 414, step: 14, Train: label_loss: 0.10814842581748962, precision: 0.32740649908029873, recall: 0.836990595611154, f1: 0.4706919347325626\n",
            "epoch: 414, step: 15, Train: label_loss: 0.11025122553110123, precision: 0.3263931414574203, recall: 0.8487261146495463, f1: 0.4714727996060113\n",
            "epoch: 414, step: 16, Train: label_loss: 0.10154817998409271, precision: 0.3206854345165042, recall: 0.8646864686467219, f1: 0.46785714281763185\n",
            "epoch: 414, step: 17, Train: label_loss: 0.09539604932069778, precision: 0.31086824529445595, recall: 0.8619528619527168, f1: 0.4569388665384193\n",
            "epoch: 414, step: 18, Train: label_loss: 0.09838496893644333, precision: 0.2903225806451436, recall: 0.8579136690645939, f1: 0.43383356067159123\n",
            "epoch: 414, step: 19, Train: label_loss: 0.10730279982089996, precision: 0.30699638118212863, recall: 0.865646258503254, f1: 0.4532502225792951\n",
            "epoch: 414, step: 20, Train: label_loss: 0.09764650464057922, precision: 0.3240460327074304, recall: 0.8670988654779793, f1: 0.47178130507498944\n",
            "epoch: 414, step: 21, Train: label_loss: 0.11538764834403992, precision: 0.29726443768995153, recall: 0.8416523235798895, f1: 0.43935309969184233\n",
            "epoch: 414, step: 22, Train: label_loss: 0.11007822304964066, precision: 0.3094089264173517, recall: 0.8650927487350986, f1: 0.45579742332854406\n",
            "epoch: 414, step: 23, Train: label_loss: 0.10986819118261337, precision: 0.29151014274979026, recall: 0.816842105262986, f1: 0.4296788482446845\n",
            "epoch: 415, step: 0, Train: label_loss: 0.0969775915145874, precision: 0.3201675643327157, recall: 0.8901830282860415, f1: 0.4709507041864003\n",
            "epoch: 415, step: 1, Train: label_loss: 0.09360949695110321, precision: 0.3268529769137104, recall: 0.8663446054749007, f1: 0.4746360828891606\n",
            "epoch: 415, step: 2, Train: label_loss: 0.08629024773836136, precision: 0.3275552898983665, recall: 0.8896103896102451, f1: 0.4788117081301262\n",
            "epoch: 415, step: 3, Train: label_loss: 0.10278265178203583, precision: 0.3079231692676886, recall: 0.8724489795916883, f1: 0.45519077192235446\n",
            "epoch: 415, step: 4, Train: label_loss: 0.10010955482721329, precision: 0.3075528700906158, recall: 0.8700854700853213, f1: 0.45446428567565395\n",
            "epoch: 415, step: 5, Train: label_loss: 0.09167896956205368, precision: 0.3042693926638422, recall: 0.8955752212387795, f1: 0.45421903048274903\n",
            "epoch: 415, step: 6, Train: label_loss: 0.1063898354768753, precision: 0.3156626506023906, recall: 0.8806722689074149, f1: 0.464745011047586\n",
            "epoch: 415, step: 7, Train: label_loss: 0.09258764982223511, precision: 0.32273545290939876, recall: 0.8705501618121568, f1: 0.47089715532154686\n",
            "epoch: 415, step: 8, Train: label_loss: 0.1063799113035202, precision: 0.308439587128093, recall: 0.8610169491523963, f1: 0.45417970492312526\n",
            "epoch: 415, step: 9, Train: label_loss: 0.09975565969944, precision: 0.3135233474833042, recall: 0.8559602649005205, f1: 0.45894363067531874\n",
            "epoch: 415, step: 10, Train: label_loss: 0.10092759877443314, precision: 0.3278985507246179, recall: 0.8814935064933633, f1: 0.4779929577069133\n",
            "epoch: 415, step: 11, Train: label_loss: 0.09561719000339508, precision: 0.32549728752258433, recall: 0.9152542372879804, f1: 0.48021342815156065\n",
            "epoch: 415, step: 12, Train: label_loss: 0.09911961853504181, precision: 0.32911392405061307, recall: 0.8834951456309249, f1: 0.4795783925822794\n",
            "epoch: 415, step: 13, Train: label_loss: 0.10173849016427994, precision: 0.33091787439611525, recall: 0.8824476650562185, f1: 0.48133508999103053\n",
            "epoch: 415, step: 14, Train: label_loss: 0.09488985687494278, precision: 0.3139604553624737, recall: 0.8866328257189701, f1: 0.4637168141206271\n",
            "epoch: 415, step: 15, Train: label_loss: 0.09762731194496155, precision: 0.31648616125148515, recall: 0.8766666666665205, f1: 0.46507515469130734\n",
            "epoch: 415, step: 16, Train: label_loss: 0.1027788519859314, precision: 0.32134146341461456, recall: 0.8541329011343833, f1: 0.46699158170591076\n",
            "epoch: 415, step: 17, Train: label_loss: 0.10807187855243683, precision: 0.3047390521895438, recall: 0.8896672504376725, f1: 0.45397676493067285\n",
            "epoch: 415, step: 18, Train: label_loss: 0.10224901139736176, precision: 0.30816077953713106, recall: 0.8679245283017378, f1: 0.45483146063544305\n",
            "epoch: 415, step: 19, Train: label_loss: 0.10206170380115509, precision: 0.3180708180707986, recall: 0.8654485049832449, f1: 0.4651785713892252\n",
            "epoch: 415, step: 20, Train: label_loss: 0.08793099224567413, precision: 0.3313289236319705, recall: 0.8787878787877386, f1: 0.48122270738377215\n",
            "epoch: 415, step: 21, Train: label_loss: 0.10323838889598846, precision: 0.3143032535297536, recall: 0.8434925864908001, f1: 0.4579606439675601\n",
            "epoch: 415, step: 22, Train: label_loss: 0.0896478071808815, precision: 0.32102441929718156, recall: 0.8923841059601171, f1: 0.4721857205041896\n",
            "epoch: 415, step: 23, Train: label_loss: 0.09394315630197525, precision: 0.3154805575935205, recall: 0.8793456032718039, f1: 0.4643628509330076\n",
            "epoch: 416, step: 0, Train: label_loss: 0.09397467970848083, precision: 0.29872495446264125, recall: 0.8482758620688192, f1: 0.44185002241316684\n",
            "epoch: 416, step: 1, Train: label_loss: 0.1173384040594101, precision: 0.3036809815950734, recall: 0.8432708688243878, f1: 0.4465493910300383\n",
            "epoch: 416, step: 2, Train: label_loss: 0.09380118548870087, precision: 0.3097991479001637, recall: 0.8483333333331918, f1: 0.45385644222559474\n",
            "epoch: 416, step: 3, Train: label_loss: 0.09193139523267746, precision: 0.3156626506023906, recall: 0.8718801996670762, f1: 0.46351172043859257\n",
            "epoch: 416, step: 4, Train: label_loss: 0.10441498458385468, precision: 0.3204182041820221, recall: 0.8389694041866603, f1: 0.46372941696040587\n",
            "epoch: 416, step: 5, Train: label_loss: 0.12443709373474121, precision: 0.2993710691823711, recall: 0.7816091954021704, f1: 0.4329240563491792\n",
            "epoch: 416, step: 6, Train: label_loss: 0.1386069804430008, precision: 0.31482649842269306, recall: 0.7945859872610199, f1: 0.45097153181651706\n",
            "epoch: 416, step: 7, Train: label_loss: 0.11502047628164291, precision: 0.29668956901934435, recall: 0.8064516129030889, f1: 0.43378995429853673\n",
            "epoch: 416, step: 8, Train: label_loss: 0.12589624524116516, precision: 0.3198226725775605, recall: 0.8224755700324393, f1: 0.4605563155091152\n",
            "epoch: 416, step: 9, Train: label_loss: 0.12519192695617676, precision: 0.30470219435734763, recall: 0.8073089700995336, f1: 0.44242148380177615\n",
            "epoch: 416, step: 10, Train: label_loss: 0.13529419898986816, precision: 0.3095238095237896, recall: 0.7963576158939079, f1: 0.445783132489769\n",
            "epoch: 416, step: 11, Train: label_loss: 0.12421479821205139, precision: 0.29307056579781987, recall: 0.7866894197950876, f1: 0.42704955994188293\n",
            "epoch: 416, step: 12, Train: label_loss: 0.129710853099823, precision: 0.2996825396825206, recall: 0.8137931034481355, f1: 0.43805104404414513\n",
            "epoch: 416, step: 13, Train: label_loss: 0.13295787572860718, precision: 0.3181818181817978, recall: 0.793929712459937, f1: 0.45429616083662233\n",
            "epoch: 416, step: 14, Train: label_loss: 0.143286794424057, precision: 0.297996121525514, recall: 0.753267973856086, f1: 0.42704955994081084\n",
            "epoch: 416, step: 15, Train: label_loss: 0.13628345727920532, precision: 0.30160771704178124, recall: 0.7989778534921977, f1: 0.4379084966921966\n",
            "epoch: 416, step: 16, Train: label_loss: 0.13231326639652252, precision: 0.32536186280677626, recall: 0.8285256410255082, f1: 0.4672390419838664\n",
            "epoch: 416, step: 17, Train: label_loss: 0.14196011424064636, precision: 0.29960835509136424, recall: 0.7536945812806644, f1: 0.42877160201436704\n",
            "epoch: 416, step: 18, Train: label_loss: 0.1463174670934677, precision: 0.3045685279187624, recall: 0.7843137254900678, f1: 0.43875685553553395\n",
            "epoch: 416, step: 19, Train: label_loss: 0.13867688179016113, precision: 0.29382093316517693, recall: 0.7805695142377251, f1: 0.4269354099464809\n",
            "epoch: 416, step: 20, Train: label_loss: 0.12962383031845093, precision: 0.3140186915887655, recall: 0.8221859706360811, f1: 0.4544634805731256\n",
            "epoch: 416, step: 21, Train: label_loss: 0.1432226151227951, precision: 0.28316326530610436, recall: 0.7971274685815445, f1: 0.4178823529024547\n",
            "epoch: 416, step: 22, Train: label_loss: 0.14116956293582916, precision: 0.298132646490644, recall: 0.7602627257798422, f1: 0.4283071229937203\n",
            "epoch: 416, step: 23, Train: label_loss: 0.1323075294494629, precision: 0.29969418960242356, recall: 0.8305084745760952, f1: 0.44044943816322685\n",
            "epoch: 417, step: 0, Train: label_loss: 0.12822119891643524, precision: 0.3136762860727532, recall: 0.8389261744965034, f1: 0.45662100452655174\n",
            "epoch: 417, step: 1, Train: label_loss: 0.12793685495853424, precision: 0.33228445563245235, recall: 0.8249999999998711, f1: 0.47375504706534644\n",
            "epoch: 417, step: 2, Train: label_loss: 0.12618854641914368, precision: 0.29283489096571386, recall: 0.8145580589253354, f1: 0.43079743350826294\n",
            "epoch: 417, step: 3, Train: label_loss: 0.1268601417541504, precision: 0.33002481389576116, recall: 0.8457869634338877, f1: 0.47478804101267935\n",
            "epoch: 417, step: 4, Train: label_loss: 0.12161113321781158, precision: 0.29334170854269515, recall: 0.8221830985914045, f1: 0.4324074073686046\n",
            "epoch: 417, step: 5, Train: label_loss: 0.1387501358985901, precision: 0.2878017789072244, recall: 0.8191681735984051, f1: 0.42595204509547235\n",
            "epoch: 417, step: 6, Train: label_loss: 0.124547079205513, precision: 0.32284980744542213, recall: 0.8047999999998712, f1: 0.4608337150300943\n",
            "epoch: 417, step: 7, Train: label_loss: 0.1241530179977417, precision: 0.3055382700684315, recall: 0.8421955403086033, f1: 0.4484018264449088\n",
            "epoch: 417, step: 8, Train: label_loss: 0.13436642289161682, precision: 0.3068749999999808, recall: 0.8224455611388907, f1: 0.4469731451583776\n",
            "epoch: 417, step: 9, Train: label_loss: 0.13982346653938293, precision: 0.30398986700441394, recall: 0.8177172061327397, f1: 0.4432132963593386\n",
            "epoch: 417, step: 10, Train: label_loss: 0.1261761486530304, precision: 0.32051282051280094, recall: 0.8564437194125846, f1: 0.466459351359704\n",
            "epoch: 417, step: 11, Train: label_loss: 0.13492709398269653, precision: 0.3179012345678816, recall: 0.8097484276728286, f1: 0.456560283647415\n",
            "epoch: 417, step: 12, Train: label_loss: 0.11003445088863373, precision: 0.3172541743970119, recall: 0.8465346534652067, f1: 0.46153846149876177\n",
            "epoch: 417, step: 13, Train: label_loss: 0.11537420749664307, precision: 0.32740649908029873, recall: 0.8599033816423736, f1: 0.4742451154129458\n",
            "epoch: 417, step: 14, Train: label_loss: 0.11897167563438416, precision: 0.3091247672253067, recall: 0.8163934426228169, f1: 0.44844664561522635\n",
            "epoch: 417, step: 15, Train: label_loss: 0.12934766709804535, precision: 0.3243581715716766, recall: 0.8068535825543914, f1: 0.46270656539005106\n",
            "epoch: 417, step: 16, Train: label_loss: 0.13620814681053162, precision: 0.3094170403587246, recall: 0.8063439065107167, f1: 0.4472222221820985\n",
            "epoch: 417, step: 17, Train: label_loss: 0.11856327950954437, precision: 0.30707692307690415, recall: 0.8471986417655607, f1: 0.45076784097265066\n",
            "epoch: 417, step: 18, Train: label_loss: 0.11882510781288147, precision: 0.3112213267203775, recall: 0.8566552901022428, f1: 0.4565711686739158\n",
            "epoch: 417, step: 19, Train: label_loss: 0.12197192013263702, precision: 0.2944099378881805, recall: 0.8301225919438125, f1: 0.43466299858579155\n",
            "epoch: 417, step: 20, Train: label_loss: 0.1307271122932434, precision: 0.31635220125784175, recall: 0.8126009693051999, f1: 0.45540968760108635\n",
            "epoch: 417, step: 21, Train: label_loss: 0.11567749083042145, precision: 0.3202492211837807, recall: 0.8653198653197196, f1: 0.4674852205153239\n",
            "epoch: 417, step: 22, Train: label_loss: 0.11023324728012085, precision: 0.3318912237329832, recall: 0.848341232227354, f1: 0.4771212793908954\n",
            "epoch: 417, step: 23, Train: label_loss: 0.12843337655067444, precision: 0.2727272727272519, recall: 0.8022471910110557, f1: 0.4070695552642522\n",
            "epoch: 418, step: 0, Train: label_loss: 0.10533110797405243, precision: 0.3280196198650933, recall: 0.8642972536347553, f1: 0.4755555555156282\n",
            "epoch: 418, step: 1, Train: label_loss: 0.12197884917259216, precision: 0.303105590062093, recall: 0.831345826234952, f1: 0.4442421483449606\n",
            "epoch: 418, step: 2, Train: label_loss: 0.12042465806007385, precision: 0.3164713140036819, recall: 0.8535773710481108, f1: 0.46174617457795636\n",
            "epoch: 418, step: 3, Train: label_loss: 0.10675317049026489, precision: 0.31180124223600547, recall: 0.8325041459368436, f1: 0.4536827835120517\n",
            "epoch: 418, step: 4, Train: label_loss: 0.11065728962421417, precision: 0.292517006802703, recall: 0.8169257340240385, f1: 0.4307832422197841\n",
            "epoch: 418, step: 5, Train: label_loss: 0.11566966772079468, precision: 0.3143712574850111, recall: 0.8793969849244757, f1: 0.4631671812580284\n",
            "epoch: 418, step: 6, Train: label_loss: 0.1071089655160904, precision: 0.3251833740831097, recall: 0.8622366288491309, f1: 0.4722592099024853\n",
            "epoch: 418, step: 7, Train: label_loss: 0.12924088537693024, precision: 0.30818008877613773, recall: 0.8006589785830641, f1: 0.4450549450147673\n",
            "epoch: 418, step: 8, Train: label_loss: 0.13853225111961365, precision: 0.2986022871664359, recall: 0.7846410684472813, f1: 0.4325816842674353\n",
            "epoch: 418, step: 9, Train: label_loss: 0.12061828374862671, precision: 0.3182367149758262, recall: 0.8783333333331869, f1: 0.4671985815211974\n",
            "epoch: 418, step: 10, Train: label_loss: 0.13057418167591095, precision: 0.3212951432129314, recall: 0.8113207547168535, f1: 0.4603033005837606\n",
            "epoch: 418, step: 11, Train: label_loss: 0.11428123712539673, precision: 0.3113032736256756, recall: 0.8372093023254422, f1: 0.453849617249952\n",
            "epoch: 418, step: 12, Train: label_loss: 0.10229386389255524, precision: 0.323636363636344, recall: 0.8811881188117358, f1: 0.47340425527981456\n",
            "epoch: 418, step: 13, Train: label_loss: 0.10180115699768066, precision: 0.32352941176468647, recall: 0.8821603927985462, f1: 0.47342995165151336\n",
            "epoch: 418, step: 14, Train: label_loss: 0.11004169285297394, precision: 0.3101343101342912, recall: 0.8595600676817496, f1: 0.45580978013147083\n",
            "epoch: 418, step: 15, Train: label_loss: 0.11461980640888214, precision: 0.3165859564164457, recall: 0.8804713804712322, f1: 0.4657168298809109\n",
            "epoch: 418, step: 16, Train: label_loss: 0.11570239067077637, precision: 0.3050430504304855, recall: 0.8435374149658429, f1: 0.4480578138724222\n",
            "epoch: 418, step: 17, Train: label_loss: 0.11813811212778091, precision: 0.3273955773955573, recall: 0.8666666666665257, f1: 0.47525635305868474\n",
            "epoch: 418, step: 18, Train: label_loss: 0.11274886131286621, precision: 0.318238213399484, recall: 0.8507462686565753, f1: 0.4632054175675571\n",
            "epoch: 418, step: 19, Train: label_loss: 0.10300347208976746, precision: 0.31930246542391344, recall: 0.8894472361807555, f1: 0.4699115043858614\n",
            "epoch: 418, step: 20, Train: label_loss: 0.11382090300321579, precision: 0.30965391621127447, recall: 0.8762886597936638, f1: 0.45760430682543785\n",
            "epoch: 418, step: 21, Train: label_loss: 0.11303989589214325, precision: 0.3119950279676624, recall: 0.8338870431892302, f1: 0.45409317047141157\n",
            "epoch: 418, step: 22, Train: label_loss: 0.11940185725688934, precision: 0.3144615384615191, recall: 0.8488372093021845, f1: 0.45891333628740666\n",
            "epoch: 418, step: 23, Train: label_loss: 0.11408655345439911, precision: 0.3045112781954658, recall: 0.841995841995667, f1: 0.44726670343968045\n",
            "epoch: 419, step: 0, Train: label_loss: 0.11781509220600128, precision: 0.3277982779827597, recall: 0.8527999999998634, f1: 0.4735673033805473\n",
            "epoch: 419, step: 1, Train: label_loss: 0.12598896026611328, precision: 0.29926108374382393, recall: 0.849650349650201, f1: 0.44262295078110636\n",
            "epoch: 419, step: 2, Train: label_loss: 0.10225054621696472, precision: 0.3128423615337606, recall: 0.8467874794067797, f1: 0.45688888884944867\n",
            "epoch: 419, step: 3, Train: label_loss: 0.09565959870815277, precision: 0.3343355381839847, recall: 0.8769716088326692, f1: 0.4841097082751857\n",
            "epoch: 419, step: 4, Train: label_loss: 0.11798246204853058, precision: 0.32920792079205885, recall: 0.8471337579616485, f1: 0.4741532976423597\n",
            "epoch: 419, step: 5, Train: label_loss: 0.11925303190946579, precision: 0.30130192188466826, recall: 0.8307692307690887, f1: 0.44222020014288044\n",
            "epoch: 419, step: 6, Train: label_loss: 0.11212144047021866, precision: 0.29719626168222446, recall: 0.8266897746965638, f1: 0.4372135654972633\n",
            "epoch: 419, step: 7, Train: label_loss: 0.1006123423576355, precision: 0.2963855421686568, recall: 0.8646748681896547, f1: 0.4414535665837422\n",
            "epoch: 419, step: 8, Train: label_loss: 0.10958945751190186, precision: 0.3237629810629002, recall: 0.8702791461410722, f1: 0.47195013353122506\n",
            "epoch: 419, step: 9, Train: label_loss: 0.09504666924476624, precision: 0.33535844471443893, recall: 0.8761904761903371, f1: 0.485061511383471\n",
            "epoch: 419, step: 10, Train: label_loss: 0.11484619230031967, precision: 0.3347560975609552, recall: 0.8742038216559117, f1: 0.48412698408689653\n",
            "epoch: 419, step: 11, Train: label_loss: 0.12862169742584229, precision: 0.30980637101809433, recall: 0.8364249578413429, f1: 0.4521422059769212\n",
            "epoch: 419, step: 12, Train: label_loss: 0.10253462195396423, precision: 0.33435582822083837, recall: 0.8818770226535789, f1: 0.4848754447999475\n",
            "epoch: 419, step: 13, Train: label_loss: 0.11042163521051407, precision: 0.3111246943765091, recall: 0.8775862068964003, f1: 0.4593862815497604\n",
            "epoch: 419, step: 14, Train: label_loss: 0.11387909203767776, precision: 0.33111782477339385, recall: 0.862992125984116, f1: 0.4786026200472141\n",
            "epoch: 419, step: 15, Train: label_loss: 0.12238392233848572, precision: 0.2997587454764596, recall: 0.8628472222220723, f1: 0.4449418083770874\n",
            "epoch: 419, step: 16, Train: label_loss: 0.11606892198324203, precision: 0.28835489833639627, recall: 0.8224956063267447, f1: 0.4270072992315943\n",
            "epoch: 419, step: 17, Train: label_loss: 0.11857432126998901, precision: 0.3275135460565727, recall: 0.8703999999998607, f1: 0.47594050739679794\n",
            "epoch: 419, step: 18, Train: label_loss: 0.11247637867927551, precision: 0.3027522935779631, recall: 0.8549222797925984, f1: 0.44715447150604976\n",
            "epoch: 419, step: 19, Train: label_loss: 0.1270287185907364, precision: 0.3045089561457502, recall: 0.8095238095236765, f1: 0.44254937159398755\n",
            "epoch: 419, step: 20, Train: label_loss: 0.1171271800994873, precision: 0.2902829028290104, recall: 0.8194444444443021, f1: 0.4287011807061073\n",
            "epoch: 419, step: 21, Train: label_loss: 0.09971985220909119, precision: 0.3170878459686933, recall: 0.8653530377666887, f1: 0.46411272563221917\n",
            "epoch: 419, step: 22, Train: label_loss: 0.11657111346721649, precision: 0.3283313325329935, recall: 0.8894308943087984, f1: 0.4796142042569343\n",
            "epoch: 419, step: 23, Train: label_loss: 0.11254584044218063, precision: 0.30081300813005907, recall: 0.8641188959658462, f1: 0.44627192978620356\n",
            "epoch: 420, step: 0, Train: label_loss: 0.09457392990589142, precision: 0.3226586102718838, recall: 0.878289473684066, f1: 0.47193990274457615\n",
            "epoch: 420, step: 1, Train: label_loss: 0.11598342657089233, precision: 0.29889975550120423, recall: 0.8639575971729921, f1: 0.44414168933506265\n",
            "epoch: 420, step: 2, Train: label_loss: 0.10224619507789612, precision: 0.3183747725894288, recall: 0.8592471358427398, f1: 0.46460176987201074\n",
            "epoch: 420, step: 3, Train: label_loss: 0.11662845313549042, precision: 0.3138101109740867, recall: 0.8469217970048507, f1: 0.4579397210581219\n",
            "epoch: 420, step: 4, Train: label_loss: 0.11661092936992645, precision: 0.3056741915802132, recall: 0.8578767123286202, f1: 0.4507422401771453\n",
            "epoch: 420, step: 5, Train: label_loss: 0.10713598132133484, precision: 0.3095525997581433, recall: 0.8692699490660662, f1: 0.45653143108026856\n",
            "epoch: 420, step: 6, Train: label_loss: 0.10377177596092224, precision: 0.29260843005496073, recall: 0.8568872987476105, f1: 0.43624772309497806\n",
            "epoch: 420, step: 7, Train: label_loss: 0.11145254969596863, precision: 0.3155610663360003, recall: 0.8441127694857637, f1: 0.4593862815487928\n",
            "epoch: 420, step: 8, Train: label_loss: 0.10104964673519135, precision: 0.32345828295040363, recall: 0.8587479935793163, f1: 0.46991655683328815\n",
            "epoch: 420, step: 9, Train: label_loss: 0.10615307092666626, precision: 0.33070388349512553, recall: 0.884740259740116, f1: 0.48144876321122987\n",
            "epoch: 420, step: 10, Train: label_loss: 0.10778286308050156, precision: 0.3095956547978087, recall: 0.8952879581150269, f1: 0.46008968606042794\n",
            "epoch: 420, step: 11, Train: label_loss: 0.11227883398532867, precision: 0.3158866995073697, recall: 0.8724489795916883, f1: 0.46383363468063654\n",
            "epoch: 420, step: 12, Train: label_loss: 0.12017989158630371, precision: 0.33415841584156347, recall: 0.8626198083065714, f1: 0.48171275642714595\n",
            "epoch: 420, step: 13, Train: label_loss: 0.11351031064987183, precision: 0.3076448828606469, recall: 0.8113821138210062, f1: 0.44613321408615386\n",
            "epoch: 420, step: 14, Train: label_loss: 0.10923206806182861, precision: 0.29513247073319193, recall: 0.8344947735190184, f1: 0.4360491579040083\n",
            "epoch: 420, step: 15, Train: label_loss: 0.11195887625217438, precision: 0.3329283110570879, recall: 0.8698412698411317, f1: 0.4815465728948949\n",
            "epoch: 420, step: 16, Train: label_loss: 0.11855922639369965, precision: 0.3113846153845962, recall: 0.8281505728312883, f1: 0.45259391767043883\n",
            "epoch: 420, step: 17, Train: label_loss: 0.1182040274143219, precision: 0.30472103004289974, recall: 0.8524871355058572, f1: 0.448961156239392\n",
            "epoch: 420, step: 18, Train: label_loss: 0.1077016294002533, precision: 0.3339350180505214, recall: 0.8795562599047734, f1: 0.48408198862120866\n",
            "epoch: 420, step: 19, Train: label_loss: 0.1027955710887909, precision: 0.31607795371496245, recall: 0.8664440734556149, f1: 0.46318607760469827\n",
            "epoch: 420, step: 20, Train: label_loss: 0.10272928327322006, precision: 0.3223844282238247, recall: 0.8534621578098464, f1: 0.4679911699380832\n",
            "epoch: 420, step: 21, Train: label_loss: 0.09797017276287079, precision: 0.32936979785967124, recall: 0.9081967213113264, f1: 0.4834205933291329\n",
            "epoch: 420, step: 22, Train: label_loss: 0.09596534073352814, precision: 0.317547055251954, recall: 0.867330016583604, f1: 0.4648888888496123\n",
            "epoch: 420, step: 23, Train: label_loss: 0.1167188435792923, precision: 0.3070044709388743, recall: 0.8323232323230642, f1: 0.44855743055393954\n",
            "epoch: 421, step: 0, Train: label_loss: 0.0998026579618454, precision: 0.318814277071971, recall: 0.8739635157544156, f1: 0.4671985815210733\n",
            "epoch: 421, step: 1, Train: label_loss: 0.10005222260951996, precision: 0.3207776427703329, recall: 0.8756218905471184, f1: 0.46954201863567857\n",
            "epoch: 421, step: 2, Train: label_loss: 0.09709581732749939, precision: 0.31939393939392, recall: 0.8625204582649979, f1: 0.46616541349435175\n",
            "epoch: 421, step: 3, Train: label_loss: 0.11258557438850403, precision: 0.3268173488087766, recall: 0.8629032258063124, f1: 0.4740806379751742\n",
            "epoch: 421, step: 4, Train: label_loss: 0.11349055171012878, precision: 0.3189122373300174, recall: 0.8486842105261762, f1: 0.46361185979852676\n",
            "epoch: 421, step: 5, Train: label_loss: 0.0973605066537857, precision: 0.31090909090907204, recall: 0.8739352640543655, f1: 0.45864997760988574\n",
            "epoch: 421, step: 6, Train: label_loss: 0.09372095763683319, precision: 0.3159490600363665, recall: 0.8741610738253566, f1: 0.4641425389364598\n",
            "epoch: 421, step: 7, Train: label_loss: 0.09568894654512405, precision: 0.3057247259439521, recall: 0.8566552901022428, f1: 0.45062836620894764\n",
            "epoch: 421, step: 8, Train: label_loss: 0.09701646864414215, precision: 0.3179611650485244, recall: 0.8733333333331877, f1: 0.4661921707793306\n",
            "epoch: 421, step: 9, Train: label_loss: 0.11025774478912354, precision: 0.3187960687960492, recall: 0.850819672131008, f1: 0.4638069704696873\n",
            "epoch: 421, step: 10, Train: label_loss: 0.10360779613256454, precision: 0.3211180124223403, recall: 0.8352180936993804, f1: 0.4638851502514521\n",
            "epoch: 421, step: 11, Train: label_loss: 0.10081550478935242, precision: 0.3301088270858325, recall: 0.8878048780486361, f1: 0.48126928158230153\n",
            "epoch: 421, step: 12, Train: label_loss: 0.11768200993537903, precision: 0.30945027794933233, recall: 0.859348198970693, f1: 0.45504087189563114\n",
            "epoch: 421, step: 13, Train: label_loss: 0.12542343139648438, precision: 0.3012859767299264, recall: 0.8526863084920532, f1: 0.44524886873965613\n",
            "epoch: 421, step: 14, Train: label_loss: 0.11597852408885956, precision: 0.3288343558282007, recall: 0.885950413222994, f1: 0.4796420581260215\n",
            "epoch: 421, step: 15, Train: label_loss: 0.10130386054515839, precision: 0.3234223300970677, recall: 0.876644736841961, f1: 0.4725177304570377\n",
            "epoch: 421, step: 16, Train: label_loss: 0.10195809602737427, precision: 0.3234761617380613, recall: 0.885950413222994, f1: 0.4739168876707639\n",
            "epoch: 421, step: 17, Train: label_loss: 0.11899488419294357, precision: 0.30154798761608037, recall: 0.8339041095888983, f1: 0.44292860387181926\n",
            "epoch: 421, step: 18, Train: label_loss: 0.09625107049942017, precision: 0.3082524271844473, recall: 0.8581081081079631, f1: 0.4535714285325002\n",
            "epoch: 421, step: 19, Train: label_loss: 0.12889011204242706, precision: 0.30397022332504314, recall: 0.8126036484244091, f1: 0.44243792321089975\n",
            "epoch: 421, step: 20, Train: label_loss: 0.10911054164171219, precision: 0.3185410334346311, recall: 0.8733333333331877, f1: 0.46681514472693886\n",
            "epoch: 421, step: 21, Train: label_loss: 0.10009126365184784, precision: 0.3125378558449235, recall: 0.8686868686867224, f1: 0.4596881959521341\n",
            "epoch: 421, step: 22, Train: label_loss: 0.12058849632740021, precision: 0.3296089385474656, recall: 0.849599999999864, f1: 0.47495527724053876\n",
            "epoch: 421, step: 23, Train: label_loss: 0.10135973989963531, precision: 0.30316742081445675, recall: 0.8288659793812724, f1: 0.44395361674703954\n",
            "epoch: 422, step: 0, Train: label_loss: 0.11913928389549255, precision: 0.3221884498480047, recall: 0.8660130718952833, f1: 0.4696499778071314\n",
            "epoch: 422, step: 1, Train: label_loss: 0.08748860657215118, precision: 0.34455802766083315, recall: 0.8869969040246304, f1: 0.49631875266645625\n",
            "epoch: 422, step: 2, Train: label_loss: 0.10294756293296814, precision: 0.30458383594690563, recall: 0.867697594501569, f1: 0.45089285710435406\n",
            "epoch: 422, step: 3, Train: label_loss: 0.10972507297992706, precision: 0.3224815724815527, recall: 0.8592471358427398, f1: 0.46895935681601314\n",
            "epoch: 422, step: 4, Train: label_loss: 0.08756925910711288, precision: 0.3012048192770903, recall: 0.8818342151673929, f1: 0.44903457562432963\n",
            "epoch: 422, step: 5, Train: label_loss: 0.09066739678382874, precision: 0.35107655502390245, recall: 0.8880484114975963, f1: 0.5032147449229126\n",
            "epoch: 422, step: 6, Train: label_loss: 0.09970836341381073, precision: 0.3101379724055003, recall: 0.8807495741054717, f1: 0.45874001770766737\n",
            "epoch: 422, step: 7, Train: label_loss: 0.09457661956548691, precision: 0.31873479318732856, recall: 0.8604269293923053, f1: 0.46515756764803834\n",
            "epoch: 422, step: 8, Train: label_loss: 0.10855033993721008, precision: 0.3211678832116593, recall: 0.8669950738914832, f1: 0.4687083887754237\n",
            "epoch: 422, step: 9, Train: label_loss: 0.10623747110366821, precision: 0.33414190418433387, recall: 0.8801916932905941, f1: 0.4843956043556719\n",
            "epoch: 422, step: 10, Train: label_loss: 0.10340853035449982, precision: 0.324770642201815, recall: 0.8592233009707347, f1: 0.47137150462059896\n",
            "epoch: 422, step: 11, Train: label_loss: 0.10962478816509247, precision: 0.2964763061968228, recall: 0.8516579406630276, f1: 0.43983776472055186\n",
            "epoch: 422, step: 12, Train: label_loss: 0.10321961343288422, precision: 0.2986069049060994, recall: 0.8725663716812614, f1: 0.4449458483374197\n",
            "epoch: 422, step: 13, Train: label_loss: 0.08640975505113602, precision: 0.3121629718394061, recall: 0.8726968174202893, f1: 0.45984112970519203\n",
            "epoch: 422, step: 14, Train: label_loss: 0.10223431885242462, precision: 0.30923450789791557, recall: 0.8497495826375876, f1: 0.45345211577375216\n",
            "epoch: 422, step: 15, Train: label_loss: 0.11764484643936157, precision: 0.305385556915526, recall: 0.8443316412858131, f1: 0.44853932580364336\n",
            "epoch: 422, step: 16, Train: label_loss: 0.10953118652105331, precision: 0.3247549019607644, recall: 0.8631921824102828, f1: 0.4719501335310222\n",
            "epoch: 422, step: 17, Train: label_loss: 0.11060401052236557, precision: 0.2862385321100742, recall: 0.8342245989303325, f1: 0.426229508158642\n",
            "epoch: 422, step: 18, Train: label_loss: 0.09321516752243042, precision: 0.31105710814092885, recall: 0.872231686541589, f1: 0.45857590681297344\n",
            "epoch: 422, step: 19, Train: label_loss: 0.10348020493984222, precision: 0.30755176613883634, recall: 0.8828671328669785, f1: 0.45618789517392255\n",
            "epoch: 422, step: 20, Train: label_loss: 0.11064521968364716, precision: 0.3177399756986441, recall: 0.8531810766719652, f1: 0.46303674188161836\n",
            "epoch: 422, step: 21, Train: label_loss: 0.10170994699001312, precision: 0.32924586143468243, recall: 0.8591999999998625, f1: 0.47606382974713407\n",
            "epoch: 422, step: 22, Train: label_loss: 0.10732295364141464, precision: 0.30741190765490234, recall: 0.8518518518517084, f1: 0.45178571424670216\n",
            "epoch: 422, step: 23, Train: label_loss: 0.09442181140184402, precision: 0.31859070464765227, recall: 0.84999999999983, f1: 0.4634678298403327\n",
            "epoch: 423, step: 0, Train: label_loss: 0.12431461364030838, precision: 0.3000619962802046, recall: 0.8359240069083185, f1: 0.44160583937714387\n",
            "epoch: 423, step: 1, Train: label_loss: 0.1127169281244278, precision: 0.31488314883146895, recall: 0.8519134775372957, f1: 0.4598114054387726\n",
            "epoch: 423, step: 2, Train: label_loss: 0.09799814224243164, precision: 0.32630945213724705, recall: 0.9063545150500156, f1: 0.479858344361206\n",
            "epoch: 423, step: 3, Train: label_loss: 0.10794305056333542, precision: 0.3160173160172965, recall: 0.8308943089429542, f1: 0.4578853046195338\n",
            "epoch: 423, step: 4, Train: label_loss: 0.12105484306812286, precision: 0.3228200371057314, recall: 0.8501628664493729, f1: 0.4679515911747658\n",
            "epoch: 423, step: 5, Train: label_loss: 0.10675543546676636, precision: 0.2968845448991877, recall: 0.8364888123922828, f1: 0.43823264198113193\n",
            "epoch: 423, step: 6, Train: label_loss: 0.10500950366258621, precision: 0.30783242258650223, recall: 0.8651877133104325, f1: 0.45409762647266705\n",
            "epoch: 423, step: 7, Train: label_loss: 0.09941259026527405, precision: 0.32091346153844225, recall: 0.868292682926688, f1: 0.4686265905704688\n",
            "epoch: 423, step: 8, Train: label_loss: 0.09340082854032516, precision: 0.3222891566264866, recall: 0.8901830282860415, f1: 0.47324192831121453\n",
            "epoch: 423, step: 9, Train: label_loss: 0.10988961160182953, precision: 0.3200483091787246, recall: 0.8660130718952833, f1: 0.4673721339993541\n",
            "epoch: 423, step: 10, Train: label_loss: 0.1108817532658577, precision: 0.3286670724284645, recall: 0.8557844690965363, f1: 0.47493403689917485\n",
            "epoch: 423, step: 11, Train: label_loss: 0.11074264347553253, precision: 0.3259396179913539, recall: 0.8343848580440324, f1: 0.4687638457725852\n",
            "epoch: 423, step: 12, Train: label_loss: 0.10155081748962402, precision: 0.31776834445116325, recall: 0.8632619439866781, f1: 0.46453900705282397\n",
            "epoch: 423, step: 13, Train: label_loss: 0.10493216663599014, precision: 0.30500301386375495, recall: 0.8739205526768784, f1: 0.45218945483202344\n",
            "epoch: 423, step: 14, Train: label_loss: 0.108973428606987, precision: 0.30456226880392695, recall: 0.8330522765597246, f1: 0.44604966136029905\n",
            "epoch: 423, step: 15, Train: label_loss: 0.09942956268787384, precision: 0.30440024110908354, recall: 0.8647260273971121, f1: 0.45028979042065126\n",
            "epoch: 423, step: 16, Train: label_loss: 0.10274545103311539, precision: 0.3095238095237906, recall: 0.8637137989777063, f1: 0.4557303370397669\n",
            "epoch: 423, step: 17, Train: label_loss: 0.10294191539287567, precision: 0.32134146341461456, recall: 0.8365079365078036, f1: 0.4643171805765975\n",
            "epoch: 423, step: 18, Train: label_loss: 0.09170380234718323, precision: 0.3187463039621337, recall: 0.9043624161072308, f1: 0.47135986004012664\n",
            "epoch: 423, step: 19, Train: label_loss: 0.11011340469121933, precision: 0.31226993865028757, recall: 0.8497495826375876, f1: 0.45670704347792834\n",
            "epoch: 423, step: 20, Train: label_loss: 0.09919629991054535, precision: 0.33272727272725255, recall: 0.888349514562963, f1: 0.4841269840872938\n",
            "epoch: 423, step: 21, Train: label_loss: 0.09101175516843796, precision: 0.33454106280191215, recall: 0.8964401294496931, f1: 0.4872471415610788\n",
            "epoch: 423, step: 22, Train: label_loss: 0.09549413621425629, precision: 0.2986698911728961, recall: 0.8666666666665146, f1: 0.4442446042783853\n",
            "epoch: 423, step: 23, Train: label_loss: 0.0944475382566452, precision: 0.30258302583023594, recall: 0.8704883227174373, f1: 0.4490690032475401\n",
            "epoch: 424, step: 0, Train: label_loss: 0.12134876847267151, precision: 0.3098503740648186, recall: 0.8311036789296269, f1: 0.4514078110412305\n",
            "epoch: 424, step: 1, Train: label_loss: 0.10552339255809784, precision: 0.302311435523096, recall: 0.8481228668940531, f1: 0.445739910275116\n",
            "epoch: 424, step: 2, Train: label_loss: 0.11298421025276184, precision: 0.32277710109620444, recall: 0.8702791461410722, f1: 0.4709018213731934\n",
            "epoch: 424, step: 3, Train: label_loss: 0.10522191226482391, precision: 0.30607336139505076, recall: 0.8852173913041939, f1: 0.45487041997964944\n",
            "epoch: 424, step: 4, Train: label_loss: 0.11323799937963486, precision: 0.3163390663390469, recall: 0.8526490066223753, f1: 0.46146953401066193\n",
            "epoch: 424, step: 5, Train: label_loss: 0.0918884128332138, precision: 0.33494851605085796, recall: 0.8805732484075031, f1: 0.4853005703856575\n",
            "epoch: 424, step: 6, Train: label_loss: 0.0950537919998169, precision: 0.3317161916312716, recall: 0.8724082934607859, f1: 0.4806678382728688\n",
            "epoch: 424, step: 7, Train: label_loss: 0.11534859985113144, precision: 0.2997527812113535, recall: 0.8304794520546522, f1: 0.4405086284805126\n",
            "epoch: 424, step: 8, Train: label_loss: 0.09036257117986679, precision: 0.31283905967448383, recall: 0.8796610169490033, f1: 0.461538461499717\n",
            "epoch: 424, step: 9, Train: label_loss: 0.10281834006309509, precision: 0.30450669914736267, recall: 0.8403361344536402, f1: 0.4470272686243015\n",
            "epoch: 424, step: 10, Train: label_loss: 0.09324623644351959, precision: 0.31848284166163043, recall: 0.8816666666665196, f1: 0.4679345421989168\n",
            "epoch: 424, step: 11, Train: label_loss: 0.08628539741039276, precision: 0.3315380011968682, recall: 0.8878205128203704, f1: 0.48278867098432937\n",
            "epoch: 424, step: 12, Train: label_loss: 0.09266139566898346, precision: 0.3421210305571994, recall: 0.9077901430841163, f1: 0.4969538728931827\n",
            "epoch: 424, step: 13, Train: label_loss: 0.0950537621974945, precision: 0.34100545124165105, recall: 0.8769470404983057, f1: 0.4910597470158969\n",
            "epoch: 424, step: 14, Train: label_loss: 0.10586479306221008, precision: 0.3196622436670495, recall: 0.892255892255742, f1: 0.4706927175454889\n",
            "epoch: 424, step: 15, Train: label_loss: 0.09663248062133789, precision: 0.2933657942787405, recall: 0.8426573426571953, f1: 0.4352144469142463\n",
            "epoch: 424, step: 16, Train: label_loss: 0.1016506776213646, precision: 0.30718165359080823, recall: 0.8745704467352449, f1: 0.45466726213209724\n",
            "epoch: 424, step: 17, Train: label_loss: 0.11633650958538055, precision: 0.31409062693976947, recall: 0.84757118927959, f1: 0.4583333332938368\n",
            "epoch: 424, step: 18, Train: label_loss: 0.11561688780784607, precision: 0.3080220453153516, recall: 0.8583617747438808, f1: 0.45335736814495714\n",
            "epoch: 424, step: 19, Train: label_loss: 0.09494449943304062, precision: 0.3089921544960586, recall: 0.8812392426848741, f1: 0.45755138512684307\n",
            "epoch: 424, step: 20, Train: label_loss: 0.10075687617063522, precision: 0.3303140096618158, recall: 0.9071310116084731, f1: 0.48428508185546487\n",
            "epoch: 424, step: 21, Train: label_loss: 0.09683637320995331, precision: 0.3016453382083911, recall: 0.8505154639173795, f1: 0.4453441295159629\n",
            "epoch: 424, step: 22, Train: label_loss: 0.10058800876140594, precision: 0.3185410334346311, recall: 0.859016393442482, f1: 0.4647450110469663\n",
            "epoch: 424, step: 23, Train: label_loss: 0.10352253913879395, precision: 0.3429844097995291, recall: 0.8867562380036685, f1: 0.49464668090190755\n",
            "epoch: 425, step: 0, Train: label_loss: 0.09331922233104706, precision: 0.32911392405061307, recall: 0.8863636363634924, f1: 0.4799999999604671\n",
            "epoch: 425, step: 1, Train: label_loss: 0.11666949838399887, precision: 0.2981062919975383, recall: 0.857644991212503, f1: 0.44242973704236815\n",
            "epoch: 425, step: 2, Train: label_loss: 0.10449283570051193, precision: 0.32562385879486755, recall: 0.8756137479540301, f1: 0.47471162374038606\n",
            "epoch: 425, step: 3, Train: label_loss: 0.0943957194685936, precision: 0.3259036144578117, recall: 0.8782467532466106, f1: 0.47539543054044325\n",
            "epoch: 425, step: 4, Train: label_loss: 0.09737499803304672, precision: 0.31892878880095443, recall: 0.8806722689074149, f1: 0.4682752457160608\n",
            "epoch: 425, step: 5, Train: label_loss: 0.10894127935171127, precision: 0.31692307692305743, recall: 0.8293075684378696, f1: 0.45859305427873936\n",
            "epoch: 425, step: 6, Train: label_loss: 0.09070031344890594, precision: 0.3202416918428809, recall: 0.895270270270119, f1: 0.47174009786947013\n",
            "epoch: 425, step: 7, Train: label_loss: 0.09689370542764664, precision: 0.327848872638615, recall: 0.862179487179349, f1: 0.4750551875980075\n",
            "epoch: 425, step: 8, Train: label_loss: 0.08972722291946411, precision: 0.3051157125456574, recall: 0.8578767123286202, f1: 0.45013477085074255\n",
            "epoch: 425, step: 9, Train: label_loss: 0.120760977268219, precision: 0.31968693558095607, recall: 0.8894472361807555, f1: 0.47032772361030756\n",
            "epoch: 425, step: 10, Train: label_loss: 0.10117920488119125, precision: 0.3120865904990792, recall: 0.8902229845624544, f1: 0.46215494208084307\n",
            "epoch: 425, step: 11, Train: label_loss: 0.0930291935801506, precision: 0.3180446590223103, recall: 0.8739635157544156, f1: 0.46637168137676305\n",
            "epoch: 425, step: 12, Train: label_loss: 0.10514698922634125, precision: 0.3082107843137066, recall: 0.862778730703111, f1: 0.4541760721959363\n",
            "epoch: 425, step: 13, Train: label_loss: 0.09257529675960541, precision: 0.3052064631956729, recall: 0.8793103448274345, f1: 0.45313194132110096\n",
            "epoch: 425, step: 14, Train: label_loss: 0.0948154553771019, precision: 0.3353510895883574, recall: 0.8697017268444474, f1: 0.4840541720873556\n",
            "epoch: 425, step: 15, Train: label_loss: 0.1065305843949318, precision: 0.3112980769230582, recall: 0.8900343642610153, f1: 0.46126447013075256\n",
            "epoch: 425, step: 16, Train: label_loss: 0.10205212235450745, precision: 0.33273273273271275, recall: 0.8793650793649397, f1: 0.48278867098409217\n",
            "epoch: 425, step: 17, Train: label_loss: 0.10033299028873444, precision: 0.3026235509456801, recall: 0.8522336769757985, f1: 0.44664565507159504\n",
            "epoch: 425, step: 18, Train: label_loss: 0.09496709704399109, precision: 0.30815347721820696, recall: 0.8786324786323284, f1: 0.45628051483057624\n",
            "epoch: 425, step: 19, Train: label_loss: 0.09347006678581238, precision: 0.3191616766466875, recall: 0.8973063973062462, f1: 0.4708480564983547\n",
            "epoch: 425, step: 20, Train: label_loss: 0.1045265793800354, precision: 0.3329283110570879, recall: 0.8726114649680139, f1: 0.4819700967058004\n",
            "epoch: 425, step: 21, Train: label_loss: 0.10850584506988525, precision: 0.30614729153984743, recall: 0.8510998307951182, f1: 0.4503133392627482\n",
            "epoch: 425, step: 22, Train: label_loss: 0.10248193889856339, precision: 0.32828588734098557, recall: 0.8798701298699869, f1: 0.4781649756992417\n",
            "epoch: 425, step: 23, Train: label_loss: 0.10828645527362823, precision: 0.3200295639319793, recall: 0.8659999999998268, f1: 0.4673502428099783\n",
            "epoch: 426, step: 0, Train: label_loss: 0.08622312545776367, precision: 0.32236842105261226, recall: 0.886513157894591, f1: 0.472807017504707\n",
            "epoch: 426, step: 1, Train: label_loss: 0.10371467471122742, precision: 0.3111246943765091, recall: 0.8554621848738058, f1: 0.45629762434452964\n",
            "epoch: 426, step: 2, Train: label_loss: 0.11202985048294067, precision: 0.301538461538443, recall: 0.8462867012088348, f1: 0.4446460979648512\n",
            "epoch: 426, step: 3, Train: label_loss: 0.10365022718906403, precision: 0.31208257437763737, recall: 0.8667790893759078, f1: 0.4589285713896006\n",
            "epoch: 426, step: 4, Train: label_loss: 0.10114619135856628, precision: 0.30150150150148336, recall: 0.8884955752210816, f1: 0.45022421520876227\n",
            "epoch: 426, step: 5, Train: label_loss: 0.09428323805332184, precision: 0.31661631419937664, recall: 0.8675496688740285, f1: 0.46392208938087925\n",
            "epoch: 426, step: 6, Train: label_loss: 0.10242782533168793, precision: 0.30086313193586306, recall: 0.8356164383560213, f1: 0.442429737041719\n",
            "epoch: 426, step: 7, Train: label_loss: 0.10272245854139328, precision: 0.30432136335968935, recall: 0.8488964346348303, f1: 0.448028673796235\n",
            "epoch: 426, step: 8, Train: label_loss: 0.09914085268974304, precision: 0.32336790726050496, recall: 0.8702791461410722, f1: 0.47153024907077495\n",
            "epoch: 426, step: 9, Train: label_loss: 0.09833632409572601, precision: 0.34507462686565105, recall: 0.8947368421051246, f1: 0.4980611804854203\n",
            "epoch: 426, step: 10, Train: label_loss: 0.1062263771891594, precision: 0.296951219512177, recall: 0.8454861111109643, f1: 0.43953068588206495\n",
            "epoch: 426, step: 11, Train: label_loss: 0.10752563178539276, precision: 0.3375603864734096, recall: 0.8748043818464984, f1: 0.4871459694586867\n",
            "epoch: 426, step: 12, Train: label_loss: 0.11170567572116852, precision: 0.2873846153845977, recall: 0.825088339222469, f1: 0.42628936554813224\n",
            "epoch: 426, step: 13, Train: label_loss: 0.0946146696805954, precision: 0.34680337756330837, recall: 0.8970358814351174, f1: 0.5002174858231597\n",
            "epoch: 426, step: 14, Train: label_loss: 0.11384385079145432, precision: 0.3357575757575554, recall: 0.8821656050954009, f1: 0.4863915715140158\n",
            "epoch: 426, step: 15, Train: label_loss: 0.11083731800317764, precision: 0.28693528693526943, recall: 0.8407871198567368, f1: 0.42785616746315913\n",
            "epoch: 426, step: 16, Train: label_loss: 0.10026732087135315, precision: 0.31782477341387805, recall: 0.8622950819670717, f1: 0.4644591611085048\n",
            "epoch: 426, step: 17, Train: label_loss: 0.1222286969423294, precision: 0.3139825218476708, recall: 0.8178861788616556, f1: 0.453766350884542\n",
            "epoch: 426, step: 18, Train: label_loss: 0.09544728696346283, precision: 0.3009768009767826, recall: 0.8355932203388413, f1: 0.44254937159477525\n",
            "epoch: 426, step: 19, Train: label_loss: 0.10472166538238525, precision: 0.3020012128562582, recall: 0.8556701030926365, f1: 0.44643657548806626\n",
            "epoch: 426, step: 20, Train: label_loss: 0.08845251798629761, precision: 0.3226586102718838, recall: 0.8697068403907378, f1: 0.47069193473351073\n",
            "epoch: 426, step: 21, Train: label_loss: 0.11183936148881912, precision: 0.3256519102486158, recall: 0.8578274760382015, f1: 0.4720879120479807\n",
            "epoch: 426, step: 22, Train: label_loss: 0.1064438670873642, precision: 0.3194945848375259, recall: 0.8835274542427813, f1: 0.4692885549764156\n",
            "epoch: 426, step: 23, Train: label_loss: 0.10414744913578033, precision: 0.32260479041913753, recall: 0.8619999999998276, f1: 0.4694989106356967\n",
            "epoch: 427, step: 0, Train: label_loss: 0.0961761474609375, precision: 0.31105710814092885, recall: 0.8634064080942894, f1: 0.45734702988509146\n",
            "epoch: 427, step: 1, Train: label_loss: 0.09664389491081238, precision: 0.3082932692307507, recall: 0.8769230769229269, f1: 0.45620275674225974\n",
            "epoch: 427, step: 2, Train: label_loss: 0.10495094209909439, precision: 0.31689717378230203, recall: 0.8887015177064268, f1: 0.46719858152148974\n",
            "epoch: 427, step: 3, Train: label_loss: 0.10597516596317291, precision: 0.32698217578363076, recall: 0.8650406504063634, f1: 0.47457627114658557\n",
            "epoch: 427, step: 4, Train: label_loss: 0.09261798858642578, precision: 0.32629674306391276, recall: 0.8986710963453656, f1: 0.4787610619077767\n",
            "epoch: 427, step: 5, Train: label_loss: 0.10085394233465195, precision: 0.32884262094302946, recall: 0.883223684210381, f1: 0.47925033463243866\n",
            "epoch: 427, step: 6, Train: label_loss: 0.10173889249563217, precision: 0.30647130647128773, recall: 0.8791593695269914, f1: 0.45450430055012603\n",
            "epoch: 427, step: 7, Train: label_loss: 0.08752818405628204, precision: 0.3245666467423596, recall: 0.9065108514188803, f1: 0.47799295770760963\n",
            "epoch: 427, step: 8, Train: label_loss: 0.10925877094268799, precision: 0.3153320918683851, recall: 0.8341543513955937, f1: 0.45765765761780225\n",
            "epoch: 427, step: 9, Train: label_loss: 0.09301511943340302, precision: 0.34461910519949546, recall: 0.8809891808344851, f1: 0.4954367665827404\n",
            "epoch: 427, step: 10, Train: label_loss: 0.09585144370794296, precision: 0.311151079136672, recall: 0.8841567291310248, f1: 0.46031042124748045\n",
            "epoch: 427, step: 11, Train: label_loss: 0.11711950600147247, precision: 0.30783466995679776, recall: 0.8261589403972142, f1: 0.4485393258031023\n",
            "epoch: 427, step: 12, Train: label_loss: 0.11831820011138916, precision: 0.29256299938535385, recall: 0.8249566724435311, f1: 0.43194192373626356\n",
            "epoch: 427, step: 13, Train: label_loss: 0.10052087903022766, precision: 0.3136778115501329, recall: 0.8528925619833301, f1: 0.4586666666273084\n",
            "epoch: 427, step: 14, Train: label_loss: 0.10032075643539429, precision: 0.28700361010828596, recall: 0.8579136690645939, f1: 0.4301172226855676\n",
            "epoch: 427, step: 15, Train: label_loss: 0.10123001784086227, precision: 0.3299340131973407, recall: 0.889967637540309, f1: 0.4814004375972572\n",
            "epoch: 427, step: 16, Train: label_loss: 0.10540834069252014, precision: 0.31807228915660735, recall: 0.8684210526314361, f1: 0.4656084655691822\n",
            "epoch: 427, step: 17, Train: label_loss: 0.1095447763800621, precision: 0.3269346130773649, recall: 0.9068219633941919, f1: 0.4805996472273173\n",
            "epoch: 427, step: 18, Train: label_loss: 0.0968489795923233, precision: 0.30736714975843554, recall: 0.8569023569022126, f1: 0.45244444440554343\n",
            "epoch: 427, step: 19, Train: label_loss: 0.0949641764163971, precision: 0.32303030303028346, recall: 0.8638573743920803, f1: 0.4702249668769701\n",
            "epoch: 427, step: 20, Train: label_loss: 0.08530043810606003, precision: 0.34624553039330475, recall: 0.8803030303028969, f1: 0.49700598798338885\n",
            "epoch: 427, step: 21, Train: label_loss: 0.11407273262739182, precision: 0.3141809290953353, recall: 0.838499184339178, f1: 0.45709204086737437\n",
            "epoch: 427, step: 22, Train: label_loss: 0.0952356681227684, precision: 0.3003597122301978, recall: 0.8962432915919684, f1: 0.44993264477600936\n",
            "epoch: 427, step: 23, Train: label_loss: 0.10971364378929138, precision: 0.32279909706543847, recall: 0.8614457831323572, f1: 0.46962233165158995\n",
            "epoch: 428, step: 0, Train: label_loss: 0.0961516797542572, precision: 0.32474535650087927, recall: 0.9048414023370775, f1: 0.477954144581898\n",
            "epoch: 428, step: 1, Train: label_loss: 0.09193728119134903, precision: 0.3255535607420511, recall: 0.8760064412236914, f1: 0.47469458983828805\n",
            "epoch: 428, step: 2, Train: label_loss: 0.10880163311958313, precision: 0.29878048780485983, recall: 0.8477508650517563, f1: 0.44183949500200026\n",
            "epoch: 428, step: 3, Train: label_loss: 0.08901964128017426, precision: 0.3285198555956481, recall: 0.8863636363634924, f1: 0.4793678665101049\n",
            "epoch: 428, step: 4, Train: label_loss: 0.09382878243923187, precision: 0.31812725090034105, recall: 0.8803986710961992, f1: 0.46737213399976385\n",
            "epoch: 428, step: 5, Train: label_loss: 0.0969402864575386, precision: 0.3136308805789919, recall: 0.8652246256238161, f1: 0.46038069938543014\n",
            "epoch: 428, step: 6, Train: label_loss: 0.10114678740501404, precision: 0.3183747725894288, recall: 0.8578431372547617, f1: 0.4643962847901981\n",
            "epoch: 428, step: 7, Train: label_loss: 0.08584962785243988, precision: 0.3082932692307507, recall: 0.878424657534096, f1: 0.4564056939116778\n",
            "epoch: 428, step: 8, Train: label_loss: 0.11588642001152039, precision: 0.30354957160340856, recall: 0.8566493955093512, f1: 0.4482602801239981\n",
            "epoch: 428, step: 9, Train: label_loss: 0.08641552925109863, precision: 0.3082524271844473, recall: 0.8668941979520705, f1: 0.4547896150015451\n",
            "epoch: 428, step: 10, Train: label_loss: 0.10329972207546234, precision: 0.3209951456310485, recall: 0.8729372937292288, f1: 0.4693877550626847\n",
            "epoch: 428, step: 11, Train: label_loss: 0.09522771835327148, precision: 0.32544019429263354, recall: 0.8631239935586371, f1: 0.47266313928999676\n",
            "epoch: 428, step: 12, Train: label_loss: 0.09867113828659058, precision: 0.30347349177329047, recall: 0.8512820512819057, f1: 0.44743935306094273\n",
            "epoch: 428, step: 13, Train: label_loss: 0.09379984438419342, precision: 0.3193685488767262, recall: 0.8580750407828942, f1: 0.46548672562414195\n",
            "epoch: 428, step: 14, Train: label_loss: 0.10223904252052307, precision: 0.30965391621127447, recall: 0.865874363327527, f1: 0.4561717352026562\n",
            "epoch: 428, step: 15, Train: label_loss: 0.10184180736541748, precision: 0.32570740517758423, recall: 0.8768233387356763, f1: 0.47497805088232137\n",
            "epoch: 428, step: 16, Train: label_loss: 0.09750013053417206, precision: 0.30890369473044765, recall: 0.865874363327527, f1: 0.45535714281834094\n",
            "epoch: 428, step: 17, Train: label_loss: 0.12306719273328781, precision: 0.31728395061726433, recall: 0.842622950819534, f1: 0.46098654704541703\n",
            "epoch: 428, step: 18, Train: label_loss: 0.10576733201742172, precision: 0.3288672350791517, recall: 0.8598726114648312, f1: 0.47577092507006713\n",
            "epoch: 428, step: 19, Train: label_loss: 0.10550487041473389, precision: 0.31812652068124586, recall: 0.8702163061562611, f1: 0.4659242761300157\n",
            "epoch: 428, step: 20, Train: label_loss: 0.09741224348545074, precision: 0.3375990249847448, recall: 0.8921095008050093, f1: 0.48983200703350993\n",
            "epoch: 428, step: 21, Train: label_loss: 0.09632117301225662, precision: 0.3068526379623828, recall: 0.8784722222220697, f1: 0.4548314606357445\n",
            "epoch: 428, step: 22, Train: label_loss: 0.10888239741325378, precision: 0.31876138433513546, recall: 0.8663366336632233, f1: 0.46604527293000725\n",
            "epoch: 428, step: 23, Train: label_loss: 0.10236819088459015, precision: 0.30922509225089967, recall: 0.8747390396657881, f1: 0.4569247545960357\n",
            "epoch: 429, step: 0, Train: label_loss: 0.09624052047729492, precision: 0.3212560386473236, recall: 0.877887788778733, f1: 0.47038019447885765\n",
            "epoch: 429, step: 1, Train: label_loss: 0.09919571876525879, precision: 0.32430806257519107, recall: 0.8749999999998579, f1: 0.47322212463126434\n",
            "epoch: 429, step: 2, Train: label_loss: 0.10661172866821289, precision: 0.31591737545563087, recall: 0.8888888888887369, f1: 0.4661586732019658\n",
            "epoch: 429, step: 3, Train: label_loss: 0.09554534405469894, precision: 0.3223289315726097, recall: 0.883223684210381, f1: 0.4722955144726551\n",
            "epoch: 429, step: 4, Train: label_loss: 0.08874274790287018, precision: 0.3327359617682, recall: 0.8940609951844471, f1: 0.4849804091898552\n",
            "epoch: 429, step: 5, Train: label_loss: 0.09448551386594772, precision: 0.3143893591293643, recall: 0.8695652173911589, f1: 0.4618117228739193\n",
            "epoch: 429, step: 6, Train: label_loss: 0.11167946457862854, precision: 0.29064039408865205, recall: 0.8413547237075149, f1: 0.4320366132341057\n",
            "epoch: 429, step: 7, Train: label_loss: 0.09191711246967316, precision: 0.3116805721096358, recall: 0.8834459459457966, f1: 0.4607929515032536\n",
            "epoch: 429, step: 8, Train: label_loss: 0.09683658182621002, precision: 0.3181818181817989, recall: 0.8779264214045354, f1: 0.4670818504947161\n",
            "epoch: 429, step: 9, Train: label_loss: 0.09384161978960037, precision: 0.31569560047560546, recall: 0.9045996592843433, f1: 0.46804759802242313\n",
            "epoch: 429, step: 10, Train: label_loss: 0.09722843766212463, precision: 0.3424408014571741, recall: 0.8637059724347834, f1: 0.49043478256799167\n",
            "epoch: 429, step: 11, Train: label_loss: 0.11066826432943344, precision: 0.3329283110570879, recall: 0.8657187993679516, f1: 0.4809126809602753\n",
            "epoch: 429, step: 12, Train: label_loss: 0.10182948410511017, precision: 0.31272949816399553, recall: 0.8617200674534803, f1: 0.4589133362877812\n",
            "epoch: 429, step: 13, Train: label_loss: 0.09378580749034882, precision: 0.31610576923075023, recall: 0.8900169204736226, f1: 0.4665188469679313\n",
            "epoch: 429, step: 14, Train: label_loss: 0.10839836299419403, precision: 0.3323114653586553, recall: 0.8562401263821712, f1: 0.47879858653211166\n",
            "epoch: 429, step: 15, Train: label_loss: 0.10446658730506897, precision: 0.3128423615337606, recall: 0.8624161073824056, f1: 0.45913354172060644\n",
            "epoch: 429, step: 16, Train: label_loss: 0.10637162625789642, precision: 0.29223181257704733, recall: 0.8389380530971966, f1: 0.43347050750622146\n",
            "epoch: 429, step: 17, Train: label_loss: 0.0861031711101532, precision: 0.3225613405146426, recall: 0.886513157894591, f1: 0.47301447999593954\n",
            "epoch: 429, step: 18, Train: label_loss: 0.10021491348743439, precision: 0.32319618366128067, recall: 0.9124579124577588, f1: 0.477322765262958\n",
            "epoch: 429, step: 19, Train: label_loss: 0.099180668592453, precision: 0.2910539215686096, recall: 0.8467023172904016, f1: 0.43319653438961037\n",
            "epoch: 429, step: 20, Train: label_loss: 0.09070556610822678, precision: 0.3301492537313236, recall: 0.8962722852510703, f1: 0.48254799297980905\n",
            "epoch: 429, step: 21, Train: label_loss: 0.08993004262447357, precision: 0.3297035692679776, recall: 0.8664546899839639, f1: 0.47765118313268157\n",
            "epoch: 429, step: 22, Train: label_loss: 0.10038365423679352, precision: 0.3287425149700402, recall: 0.8854838709675991, f1: 0.47947598249322104\n",
            "epoch: 429, step: 23, Train: label_loss: 0.10669388622045517, precision: 0.2984409799554344, recall: 0.8893805309732545, f1: 0.4469149527138541\n",
            "epoch: 430, step: 0, Train: label_loss: 0.10362818092107773, precision: 0.31899641577059024, recall: 0.8811881188117358, f1: 0.46842105259250866\n",
            "epoch: 430, step: 1, Train: label_loss: 0.10658062994480133, precision: 0.31790865384613476, recall: 0.8714991762766273, f1: 0.4658740642496499\n",
            "epoch: 430, step: 2, Train: label_loss: 0.09517477452754974, precision: 0.3132817153067115, recall: 0.9068965517239815, f1: 0.4656927843796767\n",
            "epoch: 430, step: 3, Train: label_loss: 0.07498057186603546, precision: 0.33392539964474044, recall: 0.9141004862235147, f1: 0.4891587163527838\n",
            "epoch: 430, step: 4, Train: label_loss: 0.08882157504558563, precision: 0.3287752675386249, recall: 0.9110378912683836, f1: 0.4831804280955423\n",
            "epoch: 430, step: 5, Train: label_loss: 0.10806873440742493, precision: 0.30950938824952695, recall: 0.8617200674534803, f1: 0.45543672010367653\n",
            "epoch: 430, step: 6, Train: label_loss: 0.0979873389005661, precision: 0.2929475587703259, recall: 0.8586572438161026, f1: 0.436853932546296\n",
            "epoch: 430, step: 7, Train: label_loss: 0.09829515963792801, precision: 0.31726190476188587, recall: 0.8868552412644114, f1: 0.4673388864144572\n",
            "epoch: 430, step: 8, Train: label_loss: 0.09933396428823471, precision: 0.3140243902438833, recall: 0.8612040133777823, f1: 0.46023235027357706\n",
            "epoch: 430, step: 9, Train: label_loss: 0.10030648112297058, precision: 0.3195625759416574, recall: 0.8497576736670678, f1: 0.4644591611081414\n",
            "epoch: 430, step: 10, Train: label_loss: 0.08935774862766266, precision: 0.3271420011983027, recall: 0.8878048780486361, f1: 0.47810858139668294\n",
            "epoch: 430, step: 11, Train: label_loss: 0.09646493196487427, precision: 0.30649970184852077, recall: 0.890814558058771, f1: 0.4560780833691437\n",
            "epoch: 430, step: 12, Train: label_loss: 0.09043562412261963, precision: 0.32451923076921124, recall: 0.8970099667772595, f1: 0.47661076783384415\n",
            "epoch: 430, step: 13, Train: label_loss: 0.08729536831378937, precision: 0.32002383790224553, recall: 0.9010067114092447, f1: 0.4722955144731517\n",
            "epoch: 430, step: 14, Train: label_loss: 0.11025853455066681, precision: 0.296543359611868, recall: 0.8639575971729921, f1: 0.44153498867523155\n",
            "epoch: 430, step: 15, Train: label_loss: 0.0893845483660698, precision: 0.32194244604314615, recall: 0.8876033057849771, f1: 0.47250329956494136\n",
            "epoch: 430, step: 16, Train: label_loss: 0.08961731940507889, precision: 0.30101735487730097, recall: 0.8982142857141252, f1: 0.4509188704240352\n",
            "epoch: 430, step: 17, Train: label_loss: 0.10456022620201111, precision: 0.3244390539720846, recall: 0.8656957928801188, f1: 0.47198941328187016\n",
            "epoch: 430, step: 18, Train: label_loss: 0.1005217656493187, precision: 0.3250454821103502, recall: 0.8645161290321186, f1: 0.47245482587474136\n",
            "epoch: 430, step: 19, Train: label_loss: 0.09026120603084564, precision: 0.3541919805589092, recall: 0.8675595238093946, f1: 0.5030198446524861\n",
            "epoch: 430, step: 20, Train: label_loss: 0.10920804738998413, precision: 0.33132166566081284, recall: 0.888349514562963, f1: 0.48263736259774903\n",
            "epoch: 430, step: 21, Train: label_loss: 0.07702648639678955, precision: 0.33194527067219914, recall: 0.8871224165340401, f1: 0.4831168830772112\n",
            "epoch: 430, step: 22, Train: label_loss: 0.09579377621412277, precision: 0.31820968730838023, recall: 0.863560732113001, f1: 0.4650537634014662\n",
            "epoch: 430, step: 23, Train: label_loss: 0.09815734624862671, precision: 0.29420396184884123, recall: 0.8991031390132513, f1: 0.44333886121210786\n",
            "epoch: 431, step: 0, Train: label_loss: 0.10996098071336746, precision: 0.3019207683073048, recall: 0.9014336917561108, f1: 0.4523381294587724\n",
            "epoch: 431, step: 1, Train: label_loss: 0.11051540076732635, precision: 0.3337386018236879, recall: 0.8728139904609105, f1: 0.4828496041815745\n",
            "epoch: 431, step: 2, Train: label_loss: 0.10101908445358276, precision: 0.3092537313432651, recall: 0.885470085469934, f1: 0.4584070796076079\n",
            "epoch: 431, step: 3, Train: label_loss: 0.09359715133905411, precision: 0.3237063778579829, recall: 0.8922056384741471, f1: 0.4750551875988573\n",
            "epoch: 431, step: 4, Train: label_loss: 0.08470451086759567, precision: 0.31964285714283813, recall: 0.9055649241145184, f1: 0.4725032995654408\n",
            "epoch: 431, step: 5, Train: label_loss: 0.10221211612224579, precision: 0.31419939577037376, recall: 0.8637873754151388, f1: 0.4607886574708115\n",
            "epoch: 431, step: 6, Train: label_loss: 0.08576788008213043, precision: 0.3233353329333939, recall: 0.8749999999998579, f1: 0.47218572050370006\n",
            "epoch: 431, step: 7, Train: label_loss: 0.0900786817073822, precision: 0.3178528347406322, recall: 0.8872053872052378, f1: 0.46802841914406823\n",
            "epoch: 431, step: 8, Train: label_loss: 0.08783011138439178, precision: 0.3170441001191706, recall: 0.9047619047617508, f1: 0.4695498675696477\n",
            "epoch: 431, step: 9, Train: label_loss: 0.09127546846866608, precision: 0.34422262552931976, recall: 0.8713629402755173, f1: 0.4934952297945723\n",
            "epoch: 431, step: 10, Train: label_loss: 0.09710706770420074, precision: 0.31468110709986075, recall: 0.8789915966385077, f1: 0.4634470535721217\n",
            "epoch: 431, step: 11, Train: label_loss: 0.11080820858478546, precision: 0.3125378558449235, recall: 0.870151770657526, f1: 0.45989304808941583\n",
            "epoch: 431, step: 12, Train: label_loss: 0.09700578451156616, precision: 0.32912912912910935, recall: 0.8910569105689607, f1: 0.48070175434652695\n",
            "epoch: 431, step: 13, Train: label_loss: 0.1084061935544014, precision: 0.3209500609013203, recall: 0.8611111111109704, f1: 0.4676131321698048\n",
            "epoch: 431, step: 14, Train: label_loss: 0.09370753914117813, precision: 0.339476813317459, recall: 0.9006309148263563, f1: 0.4930915370931833\n",
            "epoch: 431, step: 15, Train: label_loss: 0.11265549063682556, precision: 0.32107843137252934, recall: 0.8632619439866781, f1: 0.4680661008983556\n",
            "epoch: 431, step: 16, Train: label_loss: 0.09061745554208755, precision: 0.31758373205739726, recall: 0.8835274542427813, f1: 0.46722393308908416\n",
            "epoch: 431, step: 17, Train: label_loss: 0.09802689403295517, precision: 0.2936170212765779, recall: 0.8563829787232523, f1: 0.437301946544098\n",
            "epoch: 431, step: 18, Train: label_loss: 0.09139032661914825, precision: 0.3207434052757601, recall: 0.8842975206610107, f1: 0.4707435107396005\n",
            "epoch: 431, step: 19, Train: label_loss: 0.10424745082855225, precision: 0.30550514216574076, recall: 0.8691910499137918, f1: 0.45210384955860783\n",
            "epoch: 431, step: 20, Train: label_loss: 0.08751256763935089, precision: 0.3167777104784787, recall: 0.8716666666665214, f1: 0.4646823633549057\n",
            "epoch: 431, step: 21, Train: label_loss: 0.10508483648300171, precision: 0.31951219512193174, recall: 0.8632619439866781, f1: 0.4663996439302633\n",
            "epoch: 431, step: 22, Train: label_loss: 0.08649732172489166, precision: 0.3213859020310441, recall: 0.8951747088184866, f1: 0.47296703292811393\n",
            "epoch: 431, step: 23, Train: label_loss: 0.11714665591716766, precision: 0.3109243697478754, recall: 0.8426501035194943, f1: 0.454241071389144\n",
            "epoch: 432, step: 0, Train: label_loss: 0.09244418144226074, precision: 0.3063063063062879, recall: 0.8777969018931363, f1: 0.4541406945297275\n",
            "epoch: 432, step: 1, Train: label_loss: 0.0934029370546341, precision: 0.3165554881746321, recall: 0.8671096345513509, f1: 0.46379386935215744\n",
            "epoch: 432, step: 2, Train: label_loss: 0.10145299136638641, precision: 0.3178528347406322, recall: 0.8947368421051112, f1: 0.46906987090030466\n",
            "epoch: 432, step: 3, Train: label_loss: 0.08394815027713776, precision: 0.3273273273273077, recall: 0.8790322580643742, f1: 0.47702406998229757\n",
            "epoch: 432, step: 4, Train: label_loss: 0.10500786453485489, precision: 0.3282766990291063, recall: 0.8600953895070174, f1: 0.4751866490596645\n",
            "epoch: 432, step: 5, Train: label_loss: 0.08076367527246475, precision: 0.3043217286914583, recall: 0.8802083333331805, f1: 0.45227475464509626\n",
            "epoch: 432, step: 6, Train: label_loss: 0.10224255919456482, precision: 0.3239608801955792, recall: 0.8562197092082623, f1: 0.47006651880713496\n",
            "epoch: 432, step: 7, Train: label_loss: 0.09178037941455841, precision: 0.32383262583381905, recall: 0.8626817447494567, f1: 0.47089947085974176\n",
            "epoch: 432, step: 8, Train: label_loss: 0.0949818566441536, precision: 0.32014388489206713, recall: 0.9020270270268745, f1: 0.4725663716427079\n",
            "epoch: 432, step: 9, Train: label_loss: 0.09056487679481506, precision: 0.3295791345583681, recall: 0.9190082644626579, f1: 0.48516579402741805\n",
            "epoch: 432, step: 10, Train: label_loss: 0.0856420174241066, precision: 0.31563065781530986, recall: 0.8716666666665214, f1: 0.4634470535719131\n",
            "epoch: 432, step: 11, Train: label_loss: 0.0938110500574112, precision: 0.3099940155595266, recall: 0.8839590443684497, f1: 0.45901639340413714\n",
            "epoch: 432, step: 12, Train: label_loss: 0.09312890470027924, precision: 0.30197723187535636, recall: 0.8765217391302823, f1: 0.44919786092441066\n",
            "epoch: 432, step: 13, Train: label_loss: 0.09537099301815033, precision: 0.3261000602772558, recall: 0.8839869281044307, f1: 0.4764420959535401\n",
            "epoch: 432, step: 14, Train: label_loss: 0.0985206812620163, precision: 0.31637032495399653, recall: 0.8445171849425785, f1: 0.46030330058475044\n",
            "epoch: 432, step: 15, Train: label_loss: 0.08902544528245926, precision: 0.3218116805720905, recall: 0.8809135399672298, f1: 0.4714098646486729\n",
            "epoch: 432, step: 16, Train: label_loss: 0.12255863845348358, precision: 0.3164713140036819, recall: 0.8300970873785064, f1: 0.4582402858018865\n",
            "epoch: 432, step: 17, Train: label_loss: 0.09458410739898682, precision: 0.32938388625590465, recall: 0.9144736842103759, f1: 0.48432055745230995\n",
            "epoch: 432, step: 18, Train: label_loss: 0.09787188470363617, precision: 0.3202179176755254, recall: 0.8772802653398213, f1: 0.46917960084769633\n",
            "epoch: 432, step: 19, Train: label_loss: 0.09924538433551788, precision: 0.3257756563245629, recall: 0.9069767441858958, f1: 0.47936786651067687\n",
            "epoch: 432, step: 20, Train: label_loss: 0.09999431669712067, precision: 0.30030769230767385, recall: 0.8428324697753293, f1: 0.44283121593218355\n",
            "epoch: 432, step: 21, Train: label_loss: 0.1009828969836235, precision: 0.3161407766990099, recall: 0.8830508474574774, f1: 0.46559428056881813\n",
            "epoch: 432, step: 22, Train: label_loss: 0.10483002662658691, precision: 0.3119047619047433, recall: 0.9018932874353008, f1: 0.46351172043943684\n",
            "epoch: 432, step: 23, Train: label_loss: 0.09819173812866211, precision: 0.3275862068965272, recall: 0.8585461689585739, f1: 0.47422680408367895\n",
            "epoch: 433, step: 0, Train: label_loss: 0.0994558110833168, precision: 0.3275449101796211, recall: 0.8766025641024235, f1: 0.4768962510501535\n",
            "epoch: 433, step: 1, Train: label_loss: 0.0910748541355133, precision: 0.31197604790417294, recall: 0.8951890034362723, f1: 0.462699822341736\n",
            "epoch: 433, step: 2, Train: label_loss: 0.0857674852013588, precision: 0.31591591591589696, recall: 0.8752079866887063, f1: 0.4642541923705151\n",
            "epoch: 433, step: 3, Train: label_loss: 0.09982127696275711, precision: 0.3195195195195003, recall: 0.877887788778733, f1: 0.46851607217571445\n",
            "epoch: 433, step: 4, Train: label_loss: 0.09050623327493668, precision: 0.3269346130773649, recall: 0.8818770226535789, f1: 0.47702406998237784\n",
            "epoch: 433, step: 5, Train: label_loss: 0.11081896722316742, precision: 0.3145454545454355, recall: 0.8811544991509539, f1: 0.4635998213100028\n",
            "epoch: 433, step: 6, Train: label_loss: 0.10621997714042664, precision: 0.29681762545897816, recall: 0.8553791887123711, f1: 0.4407087687031917\n",
            "epoch: 433, step: 7, Train: label_loss: 0.10265593230724335, precision: 0.3160493827160299, recall: 0.8619528619527168, f1: 0.4625112917402803\n",
            "epoch: 433, step: 8, Train: label_loss: 0.0972612202167511, precision: 0.32014388489206713, recall: 0.8959731543622657, f1: 0.4717314487244192\n",
            "epoch: 433, step: 9, Train: label_loss: 0.09592336416244507, precision: 0.30612244897957347, recall: 0.8703071672353463, f1: 0.4529307282030224\n",
            "epoch: 433, step: 10, Train: label_loss: 0.09253598749637604, precision: 0.3243405275779182, recall: 0.8927392739272454, f1: 0.475813544375991\n",
            "epoch: 433, step: 11, Train: label_loss: 0.1106497049331665, precision: 0.3119999999999808, recall: 0.84782608695638, f1: 0.45614035083782356\n",
            "epoch: 433, step: 12, Train: label_loss: 0.0874689444899559, precision: 0.3189706762417523, recall: 0.8853820598005173, f1: 0.4689837219143836\n",
            "epoch: 433, step: 13, Train: label_loss: 0.09458120912313461, precision: 0.3056220095693597, recall: 0.8720136518769842, f1: 0.45261293175957723\n",
            "epoch: 433, step: 14, Train: label_loss: 0.08455349504947662, precision: 0.32123735871503145, recall: 0.885245901639199, f1: 0.4714098646487949\n",
            "epoch: 433, step: 15, Train: label_loss: 0.08540235459804535, precision: 0.3198813056379632, recall: 0.9013377926419897, f1: 0.47218572050443847\n",
            "epoch: 433, step: 16, Train: label_loss: 0.10075462609529495, precision: 0.3222087378640581, recall: 0.8523274478329289, f1: 0.4676354028663531\n",
            "epoch: 433, step: 17, Train: label_loss: 0.08762465417385101, precision: 0.3239951278927939, recall: 0.8608414239480807, f1: 0.4707964601372143\n",
            "epoch: 433, step: 18, Train: label_loss: 0.0877009928226471, precision: 0.31793641271743744, recall: 0.8760330578510948, f1: 0.4665492957355313\n",
            "epoch: 433, step: 19, Train: label_loss: 0.11124037206172943, precision: 0.29956763434216804, recall: 0.8304794520546522, f1: 0.440308669956457\n",
            "epoch: 433, step: 20, Train: label_loss: 0.10475916415452957, precision: 0.3108108108107917, recall: 0.8461538461537046, f1: 0.4546271338330812\n",
            "epoch: 433, step: 21, Train: label_loss: 0.09664419293403625, precision: 0.3174893357708521, recall: 0.8611570247932461, f1: 0.4639358859801873\n",
            "epoch: 433, step: 22, Train: label_loss: 0.09799474477767944, precision: 0.3387681159420085, recall: 0.9004815409308345, f1: 0.49232119346615305\n",
            "epoch: 433, step: 23, Train: label_loss: 0.09923297166824341, precision: 0.3355605048255133, recall: 0.9039999999998192, f1: 0.4894423388884532\n",
            "epoch: 434, step: 0, Train: label_loss: 0.10285888612270355, precision: 0.32210655235760427, recall: 0.8855218855217364, f1: 0.4723843735576078\n",
            "epoch: 434, step: 1, Train: label_loss: 0.10558979213237762, precision: 0.3441518677280867, recall: 0.8646153846152516, f1: 0.49233464735300675\n",
            "epoch: 434, step: 2, Train: label_loss: 0.07705377042293549, precision: 0.32225519287831916, recall: 0.9156829679593733, f1: 0.4767339771344065\n",
            "epoch: 434, step: 3, Train: label_loss: 0.07645706832408905, precision: 0.3359004739336294, recall: 0.9057507987219, f1: 0.49006050125694556\n",
            "epoch: 434, step: 4, Train: label_loss: 0.08969682455062866, precision: 0.34052757793762944, recall: 0.9059011164272877, f1: 0.49498910671405694\n",
            "epoch: 434, step: 5, Train: label_loss: 0.10171595215797424, precision: 0.2987878787878607, recall: 0.8559027777776291, f1: 0.44294699007840094\n",
            "epoch: 434, step: 6, Train: label_loss: 0.10859605669975281, precision: 0.29030265596045146, recall: 0.8348134991117522, f1: 0.43079743350887567\n",
            "epoch: 434, step: 7, Train: label_loss: 0.09143982827663422, precision: 0.3206979542719422, recall: 0.8809917355370444, f1: 0.4702249668774581\n",
            "epoch: 434, step: 8, Train: label_loss: 0.08645543456077576, precision: 0.3214497920380082, recall: 0.9046822742473403, f1: 0.4743533537534678\n",
            "epoch: 434, step: 9, Train: label_loss: 0.09046464413404465, precision: 0.3307276007215676, recall: 0.8914100486222217, f1: 0.48245614031135836\n",
            "epoch: 434, step: 10, Train: label_loss: 0.09200052171945572, precision: 0.30746089049336295, recall: 0.8602693602692154, f1: 0.4530141843583285\n",
            "epoch: 434, step: 11, Train: label_loss: 0.08668211847543716, precision: 0.31397459165152364, recall: 0.8871794871793355, f1: 0.4638069704707285\n",
            "epoch: 434, step: 12, Train: label_loss: 0.10889297723770142, precision: 0.3121529919802398, recall: 0.8518518518517084, f1: 0.4568848758072088\n",
            "epoch: 434, step: 13, Train: label_loss: 0.1115141212940216, precision: 0.31978481769274836, recall: 0.891666666666518, f1: 0.47074351073980725\n",
            "epoch: 434, step: 14, Train: label_loss: 0.09186207503080368, precision: 0.2953586497890117, recall: 0.8812949640286184, f1: 0.4424379232129231\n",
            "epoch: 434, step: 15, Train: label_loss: 0.10836484283208847, precision: 0.31681957186542403, recall: 0.8547854785477137, f1: 0.4622936188806256\n",
            "epoch: 434, step: 16, Train: label_loss: 0.09885495901107788, precision: 0.31679617453674136, recall: 0.8967851099829277, f1: 0.46819787982003597\n",
            "epoch: 434, step: 17, Train: label_loss: 0.0871395468711853, precision: 0.32358208955221945, recall: 0.8727858293074279, f1: 0.47212543550056524\n",
            "epoch: 434, step: 18, Train: label_loss: 0.10087376832962036, precision: 0.3270745003028269, recall: 0.8723747980612483, f1: 0.47577092507042446\n",
            "epoch: 434, step: 19, Train: label_loss: 0.09010784327983856, precision: 0.33173365326932625, recall: 0.8890675241156126, f1: 0.48318042809493533\n",
            "epoch: 434, step: 20, Train: label_loss: 0.10927397012710571, precision: 0.3062085593730979, recall: 0.8639455782311455, f1: 0.4521584334281635\n",
            "epoch: 434, step: 21, Train: label_loss: 0.09326162934303284, precision: 0.3218390804597506, recall: 0.874999999999856, f1: 0.4705882352547567\n",
            "epoch: 434, step: 22, Train: label_loss: 0.09602826833724976, precision: 0.3148809523809336, recall: 0.8831385642736421, f1: 0.46423870114593885\n",
            "epoch: 434, step: 23, Train: label_loss: 0.11129136383533478, precision: 0.3107599699021587, recall: 0.8480492813139943, f1: 0.4548458149386724\n",
            "epoch: 435, step: 0, Train: label_loss: 0.09522318840026855, precision: 0.3206291591046388, recall: 0.871710526315646, f1: 0.4688191065506437\n",
            "epoch: 435, step: 1, Train: label_loss: 0.08756387233734131, precision: 0.3304981773997369, recall: 0.8634920634919264, f1: 0.4780316344063187\n",
            "epoch: 435, step: 2, Train: label_loss: 0.10017228126525879, precision: 0.2891198044009603, recall: 0.8431372549018105, f1: 0.43058716427690663\n",
            "epoch: 435, step: 3, Train: label_loss: 0.09547014534473419, precision: 0.3325387365911601, recall: 0.9147540983605057, f1: 0.48776223772308935\n",
            "epoch: 435, step: 4, Train: label_loss: 0.09603197127580643, precision: 0.31303288672348883, recall: 0.8697123519457073, f1: 0.4603672189489437\n",
            "epoch: 435, step: 5, Train: label_loss: 0.10166186094284058, precision: 0.3048555623847385, recall: 0.8522336769757985, f1: 0.44907197823185957\n",
            "epoch: 435, step: 6, Train: label_loss: 0.09988909959793091, precision: 0.3111111111110924, recall: 0.8885077186962455, f1: 0.46085409248823267\n",
            "epoch: 435, step: 7, Train: label_loss: 0.09636086225509644, precision: 0.30601092896173004, recall: 0.8674698795179229, f1: 0.45242369834560653\n",
            "epoch: 435, step: 8, Train: label_loss: 0.08253578841686249, precision: 0.3215130023640472, recall: 0.9173693086001825, f1: 0.4761487964604304\n",
            "epoch: 435, step: 9, Train: label_loss: 0.0803118348121643, precision: 0.3422459893047925, recall: 0.9070866141730854, f1: 0.49698015526647593\n",
            "epoch: 435, step: 10, Train: label_loss: 0.08978109061717987, precision: 0.33071342200723514, recall: 0.871019108280116, f1: 0.479404031511336\n",
            "epoch: 435, step: 11, Train: label_loss: 0.09720179438591003, precision: 0.3214716525934667, recall: 0.8795379537952344, f1: 0.47084805649785655\n",
            "epoch: 435, step: 12, Train: label_loss: 0.10394065082073212, precision: 0.32666666666664684, recall: 0.8569157392685441, f1: 0.473014479995097\n",
            "epoch: 435, step: 13, Train: label_loss: 0.08973503857851028, precision: 0.3189448441246811, recall: 0.877887788778733, f1: 0.46789797709366976\n",
            "epoch: 435, step: 14, Train: label_loss: 0.09269508719444275, precision: 0.3092417061611191, recall: 0.9015544041449219, f1: 0.4605205116513823\n",
            "epoch: 435, step: 15, Train: label_loss: 0.0863921046257019, precision: 0.3200948429164007, recall: 0.8985024958401167, f1: 0.47202797198919544\n",
            "epoch: 435, step: 16, Train: label_loss: 0.09787945449352264, precision: 0.3317450863609094, recall: 0.8954983922828141, f1: 0.48413733155546756\n",
            "epoch: 435, step: 17, Train: label_loss: 0.10588166117668152, precision: 0.32743902439022393, recall: 0.874592833876079, f1: 0.47648624663289973\n",
            "epoch: 435, step: 18, Train: label_loss: 0.10772445797920227, precision: 0.306707317073152, recall: 0.8613013698628661, f1: 0.4523381294576348\n",
            "epoch: 435, step: 19, Train: label_loss: 0.08488120138645172, precision: 0.32125890736340135, recall: 0.9046822742473403, f1: 0.47414548637670745\n",
            "epoch: 435, step: 20, Train: label_loss: 0.09565071761608124, precision: 0.29770531400964384, recall: 0.8633975481609696, f1: 0.44274809156488193\n",
            "epoch: 435, step: 21, Train: label_loss: 0.10389204323291779, precision: 0.32194244604314615, recall: 0.9070945945944413, f1: 0.4752212388993448\n",
            "epoch: 435, step: 22, Train: label_loss: 0.11381818354129791, precision: 0.3219602977667294, recall: 0.8398058252425825, f1: 0.46547085197782967\n",
            "epoch: 435, step: 23, Train: label_loss: 0.09273557364940643, precision: 0.32195845697326986, recall: 0.8732394366195426, f1: 0.47046070456763245\n",
            "epoch: 436, step: 0, Train: label_loss: 0.0916970744729042, precision: 0.33293556085916864, recall: 0.9102773246328041, f1: 0.4875491480603472\n",
            "epoch: 436, step: 1, Train: label_loss: 0.0947042852640152, precision: 0.32558139534881725, recall: 0.8594507269788595, f1: 0.4722592099024051\n",
            "epoch: 436, step: 2, Train: label_loss: 0.10172592103481293, precision: 0.31990231990230034, recall: 0.8576104746316108, f1: 0.4659848821302381\n",
            "epoch: 436, step: 3, Train: label_loss: 0.07498108595609665, precision: 0.3279857397504261, recall: 0.8990228013027851, f1: 0.48062690461903734\n",
            "epoch: 436, step: 4, Train: label_loss: 0.08931350708007812, precision: 0.3299155609167473, recall: 0.8724082934607859, f1: 0.478774617027971\n",
            "epoch: 436, step: 5, Train: label_loss: 0.08943227678537369, precision: 0.2967625899280398, recall: 0.8935018050539902, f1: 0.445544554417973\n",
            "epoch: 436, step: 6, Train: label_loss: 0.10020308196544647, precision: 0.334350213544824, recall: 0.8616352201256506, f1: 0.4817582417179181\n",
            "epoch: 436, step: 7, Train: label_loss: 0.10276910662651062, precision: 0.3239012642985958, recall: 0.8691437802906511, f1: 0.4719298245218054\n",
            "epoch: 436, step: 8, Train: label_loss: 0.10865487158298492, precision: 0.30857487922703447, recall: 0.8646362098137285, f1: 0.45482866039732867\n",
            "epoch: 436, step: 9, Train: label_loss: 0.09969968348741531, precision: 0.2907886815171408, recall: 0.8718411552344996, f1: 0.4361173814522913\n",
            "epoch: 436, step: 10, Train: label_loss: 0.08016972988843918, precision: 0.33791866028706113, recall: 0.8982511923686965, f1: 0.4910908300341114\n",
            "epoch: 436, step: 11, Train: label_loss: 0.11337897181510925, precision: 0.2920517560073757, recall: 0.8243478260868131, f1: 0.4313011828548671\n",
            "epoch: 436, step: 12, Train: label_loss: 0.0986563116312027, precision: 0.30614729153984743, recall: 0.8568994889266002, f1: 0.45112107619435554\n",
            "epoch: 436, step: 13, Train: label_loss: 0.09049375355243683, precision: 0.32915921288012345, recall: 0.8961038961037505, f1: 0.4814653292236374\n",
            "epoch: 436, step: 14, Train: label_loss: 0.11043381690979004, precision: 0.31101643335360246, recall: 0.8646362098137285, f1: 0.4574753804444843\n",
            "epoch: 436, step: 15, Train: label_loss: 0.10147809982299805, precision: 0.3283313325329935, recall: 0.8967213114752628, f1: 0.4806678382735508\n",
            "epoch: 436, step: 16, Train: label_loss: 0.10291752219200134, precision: 0.31559854897216955, recall: 0.8628099173552293, f1: 0.4621513943830516\n",
            "epoch: 436, step: 17, Train: label_loss: 0.09941231459379196, precision: 0.3108272506082536, recall: 0.8516666666665247, f1: 0.4554367201033843\n",
            "epoch: 436, step: 18, Train: label_loss: 0.09300966560840607, precision: 0.3094089264173517, recall: 0.8754266211602602, f1: 0.45721925129826846\n",
            "epoch: 436, step: 19, Train: label_loss: 0.08895967900753021, precision: 0.3208910295002817, recall: 0.8752052545154556, f1: 0.46960352418977214\n",
            "epoch: 436, step: 20, Train: label_loss: 0.09089504927396774, precision: 0.30565583634173854, recall: 0.8683760683759199, f1: 0.45215843342829115\n",
            "epoch: 436, step: 21, Train: label_loss: 0.09127753973007202, precision: 0.33716707021789727, recall: 0.868954758190192, f1: 0.48582642821959904\n",
            "epoch: 436, step: 22, Train: label_loss: 0.09560835361480713, precision: 0.2895845875978152, recall: 0.8793418647164754, f1: 0.4356884057597894\n",
            "epoch: 436, step: 23, Train: label_loss: 0.08282487094402313, precision: 0.3238304093567015, recall: 0.8859999999998228, f1: 0.474304068483229\n",
            "epoch: 437, step: 0, Train: label_loss: 0.12363070249557495, precision: 0.3138101109740867, recall: 0.8413223140494477, f1: 0.45711719798463407\n",
            "epoch: 437, step: 1, Train: label_loss: 0.13890573382377625, precision: 0.3047559449311449, recall: 0.8296422487221755, f1: 0.4457665903496797\n",
            "epoch: 437, step: 2, Train: label_loss: 0.14399310946464539, precision: 0.3112623762376045, recall: 0.8397328881467713, f1: 0.45417607219526257\n",
            "epoch: 437, step: 3, Train: label_loss: 0.1124824732542038, precision: 0.28686994399500393, recall: 0.8261648745518232, f1: 0.42586605077001305\n",
            "epoch: 437, step: 4, Train: label_loss: 0.11609449982643127, precision: 0.3097454996896145, recall: 0.8330550918195604, f1: 0.4515837103676834\n",
            "epoch: 437, step: 5, Train: label_loss: 0.10985652357339859, precision: 0.31946955997586984, recall: 0.8760330578510948, f1: 0.46819787981945266\n",
            "epoch: 437, step: 6, Train: label_loss: 0.106553815305233, precision: 0.31722054380662734, recall: 0.8692052980131011, f1: 0.4648074368797724\n",
            "epoch: 437, step: 7, Train: label_loss: 0.10165426135063171, precision: 0.3075539568345139, recall: 0.8592964824119163, f1: 0.45298013241147034\n",
            "epoch: 437, step: 8, Train: label_loss: 0.11773937940597534, precision: 0.31169626454376537, recall: 0.8427152317879398, f1: 0.4550737594598684\n",
            "epoch: 437, step: 9, Train: label_loss: 0.11949990689754486, precision: 0.3313032886723306, recall: 0.8888888888887436, f1: 0.48269742675720373\n",
            "epoch: 437, step: 10, Train: label_loss: 0.11637624353170395, precision: 0.3134418324291553, recall: 0.8813559322032404, f1: 0.46242774562599526\n",
            "epoch: 437, step: 11, Train: label_loss: 0.12414528429508209, precision: 0.31737262124000504, recall: 0.8573797678273868, f1: 0.46326164870604325\n",
            "epoch: 437, step: 12, Train: label_loss: 0.12054471671581268, precision: 0.3010552451893047, recall: 0.834767641996414, f1: 0.4425182481361819\n",
            "epoch: 437, step: 13, Train: label_loss: 0.12100794911384583, precision: 0.3211407315560867, recall: 0.8395461912478379, f1: 0.4645739909913226\n",
            "epoch: 437, step: 14, Train: label_loss: 0.10771513730287552, precision: 0.31648616125148515, recall: 0.8900169204736226, f1: 0.46693297821247776\n",
            "epoch: 437, step: 15, Train: label_loss: 0.12503807246685028, precision: 0.32492307692305694, recall: 0.8421052631577604, f1: 0.4689165186098668\n",
            "epoch: 437, step: 16, Train: label_loss: 0.09871770441532135, precision: 0.301739652069568, recall: 0.8778359511342272, f1: 0.44910714281902914\n",
            "epoch: 437, step: 17, Train: label_loss: 0.11536060273647308, precision: 0.3155015197568197, recall: 0.8649999999998558, f1: 0.46236080174252947\n",
            "epoch: 437, step: 18, Train: label_loss: 0.10465414822101593, precision: 0.3357058125741201, recall: 0.9070512820511366, f1: 0.4900432900038157\n",
            "epoch: 437, step: 19, Train: label_loss: 0.10493557155132294, precision: 0.32361870066786136, recall: 0.8809917355370444, f1: 0.47335701594645296\n",
            "epoch: 437, step: 20, Train: label_loss: 0.1095062643289566, precision: 0.33516148689821235, recall: 0.8593749999998657, f1: 0.4822446295080305\n",
            "epoch: 437, step: 21, Train: label_loss: 0.1351679116487503, precision: 0.32495285983656036, recall: 0.8420195439738042, f1: 0.46893424032258546\n",
            "epoch: 437, step: 22, Train: label_loss: 0.13808563351631165, precision: 0.30432020330366555, recall: 0.7970049916803997, f1: 0.4404597700749084\n",
            "epoch: 437, step: 23, Train: label_loss: 0.14698222279548645, precision: 0.2960579243764846, recall: 0.7619047619046042, f1: 0.4264194669353112\n",
            "epoch: 438, step: 0, Train: label_loss: 0.15341490507125854, precision: 0.281793842034787, recall: 0.6912972085384743, f1: 0.4003804088984268\n",
            "epoch: 438, step: 1, Train: label_loss: 0.15522989630699158, precision: 0.28985507246374903, recall: 0.740740740740616, f1: 0.4166666666261975\n",
            "epoch: 438, step: 2, Train: label_loss: 0.13750706613063812, precision: 0.2954694681549379, recall: 0.7293354943272723, f1: 0.420560747622474\n",
            "epoch: 438, step: 3, Train: label_loss: 0.14353002607822418, precision: 0.30187459599222355, recall: 0.7520128824475439, f1: 0.4308118080771631\n",
            "epoch: 438, step: 4, Train: label_loss: 0.1581990271806717, precision: 0.2617586912065261, recall: 0.6326194398681, f1: 0.37029893920639156\n",
            "epoch: 438, step: 5, Train: label_loss: 0.13001316785812378, precision: 0.2924164524421406, recall: 0.7398373983738634, f1: 0.4191616766060616\n",
            "epoch: 438, step: 6, Train: label_loss: 0.14429552853107452, precision: 0.2835016835016644, recall: 0.6958677685949263, f1: 0.40287081335595487\n",
            "epoch: 438, step: 7, Train: label_loss: 0.14043787121772766, precision: 0.2941554271033851, recall: 0.7607973421925646, f1: 0.4242704955595584\n",
            "epoch: 438, step: 8, Train: label_loss: 0.14202895760536194, precision: 0.2827058072750298, recall: 0.7785588752195468, f1: 0.41479400745151296\n",
            "epoch: 438, step: 9, Train: label_loss: 0.1271016150712967, precision: 0.30659203980097594, recall: 0.8042414355626746, f1: 0.4439441692531062\n",
            "epoch: 438, step: 10, Train: label_loss: 0.16071785986423492, precision: 0.28696236559137855, recall: 0.7164429530200139, f1: 0.4097888675215009\n",
            "epoch: 438, step: 11, Train: label_loss: 0.1372789889574051, precision: 0.31136950904390753, recall: 0.7724358974357736, f1: 0.4438305708614021\n",
            "epoch: 438, step: 12, Train: label_loss: 0.1579432636499405, precision: 0.28942115768461146, recall: 0.7190082644626911, f1: 0.412713472444803\n",
            "epoch: 438, step: 13, Train: label_loss: 0.1446719616651535, precision: 0.3102352193261087, recall: 0.778309409888233, f1: 0.4436363635955683\n",
            "epoch: 438, step: 14, Train: label_loss: 0.15271863341331482, precision: 0.31116849580372424, recall: 0.7724358974357736, f1: 0.4436263230147026\n",
            "epoch: 438, step: 15, Train: label_loss: 0.15421615540981293, precision: 0.2881245944191896, recall: 0.7735191637629314, f1: 0.4198581559887811\n",
            "epoch: 438, step: 16, Train: label_loss: 0.1315569430589676, precision: 0.3006493506493311, recall: 0.7742474916386665, f1: 0.43311506076415596\n",
            "epoch: 438, step: 17, Train: label_loss: 0.14062528312206268, precision: 0.2826086956521553, recall: 0.7447916666665373, f1: 0.409742120303919\n",
            "epoch: 438, step: 18, Train: label_loss: 0.1440390646457672, precision: 0.2812499999999817, recall: 0.7619047619046275, f1: 0.4108416547394637\n",
            "epoch: 438, step: 19, Train: label_loss: 0.12936924397945404, precision: 0.3012903225806257, recall: 0.7556634304205897, f1: 0.43081180807728164\n",
            "epoch: 438, step: 20, Train: label_loss: 0.12769506871700287, precision: 0.2754374594944734, recall: 0.7352941176469315, f1: 0.400754361110713\n",
            "epoch: 438, step: 21, Train: label_loss: 0.14697936177253723, precision: 0.28283485045511814, recall: 0.7671957671956319, f1: 0.4133016626684382\n",
            "epoch: 438, step: 22, Train: label_loss: 0.14557062089443207, precision: 0.3009198423127266, recall: 0.7508196721310244, f1: 0.4296435271636117\n",
            "epoch: 438, step: 23, Train: label_loss: 0.1346006840467453, precision: 0.3135135135134893, recall: 0.8071570576539151, f1: 0.4516129031854578\n",
            "epoch: 439, step: 0, Train: label_loss: 0.14080184698104858, precision: 0.2884864165588429, recall: 0.7702936096717149, f1: 0.41976470584266734\n",
            "epoch: 439, step: 1, Train: label_loss: 0.1451067328453064, precision: 0.3038386467143589, recall: 0.7436305732482892, f1: 0.4314087759402986\n",
            "epoch: 439, step: 2, Train: label_loss: 0.15039736032485962, precision: 0.30729166666664665, recall: 0.7588424437297815, f1: 0.4374420759552216\n",
            "epoch: 439, step: 3, Train: label_loss: 0.12094128131866455, precision: 0.3153605015673783, recall: 0.8086816720255934, f1: 0.4537663508842628\n",
            "epoch: 439, step: 4, Train: label_loss: 0.14001421630382538, precision: 0.28928800513147596, recall: 0.7762478485368715, f1: 0.4214953270632072\n",
            "epoch: 439, step: 5, Train: label_loss: 0.13352859020233154, precision: 0.3139534883720727, recall: 0.7826086956520478, f1: 0.4481327800420791\n",
            "epoch: 439, step: 6, Train: label_loss: 0.12310698628425598, precision: 0.311381074168778, recall: 0.7829581993567872, f1: 0.4455626715054471\n",
            "epoch: 439, step: 7, Train: label_loss: 0.1351068764925003, precision: 0.3058064516128835, recall: 0.7796052631577665, f1: 0.4392956440744078\n",
            "epoch: 439, step: 8, Train: label_loss: 0.12608206272125244, precision: 0.3069053708439701, recall: 0.8013355592653085, f1: 0.4438280166034616\n",
            "epoch: 439, step: 9, Train: label_loss: 0.13032266497612, precision: 0.2992376111816836, recall: 0.7889447236179582, f1: 0.43390142787348995\n",
            "epoch: 439, step: 10, Train: label_loss: 0.13618166744709015, precision: 0.3108709472345638, recall: 0.8330494037477285, f1: 0.4527777777381546\n",
            "epoch: 439, step: 11, Train: label_loss: 0.13088855147361755, precision: 0.3160883280756898, recall: 0.8267326732671902, f1: 0.4573254221415932\n",
            "epoch: 439, step: 12, Train: label_loss: 0.11951644718647003, precision: 0.3300186451211728, recall: 0.8375394321765239, f1: 0.47347302715512535\n",
            "epoch: 439, step: 13, Train: label_loss: 0.12556788325309753, precision: 0.31301587301585315, recall: 0.7900641025639759, f1: 0.4483856297910524\n",
            "epoch: 439, step: 14, Train: label_loss: 0.11968263983726501, precision: 0.303964757709232, recall: 0.8076923076921726, f1: 0.4417009601797048\n",
            "epoch: 439, step: 15, Train: label_loss: 0.12311167269945145, precision: 0.2933832709113425, recall: 0.7979626485567405, f1: 0.4290278411290652\n",
            "epoch: 439, step: 16, Train: label_loss: 0.12563499808311462, precision: 0.2792452830188504, recall: 0.8072727272725805, f1: 0.4149532709898075\n",
            "epoch: 439, step: 17, Train: label_loss: 0.14587576687335968, precision: 0.29044834307990314, recall: 0.7425249169433982, f1: 0.4175618869282439\n",
            "epoch: 439, step: 18, Train: label_loss: 0.11153806000947952, precision: 0.3016169154228668, recall: 0.8164983164981789, f1: 0.44050862848009026\n",
            "epoch: 439, step: 19, Train: label_loss: 0.12330867350101471, precision: 0.30905636478782084, recall: 0.8066115702478005, f1: 0.4468864468463505\n",
            "epoch: 439, step: 20, Train: label_loss: 0.1289169192314148, precision: 0.29690461149713854, recall: 0.795262267343351, f1: 0.43238270465218315\n",
            "epoch: 439, step: 21, Train: label_loss: 0.1169612854719162, precision: 0.29943855271364317, recall: 0.7960199004973804, f1: 0.4351767905314044\n",
            "epoch: 439, step: 22, Train: label_loss: 0.12380078434944153, precision: 0.29266750948165027, recall: 0.7982758620688278, f1: 0.4283071229949277\n",
            "epoch: 439, step: 23, Train: label_loss: 0.12071830034255981, precision: 0.3009188361408652, recall: 0.8238993710690097, f1: 0.4408300616545338\n",
            "epoch: 440, step: 0, Train: label_loss: 0.1326027661561966, precision: 0.28146311221324977, recall: 0.8239564428310664, f1: 0.4195933456181956\n",
            "epoch: 440, step: 1, Train: label_loss: 0.12570935487747192, precision: 0.31806930693067337, recall: 0.8453947368419662, f1: 0.4622302157875677\n",
            "epoch: 440, step: 2, Train: label_loss: 0.12491357326507568, precision: 0.29535327816675394, recall: 0.7520259319285653, f1: 0.4241316270161394\n",
            "epoch: 440, step: 3, Train: label_loss: 0.12261124700307846, precision: 0.285624607658488, recall: 0.7926829268291301, f1: 0.41993539451570117\n",
            "epoch: 440, step: 4, Train: label_loss: 0.13707904517650604, precision: 0.29911280101392274, recall: 0.7827529021557573, f1: 0.43282897749319427\n",
            "epoch: 440, step: 5, Train: label_loss: 0.12789984047412872, precision: 0.30418250950568415, recall: 0.8067226890754946, f1: 0.4417855498911622\n",
            "epoch: 440, step: 6, Train: label_loss: 0.09908919781446457, precision: 0.32254123396454965, recall: 0.857142857142718, f1: 0.46870838877514015\n",
            "epoch: 440, step: 7, Train: label_loss: 0.11615274846553802, precision: 0.3183828174352294, recall: 0.7987321711567672, f1: 0.45528455280473185\n",
            "epoch: 440, step: 8, Train: label_loss: 0.12326591461896896, precision: 0.30130192188466826, recall: 0.8571428571427059, f1: 0.44587155959449776\n",
            "epoch: 440, step: 9, Train: label_loss: 0.12332300841808319, precision: 0.32945499081443175, recall: 0.8705501618121568, f1: 0.4780097733941528\n",
            "epoch: 440, step: 10, Train: label_loss: 0.10640199482440948, precision: 0.3056249999999809, recall: 0.831632653061083, f1: 0.44698354657857137\n",
            "epoch: 440, step: 11, Train: label_loss: 0.1158955991268158, precision: 0.29130434782606884, recall: 0.8315602836877958, f1: 0.4314627414518755\n",
            "epoch: 440, step: 12, Train: label_loss: 0.10216405242681503, precision: 0.3351581508515611, recall: 0.8718354430378367, f1: 0.4841827767612486\n",
            "epoch: 440, step: 13, Train: label_loss: 0.10868489742279053, precision: 0.32450738916254157, recall: 0.8696369636962261, f1: 0.4726457398706912\n",
            "epoch: 440, step: 14, Train: label_loss: 0.12493088841438293, precision: 0.30276381909545835, recall: 0.8060200668894972, f1: 0.4401826483620867\n",
            "epoch: 440, step: 15, Train: label_loss: 0.13782158493995667, precision: 0.30904522613063384, recall: 0.8282828282826887, f1: 0.4501372369228689\n",
            "epoch: 440, step: 16, Train: label_loss: 0.12774764001369476, precision: 0.3132454488386495, recall: 0.8140293637845327, f1: 0.4524025384911049\n",
            "epoch: 440, step: 17, Train: label_loss: 0.11024481058120728, precision: 0.31848688224525207, recall: 0.8743718592963359, f1: 0.46690518779623696\n",
            "epoch: 440, step: 18, Train: label_loss: 0.10731053352355957, precision: 0.3331276989512441, recall: 0.8450704225350789, f1: 0.47787610615408804\n",
            "epoch: 440, step: 19, Train: label_loss: 0.10151264071464539, precision: 0.3239263803680783, recall: 0.8529886914376651, f1: 0.469542018635029\n",
            "epoch: 440, step: 20, Train: label_loss: 0.10033576190471649, precision: 0.30783466995679776, recall: 0.827529021558735, f1: 0.4487410071546802\n",
            "epoch: 440, step: 21, Train: label_loss: 0.12006767094135284, precision: 0.3126954346466346, recall: 0.8130081300811686, f1: 0.45167118333833617\n",
            "epoch: 440, step: 22, Train: label_loss: 0.11549155414104462, precision: 0.29902557856271017, recall: 0.8494809688579844, f1: 0.4423423423037879\n",
            "epoch: 440, step: 23, Train: label_loss: 0.1117287129163742, precision: 0.30458430458428093, recall: 0.7951318458416238, f1: 0.4404494381621465\n",
            "epoch: 441, step: 0, Train: label_loss: 0.10575884580612183, precision: 0.32192192192190255, recall: 0.8874172185428993, f1: 0.47245482587539084\n",
            "epoch: 441, step: 1, Train: label_loss: 0.11607629805803299, precision: 0.2981177899210505, recall: 0.8598949211907425, f1: 0.44274120825748914\n",
            "epoch: 441, step: 2, Train: label_loss: 0.11668726801872253, precision: 0.3159509202453794, recall: 0.8612040133777823, f1: 0.46229802509533596\n",
            "epoch: 441, step: 3, Train: label_loss: 0.11168982088565826, precision: 0.3062843197071198, recall: 0.8670120898098674, f1: 0.45266005406417426\n",
            "epoch: 441, step: 4, Train: label_loss: 0.10778646171092987, precision: 0.33538461538459474, recall: 0.8502340093602417, f1: 0.48102383049777964\n",
            "epoch: 441, step: 5, Train: label_loss: 0.10232815146446228, precision: 0.3191230207064361, recall: 0.8576104746316108, f1: 0.4651575676479569\n",
            "epoch: 441, step: 6, Train: label_loss: 0.11494725942611694, precision: 0.3161131611315919, recall: 0.8371335504884629, f1: 0.4589285713887359\n",
            "epoch: 441, step: 7, Train: label_loss: 0.10993675887584686, precision: 0.3128760529482363, recall: 0.8652246256238161, f1: 0.4595669464921035\n",
            "epoch: 441, step: 8, Train: label_loss: 0.10580979287624359, precision: 0.31951219512193174, recall: 0.8492706645055349, f1: 0.46433318560489195\n",
            "epoch: 441, step: 9, Train: label_loss: 0.10290862619876862, precision: 0.3112864077669714, recall: 0.8465346534652067, f1: 0.45519077192160345\n",
            "epoch: 441, step: 10, Train: label_loss: 0.10227148979902267, precision: 0.32159904534604283, recall: 0.886513157894591, f1: 0.4719789841990698\n",
            "epoch: 441, step: 11, Train: label_loss: 0.10236066579818726, precision: 0.3048259010384664, recall: 0.838655462184733, f1: 0.44713261644831237\n",
            "epoch: 441, step: 12, Train: label_loss: 0.10608026385307312, precision: 0.30146163215588906, recall: 0.8699472759225184, f1: 0.44776119399158604\n",
            "epoch: 441, step: 13, Train: label_loss: 0.11753622442483902, precision: 0.3086876155267832, recall: 0.8322259136211242, f1: 0.4503370786121733\n",
            "epoch: 441, step: 14, Train: label_loss: 0.11006201058626175, precision: 0.29807093963906045, recall: 0.8146258503399975, f1: 0.4364464692090276\n",
            "epoch: 441, step: 15, Train: label_loss: 0.10893090069293976, precision: 0.3074096754439493, recall: 0.8479729729728297, f1: 0.4512359550170841\n",
            "epoch: 441, step: 16, Train: label_loss: 0.10551127791404724, precision: 0.31690997566908047, recall: 0.8756302521006931, f1: 0.46538633314539096\n",
            "epoch: 441, step: 17, Train: label_loss: 0.10464603453874588, precision: 0.3044009779950914, recall: 0.8798586572436607, f1: 0.4523160762560428\n",
            "epoch: 441, step: 18, Train: label_loss: 0.10451149195432663, precision: 0.3150431565967747, recall: 0.8363338788869334, f1: 0.45768025074390745\n",
            "epoch: 441, step: 19, Train: label_loss: 0.11308896541595459, precision: 0.3224615384615186, recall: 0.8689883913763069, f1: 0.4703770197091319\n",
            "epoch: 441, step: 20, Train: label_loss: 0.12335939705371857, precision: 0.3238036047234106, recall: 0.819182389936978, f1: 0.46414253893485186\n",
            "epoch: 441, step: 21, Train: label_loss: 0.1105998307466507, precision: 0.30603448275860184, recall: 0.8438030560270213, f1: 0.44916403068841526\n",
            "epoch: 441, step: 22, Train: label_loss: 0.11772444099187851, precision: 0.32740649908029873, recall: 0.8668831168829761, f1: 0.47530040049420524\n",
            "epoch: 441, step: 23, Train: label_loss: 0.11772412061691284, precision: 0.318113772455066, recall: 0.838264299802596, f1: 0.4612045577462845\n",
            "epoch: 442, step: 0, Train: label_loss: 0.15004763007164001, precision: 0.2939682539682353, recall: 0.7820945945944624, f1: 0.4273188739796308\n",
            "epoch: 442, step: 1, Train: label_loss: 0.1489546298980713, precision: 0.3047858942065299, recall: 0.7960526315788163, f1: 0.4408014571548172\n",
            "epoch: 442, step: 2, Train: label_loss: 0.17686399817466736, precision: 0.30992268041235116, recall: 0.7872340425530626, f1: 0.4447526583043134\n",
            "epoch: 442, step: 3, Train: label_loss: 0.15550382435321808, precision: 0.3243749999999797, recall: 0.8173228346455406, f1: 0.4644295301606219\n",
            "epoch: 442, step: 4, Train: label_loss: 0.1417233794927597, precision: 0.313432835820876, recall: 0.8386023294507755, f1: 0.456315074654781\n",
            "epoch: 442, step: 5, Train: label_loss: 0.14202693104743958, precision: 0.33058898036730017, recall: 0.8233438485803117, f1: 0.47175779480769653\n",
            "epoch: 442, step: 6, Train: label_loss: 0.1547086089849472, precision: 0.29320024953210894, recall: 0.8289241622573493, f1: 0.4331797234636606\n",
            "epoch: 442, step: 7, Train: label_loss: 0.14362505078315735, precision: 0.31301587301585315, recall: 0.812191103788993, f1: 0.4518790100422921\n",
            "epoch: 442, step: 8, Train: label_loss: 0.1420765072107315, precision: 0.2955854126679273, recall: 0.7883959044367255, f1: 0.42996742667039206\n",
            "epoch: 442, step: 9, Train: label_loss: 0.15079012513160706, precision: 0.31718346253227925, recall: 0.8169717138101802, f1: 0.45695672401736814\n",
            "epoch: 442, step: 10, Train: label_loss: 0.15246303379535675, precision: 0.300632911392386, recall: 0.8050847457625754, f1: 0.43778801839354625\n",
            "epoch: 442, step: 11, Train: label_loss: 0.13827276229858398, precision: 0.3080273802115552, recall: 0.8208955223879235, f1: 0.44796380086525617\n",
            "epoch: 442, step: 12, Train: label_loss: 0.1295648217201233, precision: 0.3148379052368881, recall: 0.8444816053510293, f1: 0.4586739327487685\n",
            "epoch: 442, step: 13, Train: label_loss: 0.12995967268943787, precision: 0.29040404040402207, recall: 0.7972270363950091, f1: 0.42572882920653743\n",
            "epoch: 442, step: 14, Train: label_loss: 0.12598983943462372, precision: 0.3276073619631701, recall: 0.8711256117453717, f1: 0.4761480160101697\n",
            "epoch: 442, step: 15, Train: label_loss: 0.14204560220241547, precision: 0.3197747183979775, recall: 0.855946398659823, f1: 0.4656036446072808\n",
            "epoch: 442, step: 16, Train: label_loss: 0.12597694993019104, precision: 0.3246430788330028, recall: 0.844911147011172, f1: 0.46905829592397774\n",
            "epoch: 442, step: 17, Train: label_loss: 0.12565675377845764, precision: 0.32452366318375386, recall: 0.857142857142718, f1: 0.47079803830162303\n",
            "epoch: 442, step: 18, Train: label_loss: 0.1543685644865036, precision: 0.31218592964822156, recall: 0.8269550748750704, f1: 0.4532603738771776\n",
            "epoch: 442, step: 19, Train: label_loss: 0.13338807225227356, precision: 0.3253086419752885, recall: 0.866776315789331, f1: 0.4730700179135946\n",
            "epoch: 442, step: 20, Train: label_loss: 0.15470652282238007, precision: 0.29032258064514294, recall: 0.8240574506282182, f1: 0.4293732459857514\n",
            "epoch: 442, step: 21, Train: label_loss: 0.11747296154499054, precision: 0.3201238390092681, recall: 0.8447712418299272, f1: 0.46430175119494554\n",
            "epoch: 442, step: 22, Train: label_loss: 0.131865993142128, precision: 0.2984520123838824, recall: 0.8296041308088072, f1: 0.43897996353117275\n",
            "epoch: 442, step: 23, Train: label_loss: 0.12168935686349869, precision: 0.3155080213903502, recall: 0.8178217821780559, f1: 0.4553472987469826\n",
            "epoch: 443, step: 0, Train: label_loss: 0.13463722169399261, precision: 0.31529850746266697, recall: 0.817741935483739, f1: 0.45511669654866027\n",
            "epoch: 443, step: 1, Train: label_loss: 0.13361065089702606, precision: 0.3228395061728196, recall: 0.832802547770568, f1: 0.4653024910628979\n",
            "epoch: 443, step: 2, Train: label_loss: 0.1018931195139885, precision: 0.30224106602057527, recall: 0.8471986417655607, f1: 0.4455357142469134\n",
            "epoch: 443, step: 3, Train: label_loss: 0.1237422525882721, precision: 0.30370370370368494, recall: 0.866197183098439, f1: 0.4497257769267826\n",
            "epoch: 443, step: 4, Train: label_loss: 0.11975458264350891, precision: 0.30697961704754123, recall: 0.8510273972601282, f1: 0.45120290509036426\n",
            "epoch: 443, step: 5, Train: label_loss: 0.11373868584632874, precision: 0.31916204559455824, recall: 0.8422764227640906, f1: 0.46291331542033404\n",
            "epoch: 443, step: 6, Train: label_loss: 0.120459645986557, precision: 0.3158866995073697, recall: 0.8493377483442301, f1: 0.46050269295864277\n",
            "epoch: 443, step: 7, Train: label_loss: 0.10043763369321823, precision: 0.34141904184352084, recall: 0.8866141732282068, f1: 0.4929947460193564\n",
            "epoch: 443, step: 8, Train: label_loss: 0.1108807623386383, precision: 0.30666666666664805, recall: 0.8724137931032978, f1: 0.4538116591542958\n",
            "epoch: 443, step: 9, Train: label_loss: 0.12710435688495636, precision: 0.3496894409937671, recall: 0.8491704374056034, f1: 0.4953805542921154\n",
            "epoch: 443, step: 10, Train: label_loss: 0.13646098971366882, precision: 0.31435493640216144, recall: 0.8902229845624544, f1: 0.4646374216265603\n",
            "epoch: 443, step: 11, Train: label_loss: 0.11419927328824997, precision: 0.32406287787180627, recall: 0.881578947368276, f1: 0.47391688767064105\n",
            "epoch: 443, step: 12, Train: label_loss: 0.10831914842128754, precision: 0.3190591073582437, recall: 0.8846153846152366, f1: 0.46897163116667046\n",
            "epoch: 443, step: 13, Train: label_loss: 0.10659249126911163, precision: 0.29024390243900666, recall: 0.8831168831167192, f1: 0.4368976594395494\n",
            "epoch: 443, step: 14, Train: label_loss: 0.12313759326934814, precision: 0.3211233211233015, recall: 0.8694214876031621, f1: 0.46901471239926135\n",
            "epoch: 443, step: 15, Train: label_loss: 0.1251143515110016, precision: 0.3115671641790851, recall: 0.8186274509802584, f1: 0.45135135131137494\n",
            "epoch: 443, step: 16, Train: label_loss: 0.11743045598268509, precision: 0.32722832722830725, recall: 0.8374999999998691, f1: 0.4705882352536731\n",
            "epoch: 443, step: 17, Train: label_loss: 0.13223399221897125, precision: 0.30830769230767335, recall: 0.8462837837836408, f1: 0.4519621109215723\n",
            "epoch: 443, step: 18, Train: label_loss: 0.13260376453399658, precision: 0.30087939698490573, recall: 0.7865353037765539, f1: 0.4352567014592522\n",
            "epoch: 443, step: 19, Train: label_loss: 0.12921471893787384, precision: 0.32510795805056597, recall: 0.8541329011343833, f1: 0.47095621086261225\n",
            "epoch: 443, step: 20, Train: label_loss: 0.12230019271373749, precision: 0.3343539497856501, recall: 0.8778135048230099, f1: 0.48425720616843304\n",
            "epoch: 443, step: 21, Train: label_loss: 0.1263009011745453, precision: 0.3048484848484664, recall: 0.8809106830121048, f1: 0.45294912197886955\n",
            "epoch: 443, step: 22, Train: label_loss: 0.12679846584796906, precision: 0.29912390488108265, recall: 0.8284228769495964, f1: 0.439540229846035\n",
            "epoch: 443, step: 23, Train: label_loss: 0.12153147161006927, precision: 0.3025335320417062, recall: 0.8826086956519821, f1: 0.45061043281431457\n",
            "epoch: 444, step: 0, Train: label_loss: 0.11644407361745834, precision: 0.3036263060848, recall: 0.8274706867670305, f1: 0.4442446042772313\n",
            "epoch: 444, step: 1, Train: label_loss: 0.12120421230792999, precision: 0.2923547400611442, recall: 0.8342059336822278, f1: 0.43297101445428143\n",
            "epoch: 444, step: 2, Train: label_loss: 0.11336509883403778, precision: 0.32492307692305694, recall: 0.8613376835235136, f1: 0.4718498659119242\n",
            "epoch: 444, step: 3, Train: label_loss: 0.09925547242164612, precision: 0.3554616777308174, recall: 0.8924242424241071, f1: 0.5084160552030638\n",
            "epoch: 444, step: 4, Train: label_loss: 0.11645100265741348, precision: 0.29731379731377916, recall: 0.8499127399649475, f1: 0.4405246494414344\n",
            "epoch: 444, step: 5, Train: label_loss: 0.12759670615196228, precision: 0.28154133001862763, recall: 0.8236363636362138, f1: 0.41963872159237536\n",
            "epoch: 444, step: 6, Train: label_loss: 0.13299623131752014, precision: 0.2983114446528894, recall: 0.8281249999998561, f1: 0.4386206896161932\n",
            "epoch: 444, step: 7, Train: label_loss: 0.11770076304674149, precision: 0.3251684017146157, recall: 0.8719211822658666, f1: 0.4736842104867038\n",
            "epoch: 444, step: 8, Train: label_loss: 0.14542703330516815, precision: 0.29787234042551325, recall: 0.7959866220734454, f1: 0.43351548265613926\n",
            "epoch: 444, step: 9, Train: label_loss: 0.1700427532196045, precision: 0.2730844793712984, recall: 0.7459749552771473, f1: 0.39980824540655796\n",
            "epoch: 444, step: 10, Train: label_loss: 0.15938866138458252, precision: 0.2887189292542837, recall: 0.763912310286549, f1: 0.41905642919234326\n",
            "epoch: 444, step: 11, Train: label_loss: 0.19392886757850647, precision: 0.29389067524113865, recall: 0.7528830313013586, f1: 0.42275670671258064\n",
            "epoch: 444, step: 12, Train: label_loss: 0.19685260951519012, precision: 0.304005252790525, recall: 0.7419871794870605, f1: 0.43129948761592235\n",
            "epoch: 444, step: 13, Train: label_loss: 0.17829331755638123, precision: 0.29595827900910715, recall: 0.7346278317150914, f1: 0.4219330854608784\n",
            "epoch: 444, step: 14, Train: label_loss: 0.1871277093887329, precision: 0.31530343007913486, recall: 0.7587301587300382, f1: 0.4454799626798232\n",
            "epoch: 444, step: 15, Train: label_loss: 0.17187584936618805, precision: 0.3111254851228777, recall: 0.7659235668788589, f1: 0.4425022998668783\n",
            "epoch: 444, step: 16, Train: label_loss: 0.1759282350540161, precision: 0.31756318859362814, recall: 0.8085808580856751, f1: 0.4560260585913849\n",
            "epoch: 444, step: 17, Train: label_loss: 0.17516066133975983, precision: 0.3194263363754681, recall: 0.7877813504821884, f1: 0.454545454504359\n",
            "epoch: 444, step: 18, Train: label_loss: 0.18580582737922668, precision: 0.3011508951406457, recall: 0.7969543147206772, f1: 0.4371229697977394\n",
            "epoch: 444, step: 19, Train: label_loss: 0.17739582061767578, precision: 0.28979857050030605, recall: 0.7797202797201433, f1: 0.4225485551475668\n",
            "epoch: 444, step: 20, Train: label_loss: 0.19048812985420227, precision: 0.2945736434108337, recall: 0.7916666666665292, f1: 0.42937853103387696\n",
            "epoch: 444, step: 21, Train: label_loss: 0.1723051518201828, precision: 0.31109643328927933, recall: 0.7596774193547161, f1: 0.44142455478535053\n",
            "epoch: 444, step: 22, Train: label_loss: 0.18717393279075623, precision: 0.3298565840938507, recall: 0.7893915756629033, f1: 0.46528735628022483\n",
            "epoch: 444, step: 23, Train: label_loss: 0.17812243103981018, precision: 0.3044534412955219, recall: 0.7784679089025304, f1: 0.4377182770258851\n",
            "epoch: 445, step: 0, Train: label_loss: 0.19091147184371948, precision: 0.3035122597746651, recall: 0.7736486486485179, f1: 0.43598286526172036\n",
            "epoch: 445, step: 1, Train: label_loss: 0.17561715841293335, precision: 0.27837116154871305, recall: 0.7239583333332076, f1: 0.40212150429928323\n",
            "epoch: 445, step: 2, Train: label_loss: 0.16493242979049683, precision: 0.3287671232876498, recall: 0.7887323943660737, f1: 0.4640883977484833\n",
            "epoch: 445, step: 3, Train: label_loss: 0.1722468137741089, precision: 0.29361979166664753, recall: 0.7802768166088615, f1: 0.4266792809441445\n",
            "epoch: 445, step: 4, Train: label_loss: 0.1894974410533905, precision: 0.2900713822193193, recall: 0.7706896551722808, f1: 0.42149929274664616\n",
            "epoch: 445, step: 5, Train: label_loss: 0.15534913539886475, precision: 0.2970550576184189, recall: 0.7669421487602037, f1: 0.4282418089121809\n",
            "epoch: 445, step: 6, Train: label_loss: 0.17717750370502472, precision: 0.2945026178010278, recall: 0.7364975450080627, f1: 0.42075736321300694\n",
            "epoch: 445, step: 7, Train: label_loss: 0.1832612156867981, precision: 0.328947368421031, recall: 0.7530120481926577, f1: 0.4578754578330968\n",
            "epoch: 445, step: 8, Train: label_loss: 0.1709565371274948, precision: 0.2917205692108479, recall: 0.7857142857141488, f1: 0.4254716980736781\n",
            "epoch: 445, step: 9, Train: label_loss: 0.14228370785713196, precision: 0.2921419518377508, recall: 0.8017391304346431, f1: 0.4282396655437192\n",
            "epoch: 445, step: 10, Train: label_loss: 0.18250398337841034, precision: 0.30076142131977784, recall: 0.8116438356162993, f1: 0.43888888884939414\n",
            "epoch: 445, step: 11, Train: label_loss: 0.17574343085289001, precision: 0.31330749354003146, recall: 0.7835218093698249, f1: 0.4476234425064484\n",
            "epoch: 445, step: 12, Train: label_loss: 0.186153382062912, precision: 0.304147465437768, recall: 0.743961352656885, f1: 0.4317757008933434\n",
            "epoch: 445, step: 13, Train: label_loss: 0.16786891222000122, precision: 0.2790697674418424, recall: 0.7755834829442054, f1: 0.41045130637434446\n",
            "epoch: 445, step: 14, Train: label_loss: 0.18882498145103455, precision: 0.30375647668391814, recall: 0.7576736672050471, f1: 0.43365695788790654\n",
            "epoch: 445, step: 15, Train: label_loss: 0.15473303198814392, precision: 0.2809343434343257, recall: 0.7862190812719458, f1: 0.4139534883332641\n",
            "epoch: 445, step: 16, Train: label_loss: 0.1390620470046997, precision: 0.3314606741572827, recall: 0.8283931357252997, f1: 0.47347302715485606\n",
            "epoch: 445, step: 17, Train: label_loss: 0.14662355184555054, precision: 0.31414267834791526, recall: 0.8136142625606461, f1: 0.45327313765728355\n",
            "epoch: 445, step: 18, Train: label_loss: 0.16939514875411987, precision: 0.3006993006992816, recall: 0.8183391003458791, f1: 0.4397954439402023\n",
            "epoch: 445, step: 19, Train: label_loss: 0.18108832836151123, precision: 0.31161853593013356, recall: 0.7400318979265167, f1: 0.4385633269903923\n",
            "epoch: 445, step: 20, Train: label_loss: 0.20146289467811584, precision: 0.30272787757815683, recall: 0.7326892109499625, f1: 0.42843691144634044\n",
            "epoch: 445, step: 21, Train: label_loss: 0.215276300907135, precision: 0.2879684418145767, recall: 0.747440273037415, f1: 0.415757000434415\n",
            "epoch: 445, step: 22, Train: label_loss: 0.20997318625450134, precision: 0.28299319727889233, recall: 0.6956521739129271, f1: 0.40232108313099807\n",
            "epoch: 445, step: 23, Train: label_loss: 0.21952912211418152, precision: 0.28242320819110217, recall: 0.6741344195517975, f1: 0.3980757666450474\n",
            "epoch: 446, step: 0, Train: label_loss: 0.22508607804775238, precision: 0.26949860724232105, recall: 0.6886120996440055, f1: 0.38738738734691613\n",
            "epoch: 446, step: 1, Train: label_loss: 0.229587122797966, precision: 0.27605633802814955, recall: 0.6712328767122138, f1: 0.3912175648289218\n",
            "epoch: 446, step: 2, Train: label_loss: 0.22013136744499207, precision: 0.28659793814431017, recall: 0.6640127388533974, f1: 0.40038406140767485\n",
            "epoch: 446, step: 3, Train: label_loss: 0.24412678182125092, precision: 0.26468555632340945, recall: 0.6535836177473286, f1: 0.3767830791522414\n",
            "epoch: 446, step: 4, Train: label_loss: 0.24165791273117065, precision: 0.2883392226148206, recall: 0.626728110598982, f1: 0.394966118059413\n",
            "epoch: 446, step: 5, Train: label_loss: 0.23802229762077332, precision: 0.27191780821915945, recall: 0.6809605488849604, f1: 0.3886441507178638\n",
            "epoch: 446, step: 6, Train: label_loss: 0.23389780521392822, precision: 0.2770270270270083, recall: 0.703259005145677, f1: 0.39747939889300604\n",
            "epoch: 446, step: 7, Train: label_loss: 0.23731297254562378, precision: 0.29082321187582383, recall: 0.7171381031612782, f1: 0.4138262121528555\n",
            "epoch: 446, step: 8, Train: label_loss: 0.24128419160842896, precision: 0.2984148862852999, recall: 0.704065040650292, f1: 0.4191674733366555\n",
            "epoch: 446, step: 9, Train: label_loss: 0.22927188873291016, precision: 0.2807377049180136, recall: 0.6737704918031682, f1: 0.3963355833721326\n",
            "epoch: 446, step: 10, Train: label_loss: 0.2250727117061615, precision: 0.3125864453665067, recall: 0.7140600315954637, f1: 0.4348244347820391\n",
            "epoch: 446, step: 11, Train: label_loss: 0.22376668453216553, precision: 0.2712912087911902, recall: 0.7028469750888429, f1: 0.3914767095732529\n",
            "epoch: 446, step: 12, Train: label_loss: 0.23427005112171173, precision: 0.30434782608693584, recall: 0.7260940032413733, f1: 0.4289133556309053\n",
            "epoch: 446, step: 13, Train: label_loss: 0.22768408060073853, precision: 0.27617079889805257, recall: 0.6552287581698275, f1: 0.388565891431112\n",
            "epoch: 446, step: 14, Train: label_loss: 0.23087568581104279, precision: 0.255960729312745, recall: 0.6414762741650893, f1: 0.36591478692660856\n",
            "epoch: 446, step: 15, Train: label_loss: 0.24511361122131348, precision: 0.29424307036245245, recall: 0.6666666666665593, f1: 0.40828402362610944\n",
            "epoch: 446, step: 16, Train: label_loss: 0.219259575009346, precision: 0.29965156794423, recall: 0.6913183279741654, f1: 0.4180845891653538\n",
            "epoch: 446, step: 17, Train: label_loss: 0.22570985555648804, precision: 0.29781420765025285, recall: 0.731543624160951, f1: 0.42330097083262247\n",
            "epoch: 446, step: 18, Train: label_loss: 0.2171187698841095, precision: 0.277587388622325, recall: 0.7006920415223701, f1: 0.39764359347919587\n",
            "epoch: 446, step: 19, Train: label_loss: 0.20803900063037872, precision: 0.29681274900396437, recall: 0.7221324717284778, f1: 0.42070588231161327\n",
            "epoch: 446, step: 20, Train: label_loss: 0.2300429493188858, precision: 0.29499323410011535, recall: 0.7147540983605385, f1: 0.4176245210313976\n",
            "epoch: 446, step: 21, Train: label_loss: 0.2186260223388672, precision: 0.3037889039242014, recall: 0.7312703583060698, f1: 0.429254302061738\n",
            "epoch: 446, step: 22, Train: label_loss: 0.21392273902893066, precision: 0.2778147901398882, recall: 0.7140410958902886, f1: 0.39999999995963315\n",
            "epoch: 446, step: 23, Train: label_loss: 0.2157839983701706, precision: 0.2991735537189835, recall: 0.7557411273484852, f1: 0.428656009432376\n",
            "epoch: 447, step: 0, Train: label_loss: 0.2191419005393982, precision: 0.28504983388702426, recall: 0.7396551724136655, f1: 0.4115107913267081\n",
            "epoch: 447, step: 1, Train: label_loss: 0.2210865616798401, precision: 0.2815665091154435, recall: 0.6938435940098678, f1: 0.40057636883497477\n",
            "epoch: 447, step: 2, Train: label_loss: 0.20848417282104492, precision: 0.26697429136451767, recall: 0.7570093457942509, f1: 0.3947368420666755\n",
            "epoch: 447, step: 3, Train: label_loss: 0.21972544491291046, precision: 0.3021189336978604, recall: 0.6938775510202991, f1: 0.4209523809100764\n",
            "epoch: 447, step: 4, Train: label_loss: 0.20939314365386963, precision: 0.2822045152722256, recall: 0.7562277580069828, f1: 0.4110251450280772\n",
            "epoch: 447, step: 5, Train: label_loss: 0.21705228090286255, precision: 0.27859042553189634, recall: 0.7211703958690668, f1: 0.4019184651875777\n",
            "epoch: 447, step: 6, Train: label_loss: 0.22376298904418945, precision: 0.3014654570830215, recall: 0.6792452830187611, f1: 0.41759304007337705\n",
            "epoch: 447, step: 7, Train: label_loss: 0.21053504943847656, precision: 0.288147138964558, recall: 0.6866883116882002, f1: 0.4059500959276079\n",
            "epoch: 447, step: 8, Train: label_loss: 0.1888149231672287, precision: 0.2951365756162362, recall: 0.7042925278218276, f1: 0.41596244127289494\n",
            "epoch: 447, step: 9, Train: label_loss: 0.20673862099647522, precision: 0.2769230769230584, recall: 0.7101200686105128, f1: 0.39846005770742704\n",
            "epoch: 447, step: 10, Train: label_loss: 0.1981603503227234, precision: 0.2920759659462808, recall: 0.7420965058235037, f1: 0.41917293229025554\n",
            "epoch: 447, step: 11, Train: label_loss: 0.20004874467849731, precision: 0.29032258064514216, recall: 0.7147487844407269, f1: 0.4129213482734842\n",
            "epoch: 447, step: 12, Train: label_loss: 0.1964389681816101, precision: 0.2927631578947176, recall: 0.7466442953018881, f1: 0.4206049148933318\n",
            "epoch: 447, step: 13, Train: label_loss: 0.20837163925170898, precision: 0.2926343729263243, recall: 0.7386934673365596, f1: 0.41920152087186097\n",
            "epoch: 447, step: 14, Train: label_loss: 0.20933592319488525, precision: 0.28426738690072356, recall: 0.685667752442885, f1: 0.40190930783441986\n",
            "epoch: 447, step: 15, Train: label_loss: 0.2004515826702118, precision: 0.30548128342243946, recall: 0.7311999999998829, f1: 0.4309288071248221\n",
            "epoch: 447, step: 16, Train: label_loss: 0.205638125538826, precision: 0.29470198675494735, recall: 0.7593856655288805, f1: 0.42461832057036347\n",
            "epoch: 447, step: 17, Train: label_loss: 0.20867115259170532, precision: 0.30120481927708825, recall: 0.7389162561575141, f1: 0.42796005702015494\n",
            "epoch: 447, step: 18, Train: label_loss: 0.20782700181007385, precision: 0.29411764705880383, recall: 0.7521367521366235, f1: 0.4228736184122085\n",
            "epoch: 447, step: 19, Train: label_loss: 0.2113824039697647, precision: 0.3287401574802934, recall: 0.795238095237969, f1: 0.46518105845439145\n",
            "epoch: 447, step: 20, Train: label_loss: 0.17819926142692566, precision: 0.30723684210524294, recall: 0.7744610281922429, f1: 0.43994347617219326\n",
            "epoch: 447, step: 21, Train: label_loss: 0.19687607884407043, precision: 0.31791530944623336, recall: 0.772151898734055, f1: 0.4503922473052026\n",
            "epoch: 447, step: 22, Train: label_loss: 0.19918794929981232, precision: 0.3159609120520967, recall: 0.7847896440128179, f1: 0.4505341383705472\n",
            "epoch: 447, step: 23, Train: label_loss: 0.20784252882003784, precision: 0.2808163265305893, recall: 0.7713004484303203, f1: 0.41172950325225954\n",
            "epoch: 448, step: 0, Train: label_loss: 0.1819719672203064, precision: 0.31578947368419025, recall: 0.8132231404957333, f1: 0.45492371701930334\n",
            "epoch: 448, step: 1, Train: label_loss: 0.18984852731227875, precision: 0.31446945337618554, recall: 0.8122923588038518, f1: 0.45340751039087246\n",
            "epoch: 448, step: 2, Train: label_loss: 0.19290228188037872, precision: 0.30342156229823736, recall: 0.8103448275860671, f1: 0.44152184120033505\n",
            "epoch: 448, step: 3, Train: label_loss: 0.18959666788578033, precision: 0.29722759509991636, recall: 0.7760942760941454, f1: 0.4298368297967424\n",
            "epoch: 448, step: 4, Train: label_loss: 0.2042374610900879, precision: 0.2855254461334907, recall: 0.7409948542022742, f1: 0.41221374041781944\n",
            "epoch: 448, step: 5, Train: label_loss: 0.19108206033706665, precision: 0.2970737913485816, recall: 0.8010291595195881, f1: 0.433410672814319\n",
            "epoch: 448, step: 6, Train: label_loss: 0.18437610566616058, precision: 0.32772020725386475, recall: 0.8006329113922783, f1: 0.46507352937050495\n",
            "epoch: 448, step: 7, Train: label_loss: 0.16982296109199524, precision: 0.2939682539682353, recall: 0.7901023890783634, f1: 0.42850532157079846\n",
            "epoch: 448, step: 8, Train: label_loss: 0.1903184950351715, precision: 0.31745009658723006, recall: 0.8162251655627787, f1: 0.45711636528184274\n",
            "epoch: 448, step: 9, Train: label_loss: 0.1797454059123993, precision: 0.303984575835456, recall: 0.7949579831931436, f1: 0.43979544393948367\n",
            "epoch: 448, step: 10, Train: label_loss: 0.1963406503200531, precision: 0.3056282722512889, recall: 0.7568881685574137, f1: 0.43543123539021367\n",
            "epoch: 448, step: 11, Train: label_loss: 0.17583614587783813, precision: 0.278815196394058, recall: 0.7677304964537646, f1: 0.4090694378446716\n",
            "epoch: 448, step: 12, Train: label_loss: 0.17079825699329376, precision: 0.31437699680509174, recall: 0.807881773398882, f1: 0.452621895083822\n",
            "epoch: 448, step: 13, Train: label_loss: 0.17131564021110535, precision: 0.29310344827584334, recall: 0.8123893805308297, f1: 0.4307836695996593\n",
            "epoch: 448, step: 14, Train: label_loss: 0.17988356947898865, precision: 0.31981981981979923, recall: 0.7914012738852242, f1: 0.4555453711780283\n",
            "epoch: 448, step: 15, Train: label_loss: 0.17881768941879272, precision: 0.3006993006992816, recall: 0.8071672354947428, f1: 0.43816581746851463\n",
            "epoch: 448, step: 16, Train: label_loss: 0.17804577946662903, precision: 0.3065976714100707, recall: 0.7694805194803945, f1: 0.43848288617567743\n",
            "epoch: 448, step: 17, Train: label_loss: 0.1612052023410797, precision: 0.3017077798861289, recall: 0.8016806722687728, f1: 0.43841911760728464\n",
            "epoch: 448, step: 18, Train: label_loss: 0.18006892502307892, precision: 0.2970491803278494, recall: 0.7626262626261342, f1: 0.4275601698510696\n",
            "epoch: 448, step: 19, Train: label_loss: 0.16293513774871826, precision: 0.29755784061694746, recall: 0.7928082191779464, f1: 0.43271028033410647\n",
            "epoch: 448, step: 20, Train: label_loss: 0.17073120176792145, precision: 0.32906530089626573, recall: 0.784732824427361, f1: 0.4636896706845333\n",
            "epoch: 448, step: 21, Train: label_loss: 0.15904885530471802, precision: 0.31360201511333036, recall: 0.8177339901476489, f1: 0.45334547105683737\n",
            "epoch: 448, step: 22, Train: label_loss: 0.17843960225582123, precision: 0.2957928802588805, recall: 0.7745762711863093, f1: 0.42810304445645114\n",
            "epoch: 448, step: 23, Train: label_loss: 0.15296456217765808, precision: 0.3428351309706978, recall: 0.8195211786370498, f1: 0.4834329168513496\n",
            "epoch: 449, step: 0, Train: label_loss: 0.157069593667984, precision: 0.2995509942270494, recall: 0.7835570469797343, f1: 0.43341067281377255\n",
            "epoch: 449, step: 1, Train: label_loss: 0.1691066324710846, precision: 0.3094629156010032, recall: 0.7844408427875551, f1: 0.44383310404008286\n",
            "epoch: 449, step: 2, Train: label_loss: 0.16604769229888916, precision: 0.2948636651870453, recall: 0.7921635434410915, f1: 0.4297597042118112\n",
            "epoch: 449, step: 3, Train: label_loss: 0.1646757870912552, precision: 0.3100824350031509, recall: 0.7964169381106194, f1: 0.4463715198135663\n",
            "epoch: 449, step: 4, Train: label_loss: 0.16169196367263794, precision: 0.33715012722644166, recall: 0.8294209702659109, f1: 0.47942107639486176\n",
            "epoch: 449, step: 5, Train: label_loss: 0.1884273886680603, precision: 0.29487179487177595, recall: 0.8056042031522231, f1: 0.43172219611277024\n",
            "epoch: 449, step: 6, Train: label_loss: 0.15163123607635498, precision: 0.327215189873397, recall: 0.8447712418299272, f1: 0.47171532842686104\n",
            "epoch: 449, step: 7, Train: label_loss: 0.1736573576927185, precision: 0.2998737373737184, recall: 0.8246527777776346, f1: 0.4398148147756629\n",
            "epoch: 449, step: 8, Train: label_loss: 0.16037727892398834, precision: 0.34313099041531353, recall: 0.8124054462933717, f1: 0.48247978432477967\n",
            "epoch: 449, step: 9, Train: label_loss: 0.1697758138179779, precision: 0.34272901985904275, recall: 0.8478605388271239, f1: 0.4881386860903426\n",
            "epoch: 449, step: 10, Train: label_loss: 0.18744784593582153, precision: 0.29442282749673837, recall: 0.7668918918917623, f1: 0.42549203369932553\n",
            "epoch: 449, step: 11, Train: label_loss: 0.18434956669807434, precision: 0.28708439897696375, recall: 0.7701543739278267, f1: 0.41825803442709736\n",
            "epoch: 449, step: 12, Train: label_loss: 0.1764196753501892, precision: 0.29615384615382717, recall: 0.7843803056025832, f1: 0.42996742667026555\n",
            "epoch: 449, step: 13, Train: label_loss: 0.16371893882751465, precision: 0.31409062693976947, recall: 0.8349834983496971, f1: 0.4564727108307794\n",
            "epoch: 449, step: 14, Train: label_loss: 0.1830449402332306, precision: 0.30183893468609374, recall: 0.8067796610168123, f1: 0.4393170281098475\n",
            "epoch: 449, step: 15, Train: label_loss: 0.1777517944574356, precision: 0.30817610062891143, recall: 0.8448275862067508, f1: 0.4516129031865965\n",
            "epoch: 449, step: 16, Train: label_loss: 0.1746419221162796, precision: 0.3074003795066219, recall: 0.825127334465055, f1: 0.44792626724151363\n",
            "epoch: 449, step: 17, Train: label_loss: 0.18958121538162231, precision: 0.30822347771498376, recall: 0.8022875816992152, f1: 0.44535147388275875\n",
            "epoch: 449, step: 18, Train: label_loss: 0.1718822568655014, precision: 0.29615626969122266, recall: 0.8103448275860671, f1: 0.4337794185117493\n",
            "epoch: 449, step: 19, Train: label_loss: 0.17957505583763123, precision: 0.310802274162962, recall: 0.8338983050846044, f1: 0.45283018863964475\n",
            "epoch: 449, step: 20, Train: label_loss: 0.1715332269668579, precision: 0.2912873862158458, recall: 0.7593220338981763, f1: 0.4210526315388308\n",
            "epoch: 449, step: 21, Train: label_loss: 0.18053756654262543, precision: 0.2947438456420296, recall: 0.7383333333332103, f1: 0.42130290057734304\n",
            "epoch: 449, step: 22, Train: label_loss: 0.17747172713279724, precision: 0.3194805194804987, recall: 0.7711598746080296, f1: 0.45179063356734955\n",
            "epoch: 449, step: 23, Train: label_loss: 0.1749812811613083, precision: 0.3006993006992773, recall: 0.8130252100838629, f1: 0.4390243902044331\n",
            "epoch: 450, step: 0, Train: label_loss: 0.16372016072273254, precision: 0.32194813409232625, recall: 0.8344262295080599, f1: 0.46462802369323286\n",
            "epoch: 450, step: 1, Train: label_loss: 0.17664791643619537, precision: 0.32484076433118947, recall: 0.8159999999998694, f1: 0.4646924828749427\n",
            "epoch: 450, step: 2, Train: label_loss: 0.1563497930765152, precision: 0.3145161290322385, recall: 0.8435940099832206, f1: 0.45820153633635424\n",
            "epoch: 450, step: 3, Train: label_loss: 0.16432544589042664, precision: 0.30618686868684936, recall: 0.8192567567566184, f1: 0.4457720587838799\n",
            "epoch: 450, step: 4, Train: label_loss: 0.17307916283607483, precision: 0.3102143757881267, recall: 0.8526863084920532, f1: 0.45492371702047757\n",
            "epoch: 450, step: 5, Train: label_loss: 0.16477108001708984, precision: 0.2861675126903372, recall: 0.7722602739724704, f1: 0.41759259255309994\n",
            "epoch: 450, step: 6, Train: label_loss: 0.16246101260185242, precision: 0.324528301886772, recall: 0.8138801261828369, f1: 0.46402877693761424\n",
            "epoch: 450, step: 7, Train: label_loss: 0.1471579670906067, precision: 0.3226817042606314, recall: 0.8401305057094877, f1: 0.4662743322369074\n",
            "epoch: 450, step: 8, Train: label_loss: 0.16494429111480713, precision: 0.29784537389098237, recall: 0.8131487889271949, f1: 0.4359925788104378\n",
            "epoch: 450, step: 9, Train: label_loss: 0.14687854051589966, precision: 0.3145510835913118, recall: 0.8537815126048984, f1: 0.45972850674793964\n",
            "epoch: 450, step: 10, Train: label_loss: 0.15695220232009888, precision: 0.32405689548544686, recall: 0.8562091503266575, f1: 0.47016599367927875\n",
            "epoch: 450, step: 11, Train: label_loss: 0.165285125374794, precision: 0.2980342422320673, recall: 0.821678321678178, f1: 0.4374127500772277\n",
            "epoch: 450, step: 12, Train: label_loss: 0.16412970423698425, precision: 0.3266583229036091, recall: 0.8515497553016554, f1: 0.4721845318459051\n",
            "epoch: 450, step: 13, Train: label_loss: 0.1660623848438263, precision: 0.317662007623868, recall: 0.8237232289949219, f1: 0.45850527277042424\n",
            "epoch: 450, step: 14, Train: label_loss: 0.17559009790420532, precision: 0.33247422680410227, recall: 0.8125984251967223, f1: 0.4718792866528488\n",
            "epoch: 450, step: 15, Train: label_loss: 0.1450575292110443, precision: 0.2954966070326776, recall: 0.8447971781303624, f1: 0.43784277875498123\n",
            "epoch: 450, step: 16, Train: label_loss: 0.16074198484420776, precision: 0.31383647798740166, recall: 0.8400673400671986, f1: 0.456959706920064\n",
            "epoch: 450, step: 17, Train: label_loss: 0.17152416706085205, precision: 0.32091868404715573, recall: 0.8503289473682811, f1: 0.4659756646740084\n",
            "epoch: 450, step: 18, Train: label_loss: 0.15176188945770264, precision: 0.31025957972804014, recall: 0.8338870431892302, f1: 0.452252252212684\n",
            "epoch: 450, step: 19, Train: label_loss: 0.1578998565673828, precision: 0.321072319201975, recall: 0.8346839546189895, f1: 0.46375506524573984\n",
            "epoch: 450, step: 20, Train: label_loss: 0.1470699906349182, precision: 0.2952144188937045, recall: 0.831873905428926, f1: 0.4357798164750572\n",
            "epoch: 450, step: 21, Train: label_loss: 0.16024214029312134, precision: 0.3222985633978562, recall: 0.8255999999998679, f1: 0.4636118597978454\n",
            "epoch: 450, step: 22, Train: label_loss: 0.16632583737373352, precision: 0.29578351164252387, recall: 0.7979626485567405, f1: 0.43158861336729587\n",
            "epoch: 450, step: 23, Train: label_loss: 0.14349907636642456, precision: 0.31515151515149126, recall: 0.8353413654616797, f1: 0.45764576453662903\n",
            "epoch: 451, step: 0, Train: label_loss: 0.1530834436416626, precision: 0.2996845425867319, recall: 0.8203799654575439, f1: 0.4390018483896006\n",
            "epoch: 451, step: 1, Train: label_loss: 0.13499313592910767, precision: 0.323238566131006, recall: 0.868770764119457, f1: 0.47117117113160123\n",
            "epoch: 451, step: 2, Train: label_loss: 0.16177847981452942, precision: 0.30654205607474727, recall: 0.8424657534245132, f1: 0.4495203288781503\n",
            "epoch: 451, step: 3, Train: label_loss: 0.13932597637176514, precision: 0.3203703703703506, recall: 0.8452768729640316, f1: 0.46463742162527205\n",
            "epoch: 451, step: 4, Train: label_loss: 0.15046721696853638, precision: 0.325639426076087, recall: 0.8220472440943587, f1: 0.4664879356161489\n",
            "epoch: 451, step: 5, Train: label_loss: 0.15513040125370026, precision: 0.32546583850929656, recall: 0.859016393442482, f1: 0.4720720720321747\n",
            "epoch: 451, step: 6, Train: label_loss: 0.1646929383277893, precision: 0.30100125156443674, recall: 0.8423817863396073, f1: 0.44352236049597743\n",
            "epoch: 451, step: 7, Train: label_loss: 0.14955273270606995, precision: 0.3015576323987351, recall: 0.8461538461536982, f1: 0.44464859895065195\n",
            "epoch: 451, step: 8, Train: label_loss: 0.14280328154563904, precision: 0.34128440366970386, recall: 0.8787401574801765, f1: 0.49162995590679653\n",
            "epoch: 451, step: 9, Train: label_loss: 0.1580836921930313, precision: 0.3162819713037856, recall: 0.8190630048463943, f1: 0.45634563452322074\n",
            "epoch: 451, step: 10, Train: label_loss: 0.1397666335105896, precision: 0.3065015479875971, recall: 0.8389830508473154, f1: 0.44897959179749836\n",
            "epoch: 451, step: 11, Train: label_loss: 0.13241010904312134, precision: 0.3267326732673065, recall: 0.8543689320386967, f1: 0.4726947179545647\n",
            "epoch: 451, step: 12, Train: label_loss: 0.13956311345100403, precision: 0.32880937692780204, recall: 0.8709150326795962, f1: 0.47738468424140207\n",
            "epoch: 451, step: 13, Train: label_loss: 0.1374480277299881, precision: 0.31690997566908047, recall: 0.8726968174202893, f1: 0.46497099505234946\n",
            "epoch: 451, step: 14, Train: label_loss: 0.15599431097507477, precision: 0.3261138613861184, recall: 0.8431999999998651, f1: 0.4703257473939168\n",
            "epoch: 451, step: 15, Train: label_loss: 0.14826589822769165, precision: 0.2988721804511091, recall: 0.8195876288658385, f1: 0.4380165288864171\n",
            "epoch: 451, step: 16, Train: label_loss: 0.14833757281303406, precision: 0.2980891719745033, recall: 0.8055077452666427, f1: 0.43514644347517406\n",
            "epoch: 451, step: 17, Train: label_loss: 0.12637871503829956, precision: 0.3219927095990084, recall: 0.8660130718952833, f1: 0.46944198401713055\n",
            "epoch: 451, step: 18, Train: label_loss: 0.1472461223602295, precision: 0.3109869646182302, recall: 0.8322259136211242, f1: 0.4527790329472488\n",
            "epoch: 451, step: 19, Train: label_loss: 0.1537708342075348, precision: 0.2968650031989573, recall: 0.7682119205296741, f1: 0.4282418089122217\n",
            "epoch: 451, step: 20, Train: label_loss: 0.1524960696697235, precision: 0.31692307692305743, recall: 0.8655462184872494, f1: 0.46396396392468525\n",
            "epoch: 451, step: 21, Train: label_loss: 0.14961758255958557, precision: 0.30111524163566905, recall: 0.8556338028167507, f1: 0.4454628780549414\n",
            "epoch: 451, step: 22, Train: label_loss: 0.14275848865509033, precision: 0.3269111249222917, recall: 0.8443017656499446, f1: 0.4713261648342672\n",
            "epoch: 451, step: 23, Train: label_loss: 0.1531207412481308, precision: 0.3135011441647358, recall: 0.8404907975458404, f1: 0.4566666666270432\n",
            "epoch: 452, step: 0, Train: label_loss: 0.12785574793815613, precision: 0.30727272727270866, recall: 0.8756476683936311, f1: 0.45491251678519024\n",
            "epoch: 452, step: 1, Train: label_loss: 0.1412201225757599, precision: 0.3113325031133056, recall: 0.8576329331044841, f1: 0.45682960251912413\n",
            "epoch: 452, step: 2, Train: label_loss: 0.138186976313591, precision: 0.33474576271184414, recall: 0.8904991948468775, f1: 0.48658161016701934\n",
            "epoch: 452, step: 3, Train: label_loss: 0.143633171916008, precision: 0.2940446650123887, recall: 0.8479427549193473, f1: 0.43666513123763223\n",
            "epoch: 452, step: 4, Train: label_loss: 0.1436149924993515, precision: 0.32740649908029873, recall: 0.8543999999998633, f1: 0.4734042552790492\n",
            "epoch: 452, step: 5, Train: label_loss: 0.1447911560535431, precision: 0.33085501858734007, recall: 0.8640776699027728, f1: 0.47849462361582745\n",
            "epoch: 452, step: 6, Train: label_loss: 0.14636673033237457, precision: 0.3086956521738939, recall: 0.8214876033056493, f1: 0.4487584649715395\n",
            "epoch: 452, step: 7, Train: label_loss: 0.1441195160150528, precision: 0.30198019801978326, recall: 0.8187919463085874, f1: 0.4412296563801215\n",
            "epoch: 452, step: 8, Train: label_loss: 0.14276188611984253, precision: 0.33478531425013475, recall: 0.8539682539681184, f1: 0.4810013410413004\n",
            "epoch: 452, step: 9, Train: label_loss: 0.13596764206886292, precision: 0.31303288672348883, recall: 0.8667790893759078, f1: 0.4599552572316669\n",
            "epoch: 452, step: 10, Train: label_loss: 0.14235341548919678, precision: 0.3095673369896216, recall: 0.8466666666665255, f1: 0.4533690316430334\n",
            "epoch: 452, step: 11, Train: label_loss: 0.14442887902259827, precision: 0.33058898036730017, recall: 0.813084112149406, f1: 0.47005853215156285\n",
            "epoch: 452, step: 12, Train: label_loss: 0.13844874501228333, precision: 0.32114564290065073, recall: 0.8682042833606477, f1: 0.4688612099249495\n",
            "epoch: 452, step: 13, Train: label_loss: 0.1384858787059784, precision: 0.3117610454262407, recall: 0.8448566610453887, f1: 0.4554545454151259\n",
            "epoch: 452, step: 14, Train: label_loss: 0.1318567991256714, precision: 0.3221183800622852, recall: 0.843393148450107, f1: 0.4661857528905276\n",
            "epoch: 452, step: 15, Train: label_loss: 0.15242032706737518, precision: 0.2992565055761896, recall: 0.8503521126759066, f1: 0.4427131072025128\n",
            "epoch: 452, step: 16, Train: label_loss: 0.12524883449077606, precision: 0.32620647525960134, recall: 0.8811881188117358, f1: 0.47614801601045464\n",
            "epoch: 452, step: 17, Train: label_loss: 0.147220641374588, precision: 0.2951732673267144, recall: 0.8324607329841478, f1: 0.43581544080187795\n",
            "epoch: 452, step: 18, Train: label_loss: 0.11301529407501221, precision: 0.3395098625223945, recall: 0.8930817610061488, f1: 0.49198787349837075\n",
            "epoch: 452, step: 19, Train: label_loss: 0.14803385734558105, precision: 0.31965707287199513, recall: 0.8787878787877308, f1: 0.4687920969523095\n",
            "epoch: 452, step: 20, Train: label_loss: 0.14951542019844055, precision: 0.3168130489334807, recall: 0.8278688524588806, f1: 0.4582577132085635\n",
            "epoch: 452, step: 21, Train: label_loss: 0.1398930847644806, precision: 0.3028213166144011, recall: 0.8256410256408845, f1: 0.44311926601573776\n",
            "epoch: 452, step: 22, Train: label_loss: 0.12567166984081268, precision: 0.3188228080931748, recall: 0.8387096774192195, f1: 0.46201688134609564\n",
            "epoch: 452, step: 23, Train: label_loss: 0.1281057894229889, precision: 0.28386605783863894, recall: 0.8056155507557655, f1: 0.4198086662529224\n",
            "epoch: 453, step: 0, Train: label_loss: 0.12071438878774643, precision: 0.3453105968331093, recall: 0.8818040435457415, f1: 0.49628008748686603\n",
            "epoch: 453, step: 1, Train: label_loss: 0.13151675462722778, precision: 0.326678765880198, recall: 0.8653846153844766, f1: 0.4743083003554264\n",
            "epoch: 453, step: 2, Train: label_loss: 0.12619200348854065, precision: 0.33150183150181123, recall: 0.8687999999998609, f1: 0.47989394604923846\n",
            "epoch: 453, step: 3, Train: label_loss: 0.12876316905021667, precision: 0.30516717325226106, recall: 0.8422818791944895, f1: 0.44801427930049614\n",
            "epoch: 453, step: 4, Train: label_loss: 0.1361205130815506, precision: 0.31607795371496245, recall: 0.8781725888323386, f1: 0.46484549928929264\n",
            "epoch: 453, step: 5, Train: label_loss: 0.12790924310684204, precision: 0.31507692307690366, recall: 0.8434925864908001, f1: 0.45878136196752833\n",
            "epoch: 453, step: 6, Train: label_loss: 0.1136605367064476, precision: 0.3123486682808528, recall: 0.8730964467003598, f1: 0.46009808288580123\n",
            "epoch: 453, step: 7, Train: label_loss: 0.12030300498008728, precision: 0.325257419745589, recall: 0.8788870703762882, f1: 0.47480106096848507\n",
            "epoch: 453, step: 8, Train: label_loss: 0.12441856414079666, precision: 0.3286670724284645, recall: 0.8823529411763263, f1: 0.4789356984083029\n",
            "epoch: 453, step: 9, Train: label_loss: 0.12156431376934052, precision: 0.3102189781021709, recall: 0.8808290155438893, f1: 0.45883940616926194\n",
            "epoch: 453, step: 10, Train: label_loss: 0.1384095847606659, precision: 0.3255384615384415, recall: 0.8831385642736421, f1: 0.47571942442103016\n",
            "epoch: 453, step: 11, Train: label_loss: 0.1246650218963623, precision: 0.34083992696285204, recall: 0.9003215434082154, f1: 0.49448123616320666\n",
            "epoch: 453, step: 12, Train: label_loss: 0.11993181705474854, precision: 0.30392749244711154, recall: 0.8871252204583973, f1: 0.4527452744893997\n",
            "epoch: 453, step: 13, Train: label_loss: 0.13874360918998718, precision: 0.3223844282238247, recall: 0.892255892255742, f1: 0.4736371760110083\n",
            "epoch: 453, step: 14, Train: label_loss: 0.1532570719718933, precision: 0.32351097178681354, recall: 0.8614357262102067, f1: 0.4703737465418475\n",
            "epoch: 453, step: 15, Train: label_loss: 0.13054263591766357, precision: 0.3187772925763993, recall: 0.8390804597699771, f1: 0.46202531641575095\n",
            "epoch: 453, step: 16, Train: label_loss: 0.13577164709568024, precision: 0.29962779156325686, recall: 0.8687050359710667, f1: 0.4455719556813787\n",
            "epoch: 453, step: 17, Train: label_loss: 0.11987315863370895, precision: 0.3246200607902538, recall: 0.8929765886286132, f1: 0.47614801601078505\n",
            "epoch: 453, step: 18, Train: label_loss: 0.12758256494998932, precision: 0.30862697448357784, recall: 0.8668941979520705, f1: 0.45519713257772365\n",
            "epoch: 453, step: 19, Train: label_loss: 0.12167154252529144, precision: 0.31272949816399553, recall: 0.8488372093021845, f1: 0.45706618958493916\n",
            "epoch: 453, step: 20, Train: label_loss: 0.1377275586128235, precision: 0.3144078144077952, recall: 0.8498349834982095, f1: 0.45900178249172846\n",
            "epoch: 453, step: 21, Train: label_loss: 0.13336877524852753, precision: 0.30323367907258675, recall: 0.8628472222220723, f1: 0.4487584649727618\n",
            "epoch: 453, step: 22, Train: label_loss: 0.1278006136417389, precision: 0.3201701093559951, recall: 0.8583061889249416, f1: 0.46637168137631374\n",
            "epoch: 453, step: 23, Train: label_loss: 0.12042534351348877, precision: 0.3348214285714036, recall: 0.8789062499998282, f1: 0.4849137930634435\n",
            "epoch: 454, step: 0, Train: label_loss: 0.1215471550822258, precision: 0.32107843137252934, recall: 0.8618421052630161, f1: 0.46785714281755\n",
            "epoch: 454, step: 1, Train: label_loss: 0.11402781307697296, precision: 0.3317161916312716, recall: 0.8865478119933733, f1: 0.48278905556491775\n",
            "epoch: 454, step: 2, Train: label_loss: 0.11664585024118423, precision: 0.3013530135301168, recall: 0.8611599297010788, f1: 0.44646924825312556\n",
            "epoch: 454, step: 3, Train: label_loss: 0.13311640918254852, precision: 0.3277982779827597, recall: 0.8680781758956241, f1: 0.4758928571030202\n",
            "epoch: 454, step: 4, Train: label_loss: 0.11526210606098175, precision: 0.3199513381994939, recall: 0.8538961038959653, f1: 0.46548672562402077\n",
            "epoch: 454, step: 5, Train: label_loss: 0.12057659029960632, precision: 0.323349633251814, recall: 0.8330708661416011, f1: 0.46587406424853267\n",
            "epoch: 454, step: 6, Train: label_loss: 0.10168357193470001, precision: 0.3206197854588605, recall: 0.9026845637582377, f1: 0.4731750219489652\n",
            "epoch: 454, step: 7, Train: label_loss: 0.13479986786842346, precision: 0.3154981549815304, recall: 0.8521594684383966, f1: 0.4605026929587252\n",
            "epoch: 454, step: 8, Train: label_loss: 0.15014486014842987, precision: 0.30445859872609526, recall: 0.7785016286643682, f1: 0.437728937688478\n",
            "epoch: 454, step: 9, Train: label_loss: 0.12443673610687256, precision: 0.31211372064274956, recall: 0.8487394957981766, f1: 0.4563940352069154\n",
            "epoch: 454, step: 10, Train: label_loss: 0.13171547651290894, precision: 0.32367758186395945, recall: 0.8223999999998683, f1: 0.464527790289295\n",
            "epoch: 454, step: 11, Train: label_loss: 0.13635896146297455, precision: 0.3214069132807567, recall: 0.8674304418983849, f1: 0.46902654863307225\n",
            "epoch: 454, step: 12, Train: label_loss: 0.12236625701189041, precision: 0.31215970961885586, recall: 0.8896551724136397, f1: 0.4621585310855519\n",
            "epoch: 454, step: 13, Train: label_loss: 0.11520183086395264, precision: 0.3074572127139176, recall: 0.8425460636514501, f1: 0.4505150021999247\n",
            "epoch: 454, step: 14, Train: label_loss: 0.12250345945358276, precision: 0.3400488400488193, recall: 0.8998384491113247, f1: 0.4935755427160188\n",
            "epoch: 454, step: 15, Train: label_loss: 0.11676657199859619, precision: 0.3106796116504666, recall: 0.872231686541589, f1: 0.458165548059661\n",
            "epoch: 454, step: 16, Train: label_loss: 0.13175779581069946, precision: 0.3188667872211984, recall: 0.89358108108093, f1: 0.4700133273712325\n",
            "epoch: 454, step: 17, Train: label_loss: 0.1169034093618393, precision: 0.3105360443622729, recall: 0.8499156829678162, f1: 0.4548736461701472\n",
            "epoch: 454, step: 18, Train: label_loss: 0.14023813605308533, precision: 0.32926829268290675, recall: 0.8723747980612483, f1: 0.4780876493625619\n",
            "epoch: 454, step: 19, Train: label_loss: 0.12181507796049118, precision: 0.3090024330900055, recall: 0.8834782608694115, f1: 0.4578639026204181\n",
            "epoch: 454, step: 20, Train: label_loss: 0.12548008561134338, precision: 0.30458383594690563, recall: 0.8752166377814774, f1: 0.4519015659571821\n",
            "epoch: 454, step: 21, Train: label_loss: 0.13368213176727295, precision: 0.3182651191203226, recall: 0.8625827814568108, f1: 0.4649709950520595\n",
            "epoch: 454, step: 22, Train: label_loss: 0.13523051142692566, precision: 0.30730793254214195, recall: 0.8159203980098149, f1: 0.4464609799965091\n",
            "epoch: 454, step: 23, Train: label_loss: 0.12450961768627167, precision: 0.31008902077149036, recall: 0.88747346072168, f1: 0.45959318302919167\n",
            "epoch: 455, step: 0, Train: label_loss: 0.1258111447095871, precision: 0.3141975308641781, recall: 0.8511705685617305, f1: 0.45897204684966353\n",
            "epoch: 455, step: 1, Train: label_loss: 0.13095712661743164, precision: 0.3059839605181798, recall: 0.8406779661015523, f1: 0.4486657620594294\n",
            "epoch: 455, step: 2, Train: label_loss: 0.11104646325111389, precision: 0.31249999999998085, recall: 0.8557046979864336, f1: 0.4578096947543065\n",
            "epoch: 455, step: 3, Train: label_loss: 0.1214393824338913, precision: 0.32788868723530984, recall: 0.891447368420906, f1: 0.4794338787753221\n",
            "epoch: 455, step: 4, Train: label_loss: 0.12093564867973328, precision: 0.32541133455208254, recall: 0.878289473684066, f1: 0.47487772339314305\n",
            "epoch: 455, step: 5, Train: label_loss: 0.12491463869810104, precision: 0.31169626454376537, recall: 0.8540268456374406, f1: 0.45670704347805335\n",
            "epoch: 455, step: 6, Train: label_loss: 0.11908631026744843, precision: 0.3102610807528652, recall: 0.8795180722890051, f1: 0.45870736082316416\n",
            "epoch: 455, step: 7, Train: label_loss: 0.12406466901302338, precision: 0.3182374541003477, recall: 0.8595041322312629, f1: 0.46449307722715616\n",
            "epoch: 455, step: 8, Train: label_loss: 0.12079018354415894, precision: 0.3166564978645322, recall: 0.8606965174127925, f1: 0.462979482565452\n",
            "epoch: 455, step: 9, Train: label_loss: 0.11065289378166199, precision: 0.32029339853298777, recall: 0.8762541806018601, f1: 0.46911369736451247\n",
            "epoch: 455, step: 10, Train: label_loss: 0.12110965698957443, precision: 0.31089351285187816, recall: 0.8410596026488674, f1: 0.45397676492927214\n",
            "epoch: 455, step: 11, Train: label_loss: 0.12029610574245453, precision: 0.328440366972457, recall: 0.8760195758563007, f1: 0.4777580070777295\n",
            "epoch: 455, step: 12, Train: label_loss: 0.11029201745986938, precision: 0.33071816535906273, recall: 0.8838709677417929, f1: 0.48133508999107044\n",
            "epoch: 455, step: 13, Train: label_loss: 0.14334404468536377, precision: 0.296296296296278, recall: 0.8586762075132631, f1: 0.440569068341805\n",
            "epoch: 455, step: 14, Train: label_loss: 0.10962217301130295, precision: 0.3230861965038985, recall: 0.8830313014825563, f1: 0.4730803177012467\n",
            "epoch: 455, step: 15, Train: label_loss: 0.12985295057296753, precision: 0.32490752157827835, recall: 0.8555194805193416, f1: 0.4709562108626524\n",
            "epoch: 455, step: 16, Train: label_loss: 0.11687692254781723, precision: 0.3385636692818142, recall: 0.9121951219510711, f1: 0.4938380281294875\n",
            "epoch: 455, step: 17, Train: label_loss: 0.13756409287452698, precision: 0.31849103277672736, recall: 0.8554817275746086, f1: 0.4641730508842591\n",
            "epoch: 455, step: 18, Train: label_loss: 0.1237654983997345, precision: 0.30905752753976073, recall: 0.8544839255497707, f1: 0.453932584230609\n",
            "epoch: 455, step: 19, Train: label_loss: 0.11691337823867798, precision: 0.32510795805056597, recall: 0.8405103668260222, f1: 0.4688612099241468\n",
            "epoch: 455, step: 20, Train: label_loss: 0.11111576855182648, precision: 0.30727272727270866, recall: 0.8786828422875427, f1: 0.45532105968316494\n",
            "epoch: 455, step: 21, Train: label_loss: 0.12110652029514313, precision: 0.3316983445738607, recall: 0.873990306946547, f1: 0.4808888888489612\n",
            "epoch: 455, step: 22, Train: label_loss: 0.15323077142238617, precision: 0.30945027794933233, recall: 0.8280991735535821, f1: 0.450539568305677\n",
            "epoch: 455, step: 23, Train: label_loss: 0.1046723797917366, precision: 0.32155997056656943, recall: 0.9085239085237197, f1: 0.47499999996133313\n",
            "epoch: 456, step: 0, Train: label_loss: 0.1273837685585022, precision: 0.3273736128236543, recall: 0.8468899521529749, f1: 0.47220987101354633\n",
            "epoch: 456, step: 1, Train: label_loss: 0.10928422212600708, precision: 0.32572115384613426, recall: 0.8943894389437468, f1: 0.47753303960839655\n",
            "epoch: 456, step: 2, Train: label_loss: 0.10359436273574829, precision: 0.3230861965038985, recall: 0.8786885245900198, f1: 0.472454825875145\n",
            "epoch: 456, step: 3, Train: label_loss: 0.12009863555431366, precision: 0.3090467516696837, recall: 0.8569023569022126, f1: 0.4542614903670675\n",
            "epoch: 456, step: 4, Train: label_loss: 0.1319103091955185, precision: 0.31520395550059854, recall: 0.8869565217389761, f1: 0.4651162790310349\n",
            "epoch: 456, step: 5, Train: label_loss: 0.13158242404460907, precision: 0.29756097560973793, recall: 0.8698752228162442, f1: 0.44343480232453847\n",
            "epoch: 456, step: 6, Train: label_loss: 0.1125292032957077, precision: 0.3158536585365661, recall: 0.8735244519391444, f1: 0.4639498432211388\n",
            "epoch: 456, step: 7, Train: label_loss: 0.12032182514667511, precision: 0.3226002430133461, recall: 0.877685950413078, f1: 0.47179031537602256\n",
            "epoch: 456, step: 8, Train: label_loss: 0.10306981205940247, precision: 0.31766124171185545, recall: 0.875415282391881, f1: 0.46616541349472074\n",
            "epoch: 456, step: 9, Train: label_loss: 0.11927329003810883, precision: 0.3319200484554614, recall: 0.9013157894735359, f1: 0.48517042935415267\n",
            "epoch: 456, step: 10, Train: label_loss: 0.1224319189786911, precision: 0.3154402895054092, recall: 0.8789915966385077, f1: 0.46426986236677054\n",
            "epoch: 456, step: 11, Train: label_loss: 0.11927010118961334, precision: 0.3222087378640581, recall: 0.862012987012847, f1: 0.46908127204515326\n",
            "epoch: 456, step: 12, Train: label_loss: 0.12356914579868317, precision: 0.30055316533495385, recall: 0.8416523235798895, f1: 0.4429347825698765\n",
            "epoch: 456, step: 13, Train: label_loss: 0.11483205854892731, precision: 0.3197815533980388, recall: 0.875415282391881, f1: 0.4684444444052089\n",
            "epoch: 456, step: 14, Train: label_loss: 0.11615777015686035, precision: 0.332121212121192, recall: 0.8753993610222243, f1: 0.4815465728950523\n",
            "epoch: 456, step: 15, Train: label_loss: 0.12021450698375702, precision: 0.3249999999999802, recall: 0.869494290375062, f1: 0.473146915184493\n",
            "epoch: 456, step: 16, Train: label_loss: 0.11080281436443329, precision: 0.3339404978749038, recall: 0.8914100486222217, f1: 0.4858657243419313\n",
            "epoch: 456, step: 17, Train: label_loss: 0.10864431411027908, precision: 0.3302919708028996, recall: 0.8674121405749412, f1: 0.4784140968763132\n",
            "epoch: 456, step: 18, Train: label_loss: 0.10673733055591583, precision: 0.33433193529057315, recall: 0.9087947882734676, f1: 0.48883048616299973\n",
            "epoch: 456, step: 19, Train: label_loss: 0.11135412752628326, precision: 0.3261520047875328, recall: 0.9068219633941919, f1: 0.479753521087808\n",
            "epoch: 456, step: 20, Train: label_loss: 0.11806239932775497, precision: 0.31743119266053105, recall: 0.8621262458470328, f1: 0.46401430483321776\n",
            "epoch: 456, step: 21, Train: label_loss: 0.11316755414009094, precision: 0.3017135862912912, recall: 0.8499999999998534, f1: 0.4453477867724929\n",
            "epoch: 456, step: 22, Train: label_loss: 0.12214647233486176, precision: 0.30325352977284814, recall: 0.8517241379308875, f1: 0.4472612041260153\n",
            "epoch: 456, step: 23, Train: label_loss: 0.1061847060918808, precision: 0.313288789903466, recall: 0.8701030927833258, f1: 0.4606986899173512\n",
            "epoch: 457, step: 0, Train: label_loss: 0.12025671452283859, precision: 0.3248919085855266, recall: 0.8335974643421816, f1: 0.4675555555151549\n",
            "epoch: 457, step: 1, Train: label_loss: 0.10581769794225693, precision: 0.333333333333313, recall: 0.865506329113787, f1: 0.48130224369056257\n",
            "epoch: 457, step: 2, Train: label_loss: 0.11032605171203613, precision: 0.31566118220595274, recall: 0.8533772652387391, f1: 0.46085409248722775\n",
            "epoch: 457, step: 3, Train: label_loss: 0.12095382809638977, precision: 0.31687995124921897, recall: 0.8623548922054954, f1: 0.46345811047759117\n",
            "epoch: 457, step: 4, Train: label_loss: 0.1073281317949295, precision: 0.32048192771082407, recall: 0.8986486486484968, f1: 0.4724689164798535\n",
            "epoch: 457, step: 5, Train: label_loss: 0.09652649611234665, precision: 0.3047390521895438, recall: 0.8834782608694115, f1: 0.45316681530526454\n",
            "epoch: 457, step: 6, Train: label_loss: 0.11272978782653809, precision: 0.31063829787232156, recall: 0.8735042735041241, f1: 0.45829596408681667\n",
            "epoch: 457, step: 7, Train: label_loss: 0.11900147795677185, precision: 0.3031618102913637, recall: 0.831632653061083, f1: 0.44434348019705955\n",
            "epoch: 457, step: 8, Train: label_loss: 0.12209329754114151, precision: 0.3220651505838769, recall: 0.8618421052630161, f1: 0.4689038030923426\n",
            "epoch: 457, step: 9, Train: label_loss: 0.11778078973293304, precision: 0.31559633027521006, recall: 0.8599999999998567, f1: 0.46174496640363416\n",
            "epoch: 457, step: 10, Train: label_loss: 0.11873792111873627, precision: 0.31588447653427704, recall: 0.898972602739572, f1: 0.4674977737816013\n",
            "epoch: 457, step: 11, Train: label_loss: 0.10456656664609909, precision: 0.326605504587136, recall: 0.8626817447494567, f1: 0.47382431229374605\n",
            "epoch: 457, step: 12, Train: label_loss: 0.1024215817451477, precision: 0.3195195195195003, recall: 0.8926174496642797, f1: 0.4705882352552529\n",
            "epoch: 457, step: 13, Train: label_loss: 0.11795096099376678, precision: 0.32623250152158695, recall: 0.8562300319487449, f1: 0.472454825874503\n",
            "epoch: 457, step: 14, Train: label_loss: 0.11089807003736496, precision: 0.30516717325226106, recall: 0.8745644599301612, f1: 0.45245606125047555\n",
            "epoch: 457, step: 15, Train: label_loss: 0.12538832426071167, precision: 0.3193329215564966, recall: 0.8602329450913709, f1: 0.4657657657262376\n",
            "epoch: 457, step: 16, Train: label_loss: 0.11158227175474167, precision: 0.3280584297017451, recall: 0.8953488372091535, f1: 0.48017817368008436\n",
            "epoch: 457, step: 17, Train: label_loss: 0.11187241226434708, precision: 0.31238560097618595, recall: 0.8338762214982355, f1: 0.45450510426567925\n",
            "epoch: 457, step: 18, Train: label_loss: 0.12971726059913635, precision: 0.3213633597078319, recall: 0.8684210526314361, f1: 0.4691248333679034\n",
            "epoch: 457, step: 19, Train: label_loss: 0.11571201682090759, precision: 0.32562385879486755, recall: 0.8629032258063124, f1: 0.472823685333574\n",
            "epoch: 457, step: 20, Train: label_loss: 0.11069370806217194, precision: 0.31515151515149603, recall: 0.8843537414964482, f1: 0.46470062551975183\n",
            "epoch: 457, step: 21, Train: label_loss: 0.12149977684020996, precision: 0.31928084314939126, recall: 0.8569051580697409, f1: 0.4652213188402601\n",
            "epoch: 457, step: 22, Train: label_loss: 0.139362633228302, precision: 0.29242329367562353, recall: 0.8192982456138913, f1: 0.4310106137129211\n",
            "epoch: 457, step: 23, Train: label_loss: 0.12387211620807648, precision: 0.3210526315789232, recall: 0.8626262626260883, f1: 0.4679452054398676\n",
            "epoch: 458, step: 0, Train: label_loss: 0.1153862327337265, precision: 0.3069908814589479, recall: 0.8647260273971121, f1: 0.4531179900913912\n",
            "epoch: 458, step: 1, Train: label_loss: 0.12820997834205627, precision: 0.30956848030016826, recall: 0.8141447368419713, f1: 0.4485727231136427\n",
            "epoch: 458, step: 2, Train: label_loss: 0.11223824322223663, precision: 0.3216049382715851, recall: 0.8683333333331885, f1: 0.4693693693298822\n",
            "epoch: 458, step: 3, Train: label_loss: 0.11746858805418015, precision: 0.33292383292381245, recall: 0.8784440842786257, f1: 0.4828507794701193\n",
            "epoch: 458, step: 4, Train: label_loss: 0.11785938590765, precision: 0.31784841075792675, recall: 0.8580858085807164, f1: 0.46387154322545354\n",
            "epoch: 458, step: 5, Train: label_loss: 0.12127621471881866, precision: 0.31982811540820627, recall: 0.8527004909982238, f1: 0.46517857138885677\n",
            "epoch: 458, step: 6, Train: label_loss: 0.1264933943748474, precision: 0.32584269662919313, recall: 0.8460291734196359, f1: 0.4704821991486335\n",
            "epoch: 458, step: 7, Train: label_loss: 0.13577760756015778, precision: 0.2852760736196144, recall: 0.8408679927665749, f1: 0.42601923954069265\n",
            "epoch: 458, step: 8, Train: label_loss: 0.1187238097190857, precision: 0.32698217578363076, recall: 0.8721311475408405, f1: 0.47563701381813706\n",
            "epoch: 458, step: 9, Train: label_loss: 0.10306903719902039, precision: 0.323349633251814, recall: 0.8714991762766273, f1: 0.47168970125339227\n",
            "epoch: 458, step: 10, Train: label_loss: 0.10785448551177979, precision: 0.3099450884685595, recall: 0.8523489932884475, f1: 0.45458612971476314\n",
            "epoch: 458, step: 11, Train: label_loss: 0.11844232678413391, precision: 0.32014833127315695, recall: 0.8519736842103861, f1: 0.4654088049916982\n",
            "epoch: 458, step: 12, Train: label_loss: 0.10918377339839935, precision: 0.31562881562879636, recall: 0.8545454545453133, f1: 0.4609897458366228\n",
            "epoch: 458, step: 13, Train: label_loss: 0.12056027352809906, precision: 0.31562881562879636, recall: 0.843393148450107, f1: 0.45935139933838065\n",
            "epoch: 458, step: 14, Train: label_loss: 0.11321922391653061, precision: 0.31659522351498365, recall: 0.8674496644293845, f1: 0.4638851502523909\n",
            "epoch: 458, step: 15, Train: label_loss: 0.12104503810405731, precision: 0.31801692865778003, recall: 0.8915254237286624, f1: 0.46880570406102107\n",
            "epoch: 458, step: 16, Train: label_loss: 0.12448801845312119, precision: 0.3256097560975411, recall: 0.8826446280990276, f1: 0.47572383069555135\n",
            "epoch: 458, step: 17, Train: label_loss: 0.11131374537944794, precision: 0.284671532846698, recall: 0.8524590163932872, f1: 0.42681258546174283\n",
            "epoch: 458, step: 18, Train: label_loss: 0.11129939556121826, precision: 0.30815347721820696, recall: 0.8697123519457073, f1: 0.45506861439248897\n",
            "epoch: 458, step: 19, Train: label_loss: 0.10887116938829422, precision: 0.3141809290953353, recall: 0.8756388415671421, f1: 0.46243814660976507\n",
            "epoch: 458, step: 20, Train: label_loss: 0.09017568826675415, precision: 0.3113264688067649, recall: 0.860971524287963, f1: 0.4572953736264312\n",
            "epoch: 458, step: 21, Train: label_loss: 0.10795893520116806, precision: 0.3194868662186732, recall: 0.8490259740258361, f1: 0.46426986236590845\n",
            "epoch: 458, step: 22, Train: label_loss: 0.10205911099910736, precision: 0.3307228915662451, recall: 0.8755980861242622, f1: 0.4801049409308628\n",
            "epoch: 458, step: 23, Train: label_loss: 0.12181276082992554, precision: 0.34270910436711005, recall: 0.8802281368819619, f1: 0.4933404368269483\n",
            "epoch: 459, step: 0, Train: label_loss: 0.1065441220998764, precision: 0.3203647416413179, recall: 0.866776315789331, f1: 0.4678206834936181\n",
            "epoch: 459, step: 1, Train: label_loss: 0.10371680557727814, precision: 0.32772098616955336, recall: 0.8905228758168479, f1: 0.47912087908150824\n",
            "epoch: 459, step: 2, Train: label_loss: 0.11753315478563309, precision: 0.3237804878048583, recall: 0.873355263157751, f1: 0.4724199287861182\n",
            "epoch: 459, step: 3, Train: label_loss: 0.10880459100008011, precision: 0.32945499081443175, recall: 0.8733766233764816, f1: 0.47843485989793183\n",
            "epoch: 459, step: 4, Train: label_loss: 0.12769676744937897, precision: 0.2924704418170322, recall: 0.8438061041291124, f1: 0.4343807763018423\n",
            "epoch: 459, step: 5, Train: label_loss: 0.10559146851301193, precision: 0.3246831623415616, recall: 0.8805237315874171, f1: 0.4744268077207345\n",
            "epoch: 459, step: 6, Train: label_loss: 0.085661381483078, precision: 0.30787448194195927, recall: 0.8934707903778533, f1: 0.45794804047262827\n",
            "epoch: 459, step: 7, Train: label_loss: 0.1154002696275711, precision: 0.32361870066786136, recall: 0.8839137645106327, f1: 0.4737777777385005\n",
            "epoch: 459, step: 8, Train: label_loss: 0.11058975756168365, precision: 0.30843373493974047, recall: 0.8842832469773947, f1: 0.4573470298856875\n",
            "epoch: 459, step: 9, Train: label_loss: 0.11769282817840576, precision: 0.2909203211858993, recall: 0.821989528795668, f1: 0.42974452550879155\n",
            "epoch: 459, step: 10, Train: label_loss: 0.10859657824039459, precision: 0.3101150817686063, recall: 0.8782161234989917, f1: 0.4583706355925412\n",
            "epoch: 459, step: 11, Train: label_loss: 0.10637956857681274, precision: 0.3138201569100595, recall: 0.8813559322032404, f1: 0.4628393413052474\n",
            "epoch: 459, step: 12, Train: label_loss: 0.11806591600179672, precision: 0.30891330891329005, recall: 0.8447412353921795, f1: 0.4523915958480949\n",
            "epoch: 459, step: 13, Train: label_loss: 0.1200578361749649, precision: 0.32559560171042606, recall: 0.8913043478259378, f1: 0.4769574943679217\n",
            "epoch: 459, step: 14, Train: label_loss: 0.11587172746658325, precision: 0.3055040197897152, recall: 0.823333333333196, f1: 0.44564727104753593\n",
            "epoch: 459, step: 15, Train: label_loss: 0.13650625944137573, precision: 0.3362445414846952, recall: 0.8421874999998683, f1: 0.4806063307661286\n",
            "epoch: 459, step: 16, Train: label_loss: 0.11224497854709625, precision: 0.329483282674752, recall: 0.861685214626254, f1: 0.47669305185088023\n",
            "epoch: 459, step: 17, Train: label_loss: 0.12558937072753906, precision: 0.32162661737521125, recall: 0.8543371522093528, f1: 0.4673231870685445\n",
            "epoch: 459, step: 18, Train: label_loss: 0.12533283233642578, precision: 0.31184775936155235, recall: 0.8382838283826999, f1: 0.4545861297143496\n",
            "epoch: 459, step: 19, Train: label_loss: 0.10192165523767471, precision: 0.3212996389891503, recall: 0.8914858096826558, f1: 0.4723573639592409\n",
            "epoch: 459, step: 20, Train: label_loss: 0.10061753541231155, precision: 0.33013780707008206, recall: 0.8988580750406363, f1: 0.4829097282691659\n",
            "epoch: 459, step: 21, Train: label_loss: 0.11770430952310562, precision: 0.31536555142501144, recall: 0.8483333333331918, f1: 0.45980126463975984\n",
            "epoch: 459, step: 22, Train: label_loss: 0.10175999999046326, precision: 0.3200948429164007, recall: 0.9106239460369459, f1: 0.4736842104877858\n",
            "epoch: 459, step: 23, Train: label_loss: 0.10393443703651428, precision: 0.3306569343065452, recall: 0.8899803536344028, f1: 0.4821713677092496\n",
            "epoch: 460, step: 0, Train: label_loss: 0.10136505961418152, precision: 0.3248019500304494, recall: 0.869494290375062, f1: 0.4729370008476697\n",
            "epoch: 460, step: 1, Train: label_loss: 0.127274751663208, precision: 0.33863080684594504, recall: 0.8683385579935943, f1: 0.4872471415602912\n",
            "epoch: 460, step: 2, Train: label_loss: 0.1323721706867218, precision: 0.2930927193528131, recall: 0.8177083333331913, f1: 0.43151626198584975\n",
            "epoch: 460, step: 3, Train: label_loss: 0.12332062423229218, precision: 0.3104715248009608, recall: 0.8564189189187742, f1: 0.4557303370395556\n",
            "epoch: 460, step: 4, Train: label_loss: 0.12248159945011139, precision: 0.3349633251833536, recall: 0.8698412698411317, f1: 0.4836716680974995\n",
            "epoch: 460, step: 5, Train: label_loss: 0.13402840495109558, precision: 0.30659203980097594, recall: 0.8327702702701295, f1: 0.4481818181424412\n",
            "epoch: 460, step: 6, Train: label_loss: 0.12410411238670349, precision: 0.29192166462666513, recall: 0.8442477876104699, f1: 0.43383356067119\n",
            "epoch: 460, step: 7, Train: label_loss: 0.1161864846944809, precision: 0.32918481642810643, recall: 0.8317610062891774, f1: 0.4716897012522394\n",
            "epoch: 460, step: 8, Train: label_loss: 0.12344005703926086, precision: 0.3264058679706402, recall: 0.8571428571427195, f1: 0.47277556436904317\n",
            "epoch: 460, step: 9, Train: label_loss: 0.1301584392786026, precision: 0.32758620689653156, recall: 0.8822553897179299, f1: 0.4777727884651814\n",
            "epoch: 460, step: 10, Train: label_loss: 0.11109760403633118, precision: 0.31917475728153405, recall: 0.8795986622072107, f1: 0.4683882457311443\n",
            "epoch: 460, step: 11, Train: label_loss: 0.13066703081130981, precision: 0.30918176139910625, recall: 0.8505154639173795, f1: 0.4535043517702895\n",
            "epoch: 460, step: 12, Train: label_loss: 0.12934118509292603, precision: 0.31458590852902873, recall: 0.8497495826375876, f1: 0.4591790707769401\n",
            "epoch: 460, step: 13, Train: label_loss: 0.1327000856399536, precision: 0.3162445954292578, recall: 0.8547579298829958, f1: 0.4616771866151764\n",
            "epoch: 460, step: 14, Train: label_loss: 0.11832787841558456, precision: 0.314975247524733, recall: 0.859797297297152, f1: 0.4610507245983934\n",
            "epoch: 460, step: 15, Train: label_loss: 0.11278186738491058, precision: 0.3105326876513129, recall: 0.878424657534096, f1: 0.45885509835134797\n",
            "epoch: 460, step: 16, Train: label_loss: 0.11936362087726593, precision: 0.32273838630804874, recall: 0.8698517298186376, f1: 0.470798038301988\n",
            "epoch: 460, step: 17, Train: label_loss: 0.11281517893075943, precision: 0.3231707317072974, recall: 0.8745874587457302, f1: 0.47195013353134774\n",
            "epoch: 460, step: 18, Train: label_loss: 0.11682885885238647, precision: 0.3285371702637693, recall: 0.904290429042755, f1: 0.4819700967066853\n",
            "epoch: 460, step: 19, Train: label_loss: 0.12641793489456177, precision: 0.28606965174127574, recall: 0.8127208480563934, f1: 0.42318307263854044\n",
            "epoch: 460, step: 20, Train: label_loss: 0.1054869219660759, precision: 0.32551143200960736, recall: 0.8942148760329099, f1: 0.47728275249721924\n",
            "epoch: 460, step: 21, Train: label_loss: 0.11697721481323242, precision: 0.2973462002412366, recall: 0.8588850174214531, f1: 0.44175627236318754\n",
            "epoch: 460, step: 22, Train: label_loss: 0.1034698635339737, precision: 0.33373205741624795, recall: 0.8871224165340401, f1: 0.485006518865055\n",
            "epoch: 460, step: 23, Train: label_loss: 0.11063502728939056, precision: 0.3296130952380707, recall: 0.8789682539680795, f1: 0.47943722939750805\n",
            "epoch: 461, step: 0, Train: label_loss: 0.10369428992271423, precision: 0.30727600721585646, recall: 0.8646362098137285, f1: 0.45341614902959254\n",
            "epoch: 461, step: 1, Train: label_loss: 0.10363240540027618, precision: 0.33552238805968143, recall: 0.9064516129030795, f1: 0.4897603485444013\n",
            "epoch: 461, step: 2, Train: label_loss: 0.12176384031772614, precision: 0.32076637824472676, recall: 0.8621262458470328, f1: 0.46756756752799794\n",
            "epoch: 461, step: 3, Train: label_loss: 0.10940811038017273, precision: 0.3293124246079415, recall: 0.8892508143321026, f1: 0.48063380277741635\n",
            "epoch: 461, step: 4, Train: label_loss: 0.11592122912406921, precision: 0.30996309963097723, recall: 0.8571428571427113, f1: 0.4552845528064776\n",
            "epoch: 461, step: 5, Train: label_loss: 0.10646290332078934, precision: 0.32531569452794196, recall: 0.8898026315788009, f1: 0.4764420959537032\n",
            "epoch: 461, step: 6, Train: label_loss: 0.10987801849842072, precision: 0.3197815533980388, recall: 0.8739635157544156, f1: 0.4682363393654433\n",
            "epoch: 461, step: 7, Train: label_loss: 0.09898088872432709, precision: 0.33211900425013163, recall: 0.8751999999998599, f1: 0.48151408446711697\n",
            "epoch: 461, step: 8, Train: label_loss: 0.12853337824344635, precision: 0.3327160493826955, recall: 0.8369565217390004, f1: 0.47614840985324297\n",
            "epoch: 461, step: 9, Train: label_loss: 0.10797633230686188, precision: 0.3184290030211288, recall: 0.8739635157544156, f1: 0.4667847652398197\n",
            "epoch: 461, step: 10, Train: label_loss: 0.11177544295787811, precision: 0.29550970873784616, recall: 0.8528896672502884, f1: 0.4389364578256415\n",
            "epoch: 461, step: 11, Train: label_loss: 0.12046690285205841, precision: 0.3078802687843428, recall: 0.8289473684209162, f1: 0.44899777278897207\n",
            "epoch: 461, step: 12, Train: label_loss: 0.10870379209518433, precision: 0.31203931203929286, recall: 0.8668941979520705, f1: 0.45889792227359016\n",
            "epoch: 461, step: 13, Train: label_loss: 0.11637865751981735, precision: 0.31145510835911383, recall: 0.8205546492657715, f1: 0.45152603227605076\n",
            "epoch: 461, step: 14, Train: label_loss: 0.11098641157150269, precision: 0.337606837606817, recall: 0.8667711598744723, f1: 0.4859402460053037\n",
            "epoch: 461, step: 15, Train: label_loss: 0.1158684641122818, precision: 0.32620647525960134, recall: 0.8725490196077005, f1: 0.47487772339298023\n",
            "epoch: 461, step: 16, Train: label_loss: 0.12395165860652924, precision: 0.2988792029887734, recall: 0.8391608391606924, f1: 0.44077134982348765\n",
            "epoch: 461, step: 17, Train: label_loss: 0.12397416681051254, precision: 0.29795158286776546, recall: 0.8333333333331886, f1: 0.43895747595567114\n",
            "epoch: 461, step: 18, Train: label_loss: 0.13680633902549744, precision: 0.31852791878170567, recall: 0.7980922098567887, f1: 0.45532879814512234\n",
            "epoch: 461, step: 19, Train: label_loss: 0.12666144967079163, precision: 0.31756756756754806, recall: 0.8718381112983352, f1: 0.46555605579152304\n",
            "epoch: 461, step: 20, Train: label_loss: 0.1057870164513588, precision: 0.307971014492735, recall: 0.890052356020787, f1: 0.45760430682582687\n",
            "epoch: 461, step: 21, Train: label_loss: 0.14633317291736603, precision: 0.3048855905998574, recall: 0.851468048359093, f1: 0.4489981784675055\n",
            "epoch: 461, step: 22, Train: label_loss: 0.11528609693050385, precision: 0.31051051051049183, recall: 0.8960138648178689, f1: 0.46119536124630106\n",
            "epoch: 461, step: 23, Train: label_loss: 0.13102111220359802, precision: 0.3110443275732298, recall: 0.8380566801617737, f1: 0.45369863009745365\n",
            "epoch: 462, step: 0, Train: label_loss: 0.11051724851131439, precision: 0.3161407766990099, recall: 0.8583196046127086, f1: 0.462084257166823\n",
            "epoch: 462, step: 1, Train: label_loss: 0.11352460831403732, precision: 0.3013530135301168, recall: 0.8347529812605051, f1: 0.4428377767345919\n",
            "epoch: 462, step: 2, Train: label_loss: 0.11696974188089371, precision: 0.3205918618988705, recall: 0.8441558441557071, f1: 0.46470062551859576\n",
            "epoch: 462, step: 3, Train: label_loss: 0.11004123091697693, precision: 0.30718165359080823, recall: 0.8569023569022126, f1: 0.4522434473178404\n",
            "epoch: 462, step: 4, Train: label_loss: 0.1279488205909729, precision: 0.3061224489795729, recall: 0.8404074702884821, f1: 0.44877606523733576\n",
            "epoch: 462, step: 5, Train: label_loss: 0.12533241510391235, precision: 0.30243902439022546, recall: 0.8581314878891249, f1: 0.4472497745331088\n",
            "epoch: 462, step: 6, Train: label_loss: 0.12038694322109222, precision: 0.3204182041820221, recall: 0.8513071895423445, f1: 0.465594280567908\n",
            "epoch: 462, step: 7, Train: label_loss: 0.11599937081336975, precision: 0.32963647566233334, recall: 0.8601286173632057, f1: 0.4766146992917465\n",
            "epoch: 462, step: 8, Train: label_loss: 0.11688292771577835, precision: 0.3117754728492793, recall: 0.8646362098137285, f1: 0.4582959640865623\n",
            "epoch: 462, step: 9, Train: label_loss: 0.12630844116210938, precision: 0.33151183970854087, recall: 0.8892508143321026, f1: 0.48297213618330426\n",
            "epoch: 462, step: 10, Train: label_loss: 0.11094076186418533, precision: 0.31729598051155194, recall: 0.8712374581938341, f1: 0.465178571389391\n",
            "epoch: 462, step: 11, Train: label_loss: 0.10197028517723083, precision: 0.32368896925857, recall: 0.8905472636814443, f1: 0.47480106096881275\n",
            "epoch: 462, step: 12, Train: label_loss: 0.10173183679580688, precision: 0.3349339735894157, recall: 0.9087947882734676, f1: 0.48947368417112797\n",
            "epoch: 462, step: 13, Train: label_loss: 0.11079977452754974, precision: 0.31801692865778003, recall: 0.8723051409617126, f1: 0.46610544967280787\n",
            "epoch: 462, step: 14, Train: label_loss: 0.11066398024559021, precision: 0.33819951338197457, recall: 0.8646967340589634, f1: 0.4862264975546389\n",
            "epoch: 462, step: 15, Train: label_loss: 0.12001430988311768, precision: 0.3018181818181635, recall: 0.8586206896550244, f1: 0.4466367712619197\n",
            "epoch: 462, step: 16, Train: label_loss: 0.11592467129230499, precision: 0.31093463653021924, recall: 0.8455149501659724, f1: 0.45466726213125547\n",
            "epoch: 462, step: 17, Train: label_loss: 0.11789073050022125, precision: 0.317547055251954, recall: 0.8849407783416438, f1: 0.4673815906670778\n",
            "epoch: 462, step: 18, Train: label_loss: 0.11714361608028412, precision: 0.3177966101694723, recall: 0.8823529411763222, f1: 0.4672897195871907\n",
            "epoch: 462, step: 19, Train: label_loss: 0.10752776265144348, precision: 0.3140643623360957, recall: 0.8993174061431912, f1: 0.46554770314180305\n",
            "epoch: 462, step: 20, Train: label_loss: 0.09454715251922607, precision: 0.31864815932406043, recall: 0.8814691151918395, f1: 0.4680851063439339\n",
            "epoch: 462, step: 21, Train: label_loss: 0.10774164646863937, precision: 0.30614729153984743, recall: 0.8468013468012042, f1: 0.4497094322363234\n",
            "epoch: 462, step: 22, Train: label_loss: 0.11050392687320709, precision: 0.31498470948010304, recall: 0.8728813559320554, f1: 0.4629213482755942\n",
            "epoch: 462, step: 23, Train: label_loss: 0.10675334930419922, precision: 0.33577712609968213, recall: 0.8962818003912141, f1: 0.4885333332936294\n",
            "epoch: 463, step: 0, Train: label_loss: 0.10670165717601776, precision: 0.3282674772036275, recall: 0.878048780487662, f1: 0.47787610615503356\n",
            "epoch: 463, step: 1, Train: label_loss: 0.09915927052497864, precision: 0.309422492401197, recall: 0.8700854700853213, f1: 0.45650224211372264\n",
            "epoch: 463, step: 2, Train: label_loss: 0.10390987992286682, precision: 0.3246041412910886, recall: 0.8795379537952344, f1: 0.47419928821680485\n",
            "epoch: 463, step: 3, Train: label_loss: 0.1273576319217682, precision: 0.3153374233128641, recall: 0.8726655348046056, f1: 0.4632717439898041\n",
            "epoch: 463, step: 4, Train: label_loss: 0.10027995705604553, precision: 0.31071428571426724, recall: 0.9031141868510547, f1: 0.4623560672780773\n",
            "epoch: 463, step: 5, Train: label_loss: 0.11148892343044281, precision: 0.30867192237717955, recall: 0.883680555555402, f1: 0.4575280898492274\n",
            "epoch: 463, step: 6, Train: label_loss: 0.10751452296972275, precision: 0.34661835748790176, recall: 0.8763358778624616, f1: 0.49675465162528326\n",
            "epoch: 463, step: 7, Train: label_loss: 0.09518607705831528, precision: 0.3026076409945238, recall: 0.8544520547943741, f1: 0.4469323779281941\n",
            "epoch: 463, step: 8, Train: label_loss: 0.09354741126298904, precision: 0.3101379724055003, recall: 0.8777589134124145, f1: 0.45833333329470904\n",
            "epoch: 463, step: 9, Train: label_loss: 0.13030599057674408, precision: 0.30421502748929113, recall: 0.8675958188151798, f1: 0.45047489819760883\n",
            "epoch: 463, step: 10, Train: label_loss: 0.11147071421146393, precision: 0.31371359223299067, recall: 0.8503289473682811, f1: 0.4583333332939184\n",
            "epoch: 463, step: 11, Train: label_loss: 0.1289035826921463, precision: 0.28641671788566153, recall: 0.8175438596489794, f1: 0.4242148383775566\n",
            "epoch: 463, step: 12, Train: label_loss: 0.1041521355509758, precision: 0.3192771084337157, recall: 0.886287625417912, f1: 0.46944198401770615\n",
            "epoch: 463, step: 13, Train: label_loss: 0.11239556968212128, precision: 0.3159490600363665, recall: 0.8640132669981982, f1: 0.4626998223408524\n",
            "epoch: 463, step: 14, Train: label_loss: 0.11008673161268234, precision: 0.3389933292904585, recall: 0.8873015873014464, f1: 0.4905660376958021\n",
            "epoch: 463, step: 15, Train: label_loss: 0.10404055565595627, precision: 0.3246987951807033, recall: 0.8735818476497773, f1: 0.4734299516512705\n",
            "epoch: 463, step: 16, Train: label_loss: 0.11386589705944061, precision: 0.3327239488116799, recall: 0.879227053139955, f1: 0.4827586206497793\n",
            "epoch: 463, step: 17, Train: label_loss: 0.12275185436010361, precision: 0.3086797066014481, recall: 0.8544839255497707, f1: 0.4535249213799179\n",
            "epoch: 463, step: 18, Train: label_loss: 0.11966148018836975, precision: 0.3003095975232012, recall: 0.8083333333331986, f1: 0.43792325052479375\n",
            "epoch: 463, step: 19, Train: label_loss: 0.10280649363994598, precision: 0.32990936555889244, recall: 0.8936170212764494, f1: 0.4819064430320623\n",
            "epoch: 463, step: 20, Train: label_loss: 0.12045924365520477, precision: 0.32521315468938333, recall: 0.8754098360654302, f1: 0.47424511541338865\n",
            "epoch: 463, step: 21, Train: label_loss: 0.10472508519887924, precision: 0.31713244228430637, recall: 0.8460291734196359, f1: 0.4613345116704164\n",
            "epoch: 463, step: 22, Train: label_loss: 0.10362817347049713, precision: 0.3029751062537764, recall: 0.8618307426596092, f1: 0.4483378256577856\n",
            "epoch: 463, step: 23, Train: label_loss: 0.09648901224136353, precision: 0.3355311355311109, recall: 0.8927875243662976, f1: 0.48775292860773634\n",
            "epoch: 464, step: 0, Train: label_loss: 0.11585992574691772, precision: 0.317547055251954, recall: 0.8789915966385077, f1: 0.4665477252062835\n",
            "epoch: 464, step: 1, Train: label_loss: 0.1016460731625557, precision: 0.3076923076922889, recall: 0.8615384615383141, f1: 0.4534412955077367\n",
            "epoch: 464, step: 2, Train: label_loss: 0.09444111585617065, precision: 0.31985294117645097, recall: 0.8585526315788061, f1: 0.46607142853183586\n",
            "epoch: 464, step: 3, Train: label_loss: 0.11074355989694595, precision: 0.28998778998777225, recall: 0.8482142857141342, f1: 0.4322111009628974\n",
            "epoch: 464, step: 4, Train: label_loss: 0.09866704046726227, precision: 0.29620710415410617, recall: 0.8754448398574954, f1: 0.44264507418620214\n",
            "epoch: 464, step: 5, Train: label_loss: 0.11134570837020874, precision: 0.3250303766706971, recall: 0.8741830065358048, f1: 0.4738706819799291\n",
            "epoch: 464, step: 6, Train: label_loss: 0.11281874775886536, precision: 0.32766990291260145, recall: 0.8653846153844766, f1: 0.4753521126361711\n",
            "epoch: 464, step: 7, Train: label_loss: 0.0967140793800354, precision: 0.3149038461538272, recall: 0.8675496688740285, f1: 0.46208112870867646\n",
            "epoch: 464, step: 8, Train: label_loss: 0.09927940368652344, precision: 0.3212996389891503, recall: 0.87684729064025, f1: 0.4702774107929406\n",
            "epoch: 464, step: 9, Train: label_loss: 0.10084229707717896, precision: 0.3131009615384427, recall: 0.8583196046127086, f1: 0.4588287097802538\n",
            "epoch: 464, step: 10, Train: label_loss: 0.1240113228559494, precision: 0.3069427527405416, recall: 0.8586030664393767, f1: 0.4522207267444712\n",
            "epoch: 464, step: 11, Train: label_loss: 0.09952820837497711, precision: 0.31892878880095443, recall: 0.8632619439866781, f1: 0.4657777777383368\n",
            "epoch: 464, step: 12, Train: label_loss: 0.09838669002056122, precision: 0.3043478260869384, recall: 0.884083044982546, f1: 0.45281346916876986\n",
            "epoch: 464, step: 13, Train: label_loss: 0.11488501727581024, precision: 0.308581862446725, recall: 0.860780984719718, f1: 0.45430107522992613\n",
            "epoch: 464, step: 14, Train: label_loss: 0.09960378706455231, precision: 0.2946482260973966, recall: 0.871886120996286, f1: 0.44044943816445054\n",
            "epoch: 464, step: 15, Train: label_loss: 0.1008085310459137, precision: 0.3303249097472725, recall: 0.8755980861242622, f1: 0.479685452122697\n",
            "epoch: 464, step: 16, Train: label_loss: 0.09965941309928894, precision: 0.32271634615382677, recall: 0.8846787479405461, f1: 0.47291941871904597\n",
            "epoch: 464, step: 17, Train: label_loss: 0.12031186372041702, precision: 0.3191358024691161, recall: 0.8489326765187439, f1: 0.46388515025185517\n",
            "epoch: 464, step: 18, Train: label_loss: 0.13452745974063873, precision: 0.3121529919802398, recall: 0.8605442176869285, f1: 0.4581258487612546\n",
            "epoch: 464, step: 19, Train: label_loss: 0.10279859602451324, precision: 0.3439759036144371, recall: 0.8866459627327815, f1: 0.495659722181902\n",
            "epoch: 464, step: 20, Train: label_loss: 0.10898586362600327, precision: 0.3178199632577882, recall: 0.8425324675323307, f1: 0.46153846149864475\n",
            "epoch: 464, step: 21, Train: label_loss: 0.13283208012580872, precision: 0.31871525633104886, recall: 0.8543046357614479, f1: 0.4642375168294778\n",
            "epoch: 464, step: 22, Train: label_loss: 0.09060467779636383, precision: 0.3441441441441235, recall: 0.8939157566301257, f1: 0.4969644405495821\n",
            "epoch: 464, step: 23, Train: label_loss: 0.1057833582162857, precision: 0.3219076005961012, recall: 0.874493927125329, f1: 0.4705882352547327\n",
            "epoch: 465, step: 0, Train: label_loss: 0.11270944774150848, precision: 0.31857318573183774, recall: 0.8547854785477137, f1: 0.46415770605359036\n",
            "epoch: 465, step: 1, Train: label_loss: 0.10080272704362869, precision: 0.325693606755107, recall: 0.904522613065175, f1: 0.47893569840892003\n",
            "epoch: 465, step: 2, Train: label_loss: 0.11802265048027039, precision: 0.2998783454987652, recall: 0.8559027777776291, f1: 0.44414414410567604\n",
            "epoch: 465, step: 3, Train: label_loss: 0.10398454964160919, precision: 0.32093581283741324, recall: 0.900673400673249, f1: 0.4732419283115064\n",
            "epoch: 465, step: 4, Train: label_loss: 0.11014428734779358, precision: 0.2988505747126256, recall: 0.8712522045853842, f1: 0.4450450450069702\n",
            "epoch: 465, step: 5, Train: label_loss: 0.129412442445755, precision: 0.30312499999998105, recall: 0.8206429780032451, f1: 0.4427202190386101\n",
            "epoch: 465, step: 6, Train: label_loss: 0.11969075351953506, precision: 0.3115455100793945, recall: 0.8429752066114309, f1: 0.4549509366242465\n",
            "epoch: 465, step: 7, Train: label_loss: 0.12481999397277832, precision: 0.307968843618915, recall: 0.8816466552314096, f1: 0.45648312607171143\n",
            "epoch: 465, step: 8, Train: label_loss: 0.12476867437362671, precision: 0.32430769230767237, recall: 0.8472668810288027, f1: 0.46906987089895047\n",
            "epoch: 465, step: 9, Train: label_loss: 0.12884873151779175, precision: 0.31425015556936436, recall: 0.8292282430212102, f1: 0.4557761732452987\n",
            "epoch: 465, step: 10, Train: label_loss: 0.11358559131622314, precision: 0.3280293757649738, recall: 0.8481012658226506, f1: 0.4730803177002467\n",
            "epoch: 465, step: 11, Train: label_loss: 0.1185259148478508, precision: 0.31211372064274956, recall: 0.8402662229615906, f1: 0.4551599819343236\n",
            "epoch: 465, step: 12, Train: label_loss: 0.11209547519683838, precision: 0.3206751054852127, recall: 0.870703764320643, f1: 0.46872246692096825\n",
            "epoch: 465, step: 13, Train: label_loss: 0.11250101029872894, precision: 0.3309481216457763, recall: 0.8908507223112534, f1: 0.482608695612632\n",
            "epoch: 465, step: 14, Train: label_loss: 0.12004789710044861, precision: 0.3093480934809158, recall: 0.8496621621620186, f1: 0.45356176731880576\n",
            "epoch: 465, step: 15, Train: label_loss: 0.11129328608512878, precision: 0.3308913308913107, recall: 0.861685214626254, f1: 0.47816497569872457\n",
            "epoch: 465, step: 16, Train: label_loss: 0.10754889249801636, precision: 0.3307276007215676, recall: 0.8957654723125577, f1: 0.48309178740018305\n",
            "epoch: 465, step: 17, Train: label_loss: 0.11197879910469055, precision: 0.30098280098278246, recall: 0.8536585365852171, f1: 0.4450499545481544\n",
            "epoch: 465, step: 18, Train: label_loss: 0.11475494503974915, precision: 0.3168498168497975, recall: 0.8752107925799535, f1: 0.4652622142146261\n",
            "epoch: 465, step: 19, Train: label_loss: 0.1170862466096878, precision: 0.2974800245851077, recall: 0.8461538461536982, f1: 0.44020009091190054\n",
            "epoch: 465, step: 20, Train: label_loss: 0.10172863304615021, precision: 0.32955899880808526, recall: 0.9050736497543527, f1: 0.4831804280953788\n",
            "epoch: 465, step: 21, Train: label_loss: 0.09284262359142303, precision: 0.3349168646080561, recall: 0.9009584664535302, f1: 0.48831168827213456\n",
            "epoch: 465, step: 22, Train: label_loss: 0.12067270278930664, precision: 0.31985294117645097, recall: 0.8685524126454461, f1: 0.46753246749308447\n",
            "epoch: 465, step: 23, Train: label_loss: 0.13242435455322266, precision: 0.3144368858654335, recall: 0.8489795918365615, f1: 0.4589078874398205\n",
            "epoch: 466, step: 0, Train: label_loss: 0.13233354687690735, precision: 0.3215613382899429, recall: 0.8317307692306359, f1: 0.46380697046912595\n",
            "epoch: 466, step: 1, Train: label_loss: 0.09949865937232971, precision: 0.3377563329312221, recall: 0.8805031446539495, f1: 0.4882301656094019\n",
            "epoch: 466, step: 2, Train: label_loss: 0.11466831713914871, precision: 0.31403940886697573, recall: 0.8415841584157027, f1: 0.45739910309939213\n",
            "epoch: 466, step: 3, Train: label_loss: 0.0986621230840683, precision: 0.32451923076921124, recall: 0.891089108910744, f1: 0.47577092507095164\n",
            "epoch: 466, step: 4, Train: label_loss: 0.10688487440347672, precision: 0.31607795371496245, recall: 0.8606965174127925, f1: 0.46236080174240546\n",
            "epoch: 466, step: 5, Train: label_loss: 0.10222262144088745, precision: 0.32267792521107824, recall: 0.9021922428329001, f1: 0.47534429138718287\n",
            "epoch: 466, step: 6, Train: label_loss: 0.10112378001213074, precision: 0.3046922608165567, recall: 0.8445945945944519, f1: 0.44782803399592475\n",
            "epoch: 466, step: 7, Train: label_loss: 0.11569301784038544, precision: 0.329483282674752, recall: 0.891447368420906, f1: 0.48113626272131343\n",
            "epoch: 466, step: 8, Train: label_loss: 0.10934976488351822, precision: 0.3222490931075984, recall: 0.8868552412644114, f1: 0.47272727268813347\n",
            "epoch: 466, step: 9, Train: label_loss: 0.11376643925905228, precision: 0.33740831295841456, recall: 0.8638497652580807, f1: 0.48527472523428533\n",
            "epoch: 466, step: 10, Train: label_loss: 0.10085985064506531, precision: 0.3063063063062879, recall: 0.890052356020787, f1: 0.4557640750288874\n",
            "epoch: 466, step: 11, Train: label_loss: 0.12452501058578491, precision: 0.32926084300547775, recall: 0.8792822185969201, f1: 0.47911111107142473\n",
            "epoch: 466, step: 12, Train: label_loss: 0.10685953497886658, precision: 0.32022126613396923, recall: 0.8583196046127086, f1: 0.46642793192099025\n",
            "epoch: 466, step: 13, Train: label_loss: 0.10981777310371399, precision: 0.30629539951571993, recall: 0.8664383561642351, f1: 0.45259391767156326\n",
            "epoch: 466, step: 14, Train: label_loss: 0.10968667268753052, precision: 0.32570740517758423, recall: 0.8825448613375395, f1: 0.47581354437570544\n",
            "epoch: 466, step: 15, Train: label_loss: 0.10708524286746979, precision: 0.2940108892921782, recall: 0.8632326820602374, f1: 0.43862815880682293\n",
            "epoch: 466, step: 16, Train: label_loss: 0.11311262845993042, precision: 0.30437424058321355, recall: 0.8391959798993569, f1: 0.4467231386144852\n",
            "epoch: 466, step: 17, Train: label_loss: 0.12738823890686035, precision: 0.3090234857849005, recall: 0.8361204013376528, f1: 0.4512635378666897\n",
            "epoch: 466, step: 18, Train: label_loss: 0.09882692992687225, precision: 0.32727272727270745, recall: 0.8809135399672298, f1: 0.4772425982812702\n",
            "epoch: 466, step: 19, Train: label_loss: 0.12138354033231735, precision: 0.2965474722564552, recall: 0.837979094076509, f1: 0.43806921671908894\n",
            "epoch: 466, step: 20, Train: label_loss: 0.10219134390354156, precision: 0.31681957186542403, recall: 0.8547854785477137, f1: 0.4622936188806256\n",
            "epoch: 466, step: 21, Train: label_loss: 0.10172375291585922, precision: 0.32552552552550595, recall: 0.8870703764319333, f1: 0.4762741651627898\n",
            "epoch: 466, step: 22, Train: label_loss: 0.11486994475126266, precision: 0.31246200607900837, recall: 0.8741496598637969, f1: 0.4603672189490707\n",
            "epoch: 466, step: 23, Train: label_loss: 0.1052614152431488, precision: 0.30872483221474206, recall: 0.8789808917195586, f1: 0.4569536423455819\n",
            "epoch: 467, step: 0, Train: label_loss: 0.1028447300195694, precision: 0.3132892363198849, recall: 0.8785834738615719, f1: 0.46187943258532005\n",
            "epoch: 467, step: 1, Train: label_loss: 0.10776044428348541, precision: 0.3453766074708913, recall: 0.8757763975153919, f1: 0.495388669261102\n",
            "epoch: 467, step: 2, Train: label_loss: 0.11251527070999146, precision: 0.3073200241984085, recall: 0.8758620689653661, f1: 0.45499328254099364\n",
            "epoch: 467, step: 3, Train: label_loss: 0.11078058183193207, precision: 0.32655576093651717, recall: 0.8426073131954145, f1: 0.4706927175440687\n",
            "epoch: 467, step: 4, Train: label_loss: 0.10615691542625427, precision: 0.33313106796114483, recall: 0.871428571428433, f1: 0.4820017558861939\n",
            "epoch: 467, step: 5, Train: label_loss: 0.1076253354549408, precision: 0.3208910295002817, recall: 0.8809917355370444, f1: 0.47043248010203514\n",
            "epoch: 467, step: 6, Train: label_loss: 0.11879676580429077, precision: 0.30577507598782333, recall: 0.8642611683847312, f1: 0.45172878307765124\n",
            "epoch: 467, step: 7, Train: label_loss: 0.11347979307174683, precision: 0.31269160024522913, recall: 0.8429752066114309, f1: 0.4561717352019893\n",
            "epoch: 467, step: 8, Train: label_loss: 0.09636018425226212, precision: 0.3177458033572951, recall: 0.8848080133554449, f1: 0.46757829727029576\n",
            "epoch: 467, step: 9, Train: label_loss: 0.09668350219726562, precision: 0.3248330297510428, recall: 0.8713355048858515, f1: 0.47324192831068235\n",
            "epoch: 467, step: 10, Train: label_loss: 0.08880928158760071, precision: 0.31474820143883003, recall: 0.8779264214045354, f1: 0.46337157983754185\n",
            "epoch: 467, step: 11, Train: label_loss: 0.1224764883518219, precision: 0.3102189781021709, recall: 0.8793103448274345, f1: 0.4586330934865827\n",
            "epoch: 467, step: 12, Train: label_loss: 0.1075480505824089, precision: 0.3021406727828561, recall: 0.8606271777001985, f1: 0.4472612041262747\n",
            "epoch: 467, step: 13, Train: label_loss: 0.10028410702943802, precision: 0.3049001814881848, recall: 0.8630136986299891, f1: 0.4506034867740734\n",
            "epoch: 467, step: 14, Train: label_loss: 0.10722324997186661, precision: 0.32277710109620444, recall: 0.8548387096772814, f1: 0.468611847882358\n",
            "epoch: 467, step: 15, Train: label_loss: 0.10417726635932922, precision: 0.30717351318207803, recall: 0.8434343434342014, f1: 0.4503370786125058\n",
            "epoch: 467, step: 16, Train: label_loss: 0.108924001455307, precision: 0.3209951456310485, recall: 0.864379084967179, f1: 0.46814159288081936\n",
            "epoch: 467, step: 17, Train: label_loss: 0.10953830927610397, precision: 0.3102610807528652, recall: 0.8646362098137285, f1: 0.4566577300772665\n",
            "epoch: 467, step: 18, Train: label_loss: 0.1124061644077301, precision: 0.3239780353874116, recall: 0.8676470588233876, f1: 0.4717903153757369\n",
            "epoch: 467, step: 19, Train: label_loss: 0.0969618707895279, precision: 0.32358208955221945, recall: 0.8856209150325349, f1: 0.4739833843070657\n",
            "epoch: 467, step: 20, Train: label_loss: 0.12070649862289429, precision: 0.31489361702125745, recall: 0.8705882352939712, f1: 0.46249999996094504\n",
            "epoch: 467, step: 21, Train: label_loss: 0.10069727152585983, precision: 0.3113264688067649, recall: 0.8524046434492781, f1: 0.4560780833680445\n",
            "epoch: 467, step: 22, Train: label_loss: 0.10553301870822906, precision: 0.3220747889022725, recall: 0.8899999999998516, f1: 0.4729849423878618\n",
            "epoch: 467, step: 23, Train: label_loss: 0.11934134364128113, precision: 0.29729729729727494, recall: 0.8552915766736814, f1: 0.44122562670261667\n",
            "epoch: 468, step: 0, Train: label_loss: 0.09518198668956757, precision: 0.3182089552238616, recall: 0.8927973199328487, f1: 0.4691901408062853\n",
            "epoch: 468, step: 1, Train: label_loss: 0.10099314153194427, precision: 0.3184290030211288, recall: 0.8696369636962261, f1: 0.46616541349455604\n",
            "epoch: 468, step: 2, Train: label_loss: 0.08746976405382156, precision: 0.3086053412462725, recall: 0.8888888888887369, f1: 0.4581497796973834\n",
            "epoch: 468, step: 3, Train: label_loss: 0.10568299889564514, precision: 0.3017031630170133, recall: 0.8581314878891249, f1: 0.44644464442591414\n",
            "epoch: 468, step: 4, Train: label_loss: 0.10684875398874283, precision: 0.3185140073081414, recall: 0.8760469011723825, f1: 0.4671728449809482\n",
            "epoch: 468, step: 5, Train: label_loss: 0.1032719761133194, precision: 0.3325358851674442, recall: 0.8967741935482424, f1: 0.48516579402680876\n",
            "epoch: 468, step: 6, Train: label_loss: 0.11104799062013626, precision: 0.33091787439611525, recall: 0.8810289389066107, f1: 0.4811237927609616\n",
            "epoch: 468, step: 7, Train: label_loss: 0.10588880628347397, precision: 0.3183475091129819, recall: 0.8604269293923053, f1: 0.4647450110470071\n",
            "epoch: 468, step: 8, Train: label_loss: 0.10164108872413635, precision: 0.3187463039621337, recall: 0.9151103565363471, f1: 0.4728070175054987\n",
            "epoch: 468, step: 9, Train: label_loss: 0.11163435876369476, precision: 0.3297232250300644, recall: 0.8925081433223302, f1: 0.4815465728955324\n",
            "epoch: 468, step: 10, Train: label_loss: 0.1034998744726181, precision: 0.31610576923075023, recall: 0.8900169204736226, f1: 0.4665188469679313\n",
            "epoch: 468, step: 11, Train: label_loss: 0.11337041854858398, precision: 0.3248019500304494, recall: 0.876644736841961, f1: 0.4739884392668648\n",
            "epoch: 468, step: 12, Train: label_loss: 0.1008264571428299, precision: 0.3214069132807567, recall: 0.8548387096772814, f1: 0.46716615245032583\n",
            "epoch: 468, step: 13, Train: label_loss: 0.09367337822914124, precision: 0.3070017953321181, recall: 0.8984238178632401, f1: 0.457627118606063\n",
            "epoch: 468, step: 14, Train: label_loss: 0.09622316062450409, precision: 0.30312124849938155, recall: 0.8767361111109588, f1: 0.4504906333248467\n",
            "epoch: 468, step: 15, Train: label_loss: 0.0931849330663681, precision: 0.31815421979354475, recall: 0.8520325203250646, f1: 0.4633068080947608\n",
            "epoch: 468, step: 16, Train: label_loss: 0.11318472772836685, precision: 0.3256097560975411, recall: 0.8640776699027728, f1: 0.4729849423871275\n",
            "epoch: 468, step: 17, Train: label_loss: 0.09860000014305115, precision: 0.3225613405146426, recall: 0.8792822185969201, f1: 0.47197898419886614\n",
            "epoch: 468, step: 18, Train: label_loss: 0.1011594831943512, precision: 0.31971153846151923, recall: 0.8941176470586731, f1: 0.47100486937239894\n",
            "epoch: 468, step: 19, Train: label_loss: 0.11753267794847488, precision: 0.3128834355828029, recall: 0.8360655737703547, f1: 0.45535714281746975\n",
            "epoch: 468, step: 20, Train: label_loss: 0.10939084738492966, precision: 0.3002436053592996, recall: 0.8544194107450859, f1: 0.44434429919536644\n",
            "epoch: 468, step: 21, Train: label_loss: 0.10730545222759247, precision: 0.3018404907975275, recall: 0.8424657534245132, f1: 0.4444444444055647\n",
            "epoch: 468, step: 22, Train: label_loss: 0.09856042265892029, precision: 0.31958762886596, recall: 0.8783333333331869, f1: 0.4686527345095244\n",
            "epoch: 468, step: 23, Train: label_loss: 0.09381143748760223, precision: 0.3478260869564961, recall: 0.9007633587784539, f1: 0.5018607123467805\n",
            "epoch: 469, step: 0, Train: label_loss: 0.09999814629554749, precision: 0.33878787878785827, recall: 0.8775510204080255, f1: 0.4888500218224692\n",
            "epoch: 469, step: 1, Train: label_loss: 0.11506842076778412, precision: 0.3079754601226805, recall: 0.8625429553263122, f1: 0.45388788422881343\n",
            "epoch: 469, step: 2, Train: label_loss: 0.1022031158208847, precision: 0.3236714975845215, recall: 0.8701298701297289, f1: 0.47183098587592803\n",
            "epoch: 469, step: 3, Train: label_loss: 0.10151357203722, precision: 0.3205596107055766, recall: 0.8768718801995212, f1: 0.46948775051754316\n",
            "epoch: 469, step: 4, Train: label_loss: 0.09687910974025726, precision: 0.31476997578690585, recall: 0.8843537414964482, f1: 0.4642857142469541\n",
            "epoch: 469, step: 5, Train: label_loss: 0.10819510370492935, precision: 0.29560505719444335, recall: 0.872113676731639, f1: 0.44154676255207553\n",
            "epoch: 469, step: 6, Train: label_loss: 0.10964566469192505, precision: 0.32035928143710657, recall: 0.8842975206610107, f1: 0.47032967029058637\n",
            "epoch: 469, step: 7, Train: label_loss: 0.09051252156496048, precision: 0.3247143716175391, recall: 0.8955223880595529, f1: 0.4766107678338028\n",
            "epoch: 469, step: 8, Train: label_loss: 0.09939412772655487, precision: 0.307968843618915, recall: 0.8877374784109001, f1: 0.45729537362719486\n",
            "epoch: 469, step: 9, Train: label_loss: 0.10380296409130096, precision: 0.3024242424242241, recall: 0.8847517730494885, f1: 0.450767840973733\n",
            "epoch: 469, step: 10, Train: label_loss: 0.09344949573278427, precision: 0.33134328358206977, recall: 0.9009740259738797, f1: 0.48450458311210337\n",
            "epoch: 469, step: 11, Train: label_loss: 0.12145835906267166, precision: 0.31717791411040996, recall: 0.8631051752920095, f1: 0.46388515025226607\n",
            "epoch: 469, step: 12, Train: label_loss: 0.10736069828271866, precision: 0.32203389830506524, recall: 0.8622366288491309, f1: 0.468929043591918\n",
            "epoch: 469, step: 13, Train: label_loss: 0.09903336316347122, precision: 0.3193529059316765, recall: 0.8957983193275805, f1: 0.47084805649831274\n",
            "epoch: 469, step: 14, Train: label_loss: 0.09504032880067825, precision: 0.3337342152735818, recall: 0.9053833605218751, f1: 0.48769771525058103\n",
            "epoch: 469, step: 15, Train: label_loss: 0.09360421448945999, precision: 0.3178807947019676, recall: 0.8829431438125613, f1: 0.46746347937670063\n",
            "epoch: 469, step: 16, Train: label_loss: 0.0902433693408966, precision: 0.3104066985645747, recall: 0.888698630136834, f1: 0.4601063829403118\n",
            "epoch: 469, step: 17, Train: label_loss: 0.08772734552621841, precision: 0.3154761904761717, recall: 0.905982905982751, f1: 0.4679911699395695\n",
            "epoch: 469, step: 18, Train: label_loss: 0.10062173008918762, precision: 0.3301435406698367, recall: 0.8789808917196053, f1: 0.4799999999602601\n",
            "epoch: 469, step: 19, Train: label_loss: 0.10831290483474731, precision: 0.318238213399484, recall: 0.8300970873785064, f1: 0.4600896860585476\n",
            "epoch: 469, step: 20, Train: label_loss: 0.09358442574739456, precision: 0.31569452796149633, recall: 0.8735440931778912, f1: 0.463780918688876\n",
            "epoch: 469, step: 21, Train: label_loss: 0.11541251093149185, precision: 0.31728395061726433, recall: 0.8412438625203206, f1: 0.46077991927887696\n",
            "epoch: 469, step: 22, Train: label_loss: 0.10252109169960022, precision: 0.32809667673714027, recall: 0.8872549019606393, f1: 0.4790471989018735\n",
            "epoch: 469, step: 23, Train: label_loss: 0.10177671909332275, precision: 0.333819241982483, recall: 0.9087301587299784, f1: 0.48827292106939396\n",
            "epoch: 470, step: 0, Train: label_loss: 0.10496848821640015, precision: 0.2913625304136076, recall: 0.8433098591547811, f1: 0.43309222419325666\n",
            "epoch: 470, step: 1, Train: label_loss: 0.07952161133289337, precision: 0.35071090047391285, recall: 0.9107692307690906, f1: 0.5064157399084862\n",
            "epoch: 470, step: 2, Train: label_loss: 0.10480405390262604, precision: 0.2830188679245111, recall: 0.8611111111109516, f1: 0.4260192395412874\n",
            "epoch: 470, step: 3, Train: label_loss: 0.09275864064693451, precision: 0.31635710005989714, recall: 0.890387858347236, f1: 0.46684350128753244\n",
            "epoch: 470, step: 4, Train: label_loss: 0.0993262529373169, precision: 0.3228111971411362, recall: 0.9033333333331827, f1: 0.4756472136513812\n",
            "epoch: 470, step: 5, Train: label_loss: 0.09392780065536499, precision: 0.346107784431117, recall: 0.8851454823888384, f1: 0.49763237189238585\n",
            "epoch: 470, step: 6, Train: label_loss: 0.09912554919719696, precision: 0.3214069132807567, recall: 0.8803986710961992, f1: 0.47090182137348063\n",
            "epoch: 470, step: 7, Train: label_loss: 0.10448004305362701, precision: 0.31464737793849823, recall: 0.8862478777587629, f1: 0.4644128113491868\n",
            "epoch: 470, step: 8, Train: label_loss: 0.11131452023983002, precision: 0.3339460784313521, recall: 0.8623417721517622, f1: 0.4814487632105957\n",
            "epoch: 470, step: 9, Train: label_loss: 0.09035129845142365, precision: 0.33074626865669665, recall: 0.9052287581697867, f1: 0.4844774813774627\n",
            "epoch: 470, step: 10, Train: label_loss: 0.10629968345165253, precision: 0.30834856794635535, recall: 0.84757118927959, f1: 0.45218945483126005\n",
            "epoch: 470, step: 11, Train: label_loss: 0.09016671031713486, precision: 0.3069069069068885, recall: 0.8996478873237852, f1: 0.45768025074572516\n",
            "epoch: 470, step: 12, Train: label_loss: 0.09724078327417374, precision: 0.32174955062909993, recall: 0.8846787479405461, f1: 0.47188049205223304\n",
            "epoch: 470, step: 13, Train: label_loss: 0.0944594144821167, precision: 0.3491017964071647, recall: 0.8833333333331994, f1: 0.5004291845087083\n",
            "epoch: 470, step: 14, Train: label_loss: 0.0969710499048233, precision: 0.3220747889022725, recall: 0.8739770867429011, f1: 0.47069193473363247\n",
            "epoch: 470, step: 15, Train: label_loss: 0.10586683452129364, precision: 0.29580036518561803, recall: 0.8466898954702357, f1: 0.4384303111929792\n",
            "epoch: 470, step: 16, Train: label_loss: 0.09854132682085037, precision: 0.32691149909690986, recall: 0.8687999999998609, f1: 0.47506561675812786\n",
            "epoch: 470, step: 17, Train: label_loss: 0.09733380377292633, precision: 0.3067632850241361, recall: 0.8743545611013985, f1: 0.45417970492350873\n",
            "epoch: 470, step: 18, Train: label_loss: 0.1093263179063797, precision: 0.3158536585365661, recall: 0.8604651162789267, f1: 0.4620874219053685\n",
            "epoch: 470, step: 19, Train: label_loss: 0.10648638755083084, precision: 0.31604342581421496, recall: 0.8941979522182774, f1: 0.467023172866895\n",
            "epoch: 470, step: 20, Train: label_loss: 0.11978448927402496, precision: 0.30218446601939913, recall: 0.8767605633801273, f1: 0.4494584837163482\n",
            "epoch: 470, step: 21, Train: label_loss: 0.10961714386940002, precision: 0.3264437689969406, recall: 0.8731707317071751, f1: 0.47522123889839646\n",
            "epoch: 470, step: 22, Train: label_loss: 0.10705739259719849, precision: 0.29847094801221413, recall: 0.8413793103446825, f1: 0.44063205413737544\n",
            "epoch: 470, step: 23, Train: label_loss: 0.10135529935359955, precision: 0.3256846780162601, recall: 0.8695652173911326, f1: 0.4738826063146367\n",
            "epoch: 471, step: 0, Train: label_loss: 0.09850101172924042, precision: 0.30655129789862134, recall: 0.8421052631577517, f1: 0.449478930635953\n",
            "epoch: 471, step: 1, Train: label_loss: 0.09710052609443665, precision: 0.33013780707008206, recall: 0.8858520900320118, f1: 0.4810126581882488\n",
            "epoch: 471, step: 2, Train: label_loss: 0.09258010983467102, precision: 0.3271420011983027, recall: 0.8892508143321026, f1: 0.47831800258875623\n",
            "epoch: 471, step: 3, Train: label_loss: 0.09173612296581268, precision: 0.32279236276847717, recall: 0.9016666666665163, f1: 0.47539543054109806\n",
            "epoch: 471, step: 4, Train: label_loss: 0.10109491646289825, precision: 0.3014032946918669, recall: 0.850258175559234, f1: 0.4450450450063611\n",
            "epoch: 471, step: 5, Train: label_loss: 0.10371037572622299, precision: 0.3207547169811125, recall: 0.8696369636962261, f1: 0.46865273450927697\n",
            "epoch: 471, step: 6, Train: label_loss: 0.09268069267272949, precision: 0.326567164179085, recall: 0.8981937602625782, f1: 0.4789842381394836\n",
            "epoch: 471, step: 7, Train: label_loss: 0.11165904253721237, precision: 0.30614729153984743, recall: 0.8672413793101952, f1: 0.4525416103977394\n",
            "epoch: 471, step: 8, Train: label_loss: 0.10407149791717529, precision: 0.3179611650485244, recall: 0.8762541806018601, f1: 0.46660730183087723\n",
            "epoch: 471, step: 9, Train: label_loss: 0.0944681242108345, precision: 0.3347432024168982, recall: 0.8779714738508909, f1: 0.48468941378326236\n",
            "epoch: 471, step: 10, Train: label_loss: 0.10941541194915771, precision: 0.3002436053592996, recall: 0.851468048359093, f1: 0.44394416925452485\n",
            "epoch: 471, step: 11, Train: label_loss: 0.11396047472953796, precision: 0.3241758241758044, recall: 0.8388625592415736, f1: 0.4676354028659594\n",
            "epoch: 471, step: 12, Train: label_loss: 0.10096685588359833, precision: 0.3179640718562684, recall: 0.8954468802696635, f1: 0.4692885549767495\n",
            "epoch: 471, step: 13, Train: label_loss: 0.100468210875988, precision: 0.31768953068590144, recall: 0.8888888888887392, f1: 0.46808510634414274\n",
            "epoch: 471, step: 14, Train: label_loss: 0.09674085676670074, precision: 0.31234718826403957, recall: 0.8573825503354265, f1: 0.4578853046203127\n",
            "epoch: 471, step: 15, Train: label_loss: 0.10231629014015198, precision: 0.32322619769555344, recall: 0.8680781758956241, f1: 0.4710561201548494\n",
            "epoch: 471, step: 16, Train: label_loss: 0.10722486674785614, precision: 0.3138330286410534, recall: 0.878839590443536, f1: 0.4625056128933754\n",
            "epoch: 471, step: 17, Train: label_loss: 0.09658260643482208, precision: 0.2994522215459343, recall: 0.8692579505298816, f1: 0.4454504300206951\n",
            "epoch: 471, step: 18, Train: label_loss: 0.11467836797237396, precision: 0.3256797583081374, recall: 0.8693548387095371, f1: 0.47384615380646083\n",
            "epoch: 471, step: 19, Train: label_loss: 0.09758962690830231, precision: 0.3259170174383448, recall: 0.8756058158318456, f1: 0.475021910565156\n",
            "epoch: 471, step: 20, Train: label_loss: 0.09936274588108063, precision: 0.31373725254947127, recall: 0.8702163061562611, f1: 0.461199294493633\n",
            "epoch: 471, step: 21, Train: label_loss: 0.09803403168916702, precision: 0.32085561497324294, recall: 0.9060402684562238, f1: 0.4738920578814735\n",
            "epoch: 471, step: 22, Train: label_loss: 0.1011633649468422, precision: 0.3211900425014984, recall: 0.8831385642736421, f1: 0.4710596615815031\n",
            "epoch: 471, step: 23, Train: label_loss: 0.10155730694532394, precision: 0.32329169728138696, recall: 0.8924949290059042, f1: 0.4746494066491499\n",
            "epoch: 472, step: 0, Train: label_loss: 0.10681522637605667, precision: 0.32926084300547775, recall: 0.8778501628663065, f1: 0.47889826739697916\n",
            "epoch: 472, step: 1, Train: label_loss: 0.08345863223075867, precision: 0.33293697978594927, recall: 0.9195402298849064, f1: 0.48886948926690504\n",
            "epoch: 472, step: 2, Train: label_loss: 0.09942677617073059, precision: 0.3029394121175583, recall: 0.8752166377814774, f1: 0.4500891265214718\n",
            "epoch: 472, step: 3, Train: label_loss: 0.11207228153944016, precision: 0.3022685469037215, recall: 0.8529411764704407, f1: 0.44635581707313643\n",
            "epoch: 472, step: 4, Train: label_loss: 0.10032088309526443, precision: 0.32548309178741996, recall: 0.880718954248222, f1: 0.47530864193586136\n",
            "epoch: 472, step: 5, Train: label_loss: 0.10002414137125015, precision: 0.3106562311860138, recall: 0.8775510204080139, f1: 0.45887060912096694\n",
            "epoch: 472, step: 6, Train: label_loss: 0.098672054708004, precision: 0.30891330891329005, recall: 0.8532883642494344, f1: 0.4536082473836096\n",
            "epoch: 472, step: 7, Train: label_loss: 0.11264658719301224, precision: 0.30218446601939913, recall: 0.8691099476438273, f1: 0.44844664561678355\n",
            "epoch: 472, step: 8, Train: label_loss: 0.09674198925495148, precision: 0.3054720384846479, recall: 0.8788927335638617, f1: 0.45336903164396464\n",
            "epoch: 472, step: 9, Train: label_loss: 0.10379132628440857, precision: 0.3163636363636172, recall: 0.8543371522093528, f1: 0.46174259173406906\n",
            "epoch: 472, step: 10, Train: label_loss: 0.09128294885158539, precision: 0.31468110709986075, recall: 0.868770764119457, f1: 0.462014134236538\n",
            "epoch: 472, step: 11, Train: label_loss: 0.10628685355186462, precision: 0.31661631419937664, recall: 0.8661157024791957, f1: 0.46371681412004373\n",
            "epoch: 472, step: 12, Train: label_loss: 0.10628534108400345, precision: 0.3036585365853473, recall: 0.8483816013627175, f1: 0.4472384373208151\n",
            "epoch: 472, step: 13, Train: label_loss: 0.10423901677131653, precision: 0.352587244283974, recall: 0.8960244648316672, f1: 0.5060449049680632\n",
            "epoch: 472, step: 14, Train: label_loss: 0.10974732786417007, precision: 0.2931968693557921, recall: 0.8790613718409965, f1: 0.4397291196012752\n",
            "epoch: 472, step: 15, Train: label_loss: 0.09364186227321625, precision: 0.31864815932406043, recall: 0.8799999999998532, f1: 0.4678777137402779\n",
            "epoch: 472, step: 16, Train: label_loss: 0.08824697881937027, precision: 0.31619844590553997, recall: 0.8846153846152366, f1: 0.465874064250022\n",
            "epoch: 472, step: 17, Train: label_loss: 0.09030754864215851, precision: 0.34393757502999134, recall: 0.8828967642525604, f1: 0.49503239736781424\n",
            "epoch: 472, step: 18, Train: label_loss: 0.11309698969125748, precision: 0.3282396088019359, recall: 0.8803278688523146, f1: 0.4781834371821188\n",
            "epoch: 472, step: 19, Train: label_loss: 0.09874917566776276, precision: 0.314859926918373, recall: 0.8703703703702238, f1: 0.46243291588223034\n",
            "epoch: 472, step: 20, Train: label_loss: 0.08995378017425537, precision: 0.34839476813315406, recall: 0.9272151898732709, f1: 0.5064822817234317\n",
            "epoch: 472, step: 21, Train: label_loss: 0.10585211962461472, precision: 0.3216444981861958, recall: 0.8525641025639659, f1: 0.46707638275210367\n",
            "epoch: 472, step: 22, Train: label_loss: 0.09759431332349777, precision: 0.32159904534604283, recall: 0.9043624161072308, f1: 0.4744718309471716\n",
            "epoch: 472, step: 23, Train: label_loss: 0.11024628579616547, precision: 0.31231231231228884, recall: 0.8648648648646851, f1: 0.45890788744028166\n",
            "epoch: 473, step: 0, Train: label_loss: 0.09885738044977188, precision: 0.33990442054956155, recall: 0.8862928348908277, f1: 0.4913644213761202\n",
            "epoch: 473, step: 1, Train: label_loss: 0.102542445063591, precision: 0.3477998794454281, recall: 0.9043887147334005, f1: 0.5023944274739839\n",
            "epoch: 473, step: 2, Train: label_loss: 0.10278154909610748, precision: 0.30727600721585646, recall: 0.8675721561967966, f1: 0.45381882767003523\n",
            "epoch: 473, step: 3, Train: label_loss: 0.09339899569749832, precision: 0.31610576923075023, recall: 0.8915254237286624, f1: 0.46672582072439844\n",
            "epoch: 473, step: 4, Train: label_loss: 0.09256571531295776, precision: 0.3166465621230207, recall: 0.8853288364248085, f1: 0.4664593513605289\n",
            "epoch: 473, step: 5, Train: label_loss: 0.09711667895317078, precision: 0.30476765238380776, recall: 0.8737024221451775, f1: 0.45190156595713876\n",
            "epoch: 473, step: 6, Train: label_loss: 0.0911669209599495, precision: 0.32887537993918975, recall: 0.8587301587300223, f1: 0.4756043955643064\n",
            "epoch: 473, step: 7, Train: label_loss: 0.0924597978591919, precision: 0.31119090365049007, recall: 0.8828522920202235, f1: 0.46017699111186233\n",
            "epoch: 473, step: 8, Train: label_loss: 0.10340035706758499, precision: 0.30778515389255834, recall: 0.8916083916082357, f1: 0.4576043068258705\n",
            "epoch: 473, step: 9, Train: label_loss: 0.10230274498462677, precision: 0.3083941605839228, recall: 0.8492462311556366, f1: 0.4524765729193741\n",
            "epoch: 473, step: 10, Train: label_loss: 0.11093760281801224, precision: 0.28262176788933957, recall: 0.8834586466163752, f1: 0.42824601363066167\n",
            "epoch: 473, step: 11, Train: label_loss: 0.08910243213176727, precision: 0.3171462829736021, recall: 0.8700657894735411, f1: 0.46485061507503983\n",
            "epoch: 473, step: 12, Train: label_loss: 0.10802324116230011, precision: 0.3118148599268994, recall: 0.8707482993195798, f1: 0.4591928250732361\n",
            "epoch: 473, step: 13, Train: label_loss: 0.10782459378242493, precision: 0.329483282674752, recall: 0.8756058158318456, f1: 0.4787985865326645\n",
            "epoch: 473, step: 14, Train: label_loss: 0.10380154848098755, precision: 0.3268529769137104, recall: 0.8747967479673374, f1: 0.4758956213668117\n",
            "epoch: 473, step: 15, Train: label_loss: 0.1071452796459198, precision: 0.3053527980535094, recall: 0.8685121107264933, f1: 0.45184518447991906\n",
            "epoch: 473, step: 16, Train: label_loss: 0.09369692206382751, precision: 0.3217286914765713, recall: 0.8948247078462612, f1: 0.47328918318401214\n",
            "epoch: 473, step: 17, Train: label_loss: 0.10554163157939911, precision: 0.3007883565797271, recall: 0.8717047451668063, f1: 0.4472497745335007\n",
            "epoch: 473, step: 18, Train: label_loss: 0.10888262093067169, precision: 0.31374924288308215, recall: 0.8647746243738121, f1: 0.4604444444053339\n",
            "epoch: 473, step: 19, Train: label_loss: 0.09510038048028946, precision: 0.3345345345345144, recall: 0.8785488958989149, f1: 0.4845585036572731\n",
            "epoch: 473, step: 20, Train: label_loss: 0.09332028776407242, precision: 0.31726190476188587, recall: 0.9033898305083214, f1: 0.4696035241905619\n",
            "epoch: 473, step: 21, Train: label_loss: 0.09622476994991302, precision: 0.309178743961334, recall: 0.8737201365186221, f1: 0.4567350579452907\n",
            "epoch: 473, step: 22, Train: label_loss: 0.0881555825471878, precision: 0.3558823529411555, recall: 0.9097744360900887, f1: 0.511627906936277\n",
            "epoch: 473, step: 23, Train: label_loss: 0.09464822709560394, precision: 0.3399558498895997, recall: 0.8901734104044526, f1: 0.49201277951266637\n",
            "epoch: 474, step: 0, Train: label_loss: 0.09482158720493317, precision: 0.3071776155717575, recall: 0.8458961474035434, f1: 0.45069165547180634\n",
            "epoch: 474, step: 1, Train: label_loss: 0.09930748492479324, precision: 0.30787589498804846, recall: 0.8927335640136863, f1: 0.4578527062617356\n",
            "epoch: 474, step: 2, Train: label_loss: 0.09037955850362778, precision: 0.3269346130773649, recall: 0.9008264462808427, f1: 0.47975352108764285\n",
            "epoch: 474, step: 3, Train: label_loss: 0.08499285578727722, precision: 0.314814814814796, recall: 0.8857142857141368, f1: 0.46452181573914175\n",
            "epoch: 474, step: 4, Train: label_loss: 0.08810757100582123, precision: 0.33412745681951556, recall: 0.9048387096772733, f1: 0.4880382774725285\n",
            "epoch: 474, step: 5, Train: label_loss: 0.09455201029777527, precision: 0.3187011425135106, recall: 0.886287625417912, f1: 0.4688191065510564\n",
            "epoch: 474, step: 6, Train: label_loss: 0.1047588437795639, precision: 0.29018404907973677, recall: 0.835689045936248, f1: 0.4307832422203507\n",
            "epoch: 474, step: 7, Train: label_loss: 0.08370637148618698, precision: 0.336710369487465, recall: 0.8841940532079993, f1: 0.4876996115266931\n",
            "epoch: 474, step: 8, Train: label_loss: 0.10678891837596893, precision: 0.3036585365853473, recall: 0.8645833333331832, f1: 0.44945848371599895\n",
            "epoch: 474, step: 9, Train: label_loss: 0.10238602757453918, precision: 0.310262529832917, recall: 0.8858603066438013, f1: 0.4595669464926913\n",
            "epoch: 474, step: 10, Train: label_loss: 0.11182933300733566, precision: 0.31398900427609566, recall: 0.860971524287963, f1: 0.4601611458873839\n",
            "epoch: 474, step: 11, Train: label_loss: 0.10231560468673706, precision: 0.30629539951571993, recall: 0.8547297297295853, f1: 0.45098039211797925\n",
            "epoch: 474, step: 12, Train: label_loss: 0.09968028962612152, precision: 0.3216867469879324, recall: 0.8797364085665765, f1: 0.47110719007984614\n",
            "epoch: 474, step: 13, Train: label_loss: 0.09651526808738708, precision: 0.33213644524235, recall: 0.8966074313407275, f1: 0.4847161571657498\n",
            "epoch: 474, step: 14, Train: label_loss: 0.07867589592933655, precision: 0.3068249258160055, recall: 0.8929188255611583, f1: 0.45671378088061987\n",
            "epoch: 474, step: 15, Train: label_loss: 0.09272012114524841, precision: 0.3475935828876799, recall: 0.9374999999998497, f1: 0.5071521456041849\n",
            "epoch: 474, step: 16, Train: label_loss: 0.08842619508504868, precision: 0.3236342042755152, recall: 0.9038142620230672, f1: 0.47660690857503385\n",
            "epoch: 474, step: 17, Train: label_loss: 0.10520748794078827, precision: 0.33615990308901655, recall: 0.8851674641146913, f1: 0.4872695346396038\n",
            "epoch: 474, step: 18, Train: label_loss: 0.10215510427951813, precision: 0.32041187159295453, recall: 0.8846153846152366, f1: 0.4704313027621641\n",
            "epoch: 474, step: 19, Train: label_loss: 0.08798565715551376, precision: 0.3178294573643221, recall: 0.8942953020132727, f1: 0.4689837219146333\n",
            "epoch: 474, step: 20, Train: label_loss: 0.10665861517190933, precision: 0.32930513595164174, recall: 0.8733974358972959, f1: 0.47827994730551776\n",
            "epoch: 474, step: 21, Train: label_loss: 0.11096985638141632, precision: 0.3114061557030591, recall: 0.8760611205431449, f1: 0.4594835262301872\n",
            "epoch: 474, step: 22, Train: label_loss: 0.10191889107227325, precision: 0.3327316486161051, recall: 0.8904991948468775, f1: 0.4844502846734502\n",
            "epoch: 474, step: 23, Train: label_loss: 0.09579207003116608, precision: 0.31021897810216714, recall: 0.8817427385890287, f1: 0.4589632828988106\n",
            "epoch: 475, step: 0, Train: label_loss: 0.10435806214809418, precision: 0.30580490724115467, recall: 0.882556131260642, f1: 0.4542222221839593\n",
            "epoch: 475, step: 1, Train: label_loss: 0.08602560311555862, precision: 0.32464454976301393, recall: 0.9057851239667923, f1: 0.4779764500265285\n",
            "epoch: 475, step: 2, Train: label_loss: 0.08835721015930176, precision: 0.3241461953265234, recall: 0.8839869281044307, f1: 0.4743533537528915\n",
            "epoch: 475, step: 3, Train: label_loss: 0.09815952181816101, precision: 0.3118872549019417, recall: 0.8700854700853213, f1: 0.4591790707775286\n",
            "epoch: 475, step: 4, Train: label_loss: 0.10989271104335785, precision: 0.3256379100850349, recall: 0.8758169934639091, f1: 0.47475642157248893\n",
            "epoch: 475, step: 5, Train: label_loss: 0.10128378868103027, precision: 0.32538226299692197, recall: 0.8735632183906611, f1: 0.4741532976431196\n",
            "epoch: 475, step: 6, Train: label_loss: 0.0926448404788971, precision: 0.3178294573643221, recall: 0.8957983193275805, f1: 0.4691901408063689\n",
            "epoch: 475, step: 7, Train: label_loss: 0.10397631675004959, precision: 0.2914147521160646, recall: 0.8515901060069166, f1: 0.4342342341962045\n",
            "epoch: 475, step: 8, Train: label_loss: 0.09266361594200134, precision: 0.30787448194195927, recall: 0.8919382504286634, f1: 0.4577464788350476\n",
            "epoch: 475, step: 9, Train: label_loss: 0.08951056003570557, precision: 0.32953181272507026, recall: 0.8728139904609105, f1: 0.47843137250918644\n",
            "epoch: 475, step: 10, Train: label_loss: 0.09694872051477432, precision: 0.3170433720219721, recall: 0.8494271685759657, f1: 0.46174377220236706\n",
            "epoch: 475, step: 11, Train: label_loss: 0.08980520069599152, precision: 0.3456716417910241, recall: 0.9018691588783642, f1: 0.49978420367159143\n",
            "epoch: 475, step: 12, Train: label_loss: 0.0977792739868164, precision: 0.3307276007215676, recall: 0.8799999999998591, f1: 0.4807692307294796\n",
            "epoch: 475, step: 13, Train: label_loss: 0.09312079846858978, precision: 0.30801944106924006, recall: 0.874137931034332, f1: 0.45552560643042833\n",
            "epoch: 475, step: 14, Train: label_loss: 0.12025922536849976, precision: 0.31693648816934517, recall: 0.8092209856914452, f1: 0.45548098429955847\n",
            "epoch: 475, step: 15, Train: label_loss: 0.10216937959194183, precision: 0.3367346938775308, recall: 0.8890649762280682, f1: 0.4884632128464824\n",
            "epoch: 475, step: 16, Train: label_loss: 0.09359343349933624, precision: 0.32093581283741324, recall: 0.8901830282860415, f1: 0.47178130507564253\n",
            "epoch: 475, step: 17, Train: label_loss: 0.10529011487960815, precision: 0.3060606060605875, recall: 0.8906525573190668, f1: 0.4555705908504786\n",
            "epoch: 475, step: 18, Train: label_loss: 0.10448858141899109, precision: 0.32052821128449455, recall: 0.8841059602647542, f1: 0.47048458145869965\n",
            "epoch: 475, step: 19, Train: label_loss: 0.09227417409420013, precision: 0.3237237237237043, recall: 0.8879736408565259, f1: 0.4744718309467162\n",
            "epoch: 475, step: 20, Train: label_loss: 0.10671442747116089, precision: 0.3063549160671279, recall: 0.8964912280700181, f1: 0.4566577300781695\n",
            "epoch: 475, step: 21, Train: label_loss: 0.08812564611434937, precision: 0.31421744324968254, recall: 0.8945578231290995, f1: 0.46507515469181104\n",
            "epoch: 475, step: 22, Train: label_loss: 0.09872113168239594, precision: 0.32735961768217875, recall: 0.8939641109297073, f1: 0.47923043284222355\n",
            "epoch: 475, step: 23, Train: label_loss: 0.11157655715942383, precision: 0.3068432671081452, recall: 0.8760504201678833, f1: 0.4544959127680676\n",
            "epoch: 476, step: 0, Train: label_loss: 0.09216560423374176, precision: 0.3238498789346051, recall: 0.8887043189367294, f1: 0.4747116237407549\n",
            "epoch: 476, step: 1, Train: label_loss: 0.09694509208202362, precision: 0.3029751062537764, recall: 0.8573883161510554, f1: 0.44773441001072356\n",
            "epoch: 476, step: 2, Train: label_loss: 0.08142721652984619, precision: 0.32162001191183315, recall: 0.8881578947366959, f1: 0.47223436812882946\n",
            "epoch: 476, step: 3, Train: label_loss: 0.10788081586360931, precision: 0.30619684082622683, recall: 0.8780487804876519, f1: 0.4540540540156719\n",
            "epoch: 476, step: 4, Train: label_loss: 0.10872630029916763, precision: 0.33090909090907084, recall: 0.8680445151032006, f1: 0.4791575251903575\n",
            "epoch: 476, step: 5, Train: label_loss: 0.0904858410358429, precision: 0.33116499112948955, recall: 0.8903020667725134, f1: 0.4827586206500907\n",
            "epoch: 476, step: 6, Train: label_loss: 0.09758220613002777, precision: 0.3382966051220763, recall: 0.9146537842188542, f1: 0.4939130434387979\n",
            "epoch: 476, step: 7, Train: label_loss: 0.09309492260217667, precision: 0.33971291866026676, recall: 0.9044585987259706, f1: 0.49391304343851977\n",
            "epoch: 476, step: 8, Train: label_loss: 0.09340383112430573, precision: 0.3339371980676127, recall: 0.8736176935227687, f1: 0.48318042809450124\n",
            "epoch: 476, step: 9, Train: label_loss: 0.10148216784000397, precision: 0.31156381066505023, recall: 0.890410958903957, f1: 0.46160674652169703\n",
            "epoch: 476, step: 10, Train: label_loss: 0.08954083174467087, precision: 0.3200483091787246, recall: 0.8731466227346172, f1: 0.46840477238668543\n",
            "epoch: 476, step: 11, Train: label_loss: 0.09458918124437332, precision: 0.3303303303303105, recall: 0.8972267536703267, f1: 0.4828797190124208\n",
            "epoch: 476, step: 12, Train: label_loss: 0.10288448631763458, precision: 0.30487071557424505, recall: 0.8848167539265471, f1: 0.4534883720548644\n",
            "epoch: 476, step: 13, Train: label_loss: 0.09208596497774124, precision: 0.2982035928143534, recall: 0.8892857142855554, f1: 0.44663677126279644\n",
            "epoch: 476, step: 14, Train: label_loss: 0.09077979624271393, precision: 0.29836264402666474, recall: 0.8723404255317602, f1: 0.44464527786527747\n",
            "epoch: 476, step: 15, Train: label_loss: 0.10961513221263885, precision: 0.3260073260073061, recall: 0.8503184713374442, f1: 0.4713150926342076\n",
            "epoch: 476, step: 16, Train: label_loss: 0.11106069386005402, precision: 0.3176761433868778, recall: 0.838499184339178, f1: 0.460779919278796\n",
            "epoch: 476, step: 17, Train: label_loss: 0.10072380304336548, precision: 0.33133971291864045, recall: 0.9052287581697867, f1: 0.48511383533725927\n",
            "epoch: 476, step: 18, Train: label_loss: 0.11469637602567673, precision: 0.30275779376496986, recall: 0.8797909407663972, f1: 0.4504906333249336\n",
            "epoch: 476, step: 19, Train: label_loss: 0.10525865852832794, precision: 0.3147581139007768, recall: 0.8566666666665238, f1: 0.4603672189485676\n",
            "epoch: 476, step: 20, Train: label_loss: 0.09754233062267303, precision: 0.3118932038834762, recall: 0.859531772575107, f1: 0.45770258232954225\n",
            "epoch: 476, step: 21, Train: label_loss: 0.08843601495027542, precision: 0.318289786223259, recall: 0.8888888888887414, f1: 0.4687363357722361\n",
            "epoch: 476, step: 22, Train: label_loss: 0.10730622708797455, precision: 0.32303030303028346, recall: 0.876644736841961, f1: 0.4720992027949726\n",
            "epoch: 476, step: 23, Train: label_loss: 0.09812590479850769, precision: 0.31185185185182873, recall: 0.8844537815124193, f1: 0.46111719601835954\n",
            "epoch: 477, step: 0, Train: label_loss: 0.12238838523626328, precision: 0.2938623682578863, recall: 0.8315789473682751, f1: 0.43426477320919815\n",
            "epoch: 477, step: 1, Train: label_loss: 0.09992924332618713, precision: 0.30718562874249655, recall: 0.882960413080743, f1: 0.4557974233290542\n",
            "epoch: 477, step: 2, Train: label_loss: 0.10578006505966187, precision: 0.33312921004284546, recall: 0.8540031397172914, f1: 0.47929515414460555\n",
            "epoch: 477, step: 3, Train: label_loss: 0.09527559578418732, precision: 0.3357357357357156, recall: 0.9074675324673851, f1: 0.4901359052652227\n",
            "epoch: 477, step: 4, Train: label_loss: 0.09577639400959015, precision: 0.30592503022972756, recall: 0.8679245283017378, f1: 0.4523915958487694\n",
            "epoch: 477, step: 5, Train: label_loss: 0.09915894269943237, precision: 0.31862152357918266, recall: 0.8827470686765689, f1: 0.4682363393656922\n",
            "epoch: 477, step: 6, Train: label_loss: 0.09439658373594284, precision: 0.3239780353874116, recall: 0.8550724637679782, f1: 0.46991150438488205\n",
            "epoch: 477, step: 7, Train: label_loss: 0.09238539636135101, precision: 0.3150932050510935, recall: 0.8941979522182774, f1: 0.4659848821312781\n",
            "epoch: 477, step: 8, Train: label_loss: 0.09413645416498184, precision: 0.34457831325299126, recall: 0.8923556942276298, f1: 0.4971751412027004\n",
            "epoch: 477, step: 9, Train: label_loss: 0.09638787806034088, precision: 0.32947624847744644, recall: 0.8600953895070174, f1: 0.476442095952861\n",
            "epoch: 477, step: 10, Train: label_loss: 0.09354335814714432, precision: 0.30847865303666216, recall: 0.882960413080743, f1: 0.4572192512984823\n",
            "epoch: 477, step: 11, Train: label_loss: 0.10054514557123184, precision: 0.31227217496960435, recall: 0.859531772575107, f1: 0.45811051689491106\n",
            "epoch: 477, step: 12, Train: label_loss: 0.08885478228330612, precision: 0.31985731272292983, recall: 0.9042016806721169, f1: 0.4725516029477388\n",
            "epoch: 477, step: 13, Train: label_loss: 0.09716373682022095, precision: 0.3251497005987829, recall: 0.8901639344260835, f1: 0.47631578943444947\n",
            "epoch: 477, step: 14, Train: label_loss: 0.08658639341592789, precision: 0.3178847296494166, recall: 0.9037162162160635, f1: 0.47032967029112777\n",
            "epoch: 477, step: 15, Train: label_loss: 0.11181142926216125, precision: 0.33150851581506496, recall: 0.8719999999998604, f1: 0.48038783601116586\n",
            "epoch: 477, step: 16, Train: label_loss: 0.09900228679180145, precision: 0.3082932692307507, recall: 0.8906249999998453, f1: 0.45803571424746925\n",
            "epoch: 477, step: 17, Train: label_loss: 0.09405877441167831, precision: 0.3161676646706397, recall: 0.8888888888887392, f1: 0.466431095367613\n",
            "epoch: 477, step: 18, Train: label_loss: 0.09912830591201782, precision: 0.31856287425147795, recall: 0.8764415156505969, f1: 0.4672815107206277\n",
            "epoch: 477, step: 19, Train: label_loss: 0.09573230147361755, precision: 0.3067632850241361, recall: 0.8743545611013985, f1: 0.45417970492350873\n",
            "epoch: 477, step: 20, Train: label_loss: 0.12451598048210144, precision: 0.2971014492753444, recall: 0.8801431127010947, f1: 0.44424379228728045\n",
            "epoch: 477, step: 21, Train: label_loss: 0.09789685159921646, precision: 0.32544019429263354, recall: 0.8729641693809652, f1: 0.47412649266273893\n",
            "epoch: 477, step: 22, Train: label_loss: 0.09106430411338806, precision: 0.33413606261286366, recall: 0.8795562599047734, f1: 0.4842931936773327\n",
            "epoch: 477, step: 23, Train: label_loss: 0.11713019013404846, precision: 0.30923994038745833, recall: 0.838383838383669, f1: 0.4518236254369005\n",
            "epoch: 478, step: 0, Train: label_loss: 0.09881571680307388, precision: 0.31226533166456116, recall: 0.8247933884296157, f1: 0.453018610945138\n",
            "epoch: 478, step: 1, Train: label_loss: 0.09879430383443832, precision: 0.31414868105513705, recall: 0.8866328257189701, f1: 0.4639220893814212\n",
            "epoch: 478, step: 2, Train: label_loss: 0.09434271603822708, precision: 0.3055222088835351, recall: 0.8914185639227861, f1: 0.455073759461269\n",
            "epoch: 478, step: 3, Train: label_loss: 0.09267615526914597, precision: 0.3281249999999803, recall: 0.8764044943818817, f1: 0.4774814166634222\n",
            "epoch: 478, step: 4, Train: label_loss: 0.09574529528617859, precision: 0.3253301320528016, recall: 0.8988391376449587, f1: 0.4777434992998477\n",
            "epoch: 478, step: 5, Train: label_loss: 0.09169011563062668, precision: 0.31487055990365354, recall: 0.8804713804712322, f1: 0.4638580930875392\n",
            "epoch: 478, step: 6, Train: label_loss: 0.09978505969047546, precision: 0.29216867469877755, recall: 0.8599290780140318, f1: 0.43615107909879425\n",
            "epoch: 478, step: 7, Train: label_loss: 0.09005270898342133, precision: 0.3259036144578117, recall: 0.8839869281044307, f1: 0.4762323943267936\n",
            "epoch: 478, step: 8, Train: label_loss: 0.10057732462882996, precision: 0.32934847579197074, recall: 0.8872785829306139, f1: 0.48038360937634067\n",
            "epoch: 478, step: 9, Train: label_loss: 0.11438242346048355, precision: 0.30006086427265366, recall: 0.8679577464787204, f1: 0.4459520578541359\n",
            "epoch: 478, step: 10, Train: label_loss: 0.10645528137683868, precision: 0.3214069132807567, recall: 0.877483443708464, f1: 0.4704837993393212\n",
            "epoch: 478, step: 11, Train: label_loss: 0.08837014436721802, precision: 0.3417796110783535, recall: 0.9148264984225686, f1: 0.497640497600853\n",
            "epoch: 478, step: 12, Train: label_loss: 0.11525951325893402, precision: 0.30091185410332516, recall: 0.8490566037734392, f1: 0.4443447037315178\n",
            "epoch: 478, step: 13, Train: label_loss: 0.10250134021043777, precision: 0.32164821648214503, recall: 0.8616144975286884, f1: 0.4684281235609076\n",
            "epoch: 478, step: 14, Train: label_loss: 0.10236652195453644, precision: 0.3219628964691609, recall: 0.884868421052486, f1: 0.4721369021109023\n",
            "epoch: 478, step: 15, Train: label_loss: 0.1075170487165451, precision: 0.3246200607902538, recall: 0.8585209003214053, f1: 0.47110719007924023\n",
            "epoch: 478, step: 16, Train: label_loss: 0.0992957204580307, precision: 0.3470873786407556, recall: 0.8854489164085316, f1: 0.49869224058722034\n",
            "epoch: 478, step: 17, Train: label_loss: 0.10608096420764923, precision: 0.30887792848333484, recall: 0.8462837837836408, f1: 0.45257452570603807\n",
            "epoch: 478, step: 18, Train: label_loss: 0.09797316044569016, precision: 0.3091905051734444, recall: 0.8865619546246271, f1: 0.4584837544742514\n",
            "epoch: 478, step: 19, Train: label_loss: 0.10302312672138214, precision: 0.33553025763928485, recall: 0.9135399673734235, f1: 0.4907975459729338\n",
            "epoch: 478, step: 20, Train: label_loss: 0.0976838618516922, precision: 0.32576210400476235, recall: 0.9128978224454082, f1: 0.4801762114149364\n",
            "epoch: 478, step: 21, Train: label_loss: 0.09833037853240967, precision: 0.3015776699028943, recall: 0.8628472222220723, f1: 0.44694244600474214\n",
            "epoch: 478, step: 22, Train: label_loss: 0.08667628467082977, precision: 0.3247298919567632, recall: 0.9001663893509317, f1: 0.47728275249738444\n",
            "epoch: 478, step: 23, Train: label_loss: 0.09843481332063675, precision: 0.34160583941603345, recall: 0.9158512720154763, f1: 0.49760765546276686\n",
            "epoch: 479, step: 0, Train: label_loss: 0.09153475612401962, precision: 0.33114166168557496, recall: 0.9008130081299348, f1: 0.4842657342263832\n",
            "epoch: 479, step: 1, Train: label_loss: 0.10800085961818695, precision: 0.3353474320241489, recall: 0.8922829581992134, f1: 0.4874835309220398\n",
            "epoch: 479, step: 2, Train: label_loss: 0.10762633383274078, precision: 0.33413606261286366, recall: 0.8951612903224362, f1: 0.486628671595619\n",
            "epoch: 479, step: 3, Train: label_loss: 0.09009978920221329, precision: 0.32895522388057735, recall: 0.8872785829306139, f1: 0.47996515675492\n",
            "epoch: 479, step: 4, Train: label_loss: 0.08596282452344894, precision: 0.3403235470341318, recall: 0.8902821316613024, f1: 0.49241439094390516\n",
            "epoch: 479, step: 5, Train: label_loss: 0.09817066043615341, precision: 0.2809057527539608, recall: 0.8211091234345579, f1: 0.41860465112476714\n",
            "epoch: 479, step: 6, Train: label_loss: 0.09976591169834137, precision: 0.32318928788799006, recall: 0.873355263157751, f1: 0.4717903153758996\n",
            "epoch: 479, step: 7, Train: label_loss: 0.08974553644657135, precision: 0.3038740920096668, recall: 0.8745644599301612, f1: 0.45103324344775936\n",
            "epoch: 479, step: 8, Train: label_loss: 0.09637782722711563, precision: 0.30210210210208394, recall: 0.8763066202089065, f1: 0.44930772662552065\n",
            "epoch: 479, step: 9, Train: label_loss: 0.11065895855426788, precision: 0.30152905198774915, recall: 0.8285714285712893, f1: 0.4421524663285483\n",
            "epoch: 479, step: 10, Train: label_loss: 0.10448205471038818, precision: 0.33110976349300597, recall: 0.88206785137304, f1: 0.48148148144175135\n",
            "epoch: 479, step: 11, Train: label_loss: 0.09093768894672394, precision: 0.316956261234253, recall: 0.8920741989880451, f1: 0.46772767458549874\n",
            "epoch: 479, step: 12, Train: label_loss: 0.08774584531784058, precision: 0.3279952550414989, recall: 0.8962722852510703, f1: 0.48024316105495624\n",
            "epoch: 479, step: 13, Train: label_loss: 0.0715010017156601, precision: 0.3268321513002171, recall: 0.9065573770490316, f1: 0.4804517810209524\n",
            "epoch: 479, step: 14, Train: label_loss: 0.10989929735660553, precision: 0.31386861313866704, recall: 0.870151770657526, f1: 0.4613321412216125\n",
            "epoch: 479, step: 15, Train: label_loss: 0.09378120303153992, precision: 0.3143028846153657, recall: 0.8760469011723825, f1: 0.46262715608670246\n",
            "epoch: 479, step: 16, Train: label_loss: 0.1150653064250946, precision: 0.3277982779827597, recall: 0.869494290375062, f1: 0.47610540415849506\n",
            "epoch: 479, step: 17, Train: label_loss: 0.09634092450141907, precision: 0.31231231231229356, recall: 0.8828522920202235, f1: 0.4614019520465352\n",
            "epoch: 479, step: 18, Train: label_loss: 0.09820646047592163, precision: 0.32219570405726, recall: 0.891089108910744, f1: 0.47326906218706866\n",
            "epoch: 479, step: 19, Train: label_loss: 0.10936542600393295, precision: 0.3079268292682739, recall: 0.8617747440271566, f1: 0.4537286612370001\n",
            "epoch: 479, step: 20, Train: label_loss: 0.09635412693023682, precision: 0.30852994555352037, recall: 0.8600337268126711, f1: 0.45414069452921757\n",
            "epoch: 479, step: 21, Train: label_loss: 0.1024748831987381, precision: 0.3213851761846706, recall: 0.861563517915169, f1: 0.4681415928807384\n",
            "epoch: 479, step: 22, Train: label_loss: 0.10183466970920563, precision: 0.30348557692305866, recall: 0.8844133099823319, f1: 0.45190156595744313\n",
            "epoch: 479, step: 23, Train: label_loss: 0.10043806582689285, precision: 0.32142857142854797, recall: 0.896341463414452, f1: 0.47317596562632935\n",
            "epoch: 480, step: 0, Train: label_loss: 0.09564598649740219, precision: 0.3103864734299329, recall: 0.8638655462183421, f1: 0.45668591733112546\n",
            "epoch: 480, step: 1, Train: label_loss: 0.09684453904628754, precision: 0.31426814268140746, recall: 0.8322475570031217, f1: 0.45624999996016474\n",
            "epoch: 480, step: 2, Train: label_loss: 0.09710507839918137, precision: 0.29372738238840207, recall: 0.8650088809945177, f1: 0.4385411976208263\n",
            "epoch: 480, step: 3, Train: label_loss: 0.12092461436986923, precision: 0.3118749999999805, recall: 0.8100649350648035, f1: 0.4503610107901429\n",
            "epoch: 480, step: 4, Train: label_loss: 0.11046165227890015, precision: 0.29236499068899485, recall: 0.8234265734264294, f1: 0.43151626198602344\n",
            "epoch: 480, step: 5, Train: label_loss: 0.10624724626541138, precision: 0.32360097323599, recall: 0.8444444444443103, f1: 0.46789797709270625\n",
            "epoch: 480, step: 6, Train: label_loss: 0.13506394624710083, precision: 0.2947434292865898, recall: 0.8425760286223895, f1: 0.43671766338297924\n",
            "epoch: 480, step: 7, Train: label_loss: 0.11263087391853333, precision: 0.3110018438844308, recall: 0.8419301164724056, f1: 0.4542190304812086\n",
            "epoch: 480, step: 8, Train: label_loss: 0.10709603875875473, precision: 0.3286413708690129, recall: 0.8390624999998688, f1: 0.47229551447138524\n",
            "epoch: 480, step: 9, Train: label_loss: 0.09845739603042603, precision: 0.3243902439024192, recall: 0.8822553897179299, f1: 0.4743646901077695\n",
            "epoch: 480, step: 10, Train: label_loss: 0.12623831629753113, precision: 0.32301980198017805, recall: 0.8432956381258734, f1: 0.4671140939196393\n",
            "epoch: 480, step: 11, Train: label_loss: 0.110852912068367, precision: 0.30079803560464696, recall: 0.8305084745761303, f1: 0.44164037850981797\n",
            "epoch: 480, step: 12, Train: label_loss: 0.09653189778327942, precision: 0.3323299217338752, recall: 0.900489396410946, f1: 0.48548812660965346\n",
            "epoch: 480, step: 13, Train: label_loss: 0.1051846593618393, precision: 0.3003058103975351, recall: 0.8509532062390206, f1: 0.4439421337769499\n",
            "epoch: 480, step: 14, Train: label_loss: 0.10457687824964523, precision: 0.31717791411040996, recall: 0.868907563025064, f1: 0.4647191010843728\n",
            "epoch: 480, step: 15, Train: label_loss: 0.1203995868563652, precision: 0.31904470300059284, recall: 0.8597359735972178, f1: 0.46538633314493544\n",
            "epoch: 480, step: 16, Train: label_loss: 0.10944390296936035, precision: 0.30564166150029104, recall: 0.823038397328744, f1: 0.4457504520400326\n",
            "epoch: 480, step: 17, Train: label_loss: 0.09227406978607178, precision: 0.34717208182910064, recall: 0.8836140888206916, f1: 0.4984881209097793\n",
            "epoch: 480, step: 18, Train: label_loss: 0.11290363222360611, precision: 0.2971813725490014, recall: 0.839100346020616, f1: 0.4389140271106543\n",
            "epoch: 480, step: 19, Train: label_loss: 0.10208766162395477, precision: 0.29796421961750164, recall: 0.8200339558572461, f1: 0.43710407235905346\n",
            "epoch: 480, step: 20, Train: label_loss: 0.1057639792561531, precision: 0.2942979767013921, recall: 0.8465608465606972, f1: 0.43676069149943836\n",
            "epoch: 480, step: 21, Train: label_loss: 0.10532569885253906, precision: 0.3107033639143541, recall: 0.8466666666665255, f1: 0.4545861297145968\n",
            "epoch: 480, step: 22, Train: label_loss: 0.08461929112672806, precision: 0.33432835820893525, recall: 0.8917197452227879, f1: 0.4863221884101399\n",
            "epoch: 480, step: 23, Train: label_loss: 0.10440736263990402, precision: 0.33433283358318333, recall: 0.8710937499998298, f1: 0.4832069338710209\n",
            "epoch: 481, step: 0, Train: label_loss: 0.10401000827550888, precision: 0.31856287425147795, recall: 0.8896321070232626, f1: 0.469135802430265\n",
            "epoch: 481, step: 1, Train: label_loss: 0.09566378593444824, precision: 0.32587666263601417, recall: 0.8679549114330325, f1: 0.47384615380642103\n",
            "epoch: 481, step: 2, Train: label_loss: 0.09510168433189392, precision: 0.3250303766706971, recall: 0.8784893267650445, f1: 0.4745011086079819\n",
            "epoch: 481, step: 3, Train: label_loss: 0.10831265151500702, precision: 0.3022113022112836, recall: 0.8497409326423402, f1: 0.4458541005502902\n",
            "epoch: 481, step: 4, Train: label_loss: 0.1035982072353363, precision: 0.29908814589663835, recall: 0.8482758620688192, f1: 0.44224719097265147\n",
            "epoch: 481, step: 5, Train: label_loss: 0.0909983366727829, precision: 0.33453887884265615, recall: 0.872641509433825, f1: 0.48366013067884683\n",
            "epoch: 481, step: 6, Train: label_loss: 0.10935607552528381, precision: 0.31771150334751563, recall: 0.8529411764704488, f1: 0.4629711751267079\n",
            "epoch: 481, step: 7, Train: label_loss: 0.10509008169174194, precision: 0.32972972972970993, recall: 0.8869143780289358, f1: 0.48073555162419246\n",
            "epoch: 481, step: 8, Train: label_loss: 0.10798094421625137, precision: 0.3004239854633373, recall: 0.8596187175041837, f1: 0.44524236979999854\n",
            "epoch: 481, step: 9, Train: label_loss: 0.11073414981365204, precision: 0.30398069963809987, recall: 0.8659793814431501, f1: 0.4499999999614969\n",
            "epoch: 481, step: 10, Train: label_loss: 0.09704065322875977, precision: 0.3311138014527645, recall: 0.8738019169327677, f1: 0.4802458296352543\n",
            "epoch: 481, step: 11, Train: label_loss: 0.09090575575828552, precision: 0.316956261234253, recall: 0.8801996672211513, f1: 0.46607929511521173\n",
            "epoch: 481, step: 12, Train: label_loss: 0.101676344871521, precision: 0.31480362537762446, recall: 0.8697829716192204, f1: 0.4622892634924331\n",
            "epoch: 481, step: 13, Train: label_loss: 0.10995568335056305, precision: 0.31376146788988907, recall: 0.878424657534096, f1: 0.462370437095019\n",
            "epoch: 481, step: 14, Train: label_loss: 0.08974547684192657, precision: 0.3214069132807567, recall: 0.877483443708464, f1: 0.4704837993393212\n",
            "epoch: 481, step: 15, Train: label_loss: 0.09940652549266815, precision: 0.3145454545454355, recall: 0.8826530612243396, f1: 0.4638069704706009\n",
            "epoch: 481, step: 16, Train: label_loss: 0.09076601266860962, precision: 0.3309352517985413, recall: 0.9093904448103938, f1: 0.48527472523555776\n",
            "epoch: 481, step: 17, Train: label_loss: 0.09435423463582993, precision: 0.309952038369286, recall: 0.8807495741054717, f1: 0.4585365853273031\n",
            "epoch: 481, step: 18, Train: label_loss: 0.10177541524171829, precision: 0.30746089049336295, recall: 0.8856152512996731, f1: 0.4564537739679535\n",
            "epoch: 481, step: 19, Train: label_loss: 0.09603201597929001, precision: 0.32429174201324146, recall: 0.8677419354837309, f1: 0.4721369021104167\n",
            "epoch: 481, step: 20, Train: label_loss: 0.0967995673418045, precision: 0.32085561497324294, recall: 0.9152542372879804, f1: 0.47514298280357853\n",
            "epoch: 481, step: 21, Train: label_loss: 0.08997124433517456, precision: 0.32217573221755397, recall: 0.880718954248222, f1: 0.4717724288447652\n",
            "epoch: 481, step: 22, Train: label_loss: 0.09825856983661652, precision: 0.30476765238380776, recall: 0.8647260273971121, f1: 0.45069165547235507\n",
            "epoch: 481, step: 23, Train: label_loss: 0.10719975084066391, precision: 0.33653846153843664, recall: 0.8633776091079954, f1: 0.48430015961898054\n",
            "epoch: 482, step: 0, Train: label_loss: 0.10634193569421768, precision: 0.3391883706844131, recall: 0.8860759493669483, f1: 0.4905825667579908\n",
            "epoch: 482, step: 1, Train: label_loss: 0.10984623432159424, precision: 0.32648125755741675, recall: 0.8809135399672298, f1: 0.4764005292944225\n",
            "epoch: 482, step: 2, Train: label_loss: 0.09396080672740936, precision: 0.31483715319660344, recall: 0.8685524126454461, f1: 0.46215139438321656\n",
            "epoch: 482, step: 3, Train: label_loss: 0.09411458671092987, precision: 0.3267973856208956, recall: 0.9046052631577459, f1: 0.4801396769579114\n",
            "epoch: 482, step: 4, Train: label_loss: 0.10419666767120361, precision: 0.282687651331702, recall: 0.8521897810217423, f1: 0.42454545450800696\n",
            "epoch: 482, step: 5, Train: label_loss: 0.09694686532020569, precision: 0.330930930930911, recall: 0.8930307941651713, f1: 0.48290972826900425\n",
            "epoch: 482, step: 6, Train: label_loss: 0.11329183727502823, precision: 0.2950310559006028, recall: 0.8467023172904016, f1: 0.43758636569171144\n",
            "epoch: 482, step: 7, Train: label_loss: 0.1019330844283104, precision: 0.3080625752105711, recall: 0.8752136752135256, f1: 0.455718736054014\n",
            "epoch: 482, step: 8, Train: label_loss: 0.09316618740558624, precision: 0.3259833134683953, recall: 0.9286926994905044, f1: 0.48257609171270827\n",
            "epoch: 482, step: 9, Train: label_loss: 0.08526081591844559, precision: 0.33451746595616727, recall: 0.8883647798740741, f1: 0.48602150533655836\n",
            "epoch: 482, step: 10, Train: label_loss: 0.10242590308189392, precision: 0.3165769000598255, recall: 0.8920741989880451, f1: 0.4673144875938034\n",
            "epoch: 482, step: 11, Train: label_loss: 0.09571616351604462, precision: 0.32531569452794196, recall: 0.8825448613375395, f1: 0.4753954305405646\n",
            "epoch: 482, step: 12, Train: label_loss: 0.09446820616722107, precision: 0.3405405405405201, recall: 0.8985736925513631, f1: 0.4939024389844879\n",
            "epoch: 482, step: 13, Train: label_loss: 0.0910930335521698, precision: 0.3335332933413117, recall: 0.8910256410254982, f1: 0.4853775643426864\n",
            "epoch: 482, step: 14, Train: label_loss: 0.09519605338573456, precision: 0.3204353083433905, recall: 0.8674304418983849, f1: 0.46799116993848594\n",
            "epoch: 482, step: 15, Train: label_loss: 0.09758605062961578, precision: 0.3014440433212815, recall: 0.8743455497380672, f1: 0.4483221476128371\n",
            "epoch: 482, step: 16, Train: label_loss: 0.09567397087812424, precision: 0.2963855421686568, recall: 0.8801431127010947, f1: 0.4434429923011605\n",
            "epoch: 482, step: 17, Train: label_loss: 0.09417299926280975, precision: 0.3287342531493504, recall: 0.8852988691436372, f1: 0.47944006995171756\n",
            "epoch: 482, step: 18, Train: label_loss: 0.10686753690242767, precision: 0.30310407790625055, recall: 0.8571428571427095, f1: 0.44784172658006594\n",
            "epoch: 482, step: 19, Train: label_loss: 0.10343082249164581, precision: 0.3361650485436689, recall: 0.8807631160570936, f1: 0.48660518221732696\n",
            "epoch: 482, step: 20, Train: label_loss: 0.09483550488948822, precision: 0.31733653269344225, recall: 0.8714991762766273, f1: 0.46525945466618823\n",
            "epoch: 482, step: 21, Train: label_loss: 0.10082520544528961, precision: 0.3430962343096029, recall: 0.8940809968845959, f1: 0.49589632825361063\n",
            "epoch: 482, step: 22, Train: label_loss: 0.10876397043466568, precision: 0.30282962071039715, recall: 0.8702422145327213, f1: 0.4493077266253471\n",
            "epoch: 482, step: 23, Train: label_loss: 0.0885978490114212, precision: 0.30418809698748683, recall: 0.8827292110872319, f1: 0.45245901635527264\n",
            "epoch: 483, step: 0, Train: label_loss: 0.09043309092521667, precision: 0.3189812007276944, recall: 0.8637110016418942, f1: 0.4658990256470138\n",
            "epoch: 483, step: 1, Train: label_loss: 0.09221252799034119, precision: 0.3139604553624737, recall: 0.8762541806018601, f1: 0.46228495805551656\n",
            "epoch: 483, step: 2, Train: label_loss: 0.09974153339862823, precision: 0.32670283303192726, recall: 0.8943894389437468, f1: 0.4785871964287556\n",
            "epoch: 483, step: 3, Train: label_loss: 0.09222641587257385, precision: 0.3132817153067115, recall: 0.878130217028234, f1: 0.46180860399982837\n",
            "epoch: 483, step: 4, Train: label_loss: 0.11302672326564789, precision: 0.30992736077479965, recall: 0.8752136752135256, f1: 0.4577559230726443\n",
            "epoch: 483, step: 5, Train: label_loss: 0.09958454221487045, precision: 0.3151183970855911, recall: 0.8649999999998558, f1: 0.461949265648398\n",
            "epoch: 483, step: 6, Train: label_loss: 0.09787403047084808, precision: 0.3117754728492793, recall: 0.855946398659823, f1: 0.45706618958514644\n",
            "epoch: 483, step: 7, Train: label_loss: 0.09914793074131012, precision: 0.3164251207729277, recall: 0.8821548821547336, f1: 0.46577777773887546\n",
            "epoch: 483, step: 8, Train: label_loss: 0.09560500830411911, precision: 0.3271196632591505, recall: 0.8859934853418752, f1: 0.4778216951735695\n",
            "epoch: 483, step: 9, Train: label_loss: 0.108085498213768, precision: 0.31421598535690576, recall: 0.8848797250857585, f1: 0.46375506524719007\n",
            "epoch: 483, step: 10, Train: label_loss: 0.10278582572937012, precision: 0.3249097472923992, recall: 0.878048780487662, f1: 0.4743083003557867\n",
            "epoch: 483, step: 11, Train: label_loss: 0.0965692549943924, precision: 0.3108839446782735, recall: 0.8762711864405294, f1: 0.4589436306759028\n",
            "epoch: 483, step: 12, Train: label_loss: 0.1052178293466568, precision: 0.3367531683765639, recall: 0.9117647058822039, f1: 0.49184662843125426\n",
            "epoch: 483, step: 13, Train: label_loss: 0.08677108585834503, precision: 0.313549160671444, recall: 0.8702163061562611, f1: 0.4609960334559478\n",
            "epoch: 483, step: 14, Train: label_loss: 0.09297531843185425, precision: 0.30612244897957347, recall: 0.8688245315160359, f1: 0.4527296937031056\n",
            "epoch: 483, step: 15, Train: label_loss: 0.08561266958713531, precision: 0.3191489361701939, recall: 0.9168081494056167, f1: 0.4734765453364856\n",
            "epoch: 483, step: 16, Train: label_loss: 0.11316476762294769, precision: 0.3055214723926193, recall: 0.834170854271217, f1: 0.44723843732039453\n",
            "epoch: 483, step: 17, Train: label_loss: 0.10509712994098663, precision: 0.3260738052026421, recall: 0.880718954248222, f1: 0.4759381898059943\n",
            "epoch: 483, step: 18, Train: label_loss: 0.10312516987323761, precision: 0.3172787477423048, recall: 0.875415282391881, f1: 0.4657534246184426\n",
            "epoch: 483, step: 19, Train: label_loss: 0.10104435682296753, precision: 0.31598062953993244, recall: 0.8656716417909012, f1: 0.4629711751270761\n",
            "epoch: 483, step: 20, Train: label_loss: 0.09627413004636765, precision: 0.3329268292682724, recall: 0.8708133971290477, f1: 0.48169386850868395\n",
            "epoch: 483, step: 21, Train: label_loss: 0.0864729955792427, precision: 0.3249400479616112, recall: 0.8856209150325349, f1: 0.4754385964519121\n",
            "epoch: 483, step: 22, Train: label_loss: 0.10201463103294373, precision: 0.32623250152158695, recall: 0.8758169934639091, f1: 0.4753880265679485\n",
            "epoch: 483, step: 23, Train: label_loss: 0.10913136601448059, precision: 0.29806259314453815, recall: 0.840336134453605, f1: 0.440044004361737\n",
            "epoch: 484, step: 0, Train: label_loss: 0.09795860946178436, precision: 0.3070388349514377, recall: 0.8504201680670839, f1: 0.4511814533715902\n",
            "epoch: 484, step: 1, Train: label_loss: 0.09045028686523438, precision: 0.317191283292959, recall: 0.8733333333331877, f1: 0.46536412074239714\n",
            "epoch: 484, step: 2, Train: label_loss: 0.11334138363599777, precision: 0.32331288343556297, recall: 0.8486312399354511, f1: 0.4682363393647136\n",
            "epoch: 484, step: 3, Train: label_loss: 0.10619054734706879, precision: 0.31338679827265187, recall: 0.8438538205978664, f1: 0.4570400359478694\n",
            "epoch: 484, step: 4, Train: label_loss: 0.09260213375091553, precision: 0.3387193297426488, recall: 0.8969889064974806, f1: 0.49174630751880727\n",
            "epoch: 484, step: 5, Train: label_loss: 0.09422813355922699, precision: 0.34196267308848033, recall: 0.8888888888887497, f1: 0.49391304343809017\n",
            "epoch: 484, step: 6, Train: label_loss: 0.09958923608064651, precision: 0.30098887515449313, recall: 0.8382099827881517, f1: 0.44292860387194755\n",
            "epoch: 484, step: 7, Train: label_loss: 0.1089688315987587, precision: 0.31750924784215057, recall: 0.8373983739836036, f1: 0.46043808668338093\n",
            "epoch: 484, step: 8, Train: label_loss: 0.10436542332172394, precision: 0.31815421979354475, recall: 0.8747913188646285, f1: 0.4666073018308357\n",
            "epoch: 484, step: 9, Train: label_loss: 0.1177935004234314, precision: 0.31659522351498365, recall: 0.843393148450107, f1: 0.4603739981793273\n",
            "epoch: 484, step: 10, Train: label_loss: 0.10385727882385254, precision: 0.3185140073081414, recall: 0.895547945205326, f1: 0.4699011679756285\n",
            "epoch: 484, step: 11, Train: label_loss: 0.10723134130239487, precision: 0.31101643335360246, recall: 0.8602693602692154, f1: 0.45686186853493704\n",
            "epoch: 484, step: 12, Train: label_loss: 0.11345041543245316, precision: 0.3122676579925457, recall: 0.8181818181816853, f1: 0.45201793717970473\n",
            "epoch: 484, step: 13, Train: label_loss: 0.0989430844783783, precision: 0.31518451300663547, recall: 0.8785834738615719, f1: 0.46393588598068586\n",
            "epoch: 484, step: 14, Train: label_loss: 0.09417816996574402, precision: 0.32269717037927015, recall: 0.9008403361343024, f1: 0.4751773049256605\n",
            "epoch: 484, step: 15, Train: label_loss: 0.11100230365991592, precision: 0.3176178660049431, recall: 0.8519134775372957, f1: 0.46272028916057434\n",
            "epoch: 484, step: 16, Train: label_loss: 0.1191735565662384, precision: 0.32702867602194463, recall: 0.8617363344050061, f1: 0.47412649266241813\n",
            "epoch: 484, step: 17, Train: label_loss: 0.11715207248926163, precision: 0.322796352583567, recall: 0.8676470588233876, f1: 0.47053610984080435\n",
            "epoch: 484, step: 18, Train: label_loss: 0.10759909451007843, precision: 0.29674306393243083, recall: 0.8677248677247146, f1: 0.44224719097321774\n",
            "epoch: 484, step: 19, Train: label_loss: 0.12287010997533798, precision: 0.30494677520348745, recall: 0.8268251273343248, f1: 0.4455626715067938\n",
            "epoch: 484, step: 20, Train: label_loss: 0.10843122005462646, precision: 0.32444168734489304, recall: 0.8517915309444866, f1: 0.46990116797438375\n",
            "epoch: 484, step: 21, Train: label_loss: 0.10286103934049606, precision: 0.29805352798051715, recall: 0.8506944444442966, f1: 0.44144144140297364\n",
            "epoch: 484, step: 22, Train: label_loss: 0.11583907902240753, precision: 0.29999999999998184, recall: 0.8608695652172416, f1: 0.4449438201863506\n",
            "epoch: 484, step: 23, Train: label_loss: 0.10107696056365967, precision: 0.30350484712898557, recall: 0.8391752577317858, f1: 0.4457831324910596\n",
            "epoch: 485, step: 0, Train: label_loss: 0.09663865715265274, precision: 0.32004904966276393, recall: 0.8351999999998663, f1: 0.4627659574067098\n",
            "epoch: 485, step: 1, Train: label_loss: 0.10812629759311676, precision: 0.31559633027521006, recall: 0.8363047001619389, f1: 0.45825932500458144\n",
            "epoch: 485, step: 2, Train: label_loss: 0.10899056494235992, precision: 0.3159490600363665, recall: 0.8362760834669604, f1: 0.4586267605235363\n",
            "epoch: 485, step: 3, Train: label_loss: 0.09644051641225815, precision: 0.3306942752740359, recall: 0.8729903536976088, f1: 0.479681978758693\n",
            "epoch: 485, step: 4, Train: label_loss: 0.10601382702589035, precision: 0.2946158499697341, recall: 0.8619469026547146, f1: 0.439134355237014\n",
            "epoch: 485, step: 5, Train: label_loss: 0.08618223667144775, precision: 0.33373205741624795, recall: 0.9102773246328041, f1: 0.48840262578126575\n",
            "epoch: 485, step: 6, Train: label_loss: 0.10330014675855637, precision: 0.31515151515149603, recall: 0.8695652173911589, f1: 0.4626334519182041\n",
            "epoch: 485, step: 7, Train: label_loss: 0.0910768210887909, precision: 0.31447688564474974, recall: 0.8733108108106632, f1: 0.46243291588231433\n",
            "epoch: 485, step: 8, Train: label_loss: 0.1019609197974205, precision: 0.31540785498487517, recall: 0.8685524126454461, f1: 0.46276595740768117\n",
            "epoch: 485, step: 9, Train: label_loss: 0.0945863425731659, precision: 0.33071816535906273, recall: 0.8824476650562185, f1: 0.4811237927610016\n",
            "epoch: 485, step: 10, Train: label_loss: 0.10065971314907074, precision: 0.3128048780487614, recall: 0.8507462686565753, f1: 0.45742309403108783\n",
            "epoch: 485, step: 11, Train: label_loss: 0.08931049704551697, precision: 0.3155048076922887, recall: 0.8823529411763222, f1: 0.4648074368801463\n",
            "epoch: 485, step: 12, Train: label_loss: 0.08644747734069824, precision: 0.3229850746268464, recall: 0.8883415435138113, f1: 0.47373029768414265\n",
            "epoch: 485, step: 13, Train: label_loss: 0.10341208428144455, precision: 0.3110709987966118, recall: 0.8747884940776861, f1: 0.4589436306758606\n",
            "epoch: 485, step: 14, Train: label_loss: 0.11016760021448135, precision: 0.32701711491440544, recall: 0.8573717948716574, f1: 0.4734513273936121\n",
            "epoch: 485, step: 15, Train: label_loss: 0.11198225617408752, precision: 0.3169533169532975, recall: 0.8486842105261762, f1: 0.4615384614988249\n",
            "epoch: 485, step: 16, Train: label_loss: 0.10186709463596344, precision: 0.311711711711693, recall: 0.8856655290100877, f1: 0.46112838734483264\n",
            "epoch: 485, step: 17, Train: label_loss: 0.09471645951271057, precision: 0.31096464949069436, recall: 0.888698630136834, f1: 0.46071904123985064\n",
            "epoch: 485, step: 18, Train: label_loss: 0.09746835380792618, precision: 0.3290909090908891, recall: 0.8701923076921682, f1: 0.47757255932689113\n",
            "epoch: 485, step: 19, Train: label_loss: 0.10862685739994049, precision: 0.3055386488131281, recall: 0.8479729729728297, f1: 0.4492170021981528\n",
            "epoch: 485, step: 20, Train: label_loss: 0.10258951783180237, precision: 0.2992125984251787, recall: 0.8837209302324, f1: 0.44705882349157894\n",
            "epoch: 485, step: 21, Train: label_loss: 0.09789705276489258, precision: 0.30930930930929074, recall: 0.9035087719296659, f1: 0.46085011181878377\n",
            "epoch: 485, step: 22, Train: label_loss: 0.09646589308977127, precision: 0.33114558472551725, recall: 0.9009740259738797, f1: 0.48429319367792956\n",
            "epoch: 485, step: 23, Train: label_loss: 0.09668824076652527, precision: 0.3091575091574865, recall: 0.877338877338695, f1: 0.45720476702533847\n",
            "epoch: 486, step: 0, Train: label_loss: 0.101640984416008, precision: 0.3333333333333131, recall: 0.8783999999998594, f1: 0.4832746478473985\n",
            "epoch: 486, step: 1, Train: label_loss: 0.11020372807979584, precision: 0.3145112325440003, recall: 0.861896838602186, f1: 0.4608540924874747\n",
            "epoch: 486, step: 2, Train: label_loss: 0.08728105574846268, precision: 0.31961836612997496, recall: 0.8903654485048355, f1: 0.4703817463410748\n",
            "epoch: 486, step: 3, Train: label_loss: 0.09827516973018646, precision: 0.30925925925924014, recall: 0.8477157360404657, f1: 0.4531886024031227\n",
            "epoch: 486, step: 4, Train: label_loss: 0.12713120877742767, precision: 0.3256681168427392, recall: 0.8291139240505017, f1: 0.4676483712222907\n",
            "epoch: 486, step: 5, Train: label_loss: 0.10835625231266022, precision: 0.3088592233009521, recall: 0.859797297297152, f1: 0.45446428567535735\n",
            "epoch: 486, step: 6, Train: label_loss: 0.10766888409852982, precision: 0.2965686274509622, recall: 0.8402777777776318, f1: 0.43840579706284616\n",
            "epoch: 486, step: 7, Train: label_loss: 0.08675207197666168, precision: 0.31419939577037376, recall: 0.8695652173911589, f1: 0.46160674652110617\n",
            "epoch: 486, step: 8, Train: label_loss: 0.10056393593549728, precision: 0.32807762280167807, recall: 0.869774919614008, f1: 0.4764420959531379\n",
            "epoch: 486, step: 9, Train: label_loss: 0.10140795260667801, precision: 0.31683765841881006, recall: 0.8720930232556691, f1: 0.464807436879855\n",
            "epoch: 486, step: 10, Train: label_loss: 0.11468800902366638, precision: 0.30949445129467884, recall: 0.8325041459368436, f1: 0.45123595501662633\n",
            "epoch: 486, step: 11, Train: label_loss: 0.0880560353398323, precision: 0.31951219512193174, recall: 0.8646864686467219, f1: 0.4666073018305468\n",
            "epoch: 486, step: 12, Train: label_loss: 0.1046052947640419, precision: 0.33598045204640586, recall: 0.8702531645568242, f1: 0.48479506386457033\n",
            "epoch: 486, step: 13, Train: label_loss: 0.11283411085605621, precision: 0.3304721030042716, recall: 0.8721682847895028, f1: 0.4793241440241298\n",
            "epoch: 486, step: 14, Train: label_loss: 0.0959591418504715, precision: 0.3024803387779611, recall: 0.863557858376362, f1: 0.44802867379666217\n",
            "epoch: 486, step: 15, Train: label_loss: 0.11859147250652313, precision: 0.2939393939393761, recall: 0.8645276292333575, f1: 0.4387155133044689\n",
            "epoch: 486, step: 16, Train: label_loss: 0.08072472363710403, precision: 0.32507374631266517, recall: 0.9183333333331802, f1: 0.48017429190033833\n",
            "epoch: 486, step: 17, Train: label_loss: 0.09246130287647247, precision: 0.32209512341960733, recall: 0.900673400673249, f1: 0.4745011086086025\n",
            "epoch: 486, step: 18, Train: label_loss: 0.10813876241445541, precision: 0.34013197360525854, recall: 0.8985736925513631, f1: 0.49347258481651624\n",
            "epoch: 486, step: 19, Train: label_loss: 0.10901517421007156, precision: 0.3115246098439189, recall: 0.869346733668196, f1: 0.458683163902787\n",
            "epoch: 486, step: 20, Train: label_loss: 0.09767980128526688, precision: 0.3073229291716502, recall: 0.8842832469773947, f1: 0.4561247215652447\n",
            "epoch: 486, step: 21, Train: label_loss: 0.10346981883049011, precision: 0.32240762812870544, recall: 0.864217252396028, f1: 0.46961805551593877\n",
            "epoch: 486, step: 22, Train: label_loss: 0.09407860040664673, precision: 0.2975256487628064, recall: 0.8588850174214531, f1: 0.4419542805534055\n",
            "epoch: 486, step: 23, Train: label_loss: 0.09575534611940384, precision: 0.3062730627306047, recall: 0.8682008368199021, f1: 0.4528096017071683\n",
            "epoch: 487, step: 0, Train: label_loss: 0.09282077103853226, precision: 0.3303030303030103, recall: 0.8890701468187783, f1: 0.48166151122868467\n",
            "epoch: 487, step: 1, Train: label_loss: 0.10665355622768402, precision: 0.32632211538459577, recall: 0.8715890850720912, f1: 0.47485789239582304\n",
            "epoch: 487, step: 2, Train: label_loss: 0.10375043004751205, precision: 0.29714978775013356, recall: 0.8596491228068667, f1: 0.4416403785106782\n",
            "epoch: 487, step: 3, Train: label_loss: 0.1052250862121582, precision: 0.29272727272725496, recall: 0.8671454219028963, f1: 0.4376982328575566\n",
            "epoch: 487, step: 4, Train: label_loss: 0.0928812250494957, precision: 0.3092537313432651, recall: 0.886986301369711, f1: 0.45861000438835925\n",
            "epoch: 487, step: 5, Train: label_loss: 0.08858700096607208, precision: 0.300543150271557, recall: 0.8556701030926365, f1: 0.44484144703607315\n",
            "epoch: 487, step: 6, Train: label_loss: 0.09054096043109894, precision: 0.32870090634439103, recall: 0.8760064412236914, f1: 0.4780316344066749\n",
            "epoch: 487, step: 7, Train: label_loss: 0.08958350121974945, precision: 0.31856287425147795, recall: 0.8881469115190503, f1: 0.4689290435926543\n",
            "epoch: 487, step: 8, Train: label_loss: 0.10255907475948334, precision: 0.326654523375815, recall: 0.8805237315874171, f1: 0.47652790075764884\n",
            "epoch: 487, step: 9, Train: label_loss: 0.10125847160816193, precision: 0.3258901629450618, recall: 0.885245901639199, f1: 0.4764005292945444\n",
            "epoch: 487, step: 10, Train: label_loss: 0.08385054022073746, precision: 0.34108527131780914, recall: 0.8951486697964169, f1: 0.49395509495136536\n",
            "epoch: 487, step: 11, Train: label_loss: 0.094713494181633, precision: 0.3261000602772558, recall: 0.8811074918565339, f1: 0.4760228772152558\n",
            "epoch: 487, step: 12, Train: label_loss: 0.09961558133363724, precision: 0.3186746987951615, recall: 0.8890756302519514, f1: 0.46917960084802895\n",
            "epoch: 487, step: 13, Train: label_loss: 0.10509619116783142, precision: 0.327848872638615, recall: 0.862179487179349, f1: 0.4750551875980075\n",
            "epoch: 487, step: 14, Train: label_loss: 0.1244749128818512, precision: 0.3058103975534981, recall: 0.8576329331044841, f1: 0.450856627553633\n",
            "epoch: 487, step: 15, Train: label_loss: 0.1079588532447815, precision: 0.29915048543687506, recall: 0.8649122807016025, f1: 0.44454463476790257\n",
            "epoch: 487, step: 16, Train: label_loss: 0.1086646318435669, precision: 0.32598039215684277, recall: 0.8692810457514919, f1: 0.47415329764299774\n",
            "epoch: 487, step: 17, Train: label_loss: 0.09463636577129364, precision: 0.3317249698431645, recall: 0.8885298869142344, f1: 0.48309178739998165\n",
            "epoch: 487, step: 18, Train: label_loss: 0.11440371721982956, precision: 0.3034188034187849, recall: 0.8438030560270213, f1: 0.44634036816940587\n",
            "epoch: 487, step: 19, Train: label_loss: 0.09848472476005554, precision: 0.32912912912910935, recall: 0.8910569105689607, f1: 0.48070175434652695\n",
            "epoch: 487, step: 20, Train: label_loss: 0.11092245578765869, precision: 0.31900726392249884, recall: 0.8917089678509489, f1: 0.4699063753512484\n",
            "epoch: 487, step: 21, Train: label_loss: 0.105343759059906, precision: 0.3281249999999803, recall: 0.8878048780486361, f1: 0.4791575251909155\n",
            "epoch: 487, step: 22, Train: label_loss: 0.08204998821020126, precision: 0.30714285714283884, recall: 0.8942807625648362, f1: 0.4572441293371778\n",
            "epoch: 487, step: 23, Train: label_loss: 0.10993899405002594, precision: 0.3330860534124382, recall: 0.8873517786559512, f1: 0.48435814451257986\n",
            "epoch: 488, step: 0, Train: label_loss: 0.08777187019586563, precision: 0.31882352941174597, recall: 0.928082191780663, f1: 0.4746059544277452\n",
            "epoch: 488, step: 1, Train: label_loss: 0.1036376953125, precision: 0.3220543806646331, recall: 0.8927973199328487, f1: 0.4733570159467842\n",
            "epoch: 488, step: 2, Train: label_loss: 0.09811311960220337, precision: 0.3056057866184264, recall: 0.860780984719718, f1: 0.4510676156196506\n",
            "epoch: 488, step: 3, Train: label_loss: 0.0918266624212265, precision: 0.31818181818179914, recall: 0.8866666666665188, f1: 0.4683098591160195\n",
            "epoch: 488, step: 4, Train: label_loss: 0.10936324298381805, precision: 0.31773399014776366, recall: 0.8363047001619389, f1: 0.4605087014326116\n",
            "epoch: 488, step: 5, Train: label_loss: 0.09908998012542725, precision: 0.3192261185005853, recall: 0.8770764119599871, f1: 0.46808510634380956\n",
            "epoch: 488, step: 6, Train: label_loss: 0.10017584264278412, precision: 0.3151183970855911, recall: 0.8494271685759657, f1: 0.45969884849901443\n",
            "epoch: 488, step: 7, Train: label_loss: 0.10160200297832489, precision: 0.30647130647128773, recall: 0.8494077834177919, f1: 0.45042620005071765\n",
            "epoch: 488, step: 8, Train: label_loss: 0.1035827100276947, precision: 0.3209951456310485, recall: 0.8518518518517146, f1: 0.46628470687955\n",
            "epoch: 488, step: 9, Train: label_loss: 0.09399545192718506, precision: 0.3082437275985479, recall: 0.8911917098444055, f1: 0.4580559253945264\n",
            "epoch: 488, step: 10, Train: label_loss: 0.09954020380973816, precision: 0.31997607655500476, recall: 0.8857615894038268, f1: 0.4701230228080684\n",
            "epoch: 488, step: 11, Train: label_loss: 0.11469056457281113, precision: 0.32570740517758423, recall: 0.8796747967478243, f1: 0.4753954305404836\n",
            "epoch: 488, step: 12, Train: label_loss: 0.09613595902919769, precision: 0.30903614457829465, recall: 0.8694915254235813, f1: 0.4559999999612671\n",
            "epoch: 488, step: 13, Train: label_loss: 0.11152626574039459, precision: 0.3137254901960592, recall: 0.8476821192051576, f1: 0.45796064396768316\n",
            "epoch: 488, step: 14, Train: label_loss: 0.11011069267988205, precision: 0.3351449275362116, recall: 0.8795562599047734, f1: 0.4853519894659039\n",
            "epoch: 488, step: 15, Train: label_loss: 0.09960521757602692, precision: 0.319877675840959, recall: 0.8658940397349559, f1: 0.46717284498065825\n",
            "epoch: 488, step: 16, Train: label_loss: 0.10278812050819397, precision: 0.31771771771769863, recall: 0.89358108108093, f1: 0.46876384577428526\n",
            "epoch: 488, step: 17, Train: label_loss: 0.09869466722011566, precision: 0.3290909090908891, recall: 0.8814935064933633, f1: 0.47925860543256626\n",
            "epoch: 488, step: 18, Train: label_loss: 0.08971225470304489, precision: 0.3132530120481739, recall: 0.890410958903957, f1: 0.4634581104783888\n",
            "epoch: 488, step: 19, Train: label_loss: 0.10401445627212524, precision: 0.3171028606207963, recall: 0.8741610738253566, f1: 0.46538633314534916\n",
            "epoch: 488, step: 20, Train: label_loss: 0.08930917084217072, precision: 0.31635710005989714, recall: 0.8799999999998532, f1: 0.46540326130966897\n",
            "epoch: 488, step: 21, Train: label_loss: 0.08705957233905792, precision: 0.3134418324291553, recall: 0.9012131715769668, f1: 0.4651162790314337\n",
            "epoch: 488, step: 22, Train: label_loss: 0.09107030183076859, precision: 0.3208459214501317, recall: 0.873355263157751, f1: 0.4692885549761274\n",
            "epoch: 488, step: 23, Train: label_loss: 0.09884090721607208, precision: 0.32739420935409597, recall: 0.8698224852069291, f1: 0.47572815530001833\n",
            "epoch: 489, step: 0, Train: label_loss: 0.08988665044307709, precision: 0.32192192192190255, recall: 0.8772504091651592, f1: 0.4710017574299256\n",
            "epoch: 489, step: 1, Train: label_loss: 0.10573241859674454, precision: 0.32903621853896076, recall: 0.8414442700155664, f1: 0.4730803177000525\n",
            "epoch: 489, step: 2, Train: label_loss: 0.11150000989437103, precision: 0.29957028852054635, recall: 0.8399311531840206, f1: 0.44162895923722173\n",
            "epoch: 489, step: 3, Train: label_loss: 0.09219150245189667, precision: 0.3281343731253552, recall: 0.8836833602583386, f1: 0.47856517931304754\n",
            "epoch: 489, step: 4, Train: label_loss: 0.09083598852157593, precision: 0.3237063778579829, recall: 0.8776508972266104, f1: 0.4729670329276219\n",
            "epoch: 489, step: 5, Train: label_loss: 0.08599524945020676, precision: 0.30619684082622683, recall: 0.8542372881354484, f1: 0.45080500890565545\n",
            "epoch: 489, step: 6, Train: label_loss: 0.09981217980384827, precision: 0.3179331306990688, recall: 0.8616144975286884, f1: 0.4644760212749684\n",
            "epoch: 489, step: 7, Train: label_loss: 0.09822219610214233, precision: 0.3026474127556978, recall: 0.8934280639430029, f1: 0.452134831422832\n",
            "epoch: 489, step: 8, Train: label_loss: 0.08966904878616333, precision: 0.33966745843228385, recall: 0.9151999999998535, f1: 0.49545257683357985\n",
            "epoch: 489, step: 9, Train: label_loss: 0.09766393899917603, precision: 0.3206060606060412, recall: 0.864379084967179, f1: 0.46772767458471387\n",
            "epoch: 489, step: 10, Train: label_loss: 0.09829050302505493, precision: 0.3383685800604025, recall: 0.8805031446539495, f1: 0.4888694892658288\n",
            "epoch: 489, step: 11, Train: label_loss: 0.10148255527019501, precision: 0.31368937998770324, recall: 0.8661016949151074, f1: 0.4605678233047689\n",
            "epoch: 489, step: 12, Train: label_loss: 0.1073235273361206, precision: 0.3067150635208526, recall: 0.8832752613238879, f1: 0.45532105968329506\n",
            "epoch: 489, step: 13, Train: label_loss: 0.107143834233284, precision: 0.2905364677516401, recall: 0.8684684684683119, f1: 0.43541102073926735\n",
            "epoch: 489, step: 14, Train: label_loss: 0.10835804790258408, precision: 0.33718104495745216, recall: 0.8699059561127163, f1: 0.4859894920787854\n",
            "epoch: 489, step: 15, Train: label_loss: 0.10248398780822754, precision: 0.31496062992124074, recall: 0.8666666666665221, f1: 0.4620168813469095\n",
            "epoch: 489, step: 16, Train: label_loss: 0.10420966148376465, precision: 0.33091349062308945, recall: 0.8724082934607859, f1: 0.47982456136359164\n",
            "epoch: 489, step: 17, Train: label_loss: 0.10556350648403168, precision: 0.31607465382297917, recall: 0.8706467661690098, f1: 0.46378091868879334\n",
            "epoch: 489, step: 18, Train: label_loss: 0.12313613295555115, precision: 0.3163771712158613, recall: 0.8542713567837764, f1: 0.46174739697273715\n",
            "epoch: 489, step: 19, Train: label_loss: 0.09112834185361862, precision: 0.3313289236319705, recall: 0.8801916932905941, f1: 0.48143294010875654\n",
            "epoch: 489, step: 20, Train: label_loss: 0.09024189412593842, precision: 0.32166172106823016, recall: 0.9078726968172683, f1: 0.47502191056605675\n",
            "epoch: 489, step: 21, Train: label_loss: 0.08195345848798752, precision: 0.3150029886431372, recall: 0.896258503401208, f1: 0.46616541349530743\n",
            "epoch: 489, step: 22, Train: label_loss: 0.11130625009536743, precision: 0.3093955715140449, recall: 0.8883161512025964, f1: 0.45894363067624355\n",
            "epoch: 489, step: 23, Train: label_loss: 0.10465577244758606, precision: 0.29325513196478786, recall: 0.8928571428569436, f1: 0.4415011037154881\n",
            "epoch: 490, step: 0, Train: label_loss: 0.1006024181842804, precision: 0.3402612826603123, recall: 0.9124203821654597, f1: 0.495674740444817\n",
            "epoch: 490, step: 1, Train: label_loss: 0.09683026373386383, precision: 0.3162031438935722, recall: 0.8760469011723825, f1: 0.46468236335503066\n",
            "epoch: 490, step: 2, Train: label_loss: 0.09954828023910522, precision: 0.3069486404833651, recall: 0.8743545611013985, f1: 0.45438282643734446\n",
            "epoch: 490, step: 3, Train: label_loss: 0.10012061893939972, precision: 0.2966830466830285, recall: 0.8356401384081599, f1: 0.43789664547352725\n",
            "epoch: 490, step: 4, Train: label_loss: 0.08941192924976349, precision: 0.31575793888554127, recall: 0.8710743801651453, f1: 0.4635004397146435\n",
            "epoch: 490, step: 5, Train: label_loss: 0.09622353315353394, precision: 0.32927571515518383, recall: 0.861464968152729, f1: 0.4764420959529004\n",
            "epoch: 490, step: 6, Train: label_loss: 0.09954807162284851, precision: 0.3283132530120284, recall: 0.8833063209074743, f1: 0.47870004387788406\n",
            "epoch: 490, step: 7, Train: label_loss: 0.10637298226356506, precision: 0.3193685488767262, recall: 0.859477124182866, f1: 0.46569278437833866\n",
            "epoch: 490, step: 8, Train: label_loss: 0.0974913239479065, precision: 0.330351818723892, recall: 0.8993506493505032, f1: 0.4832097688224161\n",
            "epoch: 490, step: 9, Train: label_loss: 0.09276676177978516, precision: 0.3301435406698367, recall: 0.9019607843135781, f1: 0.48336252185214557\n",
            "epoch: 490, step: 10, Train: label_loss: 0.0956537276506424, precision: 0.32304038004748675, recall: 0.8918032786883783, f1: 0.47428073230616663\n",
            "epoch: 490, step: 11, Train: label_loss: 0.10026298463344574, precision: 0.30834340991533804, recall: 0.8793103448274345, f1: 0.4565801252972359\n",
            "epoch: 490, step: 12, Train: label_loss: 0.09802859276533127, precision: 0.3144918821406906, recall: 0.8864406779659514, f1: 0.4642698623669809\n",
            "epoch: 490, step: 13, Train: label_loss: 0.10740822553634644, precision: 0.3157575757575566, recall: 0.8800675675674189, f1: 0.46476360388615984\n",
            "epoch: 490, step: 14, Train: label_loss: 0.10835902392864227, precision: 0.3100917431192471, recall: 0.871134020618407, f1: 0.45737483081374175\n",
            "epoch: 490, step: 15, Train: label_loss: 0.09420296549797058, precision: 0.30929678188317583, recall: 0.9026086956520168, f1: 0.46071904124023855\n",
            "epoch: 490, step: 16, Train: label_loss: 0.09049085527658463, precision: 0.34318455971047385, recall: 0.8862928348908277, f1: 0.4947826086553657\n",
            "epoch: 490, step: 17, Train: label_loss: 0.1157013401389122, precision: 0.3012939001848243, recall: 0.8563922942205154, f1: 0.44576116678005107\n",
            "epoch: 490, step: 18, Train: label_loss: 0.10165219008922577, precision: 0.3074572127139176, recall: 0.8687392055266202, f1: 0.45417607219610806\n",
            "epoch: 490, step: 19, Train: label_loss: 0.08828466385602951, precision: 0.3321407274895449, recall: 0.8998384491113247, f1: 0.4851916375912366\n",
            "epoch: 490, step: 20, Train: label_loss: 0.09975458681583405, precision: 0.3087697929354258, recall: 0.8593220338981594, f1: 0.4543010752298839\n",
            "epoch: 490, step: 21, Train: label_loss: 0.09869474172592163, precision: 0.3311298076922878, recall: 0.8872785829306139, f1: 0.4822757111201127\n",
            "epoch: 490, step: 22, Train: label_loss: 0.09485887736082077, precision: 0.3329348475791791, recall: 0.8983870967740486, f1: 0.48582642822042343\n",
            "epoch: 490, step: 23, Train: label_loss: 0.0985226035118103, precision: 0.3069526627218708, recall: 0.8755274261601529, f1: 0.45454545450696465\n",
            "epoch: 491, step: 0, Train: label_loss: 0.09719379246234894, precision: 0.2916412446613611, recall: 0.8213058419242575, f1: 0.4304367401683998\n",
            "epoch: 491, step: 1, Train: label_loss: 0.09674879163503647, precision: 0.3351449275362116, recall: 0.8823529411763302, f1: 0.485776805211699\n",
            "epoch: 491, step: 2, Train: label_loss: 0.10029572248458862, precision: 0.30834340991533804, recall: 0.8762886597936638, f1: 0.45617173520295434\n",
            "epoch: 491, step: 3, Train: label_loss: 0.08422860503196716, precision: 0.34339846062756996, recall: 0.9250398724081459, f1: 0.5008635578188466\n",
            "epoch: 491, step: 4, Train: label_loss: 0.08215279877185822, precision: 0.31899641577059024, recall: 0.8974789915964877, f1: 0.4706919347342932\n",
            "epoch: 491, step: 5, Train: label_loss: 0.09553434699773788, precision: 0.318814277071971, recall: 0.8768718801995212, f1: 0.46761313217025563\n",
            "epoch: 491, step: 6, Train: label_loss: 0.09667760133743286, precision: 0.3055386488131281, recall: 0.8685121107264933, f1: 0.4520486267061656\n",
            "epoch: 491, step: 7, Train: label_loss: 0.08834327757358551, precision: 0.33392857142855153, recall: 0.9004815409308345, f1: 0.48719062088971293\n",
            "epoch: 491, step: 8, Train: label_loss: 0.09597767889499664, precision: 0.3198795180722699, recall: 0.8835274542427813, f1: 0.46970367090298826\n",
            "epoch: 491, step: 9, Train: label_loss: 0.08699826896190643, precision: 0.31978481769274836, recall: 0.8901830282860415, f1: 0.4705364995213165\n",
            "epoch: 491, step: 10, Train: label_loss: 0.09149280190467834, precision: 0.32972972972970993, recall: 0.8798076923075513, f1: 0.4796854521228159\n",
            "epoch: 491, step: 11, Train: label_loss: 0.08595350384712219, precision: 0.31591591591589696, recall: 0.8665568369026578, f1: 0.46302816897488613\n",
            "epoch: 491, step: 12, Train: label_loss: 0.08000507950782776, precision: 0.3043735224586108, recall: 0.9066901408449107, f1: 0.4557522123517077\n",
            "epoch: 491, step: 13, Train: label_loss: 0.10527190566062927, precision: 0.31265206812650165, recall: 0.8495867768593637, f1: 0.45709204086770056\n",
            "epoch: 491, step: 14, Train: label_loss: 0.10059310495853424, precision: 0.3069129916567159, recall: 0.8910034602074582, f1: 0.4565602836497899\n",
            "epoch: 491, step: 15, Train: label_loss: 0.1070001870393753, precision: 0.2980652962514935, recall: 0.8725663716812614, f1: 0.4443442991958914\n",
            "epoch: 491, step: 16, Train: label_loss: 0.08631952106952667, precision: 0.31801909307874, recall: 0.8973063973062462, f1: 0.4696035241903934\n",
            "epoch: 491, step: 17, Train: label_loss: 0.10875596851110458, precision: 0.3246041412910886, recall: 0.8624595469254267, f1: 0.47168141588942664\n",
            "epoch: 491, step: 18, Train: label_loss: 0.10235744714736938, precision: 0.3399879007864283, recall: 0.8878357030014394, f1: 0.4916885388925448\n",
            "epoch: 491, step: 19, Train: label_loss: 0.09945955872535706, precision: 0.324275362318821, recall: 0.8890728476819719, f1: 0.475221238898845\n",
            "epoch: 491, step: 20, Train: label_loss: 0.09709052741527557, precision: 0.3171462829736021, recall: 0.8860971524286623, f1: 0.4671081677315574\n",
            "epoch: 491, step: 21, Train: label_loss: 0.10326871275901794, precision: 0.298372513562369, recall: 0.8669001751311967, f1: 0.44394618830266935\n",
            "epoch: 491, step: 22, Train: label_loss: 0.10465527325868607, precision: 0.33252427184464, recall: 0.8925081433223302, f1: 0.48452696724599287\n",
            "epoch: 491, step: 23, Train: label_loss: 0.09933608770370483, precision: 0.3400148478099228, recall: 0.8773946360151575, f1: 0.49010165860067423\n",
            "epoch: 492, step: 0, Train: label_loss: 0.09621579945087433, precision: 0.33850746268654697, recall: 0.8873239436618329, f1: 0.49006050125643624\n",
            "epoch: 492, step: 1, Train: label_loss: 0.09811864793300629, precision: 0.29613992762362507, recall: 0.872113676731639, f1: 0.4421431787104252\n",
            "epoch: 492, step: 2, Train: label_loss: 0.10113227367401123, precision: 0.3150029886431372, recall: 0.8977853492332372, f1: 0.46637168137743346\n",
            "epoch: 492, step: 3, Train: label_loss: 0.10453078150749207, precision: 0.3222222222222023, recall: 0.8378812199035572, f1: 0.465448060592918\n",
            "epoch: 492, step: 4, Train: label_loss: 0.08604342490434647, precision: 0.32992788461536476, recall: 0.8869143780289358, f1: 0.4809461234821157\n",
            "epoch: 492, step: 5, Train: label_loss: 0.08911240100860596, precision: 0.3206650831353729, recall: 0.9137055837561905, f1: 0.47472527468677406\n",
            "epoch: 492, step: 6, Train: label_loss: 0.09938157349824905, precision: 0.3412264723739926, recall: 0.8632872503838919, f1: 0.4891209747200115\n",
            "epoch: 492, step: 7, Train: label_loss: 0.08976343274116516, precision: 0.3046594982078671, recall: 0.8793103448274345, f1: 0.45252883758374385\n",
            "epoch: 492, step: 8, Train: label_loss: 0.10134059190750122, precision: 0.31693989071036327, recall: 0.8642384105958834, f1: 0.46379386935207506\n",
            "epoch: 492, step: 9, Train: label_loss: 0.10051986575126648, precision: 0.28315412186378236, recall: 0.8826815642456456, f1: 0.4287652645493438\n",
            "epoch: 492, step: 10, Train: label_loss: 0.08218734711408615, precision: 0.3151010701545591, recall: 0.8848080133554449, f1: 0.46470846116245806\n",
            "epoch: 492, step: 11, Train: label_loss: 0.09188015758991241, precision: 0.303690260133073, recall: 0.8745644599301612, f1: 0.4508307139266722\n",
            "epoch: 492, step: 12, Train: label_loss: 0.09531933069229126, precision: 0.33531157270027684, recall: 0.9098228663444589, f1: 0.4900260190412614\n",
            "epoch: 492, step: 13, Train: label_loss: 0.10299238562583923, precision: 0.31744115872056017, recall: 0.8708609271521737, f1: 0.46528084914258167\n",
            "epoch: 492, step: 14, Train: label_loss: 0.10859610140323639, precision: 0.32277710109620444, recall: 0.8745874587457302, f1: 0.47153024907089763\n",
            "epoch: 492, step: 15, Train: label_loss: 0.09996430575847626, precision: 0.3088592233009521, recall: 0.8730703259003647, f1: 0.45629762434503734\n",
            "epoch: 492, step: 16, Train: label_loss: 0.09733521938323975, precision: 0.32989690721647486, recall: 0.8774193548385681, f1: 0.4795063904406288\n",
            "epoch: 492, step: 17, Train: label_loss: 0.10695389658212662, precision: 0.3238498789346051, recall: 0.8587479935793163, f1: 0.47032967028985806\n",
            "epoch: 492, step: 18, Train: label_loss: 0.09106519818305969, precision: 0.3118214716525747, recall: 0.8559602649005205, f1: 0.45711759500944504\n",
            "epoch: 492, step: 19, Train: label_loss: 0.08919209241867065, precision: 0.3297232250300644, recall: 0.8881685575363227, f1: 0.4809126809609093\n",
            "epoch: 492, step: 20, Train: label_loss: 0.09517157822847366, precision: 0.3057401812688637, recall: 0.8754325259514055, f1: 0.4532019704049404\n",
            "epoch: 492, step: 21, Train: label_loss: 0.09536433219909668, precision: 0.30764599638769974, recall: 0.8646362098137285, f1: 0.45381882766995063\n",
            "epoch: 492, step: 22, Train: label_loss: 0.0983995646238327, precision: 0.319237641453227, recall: 0.8978224455609886, f1: 0.471001757430503\n",
            "epoch: 492, step: 23, Train: label_loss: 0.095560222864151, precision: 0.337728937728913, recall: 0.9074803149604513, f1: 0.4922584089299828\n",
            "epoch: 493, step: 0, Train: label_loss: 0.10361992567777634, precision: 0.31670673076921174, recall: 0.8783333333331869, f1: 0.4655477031412142\n",
            "epoch: 493, step: 1, Train: label_loss: 0.09698435664176941, precision: 0.30922242314645515, recall: 0.8906249999998453, f1: 0.45906040264626274\n",
            "epoch: 493, step: 2, Train: label_loss: 0.09423704445362091, precision: 0.3347305389221356, recall: 0.8830963665085492, f1: 0.48545375593056883\n",
            "epoch: 493, step: 3, Train: label_loss: 0.07454367727041245, precision: 0.33511586452760933, recall: 0.9096774193546919, f1: 0.4897959183279568\n",
            "epoch: 493, step: 4, Train: label_loss: 0.08904504776000977, precision: 0.3172905525846514, recall: 0.8989898989897476, f1: 0.46903820813003844\n",
            "epoch: 493, step: 5, Train: label_loss: 0.109405517578125, precision: 0.30885009030702537, recall: 0.8799313893652007, f1: 0.45721925129839647\n",
            "epoch: 493, step: 6, Train: label_loss: 0.09125594794750214, precision: 0.3185096153845962, recall: 0.8848080133554449, f1: 0.46840477238701567\n",
            "epoch: 493, step: 7, Train: label_loss: 0.09373167902231216, precision: 0.32246376811592253, recall: 0.8974789915964877, f1: 0.4744557973844336\n",
            "epoch: 493, step: 8, Train: label_loss: 0.10256262123584747, precision: 0.3319377990430423, recall: 0.9009740259738797, f1: 0.4851398601004686\n",
            "epoch: 493, step: 9, Train: label_loss: 0.11295615881681442, precision: 0.31607795371496245, recall: 0.8664440734556149, f1: 0.46318607760469827\n",
            "epoch: 493, step: 10, Train: label_loss: 0.0837458074092865, precision: 0.31108462455302077, recall: 0.8862478777587629, f1: 0.4605205116509546\n",
            "epoch: 493, step: 11, Train: label_loss: 0.09310735762119293, precision: 0.3126879134094821, recall: 0.8813559322032404, f1: 0.46160674652144196\n",
            "epoch: 493, step: 12, Train: label_loss: 0.1116071417927742, precision: 0.32175502742228385, recall: 0.8741721854303188, f1: 0.4703786191143012\n",
            "epoch: 493, step: 13, Train: label_loss: 0.10991400480270386, precision: 0.3240460327074304, recall: 0.8478605388271239, f1: 0.46888694123952757\n",
            "epoch: 493, step: 14, Train: label_loss: 0.10282459855079651, precision: 0.3288834951456111, recall: 0.8856209150325349, f1: 0.4796460176595795\n",
            "epoch: 493, step: 15, Train: label_loss: 0.08940647542476654, precision: 0.3417417417417212, recall: 0.8960629921258431, f1: 0.4947826086556366\n",
            "epoch: 493, step: 16, Train: label_loss: 0.08835473656654358, precision: 0.3240023823704393, recall: 0.8932676518881948, f1: 0.4755244754853691\n",
            "epoch: 493, step: 17, Train: label_loss: 0.10422500967979431, precision: 0.31292100428656994, recall: 0.8631756756755298, f1: 0.45932584265753273\n",
            "epoch: 493, step: 18, Train: label_loss: 0.08739914000034332, precision: 0.3118664281454793, recall: 0.8894557823127738, f1: 0.4618101544869037\n",
            "epoch: 493, step: 19, Train: label_loss: 0.0876438096165657, precision: 0.3081986834230815, recall: 0.8803418803417298, f1: 0.45656028364948925\n",
            "epoch: 493, step: 20, Train: label_loss: 0.09309076517820358, precision: 0.30301204819275285, recall: 0.8702422145327213, f1: 0.4495084896846138\n",
            "epoch: 493, step: 21, Train: label_loss: 0.09679646044969559, precision: 0.32338611449449917, recall: 0.8648208469053965, f1: 0.47074468081140397\n",
            "epoch: 493, step: 22, Train: label_loss: 0.11278817057609558, precision: 0.30932203389828633, recall: 0.8765008576327827, f1: 0.4572706934737018\n",
            "epoch: 493, step: 23, Train: label_loss: 0.09500381350517273, precision: 0.317647058823506, recall: 0.874493927125329, f1: 0.46601941743658687\n",
            "epoch: 494, step: 0, Train: label_loss: 0.08884934335947037, precision: 0.3177458033572951, recall: 0.8937605396288543, f1: 0.4688191065512658\n",
            "epoch: 494, step: 1, Train: label_loss: 0.10440531373023987, precision: 0.32258064516127066, recall: 0.871710526315646, f1: 0.47090182137323416\n",
            "epoch: 494, step: 2, Train: label_loss: 0.08250820636749268, precision: 0.3222156045264847, recall: 0.8883415435138113, f1: 0.4729020978629917\n",
            "epoch: 494, step: 3, Train: label_loss: 0.09243270009756088, precision: 0.3221556886227352, recall: 0.884868421052486, f1: 0.47234416150604064\n",
            "epoch: 494, step: 4, Train: label_loss: 0.08743809163570404, precision: 0.31864204883857544, recall: 0.8872305140960386, f1: 0.46888694124065455\n",
            "epoch: 494, step: 5, Train: label_loss: 0.0914895161986351, precision: 0.30801944106924006, recall: 0.871134020618407, f1: 0.4551166965502311\n",
            "epoch: 494, step: 6, Train: label_loss: 0.08708883076906204, precision: 0.3135391923990313, recall: 0.91986062717754, f1: 0.4676705048336091\n",
            "epoch: 494, step: 7, Train: label_loss: 0.09392650425434113, precision: 0.3140794223826526, recall: 0.8773109243696003, f1: 0.4625609215384487\n",
            "epoch: 494, step: 8, Train: label_loss: 0.08923214673995972, precision: 0.30983412322273046, recall: 0.9032815198616747, f1: 0.46140273485385236\n",
            "epoch: 494, step: 9, Train: label_loss: 0.10294316709041595, precision: 0.30773881499393546, recall: 0.8511705685617305, f1: 0.4520426287353767\n",
            "epoch: 494, step: 10, Train: label_loss: 0.10037650167942047, precision: 0.3231414868105322, recall: 0.8836065573769043, f1: 0.4732221246315076\n",
            "epoch: 494, step: 11, Train: label_loss: 0.10538900643587112, precision: 0.3078787878787692, recall: 0.8523489932884475, f1: 0.45235975062882483\n",
            "epoch: 494, step: 12, Train: label_loss: 0.09247032552957535, precision: 0.32487922705312045, recall: 0.8776508972266104, f1: 0.4742177170164949\n",
            "epoch: 494, step: 13, Train: label_loss: 0.09334278851747513, precision: 0.31848284166163043, recall: 0.8686371100162776, f1: 0.46607929511488255\n",
            "epoch: 494, step: 14, Train: label_loss: 0.08922073245048523, precision: 0.3299522673030829, recall: 0.8904991948468775, f1: 0.4814976055329915\n",
            "epoch: 494, step: 15, Train: label_loss: 0.09829439222812653, precision: 0.3162031438935722, recall: 0.8760469011723825, f1: 0.46468236335503066\n",
            "epoch: 494, step: 16, Train: label_loss: 0.09146346151828766, precision: 0.3031026252983113, recall: 0.8896672504376725, f1: 0.45215843342889617\n",
            "epoch: 494, step: 17, Train: label_loss: 0.10128535330295563, precision: 0.30867192237717955, recall: 0.8700854700853213, f1: 0.4556848701493047\n",
            "epoch: 494, step: 18, Train: label_loss: 0.10705442726612091, precision: 0.322796352583567, recall: 0.8719211822658666, f1: 0.4711623779551972\n",
            "epoch: 494, step: 19, Train: label_loss: 0.11211428046226501, precision: 0.3195374315276738, recall: 0.8578431372547617, f1: 0.46563192900697375\n",
            "epoch: 494, step: 20, Train: label_loss: 0.08961819112300873, precision: 0.3235117257967334, recall: 0.886326194398536, f1: 0.4740088105334659\n",
            "epoch: 494, step: 21, Train: label_loss: 0.10704371333122253, precision: 0.3339361060879847, recall: 0.8878205128203704, f1: 0.4853263249711844\n",
            "epoch: 494, step: 22, Train: label_loss: 0.08123736083507538, precision: 0.3232682060390572, recall: 0.9099999999998483, f1: 0.4770642201447616\n",
            "epoch: 494, step: 23, Train: label_loss: 0.09384478628635406, precision: 0.3395245170876419, recall: 0.8856589147285104, f1: 0.49087003218329794\n",
            "epoch: 495, step: 0, Train: label_loss: 0.10782313346862793, precision: 0.3199999999999806, recall: 0.8785357737103363, f1: 0.4691248333681913\n",
            "epoch: 495, step: 1, Train: label_loss: 0.08817455917596817, precision: 0.32271386430676563, recall: 0.9116666666665146, f1: 0.47668845312038216\n",
            "epoch: 495, step: 2, Train: label_loss: 0.09149007499217987, precision: 0.32050511124471914, recall: 0.889816360600853, f1: 0.47126436777711317\n",
            "epoch: 495, step: 3, Train: label_loss: 0.0994466245174408, precision: 0.32778804682684365, recall: 0.8498402555909185, f1: 0.47309915513986406\n",
            "epoch: 495, step: 4, Train: label_loss: 0.09836070239543915, precision: 0.3180987202924852, recall: 0.8671096345513509, f1: 0.46544806059376775\n",
            "epoch: 495, step: 5, Train: label_loss: 0.10360904783010483, precision: 0.2927120669055978, recall: 0.8844765342958691, f1: 0.43985637339167993\n",
            "epoch: 495, step: 6, Train: label_loss: 0.08987440168857574, precision: 0.3297491039426326, recall: 0.8860353130014629, f1: 0.4806269046186758\n",
            "epoch: 495, step: 7, Train: label_loss: 0.09554214030504227, precision: 0.3126506024096197, recall: 0.8606965174127925, f1: 0.458683163902538\n",
            "epoch: 495, step: 8, Train: label_loss: 0.1009180098772049, precision: 0.32391826923074973, recall: 0.8792822185969201, f1: 0.47342995165143215\n",
            "epoch: 495, step: 9, Train: label_loss: 0.10708780586719513, precision: 0.3277108433734742, recall: 0.894736842105116, f1: 0.4797178130118616\n",
            "epoch: 495, step: 10, Train: label_loss: 0.09771156311035156, precision: 0.31124260355027744, recall: 0.8960817717204606, f1: 0.4620114184948497\n",
            "epoch: 495, step: 11, Train: label_loss: 0.1004878431558609, precision: 0.3138554216867281, recall: 0.8890784982933636, f1: 0.463935885980982\n",
            "epoch: 495, step: 12, Train: label_loss: 0.10219801217317581, precision: 0.31812725090034105, recall: 0.892255892255742, f1: 0.46902654863377463\n",
            "epoch: 495, step: 13, Train: label_loss: 0.10221865773200989, precision: 0.3363526570048106, recall: 0.8676012461057838, f1: 0.48476936462461906\n",
            "epoch: 495, step: 14, Train: label_loss: 0.10552344471216202, precision: 0.32785888077856884, recall: 0.8623999999998619, f1: 0.4750991625867503\n",
            "epoch: 495, step: 15, Train: label_loss: 0.11401548981666565, precision: 0.33252866626431304, recall: 0.8930307941651713, f1: 0.48460861913367853\n",
            "epoch: 495, step: 16, Train: label_loss: 0.0884738564491272, precision: 0.32091346153844225, recall: 0.8899999999998516, f1: 0.4717314487242525\n",
            "epoch: 495, step: 17, Train: label_loss: 0.08989068865776062, precision: 0.3165859564164457, recall: 0.8864406779659514, f1: 0.46654772520649385\n",
            "epoch: 495, step: 18, Train: label_loss: 0.0883505791425705, precision: 0.3413461538461333, recall: 0.9001584786052456, f1: 0.4949891067138994\n",
            "epoch: 495, step: 19, Train: label_loss: 0.09236966818571091, precision: 0.2928143712574675, recall: 0.8858695652172307, f1: 0.44014401436405853\n",
            "epoch: 495, step: 20, Train: label_loss: 0.09269110858440399, precision: 0.31512605042014913, recall: 0.902061855669948, f1: 0.46708185049539236\n",
            "epoch: 495, step: 21, Train: label_loss: 0.09761565178632736, precision: 0.313995215310986, recall: 0.8823529411763222, f1: 0.4631671812581122\n",
            "epoch: 495, step: 22, Train: label_loss: 0.09300991892814636, precision: 0.3189706762417523, recall: 0.8957983193275805, f1: 0.47043248010245037\n",
            "epoch: 495, step: 23, Train: label_loss: 0.08985331654548645, precision: 0.32029520295200586, recall: 0.8785425101212797, f1: 0.4694429420916726\n",
            "epoch: 496, step: 0, Train: label_loss: 0.10180678963661194, precision: 0.3287671232876516, recall: 0.9019607843135781, f1: 0.48188563941955503\n",
            "epoch: 496, step: 1, Train: label_loss: 0.10027264058589935, precision: 0.3135593220338793, recall: 0.8491803278687132, f1: 0.45800176830716555\n",
            "epoch: 496, step: 2, Train: label_loss: 0.09603020548820496, precision: 0.35226586102716906, recall: 0.8887195121949865, f1: 0.504543487626976\n",
            "epoch: 496, step: 3, Train: label_loss: 0.09238424152135849, precision: 0.3311258278145496, recall: 0.8870967741934053, f1: 0.4822446295088154\n",
            "epoch: 496, step: 4, Train: label_loss: 0.09876353293657303, precision: 0.3393177737881305, recall: 0.9145161290321105, f1: 0.49498035788278416\n",
            "epoch: 496, step: 5, Train: label_loss: 0.08911886811256409, precision: 0.34027364663888515, recall: 0.9196141479098199, f1: 0.49674337816287395\n",
            "epoch: 496, step: 6, Train: label_loss: 0.09300579130649567, precision: 0.3228299643281615, recall: 0.9004975124376615, f1: 0.47527352293703745\n",
            "epoch: 496, step: 7, Train: label_loss: 0.09870125353336334, precision: 0.32639714625443955, recall: 0.888349514562963, f1: 0.47739130430848487\n",
            "epoch: 496, step: 8, Train: label_loss: 0.09752927720546722, precision: 0.31818181818179914, recall: 0.8866666666665188, f1: 0.4683098591160195\n",
            "epoch: 496, step: 9, Train: label_loss: 0.10558275878429413, precision: 0.30392156862743236, recall: 0.8611111111109615, f1: 0.4492753622802365\n",
            "epoch: 496, step: 10, Train: label_loss: 0.09143124520778656, precision: 0.3182912154031096, recall: 0.8801996672211513, f1: 0.46752098979744977\n",
            "epoch: 496, step: 11, Train: label_loss: 0.09016484022140503, precision: 0.31732522796350654, recall: 0.8628099173552293, f1: 0.46399999996064123\n",
            "epoch: 496, step: 12, Train: label_loss: 0.10974323004484177, precision: 0.2958937198067454, recall: 0.8611599297010788, f1: 0.440449438164141\n",
            "epoch: 496, step: 13, Train: label_loss: 0.09661532938480377, precision: 0.3140794223826526, recall: 0.8699999999998549, f1: 0.46153846149944205\n",
            "epoch: 496, step: 14, Train: label_loss: 0.10020449012517929, precision: 0.29927007299268255, recall: 0.8785714285712716, f1: 0.4464609799983521\n",
            "epoch: 496, step: 15, Train: label_loss: 0.09767146408557892, precision: 0.30629539951571993, recall: 0.8754325259514055, f1: 0.45381165915438193\n",
            "epoch: 496, step: 16, Train: label_loss: 0.08841951191425323, precision: 0.3049730377471357, recall: 0.8914185639227861, f1: 0.45446428567625896\n",
            "epoch: 496, step: 17, Train: label_loss: 0.09205913543701172, precision: 0.32014388489206713, recall: 0.9066213921899988, f1: 0.47319450594277673\n",
            "epoch: 496, step: 18, Train: label_loss: 0.12736620008945465, precision: 0.2987012987012802, recall: 0.838541666666521, f1: 0.44049247602141794\n",
            "epoch: 496, step: 19, Train: label_loss: 0.10425075888633728, precision: 0.31464737793849823, recall: 0.8773109243696003, f1: 0.4631765749389176\n",
            "epoch: 496, step: 20, Train: label_loss: 0.10044287145137787, precision: 0.31766124171185545, recall: 0.8682042833606477, f1: 0.46513680490336573\n",
            "epoch: 496, step: 21, Train: label_loss: 0.09699103981256485, precision: 0.33922046285016205, recall: 0.8897763578273339, f1: 0.49118165780831513\n",
            "epoch: 496, step: 22, Train: label_loss: 0.10847529768943787, precision: 0.310281517747839, recall: 0.8521008403359912, f1: 0.45491251678451067\n",
            "epoch: 496, step: 23, Train: label_loss: 0.11120812594890594, precision: 0.3258426966291891, recall: 0.852941176470421, f1: 0.4715447154071007\n",
            "epoch: 497, step: 0, Train: label_loss: 0.08773591369390488, precision: 0.3207660083781974, recall: 0.9023569023567504, f1: 0.47328918318422103\n",
            "epoch: 497, step: 1, Train: label_loss: 0.09557537734508514, precision: 0.3313143549363821, recall: 0.8808373590980868, f1: 0.48151408446727595\n",
            "epoch: 497, step: 2, Train: label_loss: 0.10491404682397842, precision: 0.320597014925354, recall: 0.8935108153076715, f1: 0.47188049205248045\n",
            "epoch: 497, step: 3, Train: label_loss: 0.1023673564195633, precision: 0.3239352129573891, recall: 0.878048780487662, f1: 0.47326906218670195\n",
            "epoch: 497, step: 4, Train: label_loss: 0.09210886806249619, precision: 0.31926605504585204, recall: 0.8787878787877308, f1: 0.4683714669864356\n",
            "epoch: 497, step: 5, Train: label_loss: 0.08354263752698898, precision: 0.312611012433374, recall: 0.9230769230767616, f1: 0.4670499778480531\n",
            "epoch: 497, step: 6, Train: label_loss: 0.09672962129116058, precision: 0.3208232445520387, recall: 0.8660130718952833, f1: 0.4681978798191666\n",
            "epoch: 497, step: 7, Train: label_loss: 0.0986991673707962, precision: 0.3166963755198861, recall: 0.9080068143098964, f1: 0.46960352419068924\n",
            "epoch: 497, step: 8, Train: label_loss: 0.10602493584156036, precision: 0.3020257826887476, recall: 0.8310810810809406, f1: 0.44304367398157163\n",
            "epoch: 497, step: 9, Train: label_loss: 0.08282379060983658, precision: 0.3303464755077461, recall: 0.8933764135701302, f1: 0.48233754902290604\n",
            "epoch: 497, step: 10, Train: label_loss: 0.08621559292078018, precision: 0.33729922665078305, recall: 0.9043062200955495, f1: 0.49133448869522023\n",
            "epoch: 497, step: 11, Train: label_loss: 0.0886673778295517, precision: 0.3184290030211288, recall: 0.8625204582649979, f1: 0.46513680490320247\n",
            "epoch: 497, step: 12, Train: label_loss: 0.11351963877677917, precision: 0.305658056580547, recall: 0.8466780238499408, f1: 0.4491640306885\n",
            "epoch: 497, step: 13, Train: label_loss: 0.10110361874103546, precision: 0.3256379100850349, recall: 0.8562300319487449, f1: 0.4718309858755289\n",
            "epoch: 497, step: 14, Train: label_loss: 0.10346509516239166, precision: 0.2973955178679408, recall: 0.8644366197181576, f1: 0.4425416854057637\n",
            "epoch: 497, step: 15, Train: label_loss: 0.0865536481142044, precision: 0.32772098616955336, recall: 0.8790322580643742, f1: 0.47744196229066116\n",
            "epoch: 497, step: 16, Train: label_loss: 0.10322761535644531, precision: 0.32975551580200774, recall: 0.8862179487178067, f1: 0.4806605823159269\n",
            "epoch: 497, step: 17, Train: label_loss: 0.11410537362098694, precision: 0.30545454545452694, recall: 0.8586030664393767, f1: 0.45060348677394557\n",
            "epoch: 497, step: 18, Train: label_loss: 0.0999513566493988, precision: 0.31397459165152364, recall: 0.8811544991509539, f1: 0.4629794825660369\n",
            "epoch: 497, step: 19, Train: label_loss: 0.08487866073846817, precision: 0.32291040288633055, recall: 0.8689320388348107, f1: 0.47084612008320614\n",
            "epoch: 497, step: 20, Train: label_loss: 0.10275907069444656, precision: 0.3235831809871832, recall: 0.8791390728475365, f1: 0.4730512249049469\n",
            "epoch: 497, step: 21, Train: label_loss: 0.10253624618053436, precision: 0.3095525997581433, recall: 0.8797250859105017, f1: 0.45796064396860714\n",
            "epoch: 497, step: 22, Train: label_loss: 0.10533671826124191, precision: 0.31968215158922253, recall: 0.8658940397349559, f1: 0.4669642856748569\n",
            "epoch: 497, step: 23, Train: label_loss: 0.104488305747509, precision: 0.3090772693173061, recall: 0.8860215053761535, f1: 0.4582869855010901\n",
            "epoch: 498, step: 0, Train: label_loss: 0.09473340213298798, precision: 0.3072792362768313, recall: 0.9019264448334672, f1: 0.45838896302391113\n",
            "epoch: 498, step: 1, Train: label_loss: 0.08803264796733856, precision: 0.3151010701545591, recall: 0.9013605442175338, f1: 0.46696035238447947\n",
            "epoch: 498, step: 2, Train: label_loss: 0.07533900439739227, precision: 0.31682577565630565, recall: 0.9030612244896423, f1: 0.4690812720463112\n",
            "epoch: 498, step: 3, Train: label_loss: 0.10248300433158875, precision: 0.31379731379729464, recall: 0.8552412645589259, f1: 0.4591335417203987\n",
            "epoch: 498, step: 4, Train: label_loss: 0.10269168019294739, precision: 0.33109756097558957, recall: 0.8619047619046251, f1: 0.47841409687615566\n",
            "epoch: 498, step: 5, Train: label_loss: 0.08262341469526291, precision: 0.3390532544378497, recall: 0.9153354632586397, f1: 0.4948186528102511\n",
            "epoch: 498, step: 6, Train: label_loss: 0.09403785318136215, precision: 0.32035928143710657, recall: 0.8976510067112587, f1: 0.4721977051686044\n",
            "epoch: 498, step: 7, Train: label_loss: 0.09574925899505615, precision: 0.3182640144665269, recall: 0.8741721854303188, f1: 0.46663720720784285\n",
            "epoch: 498, step: 8, Train: label_loss: 0.08999288827180862, precision: 0.316956261234253, recall: 0.8700657894735411, f1: 0.46464646460727993\n",
            "epoch: 498, step: 9, Train: label_loss: 0.09674686938524246, precision: 0.3335322195703858, recall: 0.8887122416532768, f1: 0.48503253792122847\n",
            "epoch: 498, step: 10, Train: label_loss: 0.09374278783798218, precision: 0.31433713257346646, recall: 0.8777219430484291, f1: 0.46289752646289406\n",
            "epoch: 498, step: 11, Train: label_loss: 0.09596521407365799, precision: 0.3182089552238616, recall: 0.8839137645106327, f1: 0.4679543458785031\n",
            "epoch: 498, step: 12, Train: label_loss: 0.1002652645111084, precision: 0.31515151515149603, recall: 0.8595041322312629, f1: 0.46119733920681644\n",
            "epoch: 498, step: 13, Train: label_loss: 0.08589281141757965, precision: 0.3146936347412067, recall: 0.8905723905722406, f1: 0.4650549450163189\n",
            "epoch: 498, step: 14, Train: label_loss: 0.09707798063755035, precision: 0.311942959001764, recall: 0.908304498269739, f1: 0.46439628479162276\n",
            "epoch: 498, step: 15, Train: label_loss: 0.08973871916532516, precision: 0.3223487118034558, recall: 0.8907284768210445, f1: 0.473383193977653\n",
            "epoch: 498, step: 16, Train: label_loss: 0.12934327125549316, precision: 0.293071735131803, recall: 0.8430335097000277, f1: 0.43494085528469784\n",
            "epoch: 498, step: 17, Train: label_loss: 0.0900329053401947, precision: 0.3250296559904908, recall: 0.904290429042755, f1: 0.4781849912350565\n",
            "epoch: 498, step: 18, Train: label_loss: 0.09306637942790985, precision: 0.34686567164177035, recall: 0.8952234206470114, f1: 0.49999999995970223\n",
            "epoch: 498, step: 19, Train: label_loss: 0.1021995097398758, precision: 0.3207434052757601, recall: 0.896147403684942, f1: 0.47240618097659\n",
            "epoch: 498, step: 20, Train: label_loss: 0.09042150527238846, precision: 0.305974652987308, recall: 0.8726333907055296, f1: 0.4530831098810883\n",
            "epoch: 498, step: 21, Train: label_loss: 0.0904814749956131, precision: 0.3189448441246811, recall: 0.8881469115190503, f1: 0.46934274367523615\n",
            "epoch: 498, step: 22, Train: label_loss: 0.08762383460998535, precision: 0.32975551580200774, recall: 0.9035947712416823, f1: 0.483180428095338\n",
            "epoch: 498, step: 23, Train: label_loss: 0.09867733716964722, precision: 0.31342182890853143, recall: 0.874485596707639, f1: 0.4614549402434057\n",
            "epoch: 499, step: 0, Train: label_loss: 0.09020896255970001, precision: 0.31569452796149633, recall: 0.8764607679464312, f1: 0.46419098139338255\n",
            "epoch: 499, step: 1, Train: label_loss: 0.09588398039340973, precision: 0.3017607771705949, recall: 0.8338926174495245, f1: 0.4431564868089098\n",
            "epoch: 499, step: 2, Train: label_loss: 0.10378217697143555, precision: 0.31379731379729464, recall: 0.8524046434492781, f1: 0.45872378398561303\n",
            "epoch: 499, step: 3, Train: label_loss: 0.0958784818649292, precision: 0.321559074299615, recall: 0.8727272727271284, f1: 0.4699599465560681\n",
            "epoch: 499, step: 4, Train: label_loss: 0.09974274039268494, precision: 0.33012627781116477, recall: 0.8783999999998594, f1: 0.4798951048553538\n",
            "epoch: 499, step: 5, Train: label_loss: 0.08826759457588196, precision: 0.3056220095693597, recall: 0.9028268551235153, f1: 0.4566577300783456\n",
            "epoch: 499, step: 6, Train: label_loss: 0.0894412100315094, precision: 0.33413751507838757, recall: 0.8724409448817523, f1: 0.48320976882166305\n",
            "epoch: 499, step: 7, Train: label_loss: 0.09405000507831573, precision: 0.30932203389828633, recall: 0.8735042735041241, f1: 0.4568618685353176\n",
            "epoch: 499, step: 8, Train: label_loss: 0.1028883308172226, precision: 0.31144578313251137, recall: 0.8777589134124145, f1: 0.4597598932472028\n",
            "epoch: 499, step: 9, Train: label_loss: 0.10007981956005096, precision: 0.31818181818179914, recall: 0.9016949152540844, f1: 0.4703801944795243\n",
            "epoch: 499, step: 10, Train: label_loss: 0.08578218519687653, precision: 0.33393070489842686, recall: 0.8943999999998569, f1: 0.4862983905649782\n",
            "epoch: 499, step: 11, Train: label_loss: 0.11039894819259644, precision: 0.34023128423613264, recall: 0.8775510204080255, f1: 0.4903508771526735\n",
            "epoch: 499, step: 12, Train: label_loss: 0.0924965888261795, precision: 0.3250296559904908, recall: 0.9163879598660675, f1: 0.47985989488249464\n",
            "epoch: 499, step: 13, Train: label_loss: 0.10560880601406097, precision: 0.3197815533980388, recall: 0.881270903009886, f1: 0.4692787176812777\n",
            "epoch: 499, step: 14, Train: label_loss: 0.0890834629535675, precision: 0.30292188431721506, recall: 0.8959435626100712, f1: 0.45276292331335233\n",
            "epoch: 499, step: 15, Train: label_loss: 0.09449183940887451, precision: 0.3069486404833651, recall: 0.8743545611013985, f1: 0.45438282643734446\n",
            "epoch: 499, step: 16, Train: label_loss: 0.10189767181873322, precision: 0.31862745098037265, recall: 0.8595041322312629, f1: 0.4649083593704209\n",
            "epoch: 499, step: 17, Train: label_loss: 0.09865294396877289, precision: 0.32531569452794196, recall: 0.8754045307441949, f1: 0.47435335375264903\n",
            "epoch: 499, step: 18, Train: label_loss: 0.09247061610221863, precision: 0.3249850924269335, recall: 0.8890701468187783, f1: 0.4759825327118441\n",
            "epoch: 499, step: 19, Train: label_loss: 0.09618252515792847, precision: 0.3038204972710549, recall: 0.8728222996514158, f1: 0.45074224017757636\n",
            "epoch: 499, step: 20, Train: label_loss: 0.10549517720937729, precision: 0.3018072289156445, recall: 0.8758741258739727, f1: 0.44892473114463616\n",
            "epoch: 499, step: 21, Train: label_loss: 0.09409689158201218, precision: 0.31588447653427704, recall: 0.863486842105121, f1: 0.4625550660400339\n",
            "epoch: 499, step: 22, Train: label_loss: 0.09673330932855606, precision: 0.33791866028706113, recall: 0.9039999999998553, f1: 0.49194601650366276\n",
            "epoch: 499, step: 23, Train: label_loss: 0.10583122819662094, precision: 0.31794489947875515, recall: 0.8455445544552781, f1: 0.4621212120814435\n",
            "epoch: 500, step: 0, Train: label_loss: 0.10350532084703445, precision: 0.296951219512177, recall: 0.8382099827881517, f1: 0.4385411976200403\n",
            "epoch: 500, step: 1, Train: label_loss: 0.0850856751203537, precision: 0.31249999999998124, recall: 0.8798646362096649, f1: 0.46119733920739964\n",
            "epoch: 500, step: 2, Train: label_loss: 0.08405721187591553, precision: 0.3183722321962706, recall: 0.8837209302324113, f1: 0.4681038275017132\n",
            "epoch: 500, step: 3, Train: label_loss: 0.09642627090215683, precision: 0.32551143200960736, recall: 0.8986710963453656, f1: 0.47791519430720797\n",
            "epoch: 500, step: 4, Train: label_loss: 0.08916084468364716, precision: 0.3301662707838284, recall: 0.8982229402260261, f1: 0.48284845849299973\n",
            "epoch: 500, step: 5, Train: label_loss: 0.08482857048511505, precision: 0.3191105769230577, recall: 0.8704918032785458, f1: 0.4670184696176926\n",
            "epoch: 500, step: 6, Train: label_loss: 0.10658296942710876, precision: 0.31983071342198793, recall: 0.8846153846152366, f1: 0.4698046180781815\n",
            "epoch: 500, step: 7, Train: label_loss: 0.08841155469417572, precision: 0.305125148986871, recall: 0.8904347826085407, f1: 0.45450510426731416\n",
            "epoch: 500, step: 8, Train: label_loss: 0.09906074404716492, precision: 0.3347305389221356, recall: 0.9239669421486075, f1: 0.49142857138948554\n",
            "epoch: 500, step: 9, Train: label_loss: 0.10244210064411163, precision: 0.3026796589524785, recall: 0.8539518900342175, f1: 0.4469424460044835\n",
            "epoch: 500, step: 10, Train: label_loss: 0.10118679702281952, precision: 0.3268765133171715, recall: 0.8794788273614202, f1: 0.4766107678333534\n",
            "epoch: 500, step: 11, Train: label_loss: 0.08984114974737167, precision: 0.3279952550414989, recall: 0.894822006472347, f1: 0.48003472218292403\n",
            "epoch: 500, step: 12, Train: label_loss: 0.09655001759529114, precision: 0.32430806257519107, recall: 0.8693548387095371, f1: 0.47239263799719333\n",
            "epoch: 500, step: 13, Train: label_loss: 0.1049967110157013, precision: 0.3199279711884562, recall: 0.8752052545154556, f1: 0.46857142853218076\n",
            "epoch: 500, step: 14, Train: label_loss: 0.09586939960718155, precision: 0.32673860911269026, recall: 0.9068219633941919, f1: 0.48038783601213836\n",
            "epoch: 500, step: 15, Train: label_loss: 0.08513357490301132, precision: 0.33532576210398474, recall: 0.89189189189175, f1: 0.48740225886554134\n",
            "epoch: 500, step: 16, Train: label_loss: 0.0909113883972168, precision: 0.3079213817748476, recall: 0.9038461538459958, f1: 0.4593513993401058\n",
            "epoch: 500, step: 17, Train: label_loss: 0.09089325368404388, precision: 0.30292188431721506, recall: 0.8788927335638617, f1: 0.4505543236868915\n",
            "epoch: 500, step: 18, Train: label_loss: 0.10829021036624908, precision: 0.3116564417177723, recall: 0.8273615635177805, f1: 0.45276292331136797\n",
            "epoch: 500, step: 19, Train: label_loss: 0.09687845408916473, precision: 0.32203389830506524, recall: 0.8881469115190503, f1: 0.47267880937893586\n",
            "epoch: 500, step: 20, Train: label_loss: 0.1084849089384079, precision: 0.3428398058252219, recall: 0.8759689922479261, f1: 0.4928041866145607\n",
            "epoch: 500, step: 21, Train: label_loss: 0.0981316789984703, precision: 0.3213859020310441, recall: 0.883415435139428, f1: 0.4713096802061307\n",
            "epoch: 500, step: 22, Train: label_loss: 0.0983496606349945, precision: 0.2917675544794012, recall: 0.8530973451325923, f1: 0.43482183126554397\n",
            "epoch: 500, step: 23, Train: label_loss: 0.09140747785568237, precision: 0.3158671586715634, recall: 0.8898128898127048, f1: 0.46623093678045174\n",
            "epoch: 501, step: 0, Train: label_loss: 0.09957060217857361, precision: 0.3184019370459856, recall: 0.8723051409617126, f1: 0.4665188469674305\n",
            "epoch: 501, step: 1, Train: label_loss: 0.10396579653024673, precision: 0.3211284513805329, recall: 0.8946488294312884, f1: 0.472614840950484\n",
            "epoch: 501, step: 2, Train: label_loss: 0.08949790894985199, precision: 0.3301662707838284, recall: 0.9174917491747661, f1: 0.48558951961169255\n",
            "epoch: 501, step: 3, Train: label_loss: 0.08403581380844116, precision: 0.3277711561382403, recall: 0.9090909090907587, f1: 0.4818221637805383\n",
            "epoch: 501, step: 4, Train: label_loss: 0.10185264050960541, precision: 0.32809667673714027, recall: 0.8743961352655596, f1: 0.4771528997845308\n",
            "epoch: 501, step: 5, Train: label_loss: 0.09675189852714539, precision: 0.31105710814092885, recall: 0.8561872909697564, f1: 0.4563279857006153\n",
            "epoch: 501, step: 6, Train: label_loss: 0.08837394416332245, precision: 0.3099940155595266, recall: 0.8691275167783776, f1: 0.45699161884077916\n",
            "epoch: 501, step: 7, Train: label_loss: 0.08729757368564606, precision: 0.31623415811705996, recall: 0.8747913188646285, f1: 0.46453900705315415\n",
            "epoch: 501, step: 8, Train: label_loss: 0.08857820928096771, precision: 0.33966745843228385, recall: 0.9036334913110736, f1: 0.4937419075994338\n",
            "epoch: 501, step: 9, Train: label_loss: 0.09433417022228241, precision: 0.3220747889022725, recall: 0.8725490196077005, f1: 0.4704845814583724\n",
            "epoch: 501, step: 10, Train: label_loss: 0.08715160191059113, precision: 0.31661631419937664, recall: 0.8791946308723356, f1: 0.4655708573577377\n",
            "epoch: 501, step: 11, Train: label_loss: 0.09270530939102173, precision: 0.3325315694527761, recall: 0.894822006472347, f1: 0.4848750547609778\n",
            "epoch: 501, step: 12, Train: label_loss: 0.10054519772529602, precision: 0.2960960960960783, recall: 0.8741134751771499, f1: 0.44235082993075503\n",
            "epoch: 501, step: 13, Train: label_loss: 0.1069781556725502, precision: 0.30935251798559293, recall: 0.8911917098444055, f1: 0.45927903867999426\n",
            "epoch: 501, step: 14, Train: label_loss: 0.0985407680273056, precision: 0.3271531100478273, recall: 0.8996710526314309, f1: 0.47982456136435553\n",
            "epoch: 501, step: 15, Train: label_loss: 0.11106130480766296, precision: 0.30741190765490234, recall: 0.869415807559988, f1: 0.4542190304820087\n",
            "epoch: 501, step: 16, Train: label_loss: 0.0998181477189064, precision: 0.31939393939392, recall: 0.8725165562912462, f1: 0.46761313217013173\n",
            "epoch: 501, step: 17, Train: label_loss: 0.09956687688827515, precision: 0.32106824925814115, recall: 0.8986710963453656, f1: 0.4731088762182762\n",
            "epoch: 501, step: 18, Train: label_loss: 0.0751606747508049, precision: 0.3463126843657613, recall: 0.9317460317458838, f1: 0.5049462365195875\n",
            "epoch: 501, step: 19, Train: label_loss: 0.10342082381248474, precision: 0.34147831398898343, recall: 0.8693623639189938, f1: 0.49035087715244274\n",
            "epoch: 501, step: 20, Train: label_loss: 0.09735405445098877, precision: 0.2913669064748027, recall: 0.8788426763108718, f1: 0.4376407023488746\n",
            "epoch: 501, step: 21, Train: label_loss: 0.1046186238527298, precision: 0.3188836104512875, recall: 0.883223684210381, f1: 0.4685863873955337\n",
            "epoch: 501, step: 22, Train: label_loss: 0.09847286343574524, precision: 0.3125748502993825, recall: 0.8729096989965095, f1: 0.46031746027859016\n",
            "epoch: 501, step: 23, Train: label_loss: 0.09489883482456207, precision: 0.3005908419497562, recall: 0.8790496760257281, f1: 0.44799119423825334\n",
            "epoch: 502, step: 0, Train: label_loss: 0.09873753786087036, precision: 0.31661631419937664, recall: 0.8733333333331877, f1: 0.46474501104737737\n",
            "epoch: 502, step: 1, Train: label_loss: 0.08558826893568039, precision: 0.3283671036948553, recall: 0.9137645107792846, f1: 0.4831214379268675\n",
            "epoch: 502, step: 2, Train: label_loss: 0.1041443794965744, precision: 0.31884057971012564, recall: 0.8741721854303188, f1: 0.46725663712893406\n",
            "epoch: 502, step: 3, Train: label_loss: 0.07836462557315826, precision: 0.33116883116881163, recall: 0.8961661341851603, f1: 0.4836206896157266\n",
            "epoch: 502, step: 4, Train: label_loss: 0.08917809277772903, precision: 0.3252225519287641, recall: 0.904290429042755, f1: 0.47839371449618656\n",
            "epoch: 502, step: 5, Train: label_loss: 0.09987883269786835, precision: 0.29718394248050944, recall: 0.8953068592056145, f1: 0.446243814627406\n",
            "epoch: 502, step: 6, Train: label_loss: 0.08935454487800598, precision: 0.3059388122375341, recall: 0.890052356020787, f1: 0.45535714281902856\n",
            "epoch: 502, step: 7, Train: label_loss: 0.09591548144817352, precision: 0.29723225030082445, recall: 0.8712522045853842, f1: 0.44324809327741466\n",
            "epoch: 502, step: 8, Train: label_loss: 0.10142090916633606, precision: 0.3287425149700402, recall: 0.9149999999998474, f1: 0.48370044048970107\n",
            "epoch: 502, step: 9, Train: label_loss: 0.08707433938980103, precision: 0.3387387387387184, recall: 0.9082125603863271, f1: 0.493438320170359\n",
            "epoch: 502, step: 10, Train: label_loss: 0.11193861812353134, precision: 0.30073349633249996, recall: 0.8255033557045595, f1: 0.44086021501457945\n",
            "epoch: 502, step: 11, Train: label_loss: 0.09942798316478729, precision: 0.31678921568625507, recall: 0.8573797678273868, f1: 0.46263982098963985\n",
            "epoch: 502, step: 12, Train: label_loss: 0.095751091837883, precision: 0.3095956547978087, recall: 0.8739352640543655, f1: 0.4572192512982258\n",
            "epoch: 502, step: 13, Train: label_loss: 0.08571333438158035, precision: 0.33712574850297383, recall: 0.8964968152864814, f1: 0.4899912967400462\n",
            "epoch: 502, step: 14, Train: label_loss: 0.11721934378147125, precision: 0.32041187159295453, recall: 0.8714991762766273, f1: 0.46855624442477467\n",
            "epoch: 502, step: 15, Train: label_loss: 0.10256895422935486, precision: 0.33475349969565826, recall: 0.8513931888543573, f1: 0.4805591961149701\n",
            "epoch: 502, step: 16, Train: label_loss: 0.09715401381254196, precision: 0.32608695652171943, recall: 0.8653846153844766, f1: 0.473684210486518\n",
            "epoch: 502, step: 17, Train: label_loss: 0.10261914134025574, precision: 0.3063549160671279, recall: 0.8749999999998501, f1: 0.45381882767024784\n",
            "epoch: 502, step: 18, Train: label_loss: 0.0935821533203125, precision: 0.3117893476959718, recall: 0.8936535162948723, f1: 0.46228926349310834\n",
            "epoch: 502, step: 19, Train: label_loss: 0.08881495147943497, precision: 0.34139150943394214, recall: 0.9075235109716445, f1: 0.496143958829126\n",
            "epoch: 502, step: 20, Train: label_loss: 0.1113864928483963, precision: 0.3297362110311553, recall: 0.8972267536703267, f1: 0.48224462950909747\n",
            "epoch: 502, step: 21, Train: label_loss: 0.09982055425643921, precision: 0.29315566323438563, recall: 0.8596802841916767, f1: 0.4372177054724235\n",
            "epoch: 502, step: 22, Train: label_loss: 0.10027448832988739, precision: 0.3208459214501317, recall: 0.8894472361807555, f1: 0.4715808170125037\n",
            "epoch: 502, step: 23, Train: label_loss: 0.10115587711334229, precision: 0.32289336316179545, recall: 0.8729838709675659, f1: 0.4714207947346164\n",
            "epoch: 503, step: 0, Train: label_loss: 0.1062650978565216, precision: 0.3304981773997369, recall: 0.9021558872303644, f1: 0.4837705646561309\n",
            "epoch: 503, step: 1, Train: label_loss: 0.09676052629947662, precision: 0.3337393422655095, recall: 0.8810289389066107, f1: 0.4840989398894347\n",
            "epoch: 503, step: 2, Train: label_loss: 0.09369616955518723, precision: 0.3166564978645322, recall: 0.8781725888323386, f1: 0.4654708519789383\n",
            "epoch: 503, step: 3, Train: label_loss: 0.09792761504650116, precision: 0.31398900427609566, recall: 0.8831615120273396, f1: 0.46327174399010224\n",
            "epoch: 503, step: 4, Train: label_loss: 0.08556338399648666, precision: 0.3185362927414326, recall: 0.898477157360254, f1: 0.47032772361055936\n",
            "epoch: 503, step: 5, Train: label_loss: 0.09953498095273972, precision: 0.33111782477339385, recall: 0.8796147672550755, f1: 0.48112379276092193\n",
            "epoch: 503, step: 6, Train: label_loss: 0.09703226387500763, precision: 0.3101150817686063, recall: 0.8767123287669731, f1: 0.4581655480597888\n",
            "epoch: 503, step: 7, Train: label_loss: 0.09970641136169434, precision: 0.31506024096383645, recall: 0.8819561551431901, f1: 0.4642698623668545\n",
            "epoch: 503, step: 8, Train: label_loss: 0.10059704631567001, precision: 0.3106617647058633, recall: 0.8521008403359912, f1: 0.45532105968239917\n",
            "epoch: 503, step: 9, Train: label_loss: 0.08786329627037048, precision: 0.30921052631577095, recall: 0.8807495741054717, f1: 0.4577246568893381\n",
            "epoch: 503, step: 10, Train: label_loss: 0.09364362061023712, precision: 0.3252656434474424, recall: 0.9198664440733021, f1: 0.48059310942494515\n",
            "epoch: 503, step: 11, Train: label_loss: 0.08482560515403748, precision: 0.32337118947995674, recall: 0.8725806451611495, f1: 0.47187091143019355\n",
            "epoch: 503, step: 12, Train: label_loss: 0.09743724763393402, precision: 0.32214765100669174, recall: 0.8613376835235136, f1: 0.46891651861042544\n",
            "epoch: 503, step: 13, Train: label_loss: 0.10632984340190887, precision: 0.324275362318821, recall: 0.8578274760382015, f1: 0.4706397896183395\n",
            "epoch: 503, step: 14, Train: label_loss: 0.0872497633099556, precision: 0.3162544169611121, recall: 0.9132653061222936, f1: 0.46981627292762673\n",
            "epoch: 503, step: 15, Train: label_loss: 0.09628581255674362, precision: 0.3254257907542381, recall: 0.8713355048858515, f1: 0.4738706819798482\n",
            "epoch: 503, step: 16, Train: label_loss: 0.09567417949438095, precision: 0.30906921241048274, recall: 0.886986301369711, f1: 0.45840707960765054\n",
            "epoch: 503, step: 17, Train: label_loss: 0.09945371747016907, precision: 0.3275030156815243, recall: 0.8872549019606393, f1: 0.4784140968768738\n",
            "epoch: 503, step: 18, Train: label_loss: 0.09279447793960571, precision: 0.31219806763283137, recall: 0.8703703703702238, f1: 0.4595555555166539\n",
            "epoch: 503, step: 19, Train: label_loss: 0.09498381614685059, precision: 0.3267267267267071, recall: 0.8918032786883783, f1: 0.4782417582024687\n",
            "epoch: 503, step: 20, Train: label_loss: 0.09337630867958069, precision: 0.3392645314353298, recall: 0.9270664505671106, f1: 0.4967433781630746\n",
            "epoch: 503, step: 21, Train: label_loss: 0.09423405677080154, precision: 0.3258084197681314, recall: 0.87684729064025, f1: 0.47508896793198463\n",
            "epoch: 503, step: 22, Train: label_loss: 0.10329028964042664, precision: 0.312499999999981, recall: 0.8714043993230335, f1: 0.46002679763863674\n",
            "epoch: 503, step: 23, Train: label_loss: 0.11087488383054733, precision: 0.30037174721187354, recall: 0.8577494692142553, f1: 0.44493392066637816\n",
            "epoch: 504, step: 0, Train: label_loss: 0.0830187276005745, precision: 0.3374777975133015, recall: 0.9004739336491467, f1: 0.49095607231172017\n",
            "epoch: 504, step: 1, Train: label_loss: 0.10476280003786087, precision: 0.3271861986912357, recall: 0.9075907590757577, f1: 0.480979449020909\n",
            "epoch: 504, step: 2, Train: label_loss: 0.09877572953701019, precision: 0.29964114832534094, recall: 0.8804920913882459, f1: 0.44712182057786926\n",
            "epoch: 504, step: 3, Train: label_loss: 0.09476500749588013, precision: 0.32261904761902843, recall: 0.9003322259134716, f1: 0.47502191056584875\n",
            "epoch: 504, step: 4, Train: label_loss: 0.09343184530735016, precision: 0.3183453237409881, recall: 0.8894472361807555, f1: 0.4688741721465683\n",
            "epoch: 504, step: 5, Train: label_loss: 0.08839761465787888, precision: 0.3153477218225231, recall: 0.8552845528453893, f1: 0.4607971966316434\n",
            "epoch: 504, step: 6, Train: label_loss: 0.09858035296201706, precision: 0.3339371980676127, recall: 0.8654147104849975, f1: 0.48191721128875253\n",
            "epoch: 504, step: 7, Train: label_loss: 0.1167171448469162, precision: 0.3056741915802132, recall: 0.8477157360404657, f1: 0.44932735422109227\n",
            "epoch: 504, step: 8, Train: label_loss: 0.07476775348186493, precision: 0.32560903149136505, recall: 0.9163879598660675, f1: 0.4804910126749929\n",
            "epoch: 504, step: 9, Train: label_loss: 0.0910818874835968, precision: 0.28690476190474484, recall: 0.8959107806689783, f1: 0.434625788962314\n",
            "epoch: 504, step: 10, Train: label_loss: 0.10421359539031982, precision: 0.3060975609755911, recall: 0.8625429553263122, f1: 0.451845184479747\n",
            "epoch: 504, step: 11, Train: label_loss: 0.09638404101133347, precision: 0.3339361060879847, recall: 0.8793650793649397, f1: 0.4840541720876287\n",
            "epoch: 504, step: 12, Train: label_loss: 0.09087769687175751, precision: 0.321665660832811, recall: 0.8853820598005173, f1: 0.4718902168710009\n",
            "epoch: 504, step: 13, Train: label_loss: 0.09271927177906036, precision: 0.3393177737881305, recall: 0.8859374999998615, f1: 0.4906966680689527\n",
            "epoch: 504, step: 14, Train: label_loss: 0.10706992447376251, precision: 0.3333333333333133, recall: 0.890675241157413, f1: 0.4851138353368567\n",
            "epoch: 504, step: 15, Train: label_loss: 0.11678186058998108, precision: 0.3174504950494853, recall: 0.8382352941175101, f1: 0.4605026929583166\n",
            "epoch: 504, step: 16, Train: label_loss: 0.09544256329536438, precision: 0.3197568389057556, recall: 0.8723051409617126, f1: 0.4679715302098113\n",
            "epoch: 504, step: 17, Train: label_loss: 0.11837181448936462, precision: 0.31874999999998005, recall: 0.8265802269042419, f1: 0.46008119075816445\n",
            "epoch: 504, step: 18, Train: label_loss: 0.11020933091640472, precision: 0.3001841620625967, recall: 0.8716577540105397, f1: 0.44657534242760377\n",
            "epoch: 504, step: 19, Train: label_loss: 0.0973554402589798, precision: 0.3315151515151314, recall: 0.8808373590980868, f1: 0.4817261118052249\n",
            "epoch: 504, step: 20, Train: label_loss: 0.10280180722475052, precision: 0.32465172622650973, recall: 0.8743882544859911, f1: 0.473498233176016\n",
            "epoch: 504, step: 21, Train: label_loss: 0.0912751853466034, precision: 0.2933413317336357, recall: 0.8763440860213483, f1: 0.4395505617601348\n",
            "epoch: 504, step: 22, Train: label_loss: 0.10885985940694809, precision: 0.31276725717774506, recall: 0.8663282571910547, f1: 0.4596050268909612\n",
            "epoch: 504, step: 23, Train: label_loss: 0.10680586099624634, precision: 0.3140929535232148, recall: 0.8747390396657881, f1: 0.4622173193212455\n",
            "epoch: 505, step: 0, Train: label_loss: 0.10602139681577682, precision: 0.3150517976843196, recall: 0.8573797678273868, f1: 0.46078431368614753\n",
            "epoch: 505, step: 1, Train: label_loss: 0.10801827162504196, precision: 0.31527693244063815, recall: 0.8590381426200896, f1: 0.4612644701298691\n",
            "epoch: 505, step: 2, Train: label_loss: 0.10940997302532196, precision: 0.32531569452794196, recall: 0.871175523349296, f1: 0.4737302976836577\n",
            "epoch: 505, step: 3, Train: label_loss: 0.08314833045005798, precision: 0.3162958508718992, recall: 0.8945578231290995, f1: 0.4673478453634054\n",
            "epoch: 505, step: 4, Train: label_loss: 0.10103891789913177, precision: 0.3243566726510877, recall: 0.8870703764319333, f1: 0.4750219105654792\n",
            "epoch: 505, step: 5, Train: label_loss: 0.10253603756427765, precision: 0.31291291291289414, recall: 0.8860544217685568, f1: 0.462494451803373\n",
            "epoch: 505, step: 6, Train: label_loss: 0.1072642058134079, precision: 0.3199753390875265, recall: 0.8251192368838115, f1: 0.46112838734307426\n",
            "epoch: 505, step: 7, Train: label_loss: 0.10196798294782639, precision: 0.30769230769228906, recall: 0.8743545611013985, f1: 0.4551971325779374\n",
            "epoch: 505, step: 8, Train: label_loss: 0.09992622584104538, precision: 0.3403869407496771, recall: 0.8769470404983057, f1: 0.49041811842656996\n",
            "epoch: 505, step: 9, Train: label_loss: 0.10355106741189957, precision: 0.3219512195121755, recall: 0.8599348534200554, f1: 0.4685004436160415\n",
            "epoch: 505, step: 10, Train: label_loss: 0.1043805480003357, precision: 0.31272727272725376, recall: 0.8760611205431449, f1: 0.4609200535565416\n",
            "epoch: 505, step: 11, Train: label_loss: 0.09355911612510681, precision: 0.3251053582179214, recall: 0.8896210873145156, f1: 0.4761904761512328\n",
            "epoch: 505, step: 12, Train: label_loss: 0.10228197276592255, precision: 0.33814681107097844, recall: 0.8906497622819507, f1: 0.49018752721693426\n",
            "epoch: 505, step: 13, Train: label_loss: 0.08962956070899963, precision: 0.32770066385031216, recall: 0.8960396039602481, f1: 0.4798939460500043\n",
            "epoch: 505, step: 14, Train: label_loss: 0.10857438296079636, precision: 0.30569007263920667, recall: 0.8721934369601256, f1: 0.4527117883972041\n",
            "epoch: 505, step: 15, Train: label_loss: 0.10865888744592667, precision: 0.30741190765490234, recall: 0.8784722222220697, f1: 0.4554455445160089\n",
            "epoch: 505, step: 16, Train: label_loss: 0.10264284908771515, precision: 0.3233353329333939, recall: 0.8909090909089435, f1: 0.4744718309467982\n",
            "epoch: 505, step: 17, Train: label_loss: 0.10575634241104126, precision: 0.33715319662241633, recall: 0.8873015873014464, f1: 0.4886363635964145\n",
            "epoch: 505, step: 18, Train: label_loss: 0.10375338792800903, precision: 0.3183747725894288, recall: 0.8823529411763222, f1: 0.4679144384636628\n",
            "epoch: 505, step: 19, Train: label_loss: 0.07587366551160812, precision: 0.3207769276044543, recall: 0.9113712374580415, f1: 0.47453199822004427\n",
            "epoch: 505, step: 20, Train: label_loss: 0.09347635507583618, precision: 0.30773845230951963, recall: 0.8709677419353359, f1: 0.4547872340039292\n",
            "epoch: 505, step: 21, Train: label_loss: 0.08186060935258865, precision: 0.2993440667859094, recall: 0.8776223776222242, f1: 0.44642063135376014\n",
            "epoch: 505, step: 22, Train: label_loss: 0.0986252874135971, precision: 0.31528279181706886, recall: 0.8896434634973022, f1: 0.4655708573580322\n",
            "epoch: 505, step: 23, Train: label_loss: 0.10567715764045715, precision: 0.2989536621823394, recall: 0.845665961944853, f1: 0.4417448922860405\n",
            "epoch: 506, step: 0, Train: label_loss: 0.0848441794514656, precision: 0.3211940298507271, recall: 0.8776508972266104, f1: 0.47027972024045145\n",
            "epoch: 506, step: 1, Train: label_loss: 0.10700950026512146, precision: 0.2962736713500124, recall: 0.8553791887123711, f1: 0.4401088928837047\n",
            "epoch: 506, step: 2, Train: label_loss: 0.10565531998872757, precision: 0.2922513727882677, recall: 0.8538324420675839, f1: 0.4354545454165108\n",
            "epoch: 506, step: 3, Train: label_loss: 0.10681300610303879, precision: 0.31512605042014913, recall: 0.8793969849244757, f1: 0.46398585943968446\n",
            "epoch: 506, step: 4, Train: label_loss: 0.09605644643306732, precision: 0.32573485302937455, recall: 0.8701923076921682, f1: 0.47402880834094147\n",
            "epoch: 506, step: 5, Train: label_loss: 0.09786264598369598, precision: 0.3131009615384427, recall: 0.8712374581938341, f1: 0.4606542882015589\n",
            "epoch: 506, step: 6, Train: label_loss: 0.09585446119308472, precision: 0.32430806257519107, recall: 0.8953488372091535, f1: 0.47614840985491136\n",
            "epoch: 506, step: 7, Train: label_loss: 0.08824796974658966, precision: 0.3071895424836419, recall: 0.8929188255611583, f1: 0.4571175950104995\n",
            "epoch: 506, step: 8, Train: label_loss: 0.09454050660133362, precision: 0.3343337334933773, recall: 0.8954983922828141, f1: 0.48688811184847947\n",
            "epoch: 506, step: 9, Train: label_loss: 0.11348435282707214, precision: 0.3193329215564966, recall: 0.8602329450913709, f1: 0.4657657657262376\n",
            "epoch: 506, step: 10, Train: label_loss: 0.09827585518360138, precision: 0.3192771084337157, recall: 0.8731466227346172, f1: 0.4675782972699655\n",
            "epoch: 506, step: 11, Train: label_loss: 0.09572885930538177, precision: 0.3036263060848, recall: 0.8372881355930784, f1: 0.4456472710479539\n",
            "epoch: 506, step: 12, Train: label_loss: 0.10466669499874115, precision: 0.3470975463793927, recall: 0.9020217729392065, f1: 0.5012964563124608\n",
            "epoch: 506, step: 13, Train: label_loss: 0.105427086353302, precision: 0.32236441194391696, recall: 0.8629690048938232, f1: 0.46938775506239944\n",
            "epoch: 506, step: 14, Train: label_loss: 0.09026318788528442, precision: 0.3152238805969961, recall: 0.8888888888887392, f1: 0.46540326130991955\n",
            "epoch: 506, step: 15, Train: label_loss: 0.10217651724815369, precision: 0.3140643623360957, recall: 0.9008547008545468, f1: 0.4657534246191568\n",
            "epoch: 506, step: 16, Train: label_loss: 0.09156065434217453, precision: 0.3327294685990137, recall: 0.884430176564866, f1: 0.4835454146157808\n",
            "epoch: 506, step: 17, Train: label_loss: 0.10173048079013824, precision: 0.31487055990365354, recall: 0.895547945205326, f1: 0.4659242761307307\n",
            "epoch: 506, step: 18, Train: label_loss: 0.07220148295164108, precision: 0.33392539964474044, recall: 0.9111470113084149, f1: 0.48873483531599005\n",
            "epoch: 506, step: 19, Train: label_loss: 0.08425688743591309, precision: 0.30432208407339817, recall: 0.9049295774646293, f1: 0.4554718652702249\n",
            "epoch: 506, step: 20, Train: label_loss: 0.09487572312355042, precision: 0.30591102985982294, recall: 0.8760907504361473, f1: 0.4534778680736083\n",
            "epoch: 506, step: 21, Train: label_loss: 0.10239477455615997, precision: 0.34468339307046925, recall: 0.8890600924497859, f1: 0.4967714162317538\n",
            "epoch: 506, step: 22, Train: label_loss: 0.10907743871212006, precision: 0.3278186274509603, recall: 0.8629032258063124, f1: 0.47513321488012583\n",
            "epoch: 506, step: 23, Train: label_loss: 0.09592410922050476, precision: 0.32046613255642237, recall: 0.903490759753408, f1: 0.4731182795311868\n",
            "epoch: 507, step: 0, Train: label_loss: 0.0933227688074112, precision: 0.3319226118500404, recall: 0.888349514562963, f1: 0.4832746478476776\n",
            "epoch: 507, step: 1, Train: label_loss: 0.09576623141765594, precision: 0.3113772455089634, recall: 0.8798646362096649, f1: 0.45997346303078473\n",
            "epoch: 507, step: 2, Train: label_loss: 0.09160546958446503, precision: 0.3297491039426326, recall: 0.893203883495001, f1: 0.4816753926307287\n",
            "epoch: 507, step: 3, Train: label_loss: 0.10423839837312698, precision: 0.29788519637460437, recall: 0.8710247349821783, f1: 0.4439441692550919\n",
            "epoch: 507, step: 4, Train: label_loss: 0.09252209961414337, precision: 0.3217286914765713, recall: 0.8993288590602517, f1: 0.4739168876711372\n",
            "epoch: 507, step: 5, Train: label_loss: 0.09421909600496292, precision: 0.32486388384753023, recall: 0.8717532467531052, f1: 0.4733362714456378\n",
            "epoch: 507, step: 6, Train: label_loss: 0.1151561290025711, precision: 0.3197781885397215, recall: 0.8384491114699776, f1: 0.4629794825648027\n",
            "epoch: 507, step: 7, Train: label_loss: 0.09087085723876953, precision: 0.3178528347406322, recall: 0.8653530377666887, f1: 0.4649316276624733\n",
            "epoch: 507, step: 8, Train: label_loss: 0.08947819471359253, precision: 0.30453172205436224, recall: 0.8857644991211097, f1: 0.4532374100338239\n",
            "epoch: 507, step: 9, Train: label_loss: 0.10991788655519485, precision: 0.3414932680538347, recall: 0.8705148205926878, f1: 0.4905494505089333\n",
            "epoch: 507, step: 10, Train: label_loss: 0.10527323931455612, precision: 0.32388419782868977, recall: 0.897993311036639, f1: 0.47606382974823014\n",
            "epoch: 507, step: 11, Train: label_loss: 0.10698540508747101, precision: 0.2895705521472215, recall: 0.8566243194190822, f1: 0.43282897749543964\n",
            "epoch: 507, step: 12, Train: label_loss: 0.08953841030597687, precision: 0.3273273273273077, recall: 0.8762057877812095, f1: 0.47660690857426236\n",
            "epoch: 507, step: 13, Train: label_loss: 0.09617626667022705, precision: 0.31404460518382676, recall: 0.8654485049832449, f1: 0.4608580273823816\n",
            "epoch: 507, step: 14, Train: label_loss: 0.08894713222980499, precision: 0.31351351351349466, recall: 0.8877551020406653, f1: 0.46338215708521935\n",
            "epoch: 507, step: 15, Train: label_loss: 0.09276317805051804, precision: 0.3084725536992656, recall: 0.8991304347824522, f1: 0.45935139933997504\n",
            "epoch: 507, step: 16, Train: label_loss: 0.10216376930475235, precision: 0.3183453237409881, recall: 0.8719211822658666, f1: 0.4664031620161102\n",
            "epoch: 507, step: 17, Train: label_loss: 0.10689138621091843, precision: 0.3176043557168592, recall: 0.8564437194125846, f1: 0.46337157983692545\n",
            "epoch: 507, step: 18, Train: label_loss: 0.09572876989841461, precision: 0.32892363199035907, recall: 0.8908794788272164, f1: 0.48045674128687627\n",
            "epoch: 507, step: 19, Train: label_loss: 0.09685250371694565, precision: 0.32630945213724705, recall: 0.8756058158318456, f1: 0.4754385964516295\n",
            "epoch: 507, step: 20, Train: label_loss: 0.08697245270013809, precision: 0.32429174201324146, recall: 0.8719611021068279, f1: 0.472759226673971\n",
            "epoch: 507, step: 21, Train: label_loss: 0.10409539937973022, precision: 0.29767726161367375, recall: 0.8499127399649475, f1: 0.4409234947555628\n",
            "epoch: 507, step: 22, Train: label_loss: 0.08718080073595047, precision: 0.3166069295101364, recall: 0.907534246575187, f1: 0.4694419840182971\n",
            "epoch: 507, step: 23, Train: label_loss: 0.09781472384929657, precision: 0.328402366863881, recall: 0.8688845401172468, f1: 0.47665056356722324\n",
            "epoch: 508, step: 0, Train: label_loss: 0.10232420265674591, precision: 0.2966830466830285, recall: 0.8429319371726277, f1: 0.43889141295554146\n",
            "epoch: 508, step: 1, Train: label_loss: 0.08951818943023682, precision: 0.32038254632394975, recall: 0.881578947368276, f1: 0.46996931166625094\n",
            "epoch: 508, step: 2, Train: label_loss: 0.11744572222232819, precision: 0.3245560318432134, recall: 0.8674304418983849, f1: 0.4723707664487425\n",
            "epoch: 508, step: 3, Train: label_loss: 0.09183423221111298, precision: 0.32091346153844225, recall: 0.8855721393033357, f1: 0.4711071900800107\n",
            "epoch: 508, step: 4, Train: label_loss: 0.0808928906917572, precision: 0.3307416267942386, recall: 0.8919354838708238, f1: 0.48254799297968853\n",
            "epoch: 508, step: 5, Train: label_loss: 0.07947840541601181, precision: 0.32581602373885304, recall: 0.9089403973508429, f1: 0.4796854521236258\n",
            "epoch: 508, step: 6, Train: label_loss: 0.09619206935167313, precision: 0.3010882708585066, recall: 0.8798586572436607, f1: 0.44864864861061765\n",
            "epoch: 508, step: 7, Train: label_loss: 0.10005912184715271, precision: 0.3082107843137066, recall: 0.8496621621620186, f1: 0.45233812945729585\n",
            "epoch: 508, step: 8, Train: label_loss: 0.09192390739917755, precision: 0.3149271844660003, recall: 0.8664440734556149, f1: 0.4619492656484396\n",
            "epoch: 508, step: 9, Train: label_loss: 0.08782435953617096, precision: 0.3183183183182992, recall: 0.8745874587457302, f1: 0.46675473355836544\n",
            "epoch: 508, step: 10, Train: label_loss: 0.10030212998390198, precision: 0.3027190332326101, recall: 0.8667820069202652, f1: 0.44872369006459145\n",
            "epoch: 508, step: 11, Train: label_loss: 0.08908616006374359, precision: 0.32347723240684073, recall: 0.9162479061975014, f1: 0.47814685310824256\n",
            "epoch: 508, step: 12, Train: label_loss: 0.08863876760005951, precision: 0.3253301320528016, recall: 0.8899835796386059, f1: 0.4764835164442679\n",
            "epoch: 508, step: 13, Train: label_loss: 0.08131946623325348, precision: 0.34818775995244516, recall: 0.9015384615383227, f1: 0.5023574795997081\n",
            "epoch: 508, step: 14, Train: label_loss: 0.09661433100700378, precision: 0.32807762280167807, recall: 0.869774919614008, f1: 0.4764420959531379\n",
            "epoch: 508, step: 15, Train: label_loss: 0.1064470186829567, precision: 0.3337356668678133, recall: 0.8694968553457751, f1: 0.48233754902223486\n",
            "epoch: 508, step: 16, Train: label_loss: 0.09825392812490463, precision: 0.3319377990430423, recall: 0.9128289473682708, f1: 0.48684210522400406\n",
            "epoch: 508, step: 17, Train: label_loss: 0.09006407111883163, precision: 0.31812725090034105, recall: 0.904436860068105, f1: 0.4706927175458272\n",
            "epoch: 508, step: 18, Train: label_loss: 0.08645598590373993, precision: 0.32342449464920786, recall: 0.8932676518881948, f1: 0.4749017895724496\n",
            "epoch: 508, step: 19, Train: label_loss: 0.10084262490272522, precision: 0.33393393393391385, recall: 0.9174917491747661, f1: 0.48965213558390286\n",
            "epoch: 508, step: 20, Train: label_loss: 0.08026474714279175, precision: 0.3234946871310317, recall: 0.914858096827894, f1: 0.4779764500267771\n",
            "epoch: 508, step: 21, Train: label_loss: 0.10467630624771118, precision: 0.30731707317071294, recall: 0.8615384615383141, f1: 0.45303370782636904\n",
            "epoch: 508, step: 22, Train: label_loss: 0.09969524294137955, precision: 0.30557219892149157, recall: 0.8854166666665129, f1: 0.4543429843716107\n",
            "epoch: 508, step: 23, Train: label_loss: 0.1140068843960762, precision: 0.3109433962263916, recall: 0.8655462184872131, f1: 0.45752359796217074\n",
            "epoch: 509, step: 0, Train: label_loss: 0.07698076963424683, precision: 0.33588685916320943, recall: 0.9076433121017662, f1: 0.49032258060568923\n",
            "epoch: 509, step: 1, Train: label_loss: 0.08375725150108337, precision: 0.32804232804230876, recall: 0.9207920792077687, f1: 0.48374512349828347\n",
            "epoch: 509, step: 2, Train: label_loss: 0.10038305819034576, precision: 0.2997572815533799, recall: 0.8606271777001985, f1: 0.44464446440808597\n",
            "epoch: 509, step: 3, Train: label_loss: 0.08724743872880936, precision: 0.33493109646492897, recall: 0.8873015873014464, f1: 0.48629839056478064\n",
            "epoch: 509, step: 4, Train: label_loss: 0.0928388461470604, precision: 0.3027190332326101, recall: 0.8682842287693469, f1: 0.4489247311444187\n",
            "epoch: 509, step: 5, Train: label_loss: 0.09823106229305267, precision: 0.3134418324291553, recall: 0.875420875420728, f1: 0.4616067465212735\n",
            "epoch: 509, step: 6, Train: label_loss: 0.09411149471998215, precision: 0.30912364945976534, recall: 0.8848797250857585, f1: 0.4581850533423683\n",
            "epoch: 509, step: 7, Train: label_loss: 0.09033512324094772, precision: 0.3367655966080959, recall: 0.8728414442698786, f1: 0.4860139859737641\n",
            "epoch: 509, step: 8, Train: label_loss: 0.11321859061717987, precision: 0.32559560171042606, recall: 0.8666666666665257, f1: 0.47335701594604596\n",
            "epoch: 509, step: 9, Train: label_loss: 0.09581220149993896, precision: 0.3014440433212815, recall: 0.8835978835977277, f1: 0.4495289367049602\n",
            "epoch: 509, step: 10, Train: label_loss: 0.09822480380535126, precision: 0.3195558297347119, recall: 0.8436482084689179, f1: 0.46353467557532124\n",
            "epoch: 509, step: 11, Train: label_loss: 0.098118856549263, precision: 0.30073349633249996, recall: 0.8601398601397097, f1: 0.44565217387461376\n",
            "epoch: 509, step: 12, Train: label_loss: 0.09020303189754486, precision: 0.32459797498509085, recall: 0.8919803600653204, f1: 0.47598253271192537\n",
            "epoch: 509, step: 13, Train: label_loss: 0.08818520605564117, precision: 0.32023809523807617, recall: 0.9134125636670775, f1: 0.4742177170174898\n",
            "epoch: 509, step: 14, Train: label_loss: 0.08652124553918839, precision: 0.31744115872056017, recall: 0.8810720268005223, f1: 0.46672582072410435\n",
            "epoch: 509, step: 15, Train: label_loss: 0.08915151655673981, precision: 0.3220543806646331, recall: 0.869494290375062, f1: 0.470017636644816\n",
            "epoch: 509, step: 16, Train: label_loss: 0.10720189660787582, precision: 0.31025957972804014, recall: 0.8243021346468268, f1: 0.45083071392519863\n",
            "epoch: 509, step: 17, Train: label_loss: 0.09094144403934479, precision: 0.32269717037927015, recall: 0.8830313014825563, f1: 0.47266313929056286\n",
            "epoch: 509, step: 18, Train: label_loss: 0.10737618058919907, precision: 0.3099450884685595, recall: 0.8537815126048984, f1: 0.45478961500116527\n",
            "epoch: 509, step: 19, Train: label_loss: 0.11900986731052399, precision: 0.32313341493266073, recall: 0.864157119476127, f1: 0.4703786191140151\n",
            "epoch: 509, step: 20, Train: label_loss: 0.0942835807800293, precision: 0.3281715306730001, recall: 0.9003267973854737, f1: 0.4810126581886516\n",
            "epoch: 509, step: 21, Train: label_loss: 0.09206148982048035, precision: 0.3006024096385361, recall: 0.8847517730494885, f1: 0.4487410071563472\n",
            "epoch: 509, step: 22, Train: label_loss: 0.08818116039037704, precision: 0.31947743467931594, recall: 0.8951747088184866, f1: 0.4708971553222411\n",
            "epoch: 509, step: 23, Train: label_loss: 0.09626371413469315, precision: 0.33258928571426094, recall: 0.8696498054473015, f1: 0.481162540325911\n",
            "epoch: 510, step: 0, Train: label_loss: 0.11424089968204498, precision: 0.3141809290953353, recall: 0.8524046434492781, f1: 0.45913354172031606\n",
            "epoch: 510, step: 1, Train: label_loss: 0.09770619869232178, precision: 0.3022142429682644, recall: 0.8721934369601256, f1: 0.44888888885062633\n",
            "epoch: 510, step: 2, Train: label_loss: 0.07464323937892914, precision: 0.3231780167263845, recall: 0.9077181208052167, f1: 0.47665198234008865\n",
            "epoch: 510, step: 3, Train: label_loss: 0.10394449532032013, precision: 0.3343265792610051, recall: 0.9033816425119318, f1: 0.4880382774724884\n",
            "epoch: 510, step: 4, Train: label_loss: 0.11072608828544617, precision: 0.3107861060328878, recall: 0.8471760797340785, f1: 0.4547481051769164\n",
            "epoch: 510, step: 5, Train: label_loss: 0.08649186789989471, precision: 0.30242173656229754, recall: 0.9094138543515258, f1: 0.45390070918236225\n",
            "epoch: 510, step: 6, Train: label_loss: 0.10046826303005219, precision: 0.32904411764703867, recall: 0.8846787479405461, f1: 0.4796784278300205\n",
            "epoch: 510, step: 7, Train: label_loss: 0.0918077677488327, precision: 0.3114852675886764, recall: 0.8779661016947664, f1: 0.4598313359577493\n",
            "epoch: 510, step: 8, Train: label_loss: 0.094154492020607, precision: 0.3273488928784963, recall: 0.8952536824875784, f1: 0.47940403151201705\n",
            "epoch: 510, step: 9, Train: label_loss: 0.0803210586309433, precision: 0.32955223880595047, recall: 0.8975609756096101, f1: 0.4820960698296665\n",
            "epoch: 510, step: 10, Train: label_loss: 0.09930717200040817, precision: 0.3317220543806446, recall: 0.8618524332808694, f1: 0.47905759158285843\n",
            "epoch: 510, step: 11, Train: label_loss: 0.10291832685470581, precision: 0.3063337393422469, recall: 0.8554421768706028, f1: 0.4511210761943132\n",
            "epoch: 510, step: 12, Train: label_loss: 0.09909912198781967, precision: 0.3502994011975838, recall: 0.8850226928894274, f1: 0.5019305018898274\n",
            "epoch: 510, step: 13, Train: label_loss: 0.09607453644275665, precision: 0.316676700782642, recall: 0.8665568369026578, f1: 0.4638447971388881\n",
            "epoch: 510, step: 14, Train: label_loss: 0.08908498287200928, precision: 0.33694344163656215, recall: 0.8917197452227879, f1: 0.4890829693924656\n",
            "epoch: 510, step: 15, Train: label_loss: 0.10728172212839127, precision: 0.3036363636363452, recall: 0.8549488054606049, f1: 0.4481216457573459\n",
            "epoch: 510, step: 16, Train: label_loss: 0.0925590842962265, precision: 0.32552552552550595, recall: 0.8856209150325349, f1: 0.47606499776477934\n",
            "epoch: 510, step: 17, Train: label_loss: 0.08455698192119598, precision: 0.32018834608591407, recall: 0.90066225165548, f1: 0.4724272687411147\n",
            "epoch: 510, step: 18, Train: label_loss: 0.10182070732116699, precision: 0.3082932692307507, recall: 0.882960413080743, f1: 0.4570155901620405\n",
            "epoch: 510, step: 19, Train: label_loss: 0.0971619263291359, precision: 0.32445520581111836, recall: 0.880131362889839, f1: 0.47412649266294205\n",
            "epoch: 510, step: 20, Train: label_loss: 0.10351352393627167, precision: 0.29681762545897816, recall: 0.8434782608694185, f1: 0.4391127206495458\n",
            "epoch: 510, step: 21, Train: label_loss: 0.09721818566322327, precision: 0.3069069069068885, recall: 0.8856152512996731, f1: 0.4558429972855523\n",
            "epoch: 510, step: 22, Train: label_loss: 0.12272311747074127, precision: 0.3067901234567712, recall: 0.8466780238499408, f1: 0.45038513815756004\n",
            "epoch: 510, step: 23, Train: label_loss: 0.11015172302722931, precision: 0.3149374540102785, recall: 0.891666666666481, f1: 0.4654703642898118\n",
            "epoch: 511, step: 0, Train: label_loss: 0.09751427173614502, precision: 0.31414868105513705, recall: 0.8851351351349855, f1: 0.4637168141205849\n",
            "epoch: 511, step: 1, Train: label_loss: 0.10089261829853058, precision: 0.3086196503917837, recall: 0.8797250859105017, f1: 0.45693886653892823\n",
            "epoch: 511, step: 2, Train: label_loss: 0.09860610216856003, precision: 0.3165554881746321, recall: 0.8685524126454461, f1: 0.4639999999608062\n",
            "epoch: 511, step: 3, Train: label_loss: 0.09699070453643799, precision: 0.32869249394671135, recall: 0.8758064516127619, f1: 0.4779929577067528\n",
            "epoch: 511, step: 4, Train: label_loss: 0.09807521104812622, precision: 0.30985915492955846, recall: 0.8518518518517084, f1: 0.4544229905311164\n",
            "epoch: 511, step: 5, Train: label_loss: 0.09430654346942902, precision: 0.306707317073152, recall: 0.8568994889266002, f1: 0.45172878307743797\n",
            "epoch: 511, step: 6, Train: label_loss: 0.10491012036800385, precision: 0.3108839446782735, recall: 0.8545454545453133, f1: 0.45590828920246307\n",
            "epoch: 511, step: 7, Train: label_loss: 0.0980079248547554, precision: 0.31242460796138044, recall: 0.8794567062816843, f1: 0.46105918999242834\n",
            "epoch: 511, step: 8, Train: label_loss: 0.10953617095947266, precision: 0.32704019488426755, recall: 0.852380952380817, f1: 0.47271126756551224\n",
            "epoch: 511, step: 9, Train: label_loss: 0.11034716665744781, precision: 0.2989690721649303, recall: 0.8456260720410212, f1: 0.4417562723627991\n",
            "epoch: 511, step: 10, Train: label_loss: 0.10476730763912201, precision: 0.3185096153845962, recall: 0.8937605396288543, f1: 0.4696499778079161\n",
            "epoch: 511, step: 11, Train: label_loss: 0.12457170337438583, precision: 0.30523076923075043, recall: 0.8493150684930052, f1: 0.449071978231774\n",
            "epoch: 511, step: 12, Train: label_loss: 0.08682896196842194, precision: 0.3370919881305438, recall: 0.9073482428113566, f1: 0.491562094291915\n",
            "epoch: 511, step: 13, Train: label_loss: 0.09408222883939743, precision: 0.33839611178612766, recall: 0.8869426751590944, f1: 0.48988566398812156\n",
            "epoch: 511, step: 14, Train: label_loss: 0.08971403539180756, precision: 0.3339317773787951, recall: 0.9058441558440087, f1: 0.48797551373409975\n",
            "epoch: 511, step: 15, Train: label_loss: 0.09804119169712067, precision: 0.30218446601939913, recall: 0.8706293706292183, f1: 0.44864864861035414\n",
            "epoch: 511, step: 16, Train: label_loss: 0.14281782507896423, precision: 0.2951732673267144, recall: 0.8195876288658385, f1: 0.43403093717667623\n",
            "epoch: 511, step: 17, Train: label_loss: 0.11374315619468689, precision: 0.3369896404631117, recall: 0.8805732484075031, f1: 0.4874394005769349\n",
            "epoch: 511, step: 18, Train: label_loss: 0.12083746492862701, precision: 0.31500926497836224, recall: 0.8388157894735462, f1: 0.45801526713583596\n",
            "epoch: 511, step: 19, Train: label_loss: 0.12005899846553802, precision: 0.31141439205953403, recall: 0.8451178451177028, f1: 0.4551223934329545\n",
            "epoch: 511, step: 20, Train: label_loss: 0.11314232647418976, precision: 0.3116564417177723, recall: 0.8369028006588406, f1: 0.45417970492241866\n",
            "epoch: 511, step: 21, Train: label_loss: 0.11176076531410217, precision: 0.31376146788988907, recall: 0.8355048859933492, f1: 0.45620275674105576\n",
            "epoch: 511, step: 22, Train: label_loss: 0.11582368612289429, precision: 0.29944886711571955, recall: 0.8563922942205154, f1: 0.44373865694886455\n",
            "epoch: 511, step: 23, Train: label_loss: 0.1195625513792038, precision: 0.32753403933431713, recall: 0.8440545808965215, f1: 0.4719346048642991\n",
            "epoch: 512, step: 0, Train: label_loss: 0.09360873699188232, precision: 0.3183747725894288, recall: 0.8898305084744254, f1: 0.46895935681688267\n",
            "epoch: 512, step: 1, Train: label_loss: 0.11013194918632507, precision: 0.3004866180048479, recall: 0.8758865248225397, f1: 0.44746376807786387\n",
            "epoch: 512, step: 2, Train: label_loss: 0.10771992057561874, precision: 0.3208818126147997, recall: 0.870431893687563, f1: 0.4689038030925889\n",
            "epoch: 512, step: 3, Train: label_loss: 0.10541445761919022, precision: 0.32131948686619904, recall: 0.8810720268005223, f1: 0.4709042076599881\n",
            "epoch: 512, step: 4, Train: label_loss: 0.11593662202358246, precision: 0.315436241610719, recall: 0.8762711864405294, f1: 0.4638851502526428\n",
            "epoch: 512, step: 5, Train: label_loss: 0.1181802824139595, precision: 0.3205445544554257, recall: 0.8464052287580316, f1: 0.46499102329942926\n",
            "epoch: 512, step: 6, Train: label_loss: 0.12000620365142822, precision: 0.3303140096618158, recall: 0.8879870129868688, f1: 0.4815140844674764\n",
            "epoch: 512, step: 7, Train: label_loss: 0.11503782868385315, precision: 0.3069007263922332, recall: 0.8622448979590369, f1: 0.45267857138981216\n",
            "epoch: 512, step: 8, Train: label_loss: 0.10330706834793091, precision: 0.30540376442013933, recall: 0.8583617747438808, f1: 0.45051500220038804\n",
            "epoch: 512, step: 9, Train: label_loss: 0.12449895590543747, precision: 0.30887792848333484, recall: 0.8520408163263856, f1: 0.45339366511927526\n",
            "epoch: 512, step: 10, Train: label_loss: 0.10159674286842346, precision: 0.33171912832927775, recall: 0.862992125984116, f1: 0.47923043284134953\n",
            "epoch: 512, step: 11, Train: label_loss: 0.0885908231139183, precision: 0.3049219687874967, recall: 0.8819444444442912, f1: 0.4531668153052212\n",
            "epoch: 512, step: 12, Train: label_loss: 0.10129885375499725, precision: 0.3139604553624737, recall: 0.8866328257189701, f1: 0.4637168141206271\n",
            "epoch: 512, step: 13, Train: label_loss: 0.08792947232723236, precision: 0.3109792284866284, recall: 0.8881355932201884, f1: 0.46065934062088354\n",
            "epoch: 512, step: 14, Train: label_loss: 0.10488833487033844, precision: 0.3091905051734444, recall: 0.8537815126048984, f1: 0.4539767649296456\n",
            "epoch: 512, step: 15, Train: label_loss: 0.11221495270729065, precision: 0.3246674727932089, recall: 0.8935108153076715, f1: 0.4762749445284879\n",
            "epoch: 512, step: 16, Train: label_loss: 0.1015387624502182, precision: 0.32796660703635494, recall: 0.8972267536703267, f1: 0.480349344938918\n",
            "epoch: 512, step: 17, Train: label_loss: 0.1078365221619606, precision: 0.3095380923815051, recall: 0.8911917098444055, f1: 0.4594835262306146\n",
            "epoch: 512, step: 18, Train: label_loss: 0.10338015854358673, precision: 0.3208910295002817, recall: 0.872340425531772, f1: 0.46919014080570814\n",
            "epoch: 512, step: 19, Train: label_loss: 0.11217289417982101, precision: 0.31724969843182643, recall: 0.8665568369026578, f1: 0.46445916110862745\n",
            "epoch: 512, step: 20, Train: label_loss: 0.10972805321216583, precision: 0.31517747858015205, recall: 0.8554817275746086, f1: 0.4606440071162447\n",
            "epoch: 512, step: 21, Train: label_loss: 0.10406005382537842, precision: 0.34371184371182273, recall: 0.8755832037323676, f1: 0.4936431389336049\n",
            "epoch: 512, step: 22, Train: label_loss: 0.11245568096637726, precision: 0.3382173382173176, recall: 0.8821656050954009, f1: 0.48896734329616554\n",
            "epoch: 512, step: 23, Train: label_loss: 0.09600076824426651, precision: 0.34225759768449043, recall: 0.9184466019415691, f1: 0.49868212963883124\n",
            "epoch: 513, step: 0, Train: label_loss: 0.10236849635839462, precision: 0.30644190246837405, recall: 0.883680555555402, f1: 0.45507375946105116\n",
            "epoch: 513, step: 1, Train: label_loss: 0.09395448863506317, precision: 0.3071342200725328, recall: 0.8728522336768259, f1: 0.45438282643730155\n",
            "epoch: 513, step: 2, Train: label_loss: 0.09951339662075043, precision: 0.3317307692307493, recall: 0.8961038961037505, f1: 0.48421052627631084\n",
            "epoch: 513, step: 3, Train: label_loss: 0.09757905453443527, precision: 0.3369304556354714, recall: 0.9006410256408812, f1: 0.4904013961208896\n",
            "epoch: 513, step: 4, Train: label_loss: 0.11602267622947693, precision: 0.30613496932513456, recall: 0.8603448275860585, f1: 0.4515837103684855\n",
            "epoch: 513, step: 5, Train: label_loss: 0.08942610025405884, precision: 0.31619844590553997, recall: 0.8950930626056014, f1: 0.4673144875938877\n",
            "epoch: 513, step: 6, Train: label_loss: 0.08653208613395691, precision: 0.3291442250149414, recall: 0.8914100486222217, f1: 0.4807692307297993\n",
            "epoch: 513, step: 7, Train: label_loss: 0.09951457381248474, precision: 0.32531569452794196, recall: 0.8854337152208043, f1: 0.4758135443757865\n",
            "epoch: 513, step: 8, Train: label_loss: 0.08920039981603622, precision: 0.33353401565320084, recall: 0.8724409448817523, f1: 0.48257839717248585\n",
            "epoch: 513, step: 9, Train: label_loss: 0.11436203122138977, precision: 0.3209951456310485, recall: 0.8846153846152366, f1: 0.47105966158154466\n",
            "epoch: 513, step: 10, Train: label_loss: 0.11093494296073914, precision: 0.32309582309580326, recall: 0.8375796178342615, f1: 0.46631205669737136\n",
            "epoch: 513, step: 11, Train: label_loss: 0.10025949031114578, precision: 0.316014669926631, recall: 0.8489326765187439, f1: 0.4605790645483957\n",
            "epoch: 513, step: 12, Train: label_loss: 0.10215482115745544, precision: 0.30224106602057527, recall: 0.8678260869563708, f1: 0.44833782565795877\n",
            "epoch: 513, step: 13, Train: label_loss: 0.09780247509479523, precision: 0.32267792521107824, recall: 0.8857615894038268, f1: 0.47303271437283884\n",
            "epoch: 513, step: 14, Train: label_loss: 0.0812644511461258, precision: 0.333530805687184, recall: 0.9080645161288857, f1: 0.4878682841894335\n",
            "epoch: 513, step: 15, Train: label_loss: 0.10184784978628159, precision: 0.3231597845601243, recall: 0.9015025041734721, f1: 0.475770925071241\n",
            "epoch: 513, step: 16, Train: label_loss: 0.09311160445213318, precision: 0.30308529945551704, recall: 0.8851590106005502, f1: 0.45155475435582854\n",
            "epoch: 513, step: 17, Train: label_loss: 0.11128474771976471, precision: 0.30085261875759434, recall: 0.8606271777001985, f1: 0.44584837541283706\n",
            "epoch: 513, step: 18, Train: label_loss: 0.09563873708248138, precision: 0.31569452796149633, recall: 0.8959044368599153, f1: 0.4668741662575564\n",
            "epoch: 513, step: 19, Train: label_loss: 0.0874193012714386, precision: 0.3249400479616112, recall: 0.8929159802304953, f1: 0.47648351644434983\n",
            "epoch: 513, step: 20, Train: label_loss: 0.10455548763275146, precision: 0.2920673076922901, recall: 0.8571428571427059, f1: 0.43567906764470327\n",
            "epoch: 513, step: 21, Train: label_loss: 0.0910596176981926, precision: 0.314626865671623, recall: 0.8725165562912462, f1: 0.4624835453756572\n",
            "epoch: 513, step: 22, Train: label_loss: 0.09701983630657196, precision: 0.3419471153845948, recall: 0.8988941548181834, f1: 0.49542882016029116\n",
            "epoch: 513, step: 23, Train: label_loss: 0.1051398366689682, precision: 0.33555062823353027, recall: 0.8781431334621125, f1: 0.48556149728614434\n",
            "epoch: 514, step: 0, Train: label_loss: 0.09826552867889404, precision: 0.3062843197071198, recall: 0.8494077834177919, f1: 0.4502242152076393\n",
            "epoch: 514, step: 1, Train: label_loss: 0.11588100343942642, precision: 0.33272506082723036, recall: 0.8724082934607859, f1: 0.48172611180498687\n",
            "epoch: 514, step: 2, Train: label_loss: 0.09989643841981888, precision: 0.3221556886227352, recall: 0.884868421052486, f1: 0.47234416150604064\n",
            "epoch: 514, step: 3, Train: label_loss: 0.087879978120327, precision: 0.3059523809523627, recall: 0.8954703832751052, f1: 0.4560780833692739\n",
            "epoch: 514, step: 4, Train: label_loss: 0.08472057431936264, precision: 0.32269717037927015, recall: 0.881578947368276, f1: 0.47245482587522675\n",
            "epoch: 514, step: 5, Train: label_loss: 0.10588380694389343, precision: 0.3168077388149748, recall: 0.8806722689074149, f1: 0.46598488213089806\n",
            "epoch: 514, step: 6, Train: label_loss: 0.09576588869094849, precision: 0.32192192192190255, recall: 0.8874172185428993, f1: 0.47245482587539084\n",
            "epoch: 514, step: 7, Train: label_loss: 0.09197337180376053, precision: 0.3087885985748035, recall: 0.925266903914426, f1: 0.46304541403189337\n",
            "epoch: 514, step: 8, Train: label_loss: 0.10296537727117538, precision: 0.3229478729778117, recall: 0.886513157894591, f1: 0.4734299516516358\n",
            "epoch: 514, step: 9, Train: label_loss: 0.08866044878959656, precision: 0.3389524382901662, recall: 0.8950715421302233, f1: 0.49170305672867054\n",
            "epoch: 514, step: 10, Train: label_loss: 0.09419240057468414, precision: 0.3162958508718992, recall: 0.8795986622072107, f1: 0.46528084914283036\n",
            "epoch: 514, step: 11, Train: label_loss: 0.10429156571626663, precision: 0.3219927095990084, recall: 0.8660130718952833, f1: 0.46944198401713055\n",
            "epoch: 514, step: 12, Train: label_loss: 0.10254782438278198, precision: 0.30163537250149597, recall: 0.8512820512819057, f1: 0.4454382826089094\n",
            "epoch: 514, step: 13, Train: label_loss: 0.09738627076148987, precision: 0.29613992762362507, recall: 0.872113676731639, f1: 0.4421431787104252\n",
            "epoch: 514, step: 14, Train: label_loss: 0.09513290226459503, precision: 0.33313143549362, recall: 0.8943089430892854, f1: 0.4854368931642919\n",
            "epoch: 514, step: 15, Train: label_loss: 0.10043928027153015, precision: 0.31502715751355975, recall: 0.8599670510706985, f1: 0.4611307420101839\n",
            "epoch: 514, step: 16, Train: label_loss: 0.09222093969583511, precision: 0.303774715398424, recall: 0.8817391304346291, f1: 0.4518716577158543\n",
            "epoch: 514, step: 17, Train: label_loss: 0.08919166028499603, precision: 0.32602071907371566, recall: 0.8629032258063124, f1: 0.47324192831044143\n",
            "epoch: 514, step: 18, Train: label_loss: 0.08867688477039337, precision: 0.33214285714283737, recall: 0.9073170731705841, f1: 0.48627450976464637\n",
            "epoch: 514, step: 19, Train: label_loss: 0.10400012135505676, precision: 0.33114558472551725, recall: 0.902439024390097, f1: 0.4845045831121438\n",
            "epoch: 514, step: 20, Train: label_loss: 0.09994975477457047, precision: 0.3059610705595921, recall: 0.8510998307951182, f1: 0.4501118567843245\n",
            "epoch: 514, step: 21, Train: label_loss: 0.09662499278783798, precision: 0.3170878459686933, recall: 0.8827470686765689, f1: 0.46657813187784913\n",
            "epoch: 514, step: 22, Train: label_loss: 0.09231795370578766, precision: 0.3307508939213152, recall: 0.8879999999998579, f1: 0.4819800260133854\n",
            "epoch: 514, step: 23, Train: label_loss: 0.09721839427947998, precision: 0.31874544128371124, recall: 0.8828282828281045, f1: 0.4683815648055565\n",
            "epoch: 515, step: 0, Train: label_loss: 0.09720674902200699, precision: 0.32291040288633055, recall: 0.8905472636814443, f1: 0.4739629302345092\n",
            "epoch: 515, step: 1, Train: label_loss: 0.08439944684505463, precision: 0.3297619047618851, recall: 0.9052287581697867, f1: 0.4834205933290514\n",
            "epoch: 515, step: 2, Train: label_loss: 0.08228838443756104, precision: 0.32379248658316495, recall: 0.9004975124376615, f1: 0.4763157894347369\n",
            "epoch: 515, step: 3, Train: label_loss: 0.09496985375881195, precision: 0.30550514216574076, recall: 0.8559322033896853, f1: 0.4502897904203962\n",
            "epoch: 515, step: 4, Train: label_loss: 0.1015247106552124, precision: 0.3187274909963794, recall: 0.8954468802696635, f1: 0.4701195218735897\n",
            "epoch: 515, step: 5, Train: label_loss: 0.11244893074035645, precision: 0.2921556516367948, recall: 0.8507194244602786, f1: 0.4349425286975353\n",
            "epoch: 515, step: 6, Train: label_loss: 0.10388685762882233, precision: 0.3011466505733071, recall: 0.8739054290716507, f1: 0.4479353680049272\n",
            "epoch: 515, step: 7, Train: label_loss: 0.09198611974716187, precision: 0.3201940570042256, recall: 0.8829431438125613, f1: 0.4699599465563576\n",
            "epoch: 515, step: 8, Train: label_loss: 0.09208517521619797, precision: 0.31899641577059024, recall: 0.8870431893686234, f1: 0.469244288186007\n",
            "epoch: 515, step: 9, Train: label_loss: 0.10062848031520844, precision: 0.3146135265700293, recall: 0.8785834738615719, f1: 0.46331702975214717\n",
            "epoch: 515, step: 10, Train: label_loss: 0.0886220782995224, precision: 0.3267622461170653, recall: 0.9011532125204446, f1: 0.47961420425726\n",
            "epoch: 515, step: 11, Train: label_loss: 0.08594010025262833, precision: 0.33193277310922376, recall: 0.879173290937857, f1: 0.4819172112891425\n",
            "epoch: 515, step: 12, Train: label_loss: 0.0864044725894928, precision: 0.312056737588634, recall: 0.9119170984454383, f1: 0.4649933949421534\n",
            "epoch: 515, step: 13, Train: label_loss: 0.1037973165512085, precision: 0.33048780487802865, recall: 0.8727858293074279, f1: 0.4794338787747973\n",
            "epoch: 515, step: 14, Train: label_loss: 0.0947776734828949, precision: 0.32269717037927015, recall: 0.8948247078462612, f1: 0.4743362831468395\n",
            "epoch: 515, step: 15, Train: label_loss: 0.0723559558391571, precision: 0.34764705882350894, recall: 0.9234374999998557, f1: 0.505128205088422\n",
            "epoch: 515, step: 16, Train: label_loss: 0.08302798867225647, precision: 0.3130590339892479, recall: 0.8808724832213286, f1: 0.4619445666132701\n",
            "epoch: 515, step: 17, Train: label_loss: 0.10408316552639008, precision: 0.3189550425273196, recall: 0.8692052980131011, f1: 0.4666666666273488\n",
            "epoch: 515, step: 18, Train: label_loss: 0.09353591501712799, precision: 0.3206650831353729, recall: 0.9060402684562238, f1: 0.47368421048765996\n",
            "epoch: 515, step: 19, Train: label_loss: 0.11748667061328888, precision: 0.31653349723415386, recall: 0.8442622950818287, f1: 0.4604380866835832\n",
            "epoch: 515, step: 20, Train: label_loss: 0.1075020283460617, precision: 0.33293124246077604, recall: 0.8975609756096101, f1: 0.4857017157545898\n",
            "epoch: 515, step: 21, Train: label_loss: 0.11298026144504547, precision: 0.32244143033290246, recall: 0.8394863563401541, f1: 0.46592427612912424\n",
            "epoch: 515, step: 22, Train: label_loss: 0.09996620565652847, precision: 0.3152107513744462, recall: 0.8657718120803916, f1: 0.46215853108487354\n",
            "epoch: 515, step: 23, Train: label_loss: 0.10355763882398605, precision: 0.3086053412462679, recall: 0.8612836438921613, f1: 0.4543965046033814\n",
            "epoch: 516, step: 0, Train: label_loss: 0.10095196962356567, precision: 0.31776275353409233, recall: 0.8645484949831329, f1: 0.4647191010842477\n",
            "epoch: 516, step: 1, Train: label_loss: 0.1266779899597168, precision: 0.30888750776878127, recall: 0.8452380952379515, f1: 0.4524351387864286\n",
            "epoch: 516, step: 2, Train: label_loss: 0.1075984388589859, precision: 0.304639804639786, recall: 0.8559176672382751, f1: 0.44934714088875144\n",
            "epoch: 516, step: 3, Train: label_loss: 0.1015886664390564, precision: 0.325780771586018, recall: 0.8511999999998637, f1: 0.47121346320172935\n",
            "epoch: 516, step: 4, Train: label_loss: 0.09831133484840393, precision: 0.33009708737862076, recall: 0.894736842105116, f1: 0.48226950350668224\n",
            "epoch: 516, step: 5, Train: label_loss: 0.102059505879879, precision: 0.30163537250149597, recall: 0.8601036269428566, f1: 0.44663677126196283\n",
            "epoch: 516, step: 6, Train: label_loss: 0.09463879466056824, precision: 0.30727272727270866, recall: 0.8637137989777063, f1: 0.4532856503859256\n",
            "epoch: 516, step: 7, Train: label_loss: 0.09657934308052063, precision: 0.33413461538459527, recall: 0.8924558587478503, f1: 0.48622649755541963\n",
            "epoch: 516, step: 8, Train: label_loss: 0.09143891930580139, precision: 0.3137019230769042, recall: 0.8817567567566077, f1: 0.46276595740805715\n",
            "epoch: 516, step: 9, Train: label_loss: 0.08611401170492172, precision: 0.31711711711709806, recall: 0.8712871287127274, f1: 0.4649933949410164\n",
            "epoch: 516, step: 10, Train: label_loss: 0.09667380899190903, precision: 0.3231597845601243, recall: 0.885245901639199, f1: 0.4734765453356121\n",
            "epoch: 516, step: 11, Train: label_loss: 0.105991430580616, precision: 0.31973203410473083, recall: 0.8735440931778912, f1: 0.468123049448022\n",
            "epoch: 516, step: 12, Train: label_loss: 0.10931814461946487, precision: 0.30471584038692234, recall: 0.8571428571427113, f1: 0.4495985726642072\n",
            "epoch: 516, step: 13, Train: label_loss: 0.10680940747261047, precision: 0.30315917375453805, recall: 0.8588640275385785, f1: 0.4481365064723959\n",
            "epoch: 516, step: 14, Train: label_loss: 0.10038577020168304, precision: 0.315380011968862, recall: 0.8993174061431912, f1: 0.4669915817071936\n",
            "epoch: 516, step: 15, Train: label_loss: 0.0848931223154068, precision: 0.3359469240048048, recall: 0.8813291139239111, f1: 0.4864628820560641\n",
            "epoch: 516, step: 16, Train: label_loss: 0.09987784922122955, precision: 0.31313737252547613, recall: 0.8938356164382031, f1: 0.4637938693529142\n",
            "epoch: 516, step: 17, Train: label_loss: 0.09819281101226807, precision: 0.31648616125148515, recall: 0.8766666666665205, f1: 0.46507515469130734\n",
            "epoch: 516, step: 18, Train: label_loss: 0.09399060159921646, precision: 0.32801418439714375, recall: 0.9128289473682708, f1: 0.4826086956132383\n",
            "epoch: 516, step: 19, Train: label_loss: 0.09881535917520523, precision: 0.2974419988102143, recall: 0.8818342151673929, f1: 0.4448398576134846\n",
            "epoch: 516, step: 20, Train: label_loss: 0.10639044642448425, precision: 0.34547662416512775, recall: 0.8582202111612581, f1: 0.49264069259972265\n",
            "epoch: 516, step: 21, Train: label_loss: 0.09905637800693512, precision: 0.33392857142855153, recall: 0.8890649762280682, f1: 0.4855041107348164\n",
            "epoch: 516, step: 22, Train: label_loss: 0.10596544295549393, precision: 0.3088942307692122, recall: 0.8846815834766119, f1: 0.4579064587589223\n",
            "epoch: 516, step: 23, Train: label_loss: 0.07921585440635681, precision: 0.33381294964026376, recall: 0.931726907630335, f1: 0.49152542368992225\n",
            "epoch: 517, step: 0, Train: label_loss: 0.10788506269454956, precision: 0.3247391037446087, recall: 0.8729372937292288, f1: 0.4733780760230728\n",
            "epoch: 517, step: 1, Train: label_loss: 0.09369175881147385, precision: 0.3355461677730636, recall: 0.8742138364778499, f1: 0.4849542084204029\n",
            "epoch: 517, step: 2, Train: label_loss: 0.10466642677783966, precision: 0.3217286914765713, recall: 0.8978224455609886, f1: 0.47370746792399643\n",
            "epoch: 517, step: 3, Train: label_loss: 0.1102728396654129, precision: 0.30303030303028466, recall: 0.9025270758121113, f1: 0.45372050812929227\n",
            "epoch: 517, step: 4, Train: label_loss: 0.08711908757686615, precision: 0.3233890214796943, recall: 0.8988391376449587, f1: 0.47564721365125684\n",
            "epoch: 517, step: 5, Train: label_loss: 0.0968143567442894, precision: 0.31582125603862826, recall: 0.8775167785233426, f1: 0.46447602127542353\n",
            "epoch: 517, step: 6, Train: label_loss: 0.1030491292476654, precision: 0.3286840509399437, recall: 0.8827361563516477, f1: 0.4790101634601955\n",
            "epoch: 517, step: 7, Train: label_loss: 0.09389734268188477, precision: 0.29587567244469243, recall: 0.8638743455495874, f1: 0.4407836152780715\n",
            "epoch: 517, step: 8, Train: label_loss: 0.09615632891654968, precision: 0.317191283292959, recall: 0.8675496688740285, f1: 0.4645390070529471\n",
            "epoch: 517, step: 9, Train: label_loss: 0.10251332819461823, precision: 0.3214285714285523, recall: 0.9015025041734721, f1: 0.4738920578813483\n",
            "epoch: 517, step: 10, Train: label_loss: 0.08434876799583435, precision: 0.3117893476959718, recall: 0.8890784982933636, f1: 0.46167478950515606\n",
            "epoch: 517, step: 11, Train: label_loss: 0.10594348609447479, precision: 0.3113264688067649, recall: 0.8580968280466013, f1: 0.45688888884977863\n",
            "epoch: 517, step: 12, Train: label_loss: 0.09934605658054352, precision: 0.31790499390984667, recall: 0.8543371522093528, f1: 0.46338215708426417\n",
            "epoch: 517, step: 13, Train: label_loss: 0.08723440021276474, precision: 0.3066825775656142, recall: 0.8877374784109001, f1: 0.45587583144738003\n",
            "epoch: 517, step: 14, Train: label_loss: 0.10309512168169022, precision: 0.31525015069316964, recall: 0.8804713804712322, f1: 0.46426986236681245\n",
            "epoch: 517, step: 15, Train: label_loss: 0.1003643274307251, precision: 0.3245560318432134, recall: 0.8589951377632319, f1: 0.4711111110712643\n",
            "epoch: 517, step: 16, Train: label_loss: 0.09527264535427094, precision: 0.3307416267942386, recall: 0.9035947712416823, f1: 0.48423817859470236\n",
            "epoch: 517, step: 17, Train: label_loss: 0.09466111660003662, precision: 0.3307555026769583, recall: 0.9144736842103759, f1: 0.48580166007453124\n",
            "epoch: 517, step: 18, Train: label_loss: 0.08833891153335571, precision: 0.32633473305336974, recall: 0.8888888888887436, f1: 0.47740236942096254\n",
            "epoch: 517, step: 19, Train: label_loss: 0.10414446890354156, precision: 0.3202889825406189, recall: 0.880794701986609, f1: 0.46975717435378334\n",
            "epoch: 517, step: 20, Train: label_loss: 0.0911605954170227, precision: 0.32653061224487834, recall: 0.8845528455283114, f1: 0.47698377900485206\n",
            "epoch: 517, step: 21, Train: label_loss: 0.11079215258359909, precision: 0.32303030303028346, recall: 0.8752052545154556, f1: 0.47189021687071336\n",
            "epoch: 517, step: 22, Train: label_loss: 0.08681411296129227, precision: 0.32086851628466095, recall: 0.8822553897179299, f1: 0.47058823525496213\n",
            "epoch: 517, step: 23, Train: label_loss: 0.09884776175022125, precision: 0.31540162122326343, recall: 0.8770491803276892, f1: 0.46395663952743754\n",
            "epoch: 518, step: 0, Train: label_loss: 0.09154605120420456, precision: 0.3359374999999798, recall: 0.9001610305956682, f1: 0.4892778993039195\n",
            "epoch: 518, step: 1, Train: label_loss: 0.10300122946500778, precision: 0.31702898550722725, recall: 0.8592471358427398, f1: 0.4631671812574515\n",
            "epoch: 518, step: 2, Train: label_loss: 0.10371287167072296, precision: 0.3181538461538266, recall: 0.839285714285578, f1: 0.4614011601564358\n",
            "epoch: 518, step: 3, Train: label_loss: 0.09100829064846039, precision: 0.32086851628466095, recall: 0.8735632183906611, f1: 0.469342743674824\n",
            "epoch: 518, step: 4, Train: label_loss: 0.09791720658540726, precision: 0.2998776009791738, recall: 0.864197530864045, f1: 0.4452521580716601\n",
            "epoch: 518, step: 5, Train: label_loss: 0.08376719057559967, precision: 0.32793764988007623, recall: 0.8908794788272164, f1: 0.4794040315118952\n",
            "epoch: 518, step: 6, Train: label_loss: 0.10813039541244507, precision: 0.3227577791335984, recall: 0.8831385642736421, f1: 0.47274352096164873\n",
            "epoch: 518, step: 7, Train: label_loss: 0.10936805605888367, precision: 0.3026235509456801, recall: 0.8747795414460537, f1: 0.44968268355197494\n",
            "epoch: 518, step: 8, Train: label_loss: 0.09986729919910431, precision: 0.3199268738573845, recall: 0.864909390444668, f1: 0.4670818504943446\n",
            "epoch: 518, step: 9, Train: label_loss: 0.09390497207641602, precision: 0.31607465382297917, recall: 0.8853288364248085, f1: 0.4658385092779544\n",
            "epoch: 518, step: 10, Train: label_loss: 0.0848342776298523, precision: 0.32660332541565756, recall: 0.9121061359865816, f1: 0.4809794490210327\n",
            "epoch: 518, step: 11, Train: label_loss: 0.09994569420814514, precision: 0.323758228605606, recall: 0.8839869281044307, f1: 0.47393780109956934\n",
            "epoch: 518, step: 12, Train: label_loss: 0.09735893458127975, precision: 0.3214069132807567, recall: 0.8589951377632319, f1: 0.46778464250225354\n",
            "epoch: 518, step: 13, Train: label_loss: 0.11178272217512131, precision: 0.31750924784215057, recall: 0.8684654300167169, f1: 0.4650112866424644\n",
            "epoch: 518, step: 14, Train: label_loss: 0.09623377025127411, precision: 0.3042168674698612, recall: 0.8588435374148199, f1: 0.4492882561890882\n",
            "epoch: 518, step: 15, Train: label_loss: 0.104642853140831, precision: 0.316207951070317, recall: 0.8674496644293845, f1: 0.4634692962404979\n",
            "epoch: 518, step: 16, Train: label_loss: 0.09225700050592422, precision: 0.31189903846151973, recall: 0.8841567291310248, f1: 0.4611283873447901\n",
            "epoch: 518, step: 17, Train: label_loss: 0.11077229678630829, precision: 0.3223487118034558, recall: 0.8981636060098667, f1: 0.4744268077212281\n",
            "epoch: 518, step: 18, Train: label_loss: 0.09722944349050522, precision: 0.32990936555889244, recall: 0.8892508143321026, f1: 0.48126928158234195\n",
            "epoch: 518, step: 19, Train: label_loss: 0.09364160150289536, precision: 0.3333333333333132, recall: 0.881977671451215, f1: 0.48381452314474965\n",
            "epoch: 518, step: 20, Train: label_loss: 0.09104013442993164, precision: 0.3353151010701346, recall: 0.899521531100335, f1: 0.4885231701639472\n",
            "epoch: 518, step: 21, Train: label_loss: 0.10132041573524475, precision: 0.31951219512193174, recall: 0.8632619439866781, f1: 0.4663996439302633\n",
            "epoch: 518, step: 22, Train: label_loss: 0.0913359522819519, precision: 0.2972488038277334, recall: 0.8628472222220723, f1: 0.44217081846718365\n",
            "epoch: 518, step: 23, Train: label_loss: 0.10923326760530472, precision: 0.305160807778586, recall: 0.8699360341149531, f1: 0.45182724248641665\n",
            "epoch: 519, step: 0, Train: label_loss: 0.08090823143720627, precision: 0.31610576923075023, recall: 0.8915254237286624, f1: 0.46672582072439844\n",
            "epoch: 519, step: 1, Train: label_loss: 0.0934816300868988, precision: 0.3087248322147463, recall: 0.864957264957117, f1: 0.45503597118421074\n",
            "epoch: 519, step: 2, Train: label_loss: 0.1079544872045517, precision: 0.3118148599268994, recall: 0.8692699490660662, f1: 0.4589870013057858\n",
            "epoch: 519, step: 3, Train: label_loss: 0.09226445853710175, precision: 0.30921052631577095, recall: 0.8733108108106632, f1: 0.4567137808800655\n",
            "epoch: 519, step: 4, Train: label_loss: 0.09949582815170288, precision: 0.3064220183486051, recall: 0.8448566610453887, f1: 0.44973070014042926\n",
            "epoch: 519, step: 5, Train: label_loss: 0.08631964772939682, precision: 0.31585220500594063, recall: 0.9013605442175338, f1: 0.467784642503452\n",
            "epoch: 519, step: 6, Train: label_loss: 0.11064067482948303, precision: 0.30295715147855745, recall: 0.8791593695269914, f1: 0.4506283662095949\n",
            "epoch: 519, step: 7, Train: label_loss: 0.08841399848461151, precision: 0.33890214797134016, recall: 0.8916797488224659, f1: 0.49113705140838204\n",
            "epoch: 519, step: 8, Train: label_loss: 0.0953676849603653, precision: 0.32531569452794196, recall: 0.8839869281044307, f1: 0.475604395565025\n",
            "epoch: 519, step: 9, Train: label_loss: 0.09427733719348907, precision: 0.31914893617019335, recall: 0.8692052980131011, f1: 0.4668741662568026\n",
            "epoch: 519, step: 10, Train: label_loss: 0.10306734591722488, precision: 0.32785888077856884, recall: 0.8707592891759497, f1: 0.47635881569154553\n",
            "epoch: 519, step: 11, Train: label_loss: 0.09387684613466263, precision: 0.3349455864570535, recall: 0.8821656050954009, f1: 0.48553900083648893\n",
            "epoch: 519, step: 12, Train: label_loss: 0.09284062683582306, precision: 0.3290909090908891, recall: 0.8687999999998609, f1: 0.4773626373227451\n",
            "epoch: 519, step: 13, Train: label_loss: 0.08139489591121674, precision: 0.3122388059701306, recall: 0.9017241379308789, f1: 0.4638580930881344\n",
            "epoch: 519, step: 14, Train: label_loss: 0.09853368252515793, precision: 0.3134777376654444, recall: 0.8905982905981383, f1: 0.4637294169618904\n",
            "epoch: 519, step: 15, Train: label_loss: 0.09494215250015259, precision: 0.31607142857140974, recall: 0.8909395973152867, f1: 0.46660808431982453\n",
            "epoch: 519, step: 16, Train: label_loss: 0.10038916766643524, precision: 0.3088235294117458, recall: 0.8499156829678162, f1: 0.4530337078260307\n",
            "epoch: 519, step: 17, Train: label_loss: 0.0955745279788971, precision: 0.32213557288540356, recall: 0.9055649241145184, f1: 0.4752212388993028\n",
            "epoch: 519, step: 18, Train: label_loss: 0.09696422517299652, precision: 0.32506053268763163, recall: 0.883223684210381, f1: 0.4752212388986808\n",
            "epoch: 519, step: 19, Train: label_loss: 0.08477937430143356, precision: 0.3144918821406906, recall: 0.8834459459457966, f1: 0.46385809308762327\n",
            "epoch: 519, step: 20, Train: label_loss: 0.08634091913700104, precision: 0.3242442205097614, recall: 0.9071310116084731, f1: 0.47772925760308327\n",
            "epoch: 519, step: 21, Train: label_loss: 0.10224677622318268, precision: 0.3310934636530036, recall: 0.8727858293074279, f1: 0.4800708591274852\n",
            "epoch: 519, step: 22, Train: label_loss: 0.13375362753868103, precision: 0.317547055251954, recall: 0.868770764119457, f1: 0.46509559800432854\n",
            "epoch: 519, step: 23, Train: label_loss: 0.09554079174995422, precision: 0.33309090909088485, recall: 0.8927875243662976, f1: 0.485169491485795\n",
            "epoch: 520, step: 0, Train: label_loss: 0.10800302028656006, precision: 0.3103030303030115, recall: 0.8692699490660662, f1: 0.45734702988526016\n",
            "epoch: 520, step: 1, Train: label_loss: 0.09962780773639679, precision: 0.3096385542168488, recall: 0.8697123519457073, f1: 0.4566859173312937\n",
            "epoch: 520, step: 2, Train: label_loss: 0.08414344489574432, precision: 0.2923627684964026, recall: 0.8892921960070981, f1: 0.44005388411179946\n",
            "epoch: 520, step: 3, Train: label_loss: 0.08854087442159653, precision: 0.3229478729778117, recall: 0.8894389438942426, f1: 0.4738461538070284\n",
            "epoch: 520, step: 4, Train: label_loss: 0.10467614978551865, precision: 0.32031249999998074, recall: 0.8853820598005173, f1: 0.4704324801021589\n",
            "epoch: 520, step: 5, Train: label_loss: 0.09382548928260803, precision: 0.28147699757867545, recall: 0.8378378378376868, f1: 0.4213864974702443\n",
            "epoch: 520, step: 6, Train: label_loss: 0.1048526018857956, precision: 0.32450738916254157, recall: 0.8418530351436354, f1: 0.4684444444042398\n",
            "epoch: 520, step: 7, Train: label_loss: 0.09353801608085632, precision: 0.31435493640216144, recall: 0.876689189189041, f1: 0.4627730717399719\n",
            "epoch: 520, step: 8, Train: label_loss: 0.0946345254778862, precision: 0.3180987202924852, recall: 0.871452420701023, f1: 0.4660714285322065\n",
            "epoch: 520, step: 9, Train: label_loss: 0.09097939729690552, precision: 0.33553025763928485, recall: 0.8818897637793887, f1: 0.4861111110711393\n",
            "epoch: 520, step: 10, Train: label_loss: 0.07914897799491882, precision: 0.3303834808259392, recall: 0.9120521172636951, f1: 0.4850584668296914\n",
            "epoch: 520, step: 11, Train: label_loss: 0.08826223760843277, precision: 0.32818073721757857, recall: 0.8990228013027851, f1: 0.48083623689457455\n",
            "epoch: 520, step: 12, Train: label_loss: 0.09873197972774506, precision: 0.3106796116504666, recall: 0.8752136752135256, f1: 0.4585759068130586\n",
            "epoch: 520, step: 13, Train: label_loss: 0.11102651059627533, precision: 0.3144078144077952, recall: 0.8512396694213469, f1: 0.4592064199338143\n",
            "epoch: 520, step: 14, Train: label_loss: 0.08928122371435165, precision: 0.3281249999999803, recall: 0.88206785137304, f1: 0.4783180025885549\n",
            "epoch: 520, step: 15, Train: label_loss: 0.09934353083372116, precision: 0.30197723187535636, recall: 0.8999999999998393, f1: 0.45222072674564723\n",
            "epoch: 520, step: 16, Train: label_loss: 0.1016291081905365, precision: 0.29933211900423196, recall: 0.8710247349821783, f1: 0.44554902843003297\n",
            "epoch: 520, step: 17, Train: label_loss: 0.08985646069049835, precision: 0.32230907997592767, recall: 0.8758169934639091, f1: 0.47120879116942094\n",
            "epoch: 520, step: 18, Train: label_loss: 0.09082786738872528, precision: 0.32457212713934447, recall: 0.8762376237622316, f1: 0.47368421048682646\n",
            "epoch: 520, step: 19, Train: label_loss: 0.0977068841457367, precision: 0.3425149700598597, recall: 0.8937499999998603, f1: 0.49523809519799317\n",
            "epoch: 520, step: 20, Train: label_loss: 0.08409060537815094, precision: 0.3307416267942386, recall: 0.9021207177812557, f1: 0.4840262581663865\n",
            "epoch: 520, step: 21, Train: label_loss: 0.0987907201051712, precision: 0.32349397590359497, recall: 0.8717532467531052, f1: 0.4718804920518672\n",
            "epoch: 520, step: 22, Train: label_loss: 0.09199336916208267, precision: 0.3339317773787951, recall: 0.8871224165340401, f1: 0.485217391264568\n",
            "epoch: 520, step: 23, Train: label_loss: 0.09448759257793427, precision: 0.3196179279940985, recall: 0.8805668016192549, f1: 0.4690026953786617\n",
            "epoch: 521, step: 0, Train: label_loss: 0.08616116642951965, precision: 0.32800473653047196, recall: 0.9081967213113264, f1: 0.4819486732972049\n",
            "epoch: 521, step: 1, Train: label_loss: 0.09220163524150848, precision: 0.31674757281551474, recall: 0.8628099173552293, f1: 0.4633821570845093\n",
            "epoch: 521, step: 2, Train: label_loss: 0.07571232318878174, precision: 0.3122412773506616, recall: 0.9119170984454383, f1: 0.4651982378474201\n",
            "epoch: 521, step: 3, Train: label_loss: 0.10679034143686295, precision: 0.3041112454655197, recall: 0.8717504332754121, f1: 0.45091887042328804\n",
            "epoch: 521, step: 4, Train: label_loss: 0.10318198800086975, precision: 0.31219512195120047, recall: 0.8547579298829958, f1: 0.45734702988484077\n",
            "epoch: 521, step: 5, Train: label_loss: 0.09917004406452179, precision: 0.29859841560022554, recall: 0.8333333333331916, f1: 0.439659039889338\n",
            "epoch: 521, step: 6, Train: label_loss: 0.10304168611764908, precision: 0.3064014916096764, recall: 0.8016260162600322, f1: 0.44334532370095514\n",
            "epoch: 521, step: 7, Train: label_loss: 0.10948032140731812, precision: 0.3197530864197333, recall: 0.8248407643310788, f1: 0.4608540924863858\n",
            "epoch: 521, step: 8, Train: label_loss: 0.1314137876033783, precision: 0.32740649908029873, recall: 0.8436018957344639, f1: 0.47173144872292494\n",
            "epoch: 521, step: 9, Train: label_loss: 0.09808880090713501, precision: 0.3194945848375259, recall: 0.8849999999998525, f1: 0.4694960211811389\n",
            "epoch: 521, step: 10, Train: label_loss: 0.1131843701004982, precision: 0.3161764705882159, recall: 0.8686868686867224, f1: 0.46361185979910535\n",
            "epoch: 521, step: 11, Train: label_loss: 0.08870364725589752, precision: 0.32895522388057735, recall: 0.890145395799533, f1: 0.4803836093764208\n",
            "epoch: 521, step: 12, Train: label_loss: 0.09207650274038315, precision: 0.31156381066505023, recall: 0.87837837837823, f1: 0.4599734630307425\n",
            "epoch: 521, step: 13, Train: label_loss: 0.09935694932937622, precision: 0.3369369369369167, recall: 0.8793103448274483, f1: 0.48719062088912346\n",
            "epoch: 521, step: 14, Train: label_loss: 0.10208427906036377, precision: 0.32080048514249115, recall: 0.8860971524286623, f1: 0.4710596615815864\n",
            "epoch: 521, step: 15, Train: label_loss: 0.10898556560277939, precision: 0.31954436450837415, recall: 0.8927973199328487, f1: 0.4706401765615792\n",
            "epoch: 521, step: 16, Train: label_loss: 0.10804508626461029, precision: 0.2994522215459343, recall: 0.8770053475934265, f1: 0.4464609799983076\n",
            "epoch: 521, step: 17, Train: label_loss: 0.09649455547332764, precision: 0.31676646706584927, recall: 0.8846153846152366, f1: 0.4664902997847625\n",
            "epoch: 521, step: 18, Train: label_loss: 0.10725614428520203, precision: 0.32044198895025655, recall: 0.8699999999998549, f1: 0.46837146698618565\n",
            "epoch: 521, step: 19, Train: label_loss: 0.11621707677841187, precision: 0.3174019607842943, recall: 0.8491803278687132, f1: 0.46208742190504065\n",
            "epoch: 521, step: 20, Train: label_loss: 0.09927533566951752, precision: 0.3231231231231037, recall: 0.886326194398536, f1: 0.4735915492565754\n",
            "epoch: 521, step: 21, Train: label_loss: 0.09965310990810394, precision: 0.31702898550722725, recall: 0.8620689655170998, f1: 0.46357615890104026\n",
            "epoch: 521, step: 22, Train: label_loss: 0.10084827244281769, precision: 0.31648616125148515, recall: 0.8679867986797247, f1: 0.46384479713892923\n",
            "epoch: 521, step: 23, Train: label_loss: 0.09615187346935272, precision: 0.3030303030302806, recall: 0.8971553610501319, f1: 0.4530386739953517\n",
            "epoch: 522, step: 0, Train: label_loss: 0.09730558842420578, precision: 0.30975609756095673, recall: 0.8396694214874645, f1: 0.45256124717662244\n",
            "epoch: 522, step: 1, Train: label_loss: 0.10718123614788055, precision: 0.32429174201324146, recall: 0.8790849673201178, f1: 0.4738000880275166\n",
            "epoch: 522, step: 2, Train: label_loss: 0.10039813816547394, precision: 0.3367469879517869, recall: 0.8720748829951837, f1: 0.4858757061744529\n",
            "epoch: 522, step: 3, Train: label_loss: 0.09651315212249756, precision: 0.3351286654697585, recall: 0.8888888888887477, f1: 0.4867448934847461\n",
            "epoch: 522, step: 4, Train: label_loss: 0.07852709293365479, precision: 0.33095238095236124, recall: 0.9099836333877397, f1: 0.48537756434320956\n",
            "epoch: 522, step: 5, Train: label_loss: 0.09256526082754135, precision: 0.3052378085490484, recall: 0.8756476683936311, f1: 0.4526785713901971\n",
            "epoch: 522, step: 6, Train: label_loss: 0.08619217574596405, precision: 0.31411411411409523, recall: 0.868770764119457, f1: 0.46140273485288036\n",
            "epoch: 522, step: 7, Train: label_loss: 0.08876404166221619, precision: 0.32743362831856476, recall: 0.9173553719006747, f1: 0.4826086956133616\n",
            "epoch: 522, step: 8, Train: label_loss: 0.09420798718929291, precision: 0.32892363199035907, recall: 0.8894308943087984, f1: 0.4802458296356939\n",
            "epoch: 522, step: 9, Train: label_loss: 0.09373815357685089, precision: 0.31578947368419163, recall: 0.9166666666665074, f1: 0.4697508896415585\n",
            "epoch: 522, step: 10, Train: label_loss: 0.09309804439544678, precision: 0.3118664281454793, recall: 0.895547945205326, f1: 0.46262715608725163\n",
            "epoch: 522, step: 11, Train: label_loss: 0.0867406576871872, precision: 0.29306220095692026, recall: 0.8812949640286184, f1: 0.4398563733915898\n",
            "epoch: 522, step: 12, Train: label_loss: 0.09101495146751404, precision: 0.3129411764705698, recall: 0.9188255613124492, f1: 0.4668714348018984\n",
            "epoch: 522, step: 13, Train: label_loss: 0.10449327528476715, precision: 0.3222087378640581, recall: 0.874794069192607, f1: 0.4709534367677092\n",
            "epoch: 522, step: 14, Train: label_loss: 0.09934063255786896, precision: 0.3309395571513865, recall: 0.8847999999998584, f1: 0.48170731703350617\n",
            "epoch: 522, step: 15, Train: label_loss: 0.09702065587043762, precision: 0.3151183970855911, recall: 0.8752107925799535, f1: 0.46339285710388595\n",
            "epoch: 522, step: 16, Train: label_loss: 0.12096048891544342, precision: 0.3071161048688947, recall: 0.8241206030149373, f1: 0.4474761254719991\n",
            "epoch: 522, step: 17, Train: label_loss: 0.10338254272937775, precision: 0.2975256487628064, recall: 0.8618881118879611, f1: 0.4423508299304031\n",
            "epoch: 522, step: 18, Train: label_loss: 0.08666901290416718, precision: 0.328217237308127, recall: 0.8953301127212728, f1: 0.48034557231491176\n",
            "epoch: 522, step: 19, Train: label_loss: 0.10318200290203094, precision: 0.3178807947019676, recall: 0.8785357737103363, f1: 0.46684350128719854\n",
            "epoch: 522, step: 20, Train: label_loss: 0.09602759778499603, precision: 0.3114949374627569, recall: 0.8834459459457966, f1: 0.4605900483982264\n",
            "epoch: 522, step: 21, Train: label_loss: 0.09049911797046661, precision: 0.32796660703635494, recall: 0.8972267536703267, f1: 0.480349344938918\n",
            "epoch: 522, step: 22, Train: label_loss: 0.08758635073900223, precision: 0.3268998793727185, recall: 0.8798701298699869, f1: 0.47669305185139765\n",
            "epoch: 522, step: 23, Train: label_loss: 0.11334104835987091, precision: 0.30190114068438767, recall: 0.8151950718684158, f1: 0.4406215315920281\n",
            "epoch: 523, step: 0, Train: label_loss: 0.08334182947874069, precision: 0.32064247471741103, recall: 0.8968386023293016, f1: 0.4723926379979676\n",
            "epoch: 523, step: 1, Train: label_loss: 0.09084919095039368, precision: 0.3093955715140449, recall: 0.8777589134124145, f1: 0.4575221238552254\n",
            "epoch: 523, step: 2, Train: label_loss: 0.101341113448143, precision: 0.31435493640216144, recall: 0.8781725888323386, f1: 0.46297948256595245\n",
            "epoch: 523, step: 3, Train: label_loss: 0.09070078283548355, precision: 0.2963186481593062, recall: 0.8554006968639624, f1: 0.44016136257940297\n",
            "epoch: 523, step: 4, Train: label_loss: 0.09337775409221649, precision: 0.3082066869300724, recall: 0.8449999999998591, f1: 0.4516703785799469\n",
            "epoch: 523, step: 5, Train: label_loss: 0.09999580681324005, precision: 0.327690447400222, recall: 0.8798701298699869, f1: 0.4775330396079897\n",
            "epoch: 523, step: 6, Train: label_loss: 0.091883584856987, precision: 0.3343265792610051, recall: 0.9166666666665169, f1: 0.4899563318385211\n",
            "epoch: 523, step: 7, Train: label_loss: 0.09162219613790512, precision: 0.3242603550295666, recall: 0.914858096827894, f1: 0.47881170813082313\n",
            "epoch: 523, step: 8, Train: label_loss: 0.08864821493625641, precision: 0.33572281959376726, recall: 0.8949044585985836, f1: 0.4882710685962497\n",
            "epoch: 523, step: 9, Train: label_loss: 0.09458005428314209, precision: 0.3059388122375341, recall: 0.8885017421601239, f1: 0.45515394909170603\n",
            "epoch: 523, step: 10, Train: label_loss: 0.08493045717477798, precision: 0.3184257602862064, recall: 0.8959731543622657, f1: 0.4698636163273036\n",
            "epoch: 523, step: 11, Train: label_loss: 0.10014292597770691, precision: 0.31711711711709806, recall: 0.904109589040941, f1: 0.46954201863647643\n",
            "epoch: 523, step: 12, Train: label_loss: 0.10193051397800446, precision: 0.3385354141656459, recall: 0.8966613672494599, f1: 0.4915032679340219\n",
            "epoch: 523, step: 13, Train: label_loss: 0.10558377206325531, precision: 0.31518451300663547, recall: 0.8785834738615719, f1: 0.46393588598068586\n",
            "epoch: 523, step: 14, Train: label_loss: 0.09867045283317566, precision: 0.3078773301262593, recall: 0.8767123287669731, f1: 0.45571873605405677\n",
            "epoch: 523, step: 15, Train: label_loss: 0.09081003069877625, precision: 0.32517899761334573, recall: 0.9038142620230672, f1: 0.4782799473063684\n",
            "epoch: 523, step: 16, Train: label_loss: 0.10626691579818726, precision: 0.32349397590359497, recall: 0.8861386138612398, f1: 0.4739629302343857\n",
            "epoch: 523, step: 17, Train: label_loss: 0.09640239179134369, precision: 0.3271752085816253, recall: 0.8955954323000169, f1: 0.479266695726804\n",
            "epoch: 523, step: 18, Train: label_loss: 0.08112695813179016, precision: 0.3270142180094593, recall: 0.893203883495001, f1: 0.4787510840890843\n",
            "epoch: 523, step: 19, Train: label_loss: 0.09397625923156738, precision: 0.3305489260143001, recall: 0.8878205128203704, f1: 0.4817391303952011\n",
            "epoch: 523, step: 20, Train: label_loss: 0.09010495990514755, precision: 0.3266908212560189, recall: 0.8839869281044307, f1: 0.4770723103661962\n",
            "epoch: 523, step: 21, Train: label_loss: 0.1019521951675415, precision: 0.32041187159295453, recall: 0.8831385642736421, f1: 0.47022222218311077\n",
            "epoch: 523, step: 22, Train: label_loss: 0.08395399898290634, precision: 0.31445427728611713, recall: 0.8942953020132727, f1: 0.46529899603304953\n",
            "epoch: 523, step: 23, Train: label_loss: 0.0976744145154953, precision: 0.3062730627306047, recall: 0.8682008368199021, f1: 0.4528096017071683\n",
            "epoch: 524, step: 0, Train: label_loss: 0.08604507893323898, precision: 0.31404460518382676, recall: 0.8875638841565778, f1: 0.4639358859809395\n",
            "epoch: 524, step: 1, Train: label_loss: 0.08560538291931152, precision: 0.32684365781708985, recall: 0.9157024793386915, f1: 0.4817391303959703\n",
            "epoch: 524, step: 2, Train: label_loss: 0.10723797231912613, precision: 0.31479217603910054, recall: 0.8612040133777823, f1: 0.46105640103505924\n",
            "epoch: 524, step: 3, Train: label_loss: 0.09090184420347214, precision: 0.3126879134094821, recall: 0.8888888888887369, f1: 0.462633451918752\n",
            "epoch: 524, step: 4, Train: label_loss: 0.0941714197397232, precision: 0.33435771358326155, recall: 0.8566929133856918, f1: 0.4809902740532961\n",
            "epoch: 524, step: 5, Train: label_loss: 0.09266844391822815, precision: 0.3198090692123914, recall: 0.8933333333331844, f1: 0.47100175743037787\n",
            "epoch: 524, step: 6, Train: label_loss: 0.0962967723608017, precision: 0.3107861060328878, recall: 0.8717948717947227, f1: 0.45822102421997135\n",
            "epoch: 524, step: 7, Train: label_loss: 0.09763556718826294, precision: 0.3347355769230568, recall: 0.8983870967740486, f1: 0.487740805564607\n",
            "epoch: 524, step: 8, Train: label_loss: 0.09520798921585083, precision: 0.33372992266506046, recall: 0.8961661341851603, f1: 0.48634590373154546\n",
            "epoch: 524, step: 9, Train: label_loss: 0.07238658517599106, precision: 0.3277909738717145, recall: 0.900489396410946, f1: 0.480626904619078\n",
            "epoch: 524, step: 10, Train: label_loss: 0.10381849855184555, precision: 0.3187274909963794, recall: 0.8762376237622316, f1: 0.467429577425631\n",
            "epoch: 524, step: 11, Train: label_loss: 0.08479383587837219, precision: 0.3170441001191706, recall: 0.8971332209104725, f1: 0.4685160721762549\n",
            "epoch: 524, step: 12, Train: label_loss: 0.10355553030967712, precision: 0.31204819277106555, recall: 0.880952380952231, f1: 0.4608540924880196\n",
            "epoch: 524, step: 13, Train: label_loss: 0.10350851714611053, precision: 0.30923450789791557, recall: 0.8525963149077298, f1: 0.4538564422257195\n",
            "epoch: 524, step: 14, Train: label_loss: 0.08518512547016144, precision: 0.3106332138590017, recall: 0.875420875420728, f1: 0.4585537918484226\n",
            "epoch: 524, step: 15, Train: label_loss: 0.10627167671918869, precision: 0.3103241296518421, recall: 0.8733108108106632, f1: 0.4579273693146813\n",
            "epoch: 524, step: 16, Train: label_loss: 0.09411315619945526, precision: 0.3213859020310441, recall: 0.8922056384741471, f1: 0.4725516029474058\n",
            "epoch: 524, step: 17, Train: label_loss: 0.09736928343772888, precision: 0.32114564290065073, recall: 0.859706362153204, f1: 0.46761313216976436\n",
            "epoch: 524, step: 18, Train: label_loss: 0.08563199639320374, precision: 0.3198813056379632, recall: 0.9074074074072546, f1: 0.47301447999652013\n",
            "epoch: 524, step: 19, Train: label_loss: 0.10211870074272156, precision: 0.33514821536598094, recall: 0.8878205128203704, f1: 0.4866051822175245\n",
            "epoch: 524, step: 20, Train: label_loss: 0.1057034581899643, precision: 0.32153752287978515, recall: 0.8783333333331869, f1: 0.470745868652105\n",
            "epoch: 524, step: 21, Train: label_loss: 0.09300404787063599, precision: 0.31730769230767325, recall: 0.8844221105526157, f1: 0.46704997784698504\n",
            "epoch: 524, step: 22, Train: label_loss: 0.11002501845359802, precision: 0.3216049382715851, recall: 0.8611570247932461, f1: 0.4683146067019359\n",
            "epoch: 524, step: 23, Train: label_loss: 0.09287892282009125, precision: 0.2983870967741717, recall: 0.886710239651223, f1: 0.4465167306260145\n",
            "epoch: 525, step: 0, Train: label_loss: 0.08292414993047714, precision: 0.3323335332933214, recall: 0.9008130081299348, f1: 0.4855390008370077\n",
            "epoch: 525, step: 1, Train: label_loss: 0.09709674119949341, precision: 0.31257557436515643, recall: 0.8659966499161028, f1: 0.45935139933903807\n",
            "epoch: 525, step: 2, Train: label_loss: 0.09297680854797363, precision: 0.3157262905161875, recall: 0.878130217028234, f1: 0.4644591611089578\n",
            "epoch: 525, step: 3, Train: label_loss: 0.09629914909601212, precision: 0.30419161676644885, recall: 0.8728522336768259, f1: 0.4511545292689128\n",
            "epoch: 525, step: 4, Train: label_loss: 0.09133142232894897, precision: 0.3228299643281615, recall: 0.9049999999998491, f1: 0.4758983347552393\n",
            "epoch: 525, step: 5, Train: label_loss: 0.08668343722820282, precision: 0.3287259615384418, recall: 0.8836833602583386, f1: 0.4791940428864085\n",
            "epoch: 525, step: 6, Train: label_loss: 0.08897757530212402, precision: 0.3150932050510935, recall: 0.8733333333331877, f1: 0.46310207685007665\n",
            "epoch: 525, step: 7, Train: label_loss: 0.09021513909101486, precision: 0.305854241338094, recall: 0.8873483535527058, f1: 0.4549089293265613\n",
            "epoch: 525, step: 8, Train: label_loss: 0.09483687579631805, precision: 0.3327294685990137, recall: 0.8773885350317073, f1: 0.4824868651089482\n",
            "epoch: 525, step: 9, Train: label_loss: 0.09787667542695999, precision: 0.3245350929813842, recall: 0.8912685337725055, f1: 0.4758135443759499\n",
            "epoch: 525, step: 10, Train: label_loss: 0.09399420022964478, precision: 0.3245823389021286, recall: 0.8976897689767495, f1: 0.47677475894429894\n",
            "epoch: 525, step: 11, Train: label_loss: 0.08637969940900803, precision: 0.3438995215310799, recall: 0.8873456790122087, f1: 0.49568965513211183\n",
            "epoch: 525, step: 12, Train: label_loss: 0.0972321555018425, precision: 0.29999999999998184, recall: 0.8730158730157189, f1: 0.44654939103090335\n",
            "epoch: 525, step: 13, Train: label_loss: 0.09091785550117493, precision: 0.32071005917157863, recall: 0.9170896785108431, f1: 0.4752301621711224\n",
            "epoch: 525, step: 14, Train: label_loss: 0.09347285330295563, precision: 0.3182640144665269, recall: 0.8799999999998532, f1: 0.46746347937661753\n",
            "epoch: 525, step: 15, Train: label_loss: 0.0930992066860199, precision: 0.33753753753751725, recall: 0.8991999999998561, f1: 0.4908296942834137\n",
            "epoch: 525, step: 16, Train: label_loss: 0.0812276229262352, precision: 0.3135846798324169, recall: 0.8941979522182774, f1: 0.4643331856061747\n",
            "epoch: 525, step: 17, Train: label_loss: 0.09374772757291794, precision: 0.30709600477040505, recall: 0.8925476603118037, f1: 0.4569653948154613\n",
            "epoch: 525, step: 18, Train: label_loss: 0.0822259709239006, precision: 0.3063549160671279, recall: 0.8765008576327827, f1: 0.45402043532363756\n",
            "epoch: 525, step: 19, Train: label_loss: 0.08092177659273148, precision: 0.32938388625590465, recall: 0.9114754098359161, f1: 0.48389904260673977\n",
            "epoch: 525, step: 20, Train: label_loss: 0.09059271961450577, precision: 0.3231780167263845, recall: 0.9031719532552749, f1: 0.4760228772158713\n",
            "epoch: 525, step: 21, Train: label_loss: 0.09199279546737671, precision: 0.3108591885441342, recall: 0.8890784982933636, f1: 0.46065428820206455\n",
            "epoch: 525, step: 22, Train: label_loss: 0.09426693618297577, precision: 0.33553025763928485, recall: 0.8846761453395127, f1: 0.48653344913471536\n",
            "epoch: 525, step: 23, Train: label_loss: 0.09186665713787079, precision: 0.31181217901685165, recall: 0.8780991735535376, f1: 0.4602057389975495\n",
            "epoch: 526, step: 0, Train: label_loss: 0.07994735240936279, precision: 0.3201675643327157, recall: 0.8901830282860415, f1: 0.4709507041864003\n",
            "epoch: 526, step: 1, Train: label_loss: 0.09546351432800293, precision: 0.3271420011983027, recall: 0.8936170212764494, f1: 0.47894736838177704\n",
            "epoch: 526, step: 2, Train: label_loss: 0.08759946376085281, precision: 0.3186943620177852, recall: 0.9040404040402518, f1: 0.4712593242264457\n",
            "epoch: 526, step: 3, Train: label_loss: 0.08834443241357803, precision: 0.311151079136672, recall: 0.8948275862067422, f1: 0.4617437722036639\n",
            "epoch: 526, step: 4, Train: label_loss: 0.09277597069740295, precision: 0.32608695652171943, recall: 0.8999999999998499, f1: 0.47872340421623183\n",
            "epoch: 526, step: 5, Train: label_loss: 0.09747286140918732, precision: 0.31601208459212593, recall: 0.8658940397349559, f1: 0.46303674188198596\n",
            "epoch: 526, step: 6, Train: label_loss: 0.07879705727100372, precision: 0.34558387670418816, recall: 0.9152276295132, f1: 0.5017211703560325\n",
            "epoch: 526, step: 7, Train: label_loss: 0.08163662999868393, precision: 0.3226571767496843, recall: 0.8888888888887436, f1: 0.47345517837689416\n",
            "epoch: 526, step: 8, Train: label_loss: 0.07724174112081528, precision: 0.31345926800470403, recall: 0.9202772963603257, f1: 0.4676354028682635\n",
            "epoch: 526, step: 9, Train: label_loss: 0.08187542855739594, precision: 0.3283935981031222, recall: 0.8964401294496931, f1: 0.48069414312774084\n",
            "epoch: 526, step: 10, Train: label_loss: 0.092862568795681, precision: 0.3367408298255961, recall: 0.8846761453395127, f1: 0.48780487800880035\n",
            "epoch: 526, step: 11, Train: label_loss: 0.09534768760204315, precision: 0.31588447653427704, recall: 0.8853288364248085, f1: 0.46563192900775846\n",
            "epoch: 526, step: 12, Train: label_loss: 0.09200267493724823, precision: 0.3230220107078927, recall: 0.9034941763725618, f1: 0.47589833475519777\n",
            "epoch: 526, step: 13, Train: label_loss: 0.08236605674028397, precision: 0.32482185273157216, recall: 0.8967213114752628, f1: 0.4768962510507175\n",
            "epoch: 526, step: 14, Train: label_loss: 0.08766339719295502, precision: 0.3438242280284831, recall: 0.9205087440380094, f1: 0.5006485083909683\n",
            "epoch: 526, step: 15, Train: label_loss: 0.09734475612640381, precision: 0.31899641577059024, recall: 0.8989898989897476, f1: 0.4708994708607672\n",
            "epoch: 526, step: 16, Train: label_loss: 0.09221494197845459, precision: 0.3113772455089634, recall: 0.8950086058518252, f1: 0.46201688134771196\n",
            "epoch: 526, step: 17, Train: label_loss: 0.09877979755401611, precision: 0.29560505719444335, recall: 0.8736654804268907, f1: 0.44174538907599087\n",
            "epoch: 526, step: 18, Train: label_loss: 0.10950368642807007, precision: 0.31713244228430637, recall: 0.8628099173552293, f1: 0.463793869352034\n",
            "epoch: 526, step: 19, Train: label_loss: 0.08906355500221252, precision: 0.3087802003535469, recall: 0.9113043478259284, f1: 0.46126760559595603\n",
            "epoch: 526, step: 20, Train: label_loss: 0.08807678520679474, precision: 0.3088057901085459, recall: 0.882758620689503, f1: 0.4575513851268861\n",
            "epoch: 526, step: 21, Train: label_loss: 0.08526796102523804, precision: 0.3327412670218867, recall: 0.9108589951376157, f1: 0.48742411097550725\n",
            "epoch: 526, step: 22, Train: label_loss: 0.09523801505565643, precision: 0.29788519637460437, recall: 0.8559027777776291, f1: 0.4419542805533187\n",
            "epoch: 526, step: 23, Train: label_loss: 0.0913262665271759, precision: 0.35324107793151105, recall: 0.9168241965971801, f1: 0.5099894847126835\n",
            "epoch: 527, step: 0, Train: label_loss: 0.08393997699022293, precision: 0.3390431187241383, recall: 0.8982785602502505, f1: 0.49228130356223004\n",
            "epoch: 527, step: 1, Train: label_loss: 0.09846572577953339, precision: 0.3094089264173517, recall: 0.868020304568381, f1: 0.4562027567420053\n",
            "epoch: 527, step: 2, Train: label_loss: 0.08074936270713806, precision: 0.3146067415730151, recall: 0.8986486486484968, f1: 0.4660534384197148\n",
            "epoch: 527, step: 3, Train: label_loss: 0.10336369276046753, precision: 0.3353510895883574, recall: 0.8807631160570936, f1: 0.48575186317790126\n",
            "epoch: 527, step: 4, Train: label_loss: 0.07969225943088531, precision: 0.3426365795724262, recall: 0.9058084772369064, f1: 0.49719948294160515\n",
            "epoch: 527, step: 5, Train: label_loss: 0.08006470650434494, precision: 0.3208999407933498, recall: 0.9124579124577588, f1: 0.4748138413981668\n",
            "epoch: 527, step: 6, Train: label_loss: 0.09737998247146606, precision: 0.31519138755978976, recall: 0.9054982817867859, f1: 0.46761313217105677\n",
            "epoch: 527, step: 7, Train: label_loss: 0.09436819702386856, precision: 0.30274135876041103, recall: 0.8850174216026332, f1: 0.4511545292692586\n",
            "epoch: 527, step: 8, Train: label_loss: 0.08693839609622955, precision: 0.33113772455087837, recall: 0.8962722852510703, f1: 0.4836029732880607\n",
            "epoch: 527, step: 9, Train: label_loss: 0.08455543220043182, precision: 0.33572281959376726, recall: 0.8822605965461723, f1: 0.4863695369569965\n",
            "epoch: 527, step: 10, Train: label_loss: 0.09150994569063187, precision: 0.311711711711693, recall: 0.8932874354559563, f1: 0.46215494208092894\n",
            "epoch: 527, step: 11, Train: label_loss: 0.08980958163738251, precision: 0.3230220107078927, recall: 0.893092105263011, f1: 0.47444298816540154\n",
            "epoch: 527, step: 12, Train: label_loss: 0.10318544507026672, precision: 0.3165165165164975, recall: 0.8857142857141368, f1: 0.4663716813770957\n",
            "epoch: 527, step: 13, Train: label_loss: 0.07379202544689178, precision: 0.3339222614840793, recall: 0.9264705882351426, f1: 0.4909090908700995\n",
            "epoch: 527, step: 14, Train: label_loss: 0.08470641076564789, precision: 0.3290017720023432, recall: 0.917627677100343, f1: 0.4843478260480618\n",
            "epoch: 527, step: 15, Train: label_loss: 0.09585066884756088, precision: 0.32093581283741324, recall: 0.8931552587644586, f1: 0.4721977051684791\n",
            "epoch: 527, step: 16, Train: label_loss: 0.08936834335327148, precision: 0.3147928994082654, recall: 0.910958904109433, f1: 0.4678979770945921\n",
            "epoch: 527, step: 17, Train: label_loss: 0.09967861324548721, precision: 0.3058894230769047, recall: 0.8791018998271365, f1: 0.453856442226483\n",
            "epoch: 527, step: 18, Train: label_loss: 0.09702042490243912, precision: 0.31242603550294007, recall: 0.9056603773583352, f1: 0.4645842498518318\n",
            "epoch: 527, step: 19, Train: label_loss: 0.08612702786922455, precision: 0.3172043010752499, recall: 0.8969594594593079, f1: 0.46866725503638074\n",
            "epoch: 527, step: 20, Train: label_loss: 0.07652080059051514, precision: 0.33177570093456005, recall: 0.9311475409834539, f1: 0.48923341942719734\n",
            "epoch: 527, step: 21, Train: label_loss: 0.10272815823554993, precision: 0.29663056558361633, recall: 0.8710247349821783, f1: 0.4425493715958118\n",
            "epoch: 527, step: 22, Train: label_loss: 0.08947201073169708, precision: 0.3325387365911601, recall: 0.8985507246375364, f1: 0.4854284471114621\n",
            "epoch: 527, step: 23, Train: label_loss: 0.09049995988607407, precision: 0.31563421828906224, recall: 0.8734693877549238, f1: 0.46370530873668486\n",
            "epoch: 528, step: 0, Train: label_loss: 0.0854300856590271, precision: 0.31272509003599563, recall: 0.8875638841565778, f1: 0.4624944518034155\n",
            "epoch: 528, step: 1, Train: label_loss: 0.09258784353733063, precision: 0.3277711561382403, recall: 0.906095551894414, f1: 0.48140043759770373\n",
            "epoch: 528, step: 2, Train: label_loss: 0.0866796150803566, precision: 0.32014388489206713, recall: 0.87684729064025, f1: 0.4690382081294169\n",
            "epoch: 528, step: 3, Train: label_loss: 0.08420508354902267, precision: 0.3435251798560945, recall: 0.8939157566301257, f1: 0.49631875266664793\n",
            "epoch: 528, step: 4, Train: label_loss: 0.10592366755008698, precision: 0.3111111111110924, recall: 0.8735244519391444, f1: 0.4588131089071989\n",
            "epoch: 528, step: 5, Train: label_loss: 0.08912624418735504, precision: 0.31550802139035555, recall: 0.8999999999998474, f1: 0.46722393308954485\n",
            "epoch: 528, step: 6, Train: label_loss: 0.08805125951766968, precision: 0.3178294573643221, recall: 0.8927973199328487, f1: 0.468777484569856\n",
            "epoch: 528, step: 7, Train: label_loss: 0.09777554869651794, precision: 0.2936555891238493, recall: 0.872531418312231, f1: 0.43942133811779543\n",
            "epoch: 528, step: 8, Train: label_loss: 0.09073945879936218, precision: 0.30231179608771175, recall: 0.9058614564829651, f1: 0.4533333332957708\n",
            "epoch: 528, step: 9, Train: label_loss: 0.09449184685945511, precision: 0.3233890214796943, recall: 0.8973509933773348, f1: 0.4754385964522396\n",
            "epoch: 528, step: 10, Train: label_loss: 0.08619755506515503, precision: 0.31799163179914414, recall: 0.8926174496642797, f1: 0.4689290435927794\n",
            "epoch: 528, step: 11, Train: label_loss: 0.08030654489994049, precision: 0.3476446034585362, recall: 0.9038759689921079, f1: 0.5021533160666378\n",
            "epoch: 528, step: 12, Train: label_loss: 0.09481008350849152, precision: 0.31421744324968254, recall: 0.8960817717204606, f1: 0.4652808491432934\n",
            "epoch: 528, step: 13, Train: label_loss: 0.08688048273324966, precision: 0.3240356083085861, recall: 0.9009900990097522, f1: 0.47664775203437953\n",
            "epoch: 528, step: 14, Train: label_loss: 0.08752813935279846, precision: 0.3267973856208956, recall: 0.8928571428569978, f1: 0.4784688994822595\n",
            "epoch: 528, step: 15, Train: label_loss: 0.09211160242557526, precision: 0.32340678975578774, recall: 0.8887070376430624, f1: 0.4742358078210959\n",
            "epoch: 528, step: 16, Train: label_loss: 0.0950738936662674, precision: 0.3066265060240779, recall: 0.8641765704582572, f1: 0.45264562023697674\n",
            "epoch: 528, step: 17, Train: label_loss: 0.09299207478761673, precision: 0.33696969696967655, recall: 0.8867623604464295, f1: 0.488361879626277\n",
            "epoch: 528, step: 18, Train: label_loss: 0.08603456616401672, precision: 0.3107378524294955, recall: 0.8794567062816843, f1: 0.45921985811740407\n",
            "epoch: 528, step: 19, Train: label_loss: 0.0797264501452446, precision: 0.3305588585017639, recall: 0.8938906752410137, f1: 0.4826388888494302\n",
            "epoch: 528, step: 20, Train: label_loss: 0.09072165936231613, precision: 0.29821428571426795, recall: 0.8978494623654304, f1: 0.44772117958719193\n",
            "epoch: 528, step: 21, Train: label_loss: 0.0922359973192215, precision: 0.335744424351999, recall: 0.8883572567781677, f1: 0.48731408569942997\n",
            "epoch: 528, step: 22, Train: label_loss: 0.08912599831819534, precision: 0.33194527067219914, recall: 0.9014539579966233, f1: 0.48521739126496577\n",
            "epoch: 528, step: 23, Train: label_loss: 0.0826723575592041, precision: 0.3110465116278844, recall: 0.8935281837158886, f1: 0.4614555255681107\n",
            "epoch: 529, step: 0, Train: label_loss: 0.09208083152770996, precision: 0.3124999999999814, recall: 0.9130434782607108, f1: 0.46563192900852796\n",
            "epoch: 529, step: 1, Train: label_loss: 0.0731862410902977, precision: 0.3468786808009218, recall: 0.9290220820187809, f1: 0.505145797558993\n",
            "epoch: 529, step: 2, Train: label_loss: 0.09546297043561935, precision: 0.320096269554734, recall: 0.8986486486484968, f1: 0.4720496894022194\n",
            "epoch: 529, step: 3, Train: label_loss: 0.08690736442804337, precision: 0.33051359516614315, recall: 0.871019108280116, f1: 0.4791940428860507\n",
            "epoch: 529, step: 4, Train: label_loss: 0.083503857254982, precision: 0.32612612612610653, recall: 0.8646496815285247, f1: 0.4736153510286542\n",
            "epoch: 529, step: 5, Train: label_loss: 0.08888129889965057, precision: 0.3323281061519703, recall: 0.8858520900320118, f1: 0.4833333332936142\n",
            "epoch: 529, step: 6, Train: label_loss: 0.10671724379062653, precision: 0.32509047044630124, recall: 0.8836065573769043, f1: 0.47530864193594263\n",
            "epoch: 529, step: 7, Train: label_loss: 0.090060293674469, precision: 0.3185362927414326, recall: 0.880597014925227, f1: 0.4678414096525738\n",
            "epoch: 529, step: 8, Train: label_loss: 0.09514078497886658, precision: 0.3132236441194203, recall: 0.8495867768593637, f1: 0.45770258232925287\n",
            "epoch: 529, step: 9, Train: label_loss: 0.08660160005092621, precision: 0.32072072072070146, recall: 0.87684729064025, f1: 0.4696569920451738\n",
            "epoch: 529, step: 10, Train: label_loss: 0.07611732184886932, precision: 0.32901706886401827, recall: 0.9209225700163227, f1: 0.4848222029099994\n",
            "epoch: 529, step: 11, Train: label_loss: 0.09926996380090714, precision: 0.303614457831307, recall: 0.8795811518323071, f1: 0.4514106582690177\n",
            "epoch: 529, step: 12, Train: label_loss: 0.09979389607906342, precision: 0.30538922155686793, recall: 0.8963093145868372, f1: 0.45556051805048187\n",
            "epoch: 529, step: 13, Train: label_loss: 0.09614507853984833, precision: 0.2980251346498924, recall: 0.8798586572436607, f1: 0.44523915955089516\n",
            "epoch: 529, step: 14, Train: label_loss: 0.09384050965309143, precision: 0.3198813056379632, recall: 0.9043624161072308, f1: 0.4725997369188299\n",
            "epoch: 529, step: 15, Train: label_loss: 0.09426571428775787, precision: 0.3121629718394061, recall: 0.9029462738299994, f1: 0.4639358859813684\n",
            "epoch: 529, step: 16, Train: label_loss: 0.08860444277524948, precision: 0.332324455205791, recall: 0.8840579710143504, f1: 0.4830620325163377\n",
            "epoch: 529, step: 17, Train: label_loss: 0.11080752313137054, precision: 0.3315151515151314, recall: 0.8696343402224372, f1: 0.48003510307539465\n",
            "epoch: 529, step: 18, Train: label_loss: 0.09130814671516418, precision: 0.3177458033572951, recall: 0.892255892255742, f1: 0.4686118478834231\n",
            "epoch: 529, step: 19, Train: label_loss: 0.1040688157081604, precision: 0.31007281553396177, recall: 0.8646362098137285, f1: 0.4564537739673553\n",
            "epoch: 529, step: 20, Train: label_loss: 0.12792927026748657, precision: 0.2919799498746684, recall: 0.8076256499132048, f1: 0.42890013801893995\n",
            "epoch: 529, step: 21, Train: label_loss: 0.10311967879533768, precision: 0.29533050333533684, recall: 0.8573943661970321, f1: 0.4393324311751992\n",
            "epoch: 529, step: 22, Train: label_loss: 0.090274378657341, precision: 0.32361870066786136, recall: 0.8638573743920803, f1: 0.4708480564974098\n",
            "epoch: 529, step: 23, Train: label_loss: 0.09523028135299683, precision: 0.33801775147926494, recall: 0.865530303030139, f1: 0.486170212725511\n",
            "epoch: 530, step: 0, Train: label_loss: 0.09768831729888916, precision: 0.32788868723530984, recall: 0.8727858293074279, f1: 0.47669305185119704\n",
            "epoch: 530, step: 1, Train: label_loss: 0.09560553729534149, precision: 0.31878787878785947, recall: 0.8752079866887063, f1: 0.4673478453628605\n",
            "epoch: 530, step: 2, Train: label_loss: 0.10335791110992432, precision: 0.3143028846153657, recall: 0.8775167785233426, f1: 0.4628318583682046\n",
            "epoch: 530, step: 3, Train: label_loss: 0.09772444516420364, precision: 0.30315917375453805, recall: 0.8559176672382751, f1: 0.4477344100106807\n",
            "epoch: 530, step: 4, Train: label_loss: 0.10522498190402985, precision: 0.30445393532639997, recall: 0.8588640275385785, f1: 0.4495495495108653\n",
            "epoch: 530, step: 5, Train: label_loss: 0.08977833390235901, precision: 0.31862152357918266, recall: 0.8696369636962261, f1: 0.4663716813766396\n",
            "epoch: 530, step: 6, Train: label_loss: 0.09647426009178162, precision: 0.32552552552550595, recall: 0.8827361563516477, f1: 0.47564721365080703\n",
            "epoch: 530, step: 7, Train: label_loss: 0.10895294696092606, precision: 0.32785888077856884, recall: 0.8721682847895028, f1: 0.47656940756413496\n",
            "epoch: 530, step: 8, Train: label_loss: 0.09982968866825104, precision: 0.3095956547978087, recall: 0.8650927487350986, f1: 0.4559999999611406\n",
            "epoch: 530, step: 9, Train: label_loss: 0.10815033316612244, precision: 0.3099022004889786, recall: 0.8535353535352098, f1: 0.45470852014024826\n",
            "epoch: 530, step: 10, Train: label_loss: 0.0853191465139389, precision: 0.31313737252547613, recall: 0.8892674616693544, f1: 0.4631765749392553\n",
            "epoch: 530, step: 11, Train: label_loss: 0.09386281669139862, precision: 0.3135391923990313, recall: 0.9072164948452048, f1: 0.46601941743751235\n",
            "epoch: 530, step: 12, Train: label_loss: 0.10196591913700104, precision: 0.3132530120481739, recall: 0.8813559322032404, f1: 0.4622222221834888\n",
            "epoch: 530, step: 13, Train: label_loss: 0.09216247498989105, precision: 0.31705846895718404, recall: 0.8622950819670717, f1: 0.46364037016778564\n",
            "epoch: 530, step: 14, Train: label_loss: 0.09969909489154816, precision: 0.34725536992838024, recall: 0.9150943396224975, f1: 0.5034602075725304\n",
            "epoch: 530, step: 15, Train: label_loss: 0.10426683723926544, precision: 0.3325358851674442, recall: 0.8953301127212728, f1: 0.484954208420994\n",
            "epoch: 530, step: 16, Train: label_loss: 0.10637222230434418, precision: 0.31566118220595274, recall: 0.857615894039593, f1: 0.4614699331454824\n",
            "epoch: 530, step: 17, Train: label_loss: 0.10128087550401688, precision: 0.31702898550722725, recall: 0.8823529411763222, f1: 0.466459351360445\n",
            "epoch: 530, step: 18, Train: label_loss: 0.10255243629217148, precision: 0.3174893357708521, recall: 0.8845500848894933, f1: 0.46726457395211685\n",
            "epoch: 530, step: 19, Train: label_loss: 0.09837888181209564, precision: 0.32442067736183455, recall: 0.9024793388428259, f1: 0.47727272723378494\n",
            "epoch: 530, step: 20, Train: label_loss: 0.10184460878372192, precision: 0.3363363363363161, recall: 0.9003215434082154, f1: 0.4897245299122585\n",
            "epoch: 530, step: 21, Train: label_loss: 0.10605187714099884, precision: 0.30263965623079786, recall: 0.8370118845499427, f1: 0.4445446347670844\n",
            "epoch: 530, step: 22, Train: label_loss: 0.09734973311424255, precision: 0.3079231692676886, recall: 0.8906249999998453, f1: 0.45762711860584515\n",
            "epoch: 530, step: 23, Train: label_loss: 0.09491027146577835, precision: 0.3269654665686755, recall: 0.8794466403160317, f1: 0.47670058914093855\n",
            "epoch: 531, step: 0, Train: label_loss: 0.10199311375617981, precision: 0.31345100426048, recall: 0.8758503401359053, f1: 0.461676378266832\n",
            "epoch: 531, step: 1, Train: label_loss: 0.09115498512983322, precision: 0.31799163179914414, recall: 0.8851913477535964, f1: 0.46789797709387604\n",
            "epoch: 531, step: 2, Train: label_loss: 0.09611710906028748, precision: 0.30759878419451014, recall: 0.8679245283017378, f1: 0.45421903048196577\n",
            "epoch: 531, step: 3, Train: label_loss: 0.09277383983135223, precision: 0.32587666263601417, recall: 0.880718954248222, f1: 0.47572815530033646\n",
            "epoch: 531, step: 4, Train: label_loss: 0.0927029401063919, precision: 0.3086124401913691, recall: 0.8835616438354651, f1: 0.45744680847222685\n",
            "epoch: 531, step: 5, Train: label_loss: 0.09036038815975189, precision: 0.293908929627422, recall: 0.8971119133572387, f1: 0.4427616926131196\n",
            "epoch: 531, step: 6, Train: label_loss: 0.09891468286514282, precision: 0.3141297756215698, recall: 0.8749999999998521, f1: 0.4622936188812071\n",
            "epoch: 531, step: 7, Train: label_loss: 0.11536180973052979, precision: 0.3333333333333128, recall: 0.8426791277257254, f1: 0.47770419421982274\n",
            "epoch: 531, step: 8, Train: label_loss: 0.10294869542121887, precision: 0.2942598187311, recall: 0.8499127399649475, f1: 0.4371633751861694\n",
            "epoch: 531, step: 9, Train: label_loss: 0.08536259829998016, precision: 0.3317450863609094, recall: 0.8954983922828141, f1: 0.48413733155546756\n",
            "epoch: 531, step: 10, Train: label_loss: 0.09832347929477692, precision: 0.30445246690732225, recall: 0.8987566607458438, f1: 0.4548314606363149\n",
            "epoch: 531, step: 11, Train: label_loss: 0.09126970916986465, precision: 0.3104265402843418, recall: 0.9097222222220642, f1: 0.4628975264637881\n",
            "epoch: 531, step: 12, Train: label_loss: 0.09025593101978302, precision: 0.3476446034585362, recall: 0.9123630672925019, f1: 0.5034542313935061\n",
            "epoch: 531, step: 13, Train: label_loss: 0.09038609266281128, precision: 0.32271634615382677, recall: 0.8675282714053525, f1: 0.47043363990787224\n",
            "epoch: 531, step: 14, Train: label_loss: 0.09653481096029282, precision: 0.31900726392249884, recall: 0.8739635157544156, f1: 0.4674057649275191\n",
            "epoch: 531, step: 15, Train: label_loss: 0.10223399102687836, precision: 0.3288834951456111, recall: 0.8562401263821712, f1: 0.47523016216941594\n",
            "epoch: 531, step: 16, Train: label_loss: 0.09554993361234665, precision: 0.3038204972710549, recall: 0.8578767123286202, f1: 0.4487236900643336\n",
            "epoch: 531, step: 17, Train: label_loss: 0.08488579094409943, precision: 0.32121573301547546, recall: 0.9089376053961367, f1: 0.4746807573369765\n",
            "epoch: 531, step: 18, Train: label_loss: 0.09723133593797684, precision: 0.3349397590361244, recall: 0.8811410459586558, f1: 0.4853775643424101\n",
            "epoch: 531, step: 19, Train: label_loss: 0.09221037477254868, precision: 0.31663685152055354, recall: 0.9015280135821898, f1: 0.46866725503650736\n",
            "epoch: 531, step: 20, Train: label_loss: 0.0960213840007782, precision: 0.32539682539680553, recall: 0.8555377207061227, f1: 0.47147279960620886\n",
            "epoch: 531, step: 21, Train: label_loss: 0.09237851947546005, precision: 0.32248342374922706, recall: 0.891666666666518, f1: 0.47366091186887016\n",
            "epoch: 531, step: 22, Train: label_loss: 0.08983868360519409, precision: 0.32819905213268197, recall: 0.9233333333331794, f1: 0.4842657342269981\n",
            "epoch: 531, step: 23, Train: label_loss: 0.09271907806396484, precision: 0.33698830409354263, recall: 0.8951456310677873, f1: 0.4896441847716796\n",
            "epoch: 532, step: 0, Train: label_loss: 0.08647763729095459, precision: 0.3219013237063585, recall: 0.8842975206610107, f1: 0.4719894132823984\n",
            "epoch: 532, step: 1, Train: label_loss: 0.08692535758018494, precision: 0.31600955794502295, recall: 0.9027303754264671, f1: 0.4681415928819006\n",
            "epoch: 532, step: 2, Train: label_loss: 0.08987625688314438, precision: 0.3343355381839847, recall: 0.8881789137378773, f1: 0.4858016600738063\n",
            "epoch: 532, step: 3, Train: label_loss: 0.09964598715305328, precision: 0.30943847072877484, recall: 0.8885077186962455, f1: 0.4590163934042653\n",
            "epoch: 532, step: 4, Train: label_loss: 0.08577463030815125, precision: 0.3517972893340983, recall: 0.9086757990866197, f1: 0.5072217501721207\n",
            "epoch: 532, step: 5, Train: label_loss: 0.08427617698907852, precision: 0.326458456098979, recall: 0.9008130081299348, f1: 0.47923875428616897\n",
            "epoch: 532, step: 6, Train: label_loss: 0.08618862181901932, precision: 0.319569120287234, recall: 0.9005059021920909, f1: 0.47173144872454503\n",
            "epoch: 532, step: 7, Train: label_loss: 0.09001782536506653, precision: 0.3082394783639414, recall: 0.9219858156026733, f1: 0.4620168813484541\n",
            "epoch: 532, step: 8, Train: label_loss: 0.08929996192455292, precision: 0.31964285714283813, recall: 0.8905472636814443, f1: 0.4704336399085236\n",
            "epoch: 532, step: 9, Train: label_loss: 0.08402840793132782, precision: 0.3195195195195003, recall: 0.8881469115190503, f1: 0.46996466427199735\n",
            "epoch: 532, step: 10, Train: label_loss: 0.07644040137529373, precision: 0.31591309453903016, recall: 0.9087837837836302, f1: 0.46884531586581596\n",
            "epoch: 532, step: 11, Train: label_loss: 0.09127567708492279, precision: 0.3349140486069748, recall: 0.9142394822004992, f1: 0.49023861167437766\n",
            "epoch: 532, step: 12, Train: label_loss: 0.09809240698814392, precision: 0.3022142429682644, recall: 0.8844133099823319, f1: 0.45049063332506456\n",
            "epoch: 532, step: 13, Train: label_loss: 0.093645840883255, precision: 0.32055122828038823, recall: 0.891666666666518, f1: 0.47157338030482043\n",
            "epoch: 532, step: 14, Train: label_loss: 0.08627263456583023, precision: 0.33806986382472837, recall: 0.9121405750797265, f1: 0.49330453559764864\n",
            "epoch: 532, step: 15, Train: label_loss: 0.0821877121925354, precision: 0.3303624480094872, recall: 0.902597402597256, f1: 0.4836885602043122\n",
            "epoch: 532, step: 16, Train: label_loss: 0.1040726900100708, precision: 0.309178743961334, recall: 0.8634064080942894, f1: 0.4553134726156427\n",
            "epoch: 532, step: 17, Train: label_loss: 0.09077783674001694, precision: 0.3045023696682284, recall: 0.901754385964754, f1: 0.455270150537948\n",
            "epoch: 532, step: 18, Train: label_loss: 0.08439677953720093, precision: 0.2967625899280398, recall: 0.8776595744679294, f1: 0.44354838705896715\n",
            "epoch: 532, step: 19, Train: label_loss: 0.10228776931762695, precision: 0.3157255616271818, recall: 0.8813559322032404, f1: 0.46490835937104563\n",
            "epoch: 532, step: 20, Train: label_loss: 0.09397299587726593, precision: 0.3449101796406979, recall: 0.8916408668729269, f1: 0.4974093263846019\n",
            "epoch: 532, step: 21, Train: label_loss: 0.08592745661735535, precision: 0.3229850746268464, recall: 0.8942148760329099, f1: 0.47456140346974235\n",
            "epoch: 532, step: 22, Train: label_loss: 0.08740346133708954, precision: 0.32956573468171746, recall: 0.9067103109654816, f1: 0.48342059332909215\n",
            "epoch: 532, step: 23, Train: label_loss: 0.08525995910167694, precision: 0.31746031746029457, recall: 0.9053497942384968, f1: 0.47008547004697676\n",
            "epoch: 533, step: 0, Train: label_loss: 0.09506912529468536, precision: 0.32539682539680553, recall: 0.8555377207061227, f1: 0.47147279960620886\n",
            "epoch: 533, step: 1, Train: label_loss: 0.08979911357164383, precision: 0.3207434052757601, recall: 0.900673400673249, f1: 0.47303271437325467\n",
            "epoch: 533, step: 2, Train: label_loss: 0.09148816019296646, precision: 0.3231046931407748, recall: 0.8935108153076715, f1: 0.4745912505133131\n",
            "epoch: 533, step: 3, Train: label_loss: 0.08775846660137177, precision: 0.3115246098439189, recall: 0.8841567291310248, f1: 0.4607190412397228\n",
            "epoch: 533, step: 4, Train: label_loss: 0.0838322788476944, precision: 0.3170011806375255, recall: 0.9210977701542159, f1: 0.47167325424381185\n",
            "epoch: 533, step: 5, Train: label_loss: 0.09050939977169037, precision: 0.3196374622356302, recall: 0.8700657894735411, f1: 0.4675209897971616\n",
            "epoch: 533, step: 6, Train: label_loss: 0.08650049567222595, precision: 0.3386430678465877, recall: 0.9154704944177168, f1: 0.4944013780828434\n",
            "epoch: 533, step: 7, Train: label_loss: 0.08064277470111847, precision: 0.33195266272187385, recall: 0.9077669902911152, f1: 0.48613518193648114\n",
            "epoch: 533, step: 8, Train: label_loss: 0.09110077470541, precision: 0.31125827814567664, recall: 0.8645484949831329, f1: 0.4577246568888751\n",
            "epoch: 533, step: 9, Train: label_loss: 0.0867217630147934, precision: 0.32305868405451554, recall: 0.9098497495824858, f1: 0.47681539803652484\n",
            "epoch: 533, step: 10, Train: label_loss: 0.08355812728404999, precision: 0.33897280966765325, recall: 0.8834645669289947, f1: 0.48995633183760623\n",
            "epoch: 533, step: 11, Train: label_loss: 0.08714279532432556, precision: 0.31294536817100277, recall: 0.8932203389828994, f1: 0.4635004397152695\n",
            "epoch: 533, step: 12, Train: label_loss: 0.08060155808925629, precision: 0.313325330132034, recall: 0.8832487309643174, f1: 0.4625609215386169\n",
            "epoch: 533, step: 13, Train: label_loss: 0.07573886960744858, precision: 0.33787788974508964, recall: 0.9328968903435461, f1: 0.4960835508747571\n",
            "epoch: 533, step: 14, Train: label_loss: 0.08265113830566406, precision: 0.32517899761334573, recall: 0.9098497495824858, f1: 0.47912087908204265\n",
            "epoch: 533, step: 15, Train: label_loss: 0.09004653990268707, precision: 0.30481283422458083, recall: 0.8937282229963599, f1: 0.45458573323628937\n",
            "epoch: 533, step: 16, Train: label_loss: 0.08890292048454285, precision: 0.3132166566083094, recall: 0.8708053691273706, f1: 0.4607190412393434\n",
            "epoch: 533, step: 17, Train: label_loss: 0.08091939985752106, precision: 0.33530106257377007, recall: 0.9073482428113566, f1: 0.4896551723743468\n",
            "epoch: 533, step: 18, Train: label_loss: 0.09793008118867874, precision: 0.29696969696967895, recall: 0.8361774744025876, f1: 0.4382826475462556\n",
            "epoch: 533, step: 19, Train: label_loss: 0.10172846168279648, precision: 0.31433713257346646, recall: 0.8941979522182774, f1: 0.4651575676489971\n",
            "epoch: 533, step: 20, Train: label_loss: 0.09952279925346375, precision: 0.30778515389255834, recall: 0.8688245315160359, f1: 0.45454545450678213\n",
            "epoch: 533, step: 21, Train: label_loss: 0.09624828398227692, precision: 0.32633473305336974, recall: 0.8831168831167396, f1: 0.4765659219929682\n",
            "epoch: 533, step: 22, Train: label_loss: 0.09324291348457336, precision: 0.32048192771082407, recall: 0.8764415156505969, f1: 0.4693427436749059\n",
            "epoch: 533, step: 23, Train: label_loss: 0.12197139114141464, precision: 0.30513595166160834, recall: 0.8469601677147072, f1: 0.44863964460287464\n",
            "epoch: 534, step: 0, Train: label_loss: 0.08373972773551941, precision: 0.313549160671444, recall: 0.8909710391821309, f1: 0.4638580930878348\n",
            "epoch: 534, step: 1, Train: label_loss: 0.09350323677062988, precision: 0.31997571341831693, recall: 0.881270903009886, f1: 0.46948775051766756\n",
            "epoch: 534, step: 2, Train: label_loss: 0.08118525892496109, precision: 0.3236686390532353, recall: 0.9086378737540018, f1: 0.47731239088618155\n",
            "epoch: 534, step: 3, Train: label_loss: 0.08701598644256592, precision: 0.3196374622356302, recall: 0.8758278145693914, f1: 0.4683488268753454\n",
            "epoch: 534, step: 4, Train: label_loss: 0.08274859189987183, precision: 0.31679617453674136, recall: 0.904436860068105, f1: 0.4692341743749927\n",
            "epoch: 534, step: 5, Train: label_loss: 0.09131766110658646, precision: 0.327947336923978, recall: 0.886731391585617, f1: 0.4788117081300457\n",
            "epoch: 534, step: 6, Train: label_loss: 0.08669012784957886, precision: 0.3073229291716502, recall: 0.8888888888887345, f1: 0.45673505794572034\n",
            "epoch: 534, step: 7, Train: label_loss: 0.09262070059776306, precision: 0.3201675643327157, recall: 0.8976510067112587, f1: 0.4719894132827717\n",
            "epoch: 534, step: 8, Train: label_loss: 0.08008426427841187, precision: 0.3251935675997424, recall: 0.8863636363634924, f1: 0.4758169934247376\n",
            "epoch: 534, step: 9, Train: label_loss: 0.0908152312040329, precision: 0.3094089264173517, recall: 0.8535773710481108, f1: 0.4541832668931775\n",
            "epoch: 534, step: 10, Train: label_loss: 0.09195984899997711, precision: 0.310427968655798, recall: 0.8910034602074582, f1: 0.46043808668492475\n",
            "epoch: 534, step: 11, Train: label_loss: 0.09746526181697845, precision: 0.30095923261389085, recall: 0.8900709219856577, f1: 0.44982078849265833\n",
            "epoch: 534, step: 12, Train: label_loss: 0.09394451975822449, precision: 0.3198090692123914, recall: 0.8993288590602517, f1: 0.4718309858767494\n",
            "epoch: 534, step: 13, Train: label_loss: 0.09294523298740387, precision: 0.332931968693538, recall: 0.8833865814695074, f1: 0.4836029732877013\n",
            "epoch: 534, step: 14, Train: label_loss: 0.08879043161869049, precision: 0.3143712574850111, recall: 0.8853288364248085, f1: 0.4639858594398521\n",
            "epoch: 534, step: 15, Train: label_loss: 0.09279860556125641, precision: 0.3311138014527645, recall: 0.8682539682538304, f1: 0.4794040315112573\n",
            "epoch: 534, step: 16, Train: label_loss: 0.09969982504844666, precision: 0.29868578255673245, recall: 0.8833922261482537, f1: 0.4464285713907651\n",
            "epoch: 534, step: 17, Train: label_loss: 0.09568800032138824, precision: 0.33070388349512553, recall: 0.8833063209074743, f1: 0.481236203050825\n",
            "epoch: 534, step: 18, Train: label_loss: 0.10007530450820923, precision: 0.3333333333333131, recall: 0.8814102564101151, f1: 0.4837291116575853\n",
            "epoch: 534, step: 19, Train: label_loss: 0.08465401828289032, precision: 0.3244523386619109, recall: 0.904290429042755, f1: 0.4775599128151231\n",
            "epoch: 534, step: 20, Train: label_loss: 0.10070586204528809, precision: 0.3419782870928624, recall: 0.8831775700933203, f1: 0.4930434782205834\n",
            "epoch: 534, step: 21, Train: label_loss: 0.10241024941205978, precision: 0.3130277442701862, recall: 0.8811544991509539, f1: 0.46194926564885896\n",
            "epoch: 534, step: 22, Train: label_loss: 0.08588680624961853, precision: 0.3241954707985504, recall: 0.8962108731464751, f1: 0.47614879645984864\n",
            "epoch: 534, step: 23, Train: label_loss: 0.08660303056240082, precision: 0.3241877256317455, recall: 0.9034205231386513, f1: 0.4771519659547047\n",
            "epoch: 535, step: 0, Train: label_loss: 0.08798761665821075, precision: 0.3367531683765639, recall: 0.8815165876775858, f1: 0.4873362445014398\n",
            "epoch: 535, step: 1, Train: label_loss: 0.09640396386384964, precision: 0.33131801692863777, recall: 0.8968903436987075, f1: 0.4838852096735839\n",
            "epoch: 535, step: 2, Train: label_loss: 0.09016210585832596, precision: 0.31323877068556066, recall: 0.9217391304346222, f1: 0.46757829727131667\n",
            "epoch: 535, step: 3, Train: label_loss: 0.08663535863161087, precision: 0.3432480666269873, recall: 0.8987538940808568, f1: 0.4967714162320216\n",
            "epoch: 535, step: 4, Train: label_loss: 0.09772666543722153, precision: 0.32134292565945316, recall: 0.8772504091651592, f1: 0.4703817463407055\n",
            "epoch: 535, step: 5, Train: label_loss: 0.0868186429142952, precision: 0.3070017953321181, recall: 0.8906249999998453, f1: 0.45660881171083184\n",
            "epoch: 535, step: 6, Train: label_loss: 0.09093614667654037, precision: 0.3273809523809329, recall: 0.9090909090907587, f1: 0.48140043759778595\n",
            "epoch: 535, step: 7, Train: label_loss: 0.10588648915290833, precision: 0.31310679611648584, recall: 0.8850771869638275, f1: 0.4625728372540462\n",
            "epoch: 535, step: 8, Train: label_loss: 0.07601405680179596, precision: 0.3130537507383158, recall: 0.9169550173008794, f1: 0.4667547335595458\n",
            "epoch: 535, step: 9, Train: label_loss: 0.08383641391992569, precision: 0.31445783132528227, recall: 0.8685524126454461, f1: 0.46174259173447946\n",
            "epoch: 535, step: 10, Train: label_loss: 0.08281190693378448, precision: 0.3025458851391177, recall: 0.898066783831125, f1: 0.45261293176031275\n",
            "epoch: 535, step: 11, Train: label_loss: 0.08889017254114151, precision: 0.323232323232304, recall: 0.90066225165548, f1: 0.47573240048579274\n",
            "epoch: 535, step: 12, Train: label_loss: 0.08201192319393158, precision: 0.33748517200472494, recall: 0.9147909967844188, f1: 0.4930675909484518\n",
            "epoch: 535, step: 13, Train: label_loss: 0.10064573585987091, precision: 0.3247298919567632, recall: 0.8883415435138113, f1: 0.4756043955651471\n",
            "epoch: 535, step: 14, Train: label_loss: 0.08372234553098679, precision: 0.33173365326932625, recall: 0.8933764135701302, f1: 0.483814523145068\n",
            "epoch: 535, step: 15, Train: label_loss: 0.09138963371515274, precision: 0.31705846895718404, recall: 0.8694214876031621, f1: 0.4646643109148593\n",
            "epoch: 535, step: 16, Train: label_loss: 0.08814406394958496, precision: 0.3235995232419354, recall: 0.8960396039602481, f1: 0.47548161116937926\n",
            "epoch: 535, step: 17, Train: label_loss: 0.09894447773694992, precision: 0.30927835051544517, recall: 0.8703071672353463, f1: 0.45637583888744415\n",
            "epoch: 535, step: 18, Train: label_loss: 0.08732113242149353, precision: 0.3219013237063585, recall: 0.8784893267650445, f1: 0.4711580801016152\n",
            "epoch: 535, step: 19, Train: label_loss: 0.09002363681793213, precision: 0.32640949554894205, recall: 0.8986928104573695, f1: 0.47888550279064684\n",
            "epoch: 535, step: 20, Train: label_loss: 0.0957319438457489, precision: 0.30550514216574076, recall: 0.8647260273971121, f1: 0.45149754131140013\n",
            "epoch: 535, step: 21, Train: label_loss: 0.10253638029098511, precision: 0.31502715751355975, recall: 0.8758389261743497, f1: 0.4633821570848824\n",
            "epoch: 535, step: 22, Train: label_loss: 0.08657129853963852, precision: 0.31918708906154697, recall: 0.9020270270268745, f1: 0.47152317876929434\n",
            "epoch: 535, step: 23, Train: label_loss: 0.10270138084888458, precision: 0.3193524650478058, recall: 0.8839103869651967, f1: 0.4691891891501454\n",
            "epoch: 536, step: 0, Train: label_loss: 0.0898042768239975, precision: 0.33114166168557496, recall: 0.9008130081299348, f1: 0.4842657342263832\n",
            "epoch: 536, step: 1, Train: label_loss: 0.09586354345083237, precision: 0.31497005988022064, recall: 0.8810720268005223, f1: 0.46404940446049864\n",
            "epoch: 536, step: 2, Train: label_loss: 0.07647991925477982, precision: 0.3240685984624291, recall: 0.9118136439266369, f1: 0.47818499123526303\n",
            "epoch: 536, step: 3, Train: label_loss: 0.09333580732345581, precision: 0.31283905967448383, recall: 0.8917525773194344, f1: 0.4631860776054158\n",
            "epoch: 536, step: 4, Train: label_loss: 0.0844106674194336, precision: 0.33748517200472494, recall: 0.9060509554138684, f1: 0.4917891097270478\n",
            "epoch: 536, step: 5, Train: label_loss: 0.08122841268777847, precision: 0.33175355450235, recall: 0.8988764044942377, f1: 0.48463868451271863\n",
            "epoch: 536, step: 6, Train: label_loss: 0.0852700024843216, precision: 0.2935560859188369, recall: 0.8864864864863267, f1: 0.44105782156724566\n",
            "epoch: 536, step: 7, Train: label_loss: 0.08910930156707764, precision: 0.3228111971411362, recall: 0.8929159802304953, f1: 0.47419072612018387\n",
            "epoch: 536, step: 8, Train: label_loss: 0.10005898773670197, precision: 0.29819277108431935, recall: 0.8839285714284135, f1: 0.4459459459081816\n",
            "epoch: 536, step: 9, Train: label_loss: 0.0903143584728241, precision: 0.32236842105261226, recall: 0.8778501628663065, f1: 0.47156605420388825\n",
            "epoch: 536, step: 10, Train: label_loss: 0.08880004286766052, precision: 0.3194029850746078, recall: 0.8842975206610107, f1: 0.469298245575006\n",
            "epoch: 536, step: 11, Train: label_loss: 0.08769378066062927, precision: 0.31966726084371244, recall: 0.9165247018737791, f1: 0.47400881053430116\n",
            "epoch: 536, step: 12, Train: label_loss: 0.0930313766002655, precision: 0.3171619163128977, recall: 0.8601973684209111, f1: 0.4634470535715837\n",
            "epoch: 536, step: 13, Train: label_loss: 0.08048155903816223, precision: 0.3449729078867944, recall: 0.8939157566301257, f1: 0.4978279756331008\n",
            "epoch: 536, step: 14, Train: label_loss: 0.08432698249816895, precision: 0.3197640117993912, recall: 0.9186440677964544, f1: 0.4743982494146054\n",
            "epoch: 536, step: 15, Train: label_loss: 0.09069893509149551, precision: 0.2983822648292212, recall: 0.8814159292033837, f1: 0.4458370635252863\n",
            "epoch: 536, step: 16, Train: label_loss: 0.09331464767456055, precision: 0.33731343283580073, recall: 0.8869701726843191, f1: 0.4887543252195516\n",
            "epoch: 536, step: 17, Train: label_loss: 0.08765465766191483, precision: 0.33293627159021244, recall: 0.9133986928103082, f1: 0.48799650803587924\n",
            "epoch: 536, step: 18, Train: label_loss: 0.09358320385217667, precision: 0.3115246098439189, recall: 0.8722689075628786, f1: 0.4590888986785599\n",
            "epoch: 536, step: 19, Train: label_loss: 0.10121194273233414, precision: 0.3109243697478805, recall: 0.8676716917921494, f1: 0.45779938131330417\n",
            "epoch: 536, step: 20, Train: label_loss: 0.09419810771942139, precision: 0.31815493790654537, recall: 0.9011725293130818, f1: 0.47027972024111037\n",
            "epoch: 536, step: 21, Train: label_loss: 0.07938016206026077, precision: 0.3408685306365056, recall: 0.9023622047242673, f1: 0.4948186528098972\n",
            "epoch: 536, step: 22, Train: label_loss: 0.09121016412973404, precision: 0.3120143454871302, recall: 0.9015544041449219, f1: 0.46358792180900527\n",
            "epoch: 536, step: 23, Train: label_loss: 0.09085795283317566, precision: 0.3157509157508926, recall: 0.8813905930468545, f1: 0.46494066878527623\n",
            "epoch: 537, step: 0, Train: label_loss: 0.10844320058822632, precision: 0.31144578313251137, recall: 0.861666666666523, f1: 0.4575221238547641\n",
            "epoch: 537, step: 1, Train: label_loss: 0.10395239293575287, precision: 0.3284760170005872, recall: 0.8854337152208043, f1: 0.47918511953532805\n",
            "epoch: 537, step: 2, Train: label_loss: 0.08733226358890533, precision: 0.32788868723530984, recall: 0.8973509933773348, f1: 0.4802835622115336\n",
            "epoch: 537, step: 3, Train: label_loss: 0.10567128658294678, precision: 0.3143915997529145, recall: 0.8554621848738058, f1: 0.45980126463996773\n",
            "epoch: 537, step: 4, Train: label_loss: 0.10520364344120026, precision: 0.32457212713934447, recall: 0.8606158833061813, f1: 0.4713715046206389\n",
            "epoch: 537, step: 5, Train: label_loss: 0.13178454339504242, precision: 0.3095838587641671, recall: 0.8169717138101802, f1: 0.44901691811282207\n",
            "epoch: 537, step: 6, Train: label_loss: 0.09656499326229095, precision: 0.3222087378640581, recall: 0.8676470588233876, f1: 0.469911504385244\n",
            "epoch: 537, step: 7, Train: label_loss: 0.10869618505239487, precision: 0.322796352583567, recall: 0.8550724637679782, f1: 0.4686672550351913\n",
            "epoch: 537, step: 8, Train: label_loss: 0.09942444413900375, precision: 0.31341463414632237, recall: 0.8566666666665238, f1: 0.45892857138930854\n",
            "epoch: 537, step: 9, Train: label_loss: 0.11670811474323273, precision: 0.2844720496894233, recall: 0.8134991119003883, f1: 0.42153704552070365\n",
            "epoch: 537, step: 10, Train: label_loss: 0.12240809202194214, precision: 0.32405689548544686, recall: 0.8330683624799947, f1: 0.4666073018296248\n",
            "epoch: 537, step: 11, Train: label_loss: 0.09625103324651718, precision: 0.33534378769599904, recall: 0.8660436137070302, f1: 0.48347826082927975\n",
            "epoch: 537, step: 12, Train: label_loss: 0.11481942981481552, precision: 0.3168927250308066, recall: 0.8371335504884629, f1: 0.45974955273292867\n",
            "epoch: 537, step: 13, Train: label_loss: 0.11121866852045059, precision: 0.28927680798003186, recall: 0.799999999999862, f1: 0.42490842486937763\n",
            "epoch: 537, step: 14, Train: label_loss: 0.10314566642045975, precision: 0.2929475587703259, recall: 0.8756756756755179, f1: 0.43902439020629513\n",
            "epoch: 537, step: 15, Train: label_loss: 0.11898599565029144, precision: 0.30178242163489233, recall: 0.8629173989453667, f1: 0.447176684843168\n",
            "epoch: 537, step: 16, Train: label_loss: 0.11403685063123703, precision: 0.31916204559455824, recall: 0.8604651162789267, f1: 0.4656179774885763\n",
            "epoch: 537, step: 17, Train: label_loss: 0.11588307470083237, precision: 0.3185185185184988, recall: 0.8514851485147109, f1: 0.46361185979860847\n",
            "epoch: 537, step: 18, Train: label_loss: 0.1103660836815834, precision: 0.32340425531912925, recall: 0.85668276972611, f1: 0.46954986756828915\n",
            "epoch: 537, step: 19, Train: label_loss: 0.10001598298549652, precision: 0.31459987782527093, recall: 0.8401305057094877, f1: 0.4577777777380933\n",
            "epoch: 537, step: 20, Train: label_loss: 0.10398978739976883, precision: 0.3194103194102998, recall: 0.8566721581547188, f1: 0.46532438474786475\n",
            "epoch: 537, step: 21, Train: label_loss: 0.11485064774751663, precision: 0.3043209876543022, recall: 0.8470790378005417, f1: 0.447774750188136\n",
            "epoch: 537, step: 22, Train: label_loss: 0.10837624967098236, precision: 0.3251982916412248, recall: 0.8666666666665257, f1: 0.47293700084758905\n",
            "epoch: 537, step: 23, Train: label_loss: 0.11389768868684769, precision: 0.30128690386068874, recall: 0.8652173913041598, f1: 0.4469399213541114\n",
            "epoch: 538, step: 0, Train: label_loss: 0.1006193608045578, precision: 0.31901840490795585, recall: 0.8566721581547188, f1: 0.464908359370339\n",
            "epoch: 538, step: 1, Train: label_loss: 0.10614614188671112, precision: 0.3128457283343385, recall: 0.8483333333331918, f1: 0.4571171979848402\n",
            "epoch: 538, step: 2, Train: label_loss: 0.1109112799167633, precision: 0.31131498470946106, recall: 0.8686006825937084, f1: 0.45835209361262086\n",
            "epoch: 538, step: 3, Train: label_loss: 0.1020234227180481, precision: 0.30978260869563345, recall: 0.868020304568381, f1: 0.4566088117101902\n",
            "epoch: 538, step: 4, Train: label_loss: 0.10174021124839783, precision: 0.3125378558449235, recall: 0.8745762711862923, f1: 0.4605087014337235\n",
            "epoch: 538, step: 5, Train: label_loss: 0.0920155793428421, precision: 0.2924471299093479, recall: 0.8627450980390619, f1: 0.4368231046552875\n",
            "epoch: 538, step: 6, Train: label_loss: 0.10992071032524109, precision: 0.32829504232162465, recall: 0.8960396039602481, f1: 0.4805309734120366\n",
            "epoch: 538, step: 7, Train: label_loss: 0.10396634042263031, precision: 0.3465943339360852, recall: 0.8846153846152485, f1: 0.4980511043336926\n",
            "epoch: 538, step: 8, Train: label_loss: 0.10178491473197937, precision: 0.3232445520580918, recall: 0.8914858096826558, f1: 0.47445579738426674\n",
            "epoch: 538, step: 9, Train: label_loss: 0.1205565482378006, precision: 0.3161810291382321, recall: 0.8374384236451826, f1: 0.4590459045506259\n",
            "epoch: 538, step: 10, Train: label_loss: 0.09155362844467163, precision: 0.3075539568345139, recall: 0.8860103626941475, f1: 0.45660881171070206\n",
            "epoch: 538, step: 11, Train: label_loss: 0.11662815511226654, precision: 0.32316313823161125, recall: 0.8251192368838115, f1: 0.46442953016085514\n",
            "epoch: 538, step: 12, Train: label_loss: 0.09404788911342621, precision: 0.33373639661424825, recall: 0.8846153846152428, f1: 0.4846356452630768\n",
            "epoch: 538, step: 13, Train: label_loss: 0.09530225396156311, precision: 0.3183747725894288, recall: 0.8853288364248085, f1: 0.46833184652661713\n",
            "epoch: 538, step: 14, Train: label_loss: 0.08563912659883499, precision: 0.3078773301262593, recall: 0.8873483535527058, f1: 0.45714285710456887\n",
            "epoch: 538, step: 15, Train: label_loss: 0.11148840188980103, precision: 0.32541133455208254, recall: 0.87684729064025, f1: 0.4746666666271432\n",
            "epoch: 538, step: 16, Train: label_loss: 0.11165347695350647, precision: 0.31871525633104886, recall: 0.839024390243766, f1: 0.46195165618208067\n",
            "epoch: 538, step: 17, Train: label_loss: 0.09884868562221527, precision: 0.3140947752126176, recall: 0.8517298187807493, f1: 0.45894363067519556\n",
            "epoch: 538, step: 18, Train: label_loss: 0.1109386682510376, precision: 0.30445393532639997, recall: 0.8457627118642633, f1: 0.4477344100103833\n",
            "epoch: 538, step: 19, Train: label_loss: 0.08928699791431427, precision: 0.30875299760189995, recall: 0.8699324324322855, f1: 0.4557522123506741\n",
            "epoch: 538, step: 20, Train: label_loss: 0.11724841594696045, precision: 0.31776275353409233, recall: 0.861666666666523, f1: 0.4643017511954367\n",
            "epoch: 538, step: 21, Train: label_loss: 0.09861695021390915, precision: 0.31547260686331635, recall: 0.8646864686467219, f1: 0.46228495805518566\n",
            "epoch: 538, step: 22, Train: label_loss: 0.12436816841363907, precision: 0.3078802687843428, recall: 0.8513513513512074, f1: 0.45222072674426\n",
            "epoch: 538, step: 23, Train: label_loss: 0.11138554662466049, precision: 0.3218562874251256, recall: 0.84812623274145, f1: 0.4666304937202394\n",
            "epoch: 539, step: 0, Train: label_loss: 0.12645292282104492, precision: 0.30451127819546964, recall: 0.8237288135591824, f1: 0.4446477584234946\n",
            "epoch: 539, step: 1, Train: label_loss: 0.10085099935531616, precision: 0.31771150334751563, recall: 0.8758389261743497, f1: 0.4662795890631695\n",
            "epoch: 539, step: 2, Train: label_loss: 0.08914615213871002, precision: 0.32252252252250313, recall: 0.9025210084032096, f1: 0.47522123889921886\n",
            "epoch: 539, step: 3, Train: label_loss: 0.10756940394639969, precision: 0.296809151113769, recall: 0.8850987432673455, f1: 0.44454463476847905\n",
            "epoch: 539, step: 4, Train: label_loss: 0.10169325023889542, precision: 0.31466828971391875, recall: 0.8631051752920095, f1: 0.4611953612453679\n",
            "epoch: 539, step: 5, Train: label_loss: 0.10553077608346939, precision: 0.31038721573446154, recall: 0.8458961474035434, f1: 0.4541366906081656\n",
            "epoch: 539, step: 6, Train: label_loss: 0.08985787630081177, precision: 0.338700059630272, recall: 0.9087999999998545, f1: 0.4934839269803819\n",
            "epoch: 539, step: 7, Train: label_loss: 0.1006283164024353, precision: 0.3275135460565727, recall: 0.873194221508688, f1: 0.47635726791124844\n",
            "epoch: 539, step: 8, Train: label_loss: 0.09850165247917175, precision: 0.3184019370459856, recall: 0.8622950819670717, f1: 0.46507515469089616\n",
            "epoch: 539, step: 9, Train: label_loss: 0.10996697843074799, precision: 0.32766990291260145, recall: 0.8557844690965363, f1: 0.4738920578800557\n",
            "epoch: 539, step: 10, Train: label_loss: 0.10322311520576477, precision: 0.3240121580546915, recall: 0.8809917355370444, f1: 0.47377777773841817\n",
            "epoch: 539, step: 11, Train: label_loss: 0.10528398305177689, precision: 0.3153753026634192, recall: 0.8712374581938341, f1: 0.46311111107204195\n",
            "epoch: 539, step: 12, Train: label_loss: 0.10455891489982605, precision: 0.31208257437763737, recall: 0.8653198653197196, f1: 0.4587237839859871\n",
            "epoch: 539, step: 13, Train: label_loss: 0.09541849792003632, precision: 0.29400977995108224, recall: 0.8528368794324729, f1: 0.4372727272345592\n",
            "epoch: 539, step: 14, Train: label_loss: 0.09242608398199081, precision: 0.33472803347278335, recall: 0.9017713365537999, f1: 0.488230165609993\n",
            "epoch: 539, step: 15, Train: label_loss: 0.09705723822116852, precision: 0.3087613293051173, recall: 0.8705281090288125, f1: 0.4558429972851233\n",
            "epoch: 539, step: 16, Train: label_loss: 0.10964380949735641, precision: 0.33493109646492897, recall: 0.891547049441644, f1: 0.4869337978696634\n",
            "epoch: 539, step: 17, Train: label_loss: 0.10171006619930267, precision: 0.30303030303028466, recall: 0.8561643835614972, f1: 0.44762757381989415\n",
            "epoch: 539, step: 18, Train: label_loss: 0.08052487671375275, precision: 0.33824395992926704, recall: 0.9154704944177168, f1: 0.4939759035750143\n",
            "epoch: 539, step: 19, Train: label_loss: 0.09591129422187805, precision: 0.303690260133073, recall: 0.8791593695269914, f1: 0.45143884888265734\n",
            "epoch: 539, step: 20, Train: label_loss: 0.0922653079032898, precision: 0.33840749414517923, recall: 0.9218500797446695, f1: 0.4950749464274834\n",
            "epoch: 539, step: 21, Train: label_loss: 0.09455829858779907, precision: 0.3237063778579829, recall: 0.8907284768210445, f1: 0.4748455427675658\n",
            "epoch: 539, step: 22, Train: label_loss: 0.09077345579862595, precision: 0.31464737793849823, recall: 0.8817567567566077, f1: 0.46379386935257466\n",
            "epoch: 539, step: 23, Train: label_loss: 0.09676466882228851, precision: 0.32719233603534803, recall: 0.8969696969695158, f1: 0.47948164142946254\n",
            "epoch: 540, step: 0, Train: label_loss: 0.07997287809848785, precision: 0.31420118343193404, recall: 0.9030612244896423, f1: 0.4661984196280341\n",
            "epoch: 540, step: 1, Train: label_loss: 0.1031099408864975, precision: 0.3157255616271818, recall: 0.8666666666665221, f1: 0.4628393413048286\n",
            "epoch: 540, step: 2, Train: label_loss: 0.09356237202882767, precision: 0.29803688280783475, recall: 0.8728222996514158, f1: 0.44434589796644475\n",
            "epoch: 540, step: 3, Train: label_loss: 0.08997943997383118, precision: 0.30625752105894666, recall: 0.865646258503254, f1: 0.45244444440579656\n",
            "epoch: 540, step: 4, Train: label_loss: 0.09167686104774475, precision: 0.3269346130773649, recall: 0.8993399339932509, f1: 0.4795424548662634\n",
            "epoch: 540, step: 5, Train: label_loss: 0.1069803535938263, precision: 0.3153098420412931, recall: 0.8678929765884835, f1: 0.4625668448806504\n",
            "epoch: 540, step: 6, Train: label_loss: 0.10207200050354004, precision: 0.3317249698431645, recall: 0.8828250401282691, f1: 0.4822446295086957\n",
            "epoch: 540, step: 7, Train: label_loss: 0.10223831236362457, precision: 0.3054878048780301, recall: 0.8549488054606049, f1: 0.45013477085065734\n",
            "epoch: 540, step: 8, Train: label_loss: 0.08559650182723999, precision: 0.3289786223277714, recall: 0.9022801302930126, f1: 0.482158398568283\n",
            "epoch: 540, step: 9, Train: label_loss: 0.08367515355348587, precision: 0.33171912832927775, recall: 0.8925081433223302, f1: 0.4836716680981366\n",
            "epoch: 540, step: 10, Train: label_loss: 0.10016726702451706, precision: 0.2912323727774193, recall: 0.8574007220215059, f1: 0.4347826086577602\n",
            "epoch: 540, step: 11, Train: label_loss: 0.11398636549711227, precision: 0.31051344743274384, recall: 0.8881118881117328, f1: 0.4601449274978007\n",
            "epoch: 540, step: 12, Train: label_loss: 0.10624204576015472, precision: 0.30933496034165286, recall: 0.84782608695638, f1: 0.4532856503854631\n",
            "epoch: 540, step: 13, Train: label_loss: 0.09825921058654785, precision: 0.32684114424830635, recall: 0.8550955414011376, f1: 0.4729194187182024\n",
            "epoch: 540, step: 14, Train: label_loss: 0.09244468063116074, precision: 0.316109422492382, recall: 0.8427876823337369, f1: 0.45977011490281494\n",
            "epoch: 540, step: 15, Train: label_loss: 0.09886807203292847, precision: 0.3107617896009486, recall: 0.8580968280466013, f1: 0.4562805148299866\n",
            "epoch: 540, step: 16, Train: label_loss: 0.0981532409787178, precision: 0.3319200484554614, recall: 0.8925081433223302, f1: 0.48388520967346227\n",
            "epoch: 540, step: 17, Train: label_loss: 0.09499295800924301, precision: 0.3401688781664451, recall: 0.8952380952379531, f1: 0.4930069929670434\n",
            "epoch: 540, step: 18, Train: label_loss: 0.0977751836180687, precision: 0.3103654883163385, recall: 0.8779661016947664, f1: 0.45861000438810406\n",
            "epoch: 540, step: 19, Train: label_loss: 0.09979763627052307, precision: 0.3184290030211288, recall: 0.8569105691055516, f1: 0.46431718057719423\n",
            "epoch: 540, step: 20, Train: label_loss: 0.10874897241592407, precision: 0.3214716525934667, recall: 0.869494290375062, f1: 0.46939674148410343\n",
            "epoch: 540, step: 21, Train: label_loss: 0.10520955175161362, precision: 0.3225609756097364, recall: 0.865793780687256, f1: 0.4700133273704466\n",
            "epoch: 540, step: 22, Train: label_loss: 0.0931553840637207, precision: 0.32955899880808526, recall: 0.908045977011345, f1: 0.4836029732883853\n",
            "epoch: 540, step: 23, Train: label_loss: 0.09383302927017212, precision: 0.31821506949522177, recall: 0.9100418410039938, f1: 0.4715447154087119\n",
            "epoch: 541, step: 0, Train: label_loss: 0.09425230324268341, precision: 0.3195020746887777, recall: 0.9213675213673638, f1: 0.4744718309476366\n",
            "epoch: 541, step: 1, Train: label_loss: 0.09054674953222275, precision: 0.3056220095693597, recall: 0.8856152512996731, f1: 0.4544241884900471\n",
            "epoch: 541, step: 2, Train: label_loss: 0.09058704227209091, precision: 0.33293627159021244, recall: 0.8958333333331897, f1: 0.48545375593092377\n",
            "epoch: 541, step: 3, Train: label_loss: 0.08564464747905731, precision: 0.32624113475175376, recall: 0.9230769230767687, f1: 0.4820960698303647\n",
            "epoch: 541, step: 4, Train: label_loss: 0.08881539106369019, precision: 0.306586826347287, recall: 0.8873483535527058, f1: 0.45571873605435775\n",
            "epoch: 541, step: 5, Train: label_loss: 0.09061416238546371, precision: 0.3347305389221356, recall: 0.9001610305956682, f1: 0.4879965080355164\n",
            "epoch: 541, step: 6, Train: label_loss: 0.09813310205936432, precision: 0.32560903149136505, recall: 0.9118136439266369, f1: 0.4798598948823698\n",
            "epoch: 541, step: 7, Train: label_loss: 0.09823819994926453, precision: 0.2973955178679408, recall: 0.8509532062390206, f1: 0.4407540394588858\n",
            "epoch: 541, step: 8, Train: label_loss: 0.08931788802146912, precision: 0.33413461538459527, recall: 0.9011345218799187, f1: 0.48750548001310023\n",
            "epoch: 541, step: 9, Train: label_loss: 0.10114854574203491, precision: 0.3309395571513865, recall: 0.9050736497543527, f1: 0.4846625766478623\n",
            "epoch: 541, step: 10, Train: label_loss: 0.09757444262504578, precision: 0.32409638554214915, recall: 0.8677419354837309, f1: 0.4719298245217653\n",
            "epoch: 541, step: 11, Train: label_loss: 0.09594187140464783, precision: 0.34943351222418906, recall: 0.9057187017000146, f1: 0.504302925949451\n",
            "epoch: 541, step: 12, Train: label_loss: 0.10553295910358429, precision: 0.30984204131225335, recall: 0.8629441624364022, f1: 0.4559678139977364\n",
            "epoch: 541, step: 13, Train: label_loss: 0.09427078813314438, precision: 0.32045184304397617, recall: 0.8968386023293016, f1: 0.4721857205043137\n",
            "epoch: 541, step: 14, Train: label_loss: 0.08637332916259766, precision: 0.333734939759016, recall: 0.8807631160570936, f1: 0.484054172087668\n",
            "epoch: 541, step: 15, Train: label_loss: 0.10295616090297699, precision: 0.31575720416920194, recall: 0.8401305057094877, f1: 0.4590017824914435\n",
            "epoch: 541, step: 16, Train: label_loss: 0.08378539979457855, precision: 0.32565011820329043, recall: 0.912251655628988, f1: 0.4799651567556108\n",
            "epoch: 541, step: 17, Train: label_loss: 0.09428763389587402, precision: 0.29874025194959214, recall: 0.8721541155865372, f1: 0.4450402144391634\n",
            "epoch: 541, step: 18, Train: label_loss: 0.10296371579170227, precision: 0.3084975369457938, recall: 0.8520408163263856, f1: 0.4529837250965507\n",
            "epoch: 541, step: 19, Train: label_loss: 0.10382522642612457, precision: 0.317547055251954, recall: 0.8731218697828258, f1: 0.4657168298807021\n",
            "epoch: 541, step: 20, Train: label_loss: 0.10230240225791931, precision: 0.3025672371637957, recall: 0.8638743455495874, f1: 0.4481665911792833\n",
            "epoch: 541, step: 21, Train: label_loss: 0.09831270575523376, precision: 0.329483282674752, recall: 0.8813008130079867, f1: 0.4796460176594581\n",
            "epoch: 541, step: 22, Train: label_loss: 0.10256057977676392, precision: 0.31283905967448383, recall: 0.8664440734556149, f1: 0.45969884849950765\n",
            "epoch: 541, step: 23, Train: label_loss: 0.10120782256126404, precision: 0.316911764705859, recall: 0.8960498960497097, f1: 0.4682237913790552\n",
            "epoch: 542, step: 0, Train: label_loss: 0.09461309015750885, precision: 0.3309265944644807, recall: 0.9090909090907587, f1: 0.4852227613194506\n",
            "epoch: 542, step: 1, Train: label_loss: 0.09596627950668335, precision: 0.31242532855434213, recall: 0.8924914675766394, f1: 0.4628318583686267\n",
            "epoch: 542, step: 2, Train: label_loss: 0.09246364235877991, precision: 0.3339296362551977, recall: 0.9105691056909088, f1: 0.48865619542317024\n",
            "epoch: 542, step: 3, Train: label_loss: 0.09949322789907455, precision: 0.32142857142855197, recall: 0.8676470588233876, f1: 0.46908127204531497\n",
            "epoch: 542, step: 4, Train: label_loss: 0.09622414410114288, precision: 0.30545454545452694, recall: 0.8586030664393767, f1: 0.45060348677394557\n",
            "epoch: 542, step: 5, Train: label_loss: 0.08631150424480438, precision: 0.32166172106823016, recall: 0.9155405405403858, f1: 0.47606499776560723\n",
            "epoch: 542, step: 6, Train: label_loss: 0.08673539757728577, precision: 0.32474535650087927, recall: 0.8929159802304953, f1: 0.4762741651629532\n",
            "epoch: 542, step: 7, Train: label_loss: 0.09202849864959717, precision: 0.3024506873879078, recall: 0.8739205526768784, f1: 0.4493783303347615\n",
            "epoch: 542, step: 8, Train: label_loss: 0.11360912024974823, precision: 0.3017348203221622, recall: 0.8198653198651817, f1: 0.44112318836642733\n",
            "epoch: 542, step: 9, Train: label_loss: 0.09011419862508774, precision: 0.31978481769274836, recall: 0.896147403684942, f1: 0.4713656387277124\n",
            "epoch: 542, step: 10, Train: label_loss: 0.10198023915290833, precision: 0.3158536585365661, recall: 0.8505747126435385, f1: 0.4606491773726499\n",
            "epoch: 542, step: 11, Train: label_loss: 0.08084733784198761, precision: 0.32939089296272445, recall: 0.917627677100343, f1: 0.48476936462600956\n",
            "epoch: 542, step: 12, Train: label_loss: 0.09137721359729767, precision: 0.31428571428569557, recall: 0.8979591836733166, f1: 0.4656084655700158\n",
            "epoch: 542, step: 13, Train: label_loss: 0.10595817863941193, precision: 0.32908318154217797, recall: 0.8727858293074279, f1: 0.47795414458100155\n",
            "epoch: 542, step: 14, Train: label_loss: 0.08455993235111237, precision: 0.3095380923815051, recall: 0.8989547038325959, f1: 0.46050870143440964\n",
            "epoch: 542, step: 15, Train: label_loss: 0.1117708683013916, precision: 0.3304825901038283, recall: 0.869774919614008, f1: 0.47897299686133543\n",
            "epoch: 542, step: 16, Train: label_loss: 0.1172102689743042, precision: 0.29240121580545336, recall: 0.8874538745385816, f1: 0.4398719706988462\n",
            "epoch: 542, step: 17, Train: label_loss: 0.09795545041561127, precision: 0.3339328537170064, recall: 0.9056910569104217, f1: 0.4879544458651058\n",
            "epoch: 542, step: 18, Train: label_loss: 0.07588537037372589, precision: 0.33958944281522935, recall: 0.9249201277953794, f1: 0.4967824967431676\n",
            "epoch: 542, step: 19, Train: label_loss: 0.09156045317649841, precision: 0.29575757575755784, recall: 0.8486956521737654, f1: 0.43865168535489046\n",
            "epoch: 542, step: 20, Train: label_loss: 0.10187314450740814, precision: 0.3359516616313996, recall: 0.8895999999998576, f1: 0.4877192982057753\n",
            "epoch: 542, step: 21, Train: label_loss: 0.0899038314819336, precision: 0.33373205741624795, recall: 0.892799999999857, f1: 0.48585111010401155\n",
            "epoch: 542, step: 22, Train: label_loss: 0.08535896986722946, precision: 0.3224852071005726, recall: 0.8919803600653204, f1: 0.4737070838375288\n",
            "epoch: 542, step: 23, Train: label_loss: 0.10679411888122559, precision: 0.3174962292609112, recall: 0.8336633663364686, f1: 0.4598580010523017\n",
            "epoch: 543, step: 0, Train: label_loss: 0.07643301784992218, precision: 0.3448894202032071, recall: 0.901562499999859, f1: 0.49891915257558034\n",
            "epoch: 543, step: 1, Train: label_loss: 0.0909782126545906, precision: 0.3150932050510935, recall: 0.8851351351349855, f1: 0.46474501104771193\n",
            "epoch: 543, step: 2, Train: label_loss: 0.09085310995578766, precision: 0.33114558472551725, recall: 0.906862745097891, f1: 0.48513986010063054\n",
            "epoch: 543, step: 3, Train: label_loss: 0.08851949125528336, precision: 0.3124627310673636, recall: 0.897260273972449, f1: 0.46351172043930816\n",
            "epoch: 543, step: 4, Train: label_loss: 0.09494434297084808, precision: 0.3098086124401728, recall: 0.886986301369711, f1: 0.4592198581176168\n",
            "epoch: 543, step: 5, Train: label_loss: 0.0944378674030304, precision: 0.3237237237237043, recall: 0.9058823529410241, f1: 0.4769911504036435\n",
            "epoch: 543, step: 6, Train: label_loss: 0.08421865105628967, precision: 0.32626619552412683, recall: 0.9187396351573932, f1: 0.4815297696266442\n",
            "epoch: 543, step: 7, Train: label_loss: 0.09263353049755096, precision: 0.31164991129507325, recall: 0.9070567986229074, f1: 0.4639084506661189\n",
            "epoch: 543, step: 8, Train: label_loss: 0.09199641644954681, precision: 0.29545454545452776, recall: 0.8697183098590018, f1: 0.4410714285335346\n",
            "epoch: 543, step: 9, Train: label_loss: 0.07579119503498077, precision: 0.32446808510636377, recall: 0.9074380165287755, f1: 0.4780148018766974\n",
            "epoch: 543, step: 10, Train: label_loss: 0.08970766514539719, precision: 0.31234718826403957, recall: 0.8488372093021845, f1: 0.4566577300768074\n",
            "epoch: 543, step: 11, Train: label_loss: 0.08466137200593948, precision: 0.3315602836879237, recall: 0.9136807817588087, f1: 0.4865568082869902\n",
            "epoch: 543, step: 12, Train: label_loss: 0.08434208482503891, precision: 0.3110709987966118, recall: 0.8588039867108207, f1: 0.4567137808796479\n",
            "epoch: 543, step: 13, Train: label_loss: 0.09287548065185547, precision: 0.32102441929718156, recall: 0.8953488372091535, f1: 0.4725997369185801\n",
            "epoch: 543, step: 14, Train: label_loss: 0.09092395007610321, precision: 0.3193277310924178, recall: 0.8956228956227448, f1: 0.47079646013819915\n",
            "epoch: 543, step: 15, Train: label_loss: 0.0904635488986969, precision: 0.317191283292959, recall: 0.8661157024791957, f1: 0.4643331856053796\n",
            "epoch: 543, step: 16, Train: label_loss: 0.08361479640007019, precision: 0.31966726084371244, recall: 0.9072512647553276, f1: 0.47275922667495873\n",
            "epoch: 543, step: 17, Train: label_loss: 0.08817622065544128, precision: 0.31313737252547613, recall: 0.880269814502381, f1: 0.4619469026161181\n",
            "epoch: 543, step: 18, Train: label_loss: 0.10158401727676392, precision: 0.31730769230767325, recall: 0.887394957983044, f1: 0.46746347937682603\n",
            "epoch: 543, step: 19, Train: label_loss: 0.09274367988109589, precision: 0.3172043010752499, recall: 0.8894472361807555, f1: 0.4676354028674128\n",
            "epoch: 543, step: 20, Train: label_loss: 0.08330938220024109, precision: 0.33996383363469923, recall: 0.8854003139716035, f1: 0.4912891985661357\n",
            "epoch: 543, step: 21, Train: label_loss: 0.08907217532396317, precision: 0.3391148325358649, recall: 0.8971518987340352, f1: 0.4921874999601449\n",
            "epoch: 543, step: 22, Train: label_loss: 0.09858353435993195, precision: 0.32217573221755397, recall: 0.89386401326685, f1: 0.4736379612966858\n",
            "epoch: 543, step: 23, Train: label_loss: 0.08427703380584717, precision: 0.3153678077202975, recall: 0.8909465020574299, f1: 0.465841850418568\n",
            "epoch: 544, step: 0, Train: label_loss: 0.089400514960289, precision: 0.30580490724115467, recall: 0.8749999999998501, f1: 0.4532150775668995\n",
            "epoch: 544, step: 1, Train: label_loss: 0.09213542193174362, precision: 0.3246987951807033, recall: 0.886513157894591, f1: 0.47530864193602435\n",
            "epoch: 544, step: 2, Train: label_loss: 0.09737778455018997, precision: 0.3182912154031096, recall: 0.8890756302519514, f1: 0.46876384577415925\n",
            "epoch: 544, step: 3, Train: label_loss: 0.07609587907791138, precision: 0.3196915776986762, recall: 0.8953488372091535, f1: 0.4711538461150282\n",
            "epoch: 544, step: 4, Train: label_loss: 0.09139913320541382, precision: 0.33695652173911006, recall: 0.8773584905658998, f1: 0.4869109947242578\n",
            "epoch: 544, step: 5, Train: label_loss: 0.09091520309448242, precision: 0.31055155875297896, recall: 0.8946459412779111, f1: 0.46105918999285567\n",
            "epoch: 544, step: 6, Train: label_loss: 0.08572046458721161, precision: 0.3236514522821385, recall: 0.8980263157893259, f1: 0.475816993425063\n",
            "epoch: 544, step: 7, Train: label_loss: 0.09608270972967148, precision: 0.3085680047932709, recall: 0.8714043993230335, f1: 0.45575221235071617\n",
            "epoch: 544, step: 8, Train: label_loss: 0.09832983464002609, precision: 0.296522269676614, recall: 0.8571428571427059, f1: 0.4406165004150764\n",
            "epoch: 544, step: 9, Train: label_loss: 0.09737493842840195, precision: 0.32949029126211593, recall: 0.8772213247171442, f1: 0.4790471989015913\n",
            "epoch: 544, step: 10, Train: label_loss: 0.0864359438419342, precision: 0.31350386674596586, recall: 0.8932203389828994, f1: 0.4641127256330088\n",
            "epoch: 544, step: 11, Train: label_loss: 0.08933959901332855, precision: 0.3087971274685632, recall: 0.8835616438354651, f1: 0.4576496673673425\n",
            "epoch: 544, step: 12, Train: label_loss: 0.10775448381900787, precision: 0.3138461538461345, recall: 0.8279220779219435, f1: 0.4551539490899482\n",
            "epoch: 544, step: 13, Train: label_loss: 0.08306869119405746, precision: 0.3223880597014733, recall: 0.8985024958401167, f1: 0.47451669591891255\n",
            "epoch: 544, step: 14, Train: label_loss: 0.08229519426822662, precision: 0.31426886792450975, recall: 0.9221453287195636, f1: 0.4687774845706636\n",
            "epoch: 544, step: 15, Train: label_loss: 0.09962420165538788, precision: 0.3271196632591505, recall: 0.8816855753645247, f1: 0.47719298241662206\n",
            "epoch: 544, step: 16, Train: label_loss: 0.08973270654678345, precision: 0.32595693779902357, recall: 0.8861788617884737, f1: 0.47660690857454335\n",
            "epoch: 544, step: 17, Train: label_loss: 0.0905473381280899, precision: 0.3060982830076787, recall: 0.8975694444442885, f1: 0.4565121412423861\n",
            "epoch: 544, step: 18, Train: label_loss: 0.09105097502470016, precision: 0.3415514131088189, recall: 0.8902821316613024, f1: 0.49369839196335547\n",
            "epoch: 544, step: 19, Train: label_loss: 0.09971779584884644, precision: 0.327690447400222, recall: 0.8841761827078491, f1: 0.4781649756993628\n",
            "epoch: 544, step: 20, Train: label_loss: 0.09586109966039658, precision: 0.31925165962581054, recall: 0.8729372937292288, f1: 0.4675209897972435\n",
            "epoch: 544, step: 21, Train: label_loss: 0.09148212522268295, precision: 0.3217703349282104, recall: 0.8892561983469603, f1: 0.47255160294732335\n",
            "epoch: 544, step: 22, Train: label_loss: 0.11949001252651215, precision: 0.31104294478525696, recall: 0.8394039735097948, f1: 0.45389435985307497\n",
            "epoch: 544, step: 23, Train: label_loss: 0.09148278087377548, precision: 0.31652046783623417, recall: 0.8891170431209674, f1: 0.46684636114721156\n",
            "epoch: 545, step: 0, Train: label_loss: 0.08133457601070404, precision: 0.3091988130563615, recall: 0.8982758620688106, f1: 0.460044150072235\n",
            "epoch: 545, step: 1, Train: label_loss: 0.08912814408540726, precision: 0.3001797483522888, recall: 0.8789473684208984, f1: 0.4475212147900547\n",
            "epoch: 545, step: 2, Train: label_loss: 0.10267169773578644, precision: 0.3165249088699686, recall: 0.8527004909982238, f1: 0.46167478950411556\n",
            "epoch: 545, step: 3, Train: label_loss: 0.09233881533145905, precision: 0.29855247285884806, recall: 0.8823529411763132, f1: 0.44614691298606424\n",
            "epoch: 545, step: 4, Train: label_loss: 0.0834665596485138, precision: 0.3273809523809329, recall: 0.9212730318256412, f1: 0.4830917874008821\n",
            "epoch: 545, step: 5, Train: label_loss: 0.10758717358112335, precision: 0.3241925655088163, recall: 0.8721311475408405, f1: 0.47267880937848344\n",
            "epoch: 545, step: 6, Train: label_loss: 0.1040717139840126, precision: 0.32593037214883996, recall: 0.9034941763725618, f1: 0.4790471989023247\n",
            "epoch: 545, step: 7, Train: label_loss: 0.10430485010147095, precision: 0.32653061224487834, recall: 0.8918032786883783, f1: 0.47803163440711866\n",
            "epoch: 545, step: 8, Train: label_loss: 0.09339924156665802, precision: 0.33213644524235, recall: 0.8894230769229343, f1: 0.48366013067931835\n",
            "epoch: 545, step: 9, Train: label_loss: 0.0961020290851593, precision: 0.3267267267267071, recall: 0.8802588996762329, f1: 0.4765659219928877\n",
            "epoch: 545, step: 10, Train: label_loss: 0.09286616742610931, precision: 0.30618311533886405, recall: 0.9003496503494929, f1: 0.4569653948156788\n",
            "epoch: 545, step: 11, Train: label_loss: 0.0853540226817131, precision: 0.3120143454871302, recall: 0.9141856392292619, f1: 0.46524064167324686\n",
            "epoch: 545, step: 12, Train: label_loss: 0.08458104729652405, precision: 0.35520094562645654, recall: 0.9317829457362896, f1: 0.5143346169903725\n",
            "epoch: 545, step: 13, Train: label_loss: 0.1005464419722557, precision: 0.326567164179085, recall: 0.8967213114752628, f1: 0.4787746170286534\n",
            "epoch: 545, step: 14, Train: label_loss: 0.0890452116727829, precision: 0.3293627159023032, recall: 0.894822006472347, f1: 0.4814976055331118\n",
            "epoch: 545, step: 15, Train: label_loss: 0.10612344741821289, precision: 0.3185410334346311, recall: 0.870431893687563, f1: 0.4663996439304688\n",
            "epoch: 545, step: 16, Train: label_loss: 0.08171363174915314, precision: 0.3122786304604302, recall: 0.9073756432245441, f1: 0.46464646460832726\n",
            "epoch: 545, step: 17, Train: label_loss: 0.10452456772327423, precision: 0.31291291291289414, recall: 0.8697829716192204, f1: 0.4602473497843658\n",
            "epoch: 545, step: 18, Train: label_loss: 0.08582757413387299, precision: 0.33493109646492897, recall: 0.891547049441644, f1: 0.4869337978696634\n",
            "epoch: 545, step: 19, Train: label_loss: 0.09956677258014679, precision: 0.3087697929354258, recall: 0.8786828422875427, f1: 0.4569625957253338\n",
            "epoch: 545, step: 20, Train: label_loss: 0.09029020369052887, precision: 0.32728372655775395, recall: 0.871175523349296, f1: 0.4758135443753836\n",
            "epoch: 545, step: 21, Train: label_loss: 0.09260769188404083, precision: 0.32045866022931074, recall: 0.8762376237622316, f1: 0.46928855497620936\n",
            "epoch: 545, step: 22, Train: label_loss: 0.10572391748428345, precision: 0.3103030303030115, recall: 0.8663282571910547, f1: 0.4569388665385455\n",
            "epoch: 545, step: 23, Train: label_loss: 0.0802772045135498, precision: 0.33725202057308323, recall: 0.891262135922157, f1: 0.4893390191498815\n",
            "epoch: 546, step: 0, Train: label_loss: 0.08474951982498169, precision: 0.3331318016928456, recall: 0.8663522012577254, f1: 0.4812227073834196\n",
            "epoch: 546, step: 1, Train: label_loss: 0.09536045789718628, precision: 0.31350386674596586, recall: 0.896258503401208, f1: 0.46452181573943707\n",
            "epoch: 546, step: 2, Train: label_loss: 0.08877713978290558, precision: 0.31455961653682957, recall: 0.8974358974357439, f1: 0.4658385092782931\n",
            "epoch: 546, step: 3, Train: label_loss: 0.10215657949447632, precision: 0.3052064631956729, recall: 0.8762886597936638, f1: 0.45272969370331917\n",
            "epoch: 546, step: 4, Train: label_loss: 0.09264175593852997, precision: 0.3229291716686481, recall: 0.884868421052486, f1: 0.4731750219484685\n",
            "epoch: 546, step: 5, Train: label_loss: 0.09342412650585175, precision: 0.3126879134094821, recall: 0.8768971332207627, f1: 0.4609929077626252\n",
            "epoch: 546, step: 6, Train: label_loss: 0.07983875274658203, precision: 0.32136445242367917, recall: 0.8949999999998508, f1: 0.47291941871933485\n",
            "epoch: 546, step: 7, Train: label_loss: 0.09077952802181244, precision: 0.3365212193663875, recall: 0.8866141732282068, f1: 0.4878682841888405\n",
            "epoch: 546, step: 8, Train: label_loss: 0.09749814867973328, precision: 0.31346841477948073, recall: 0.9022298456259172, f1: 0.4652808491434641\n",
            "epoch: 546, step: 9, Train: label_loss: 0.09729932248592377, precision: 0.3008474576271004, recall: 0.8628472222220723, f1: 0.44614003586826434\n",
            "epoch: 546, step: 10, Train: label_loss: 0.09005579352378845, precision: 0.3515764425936733, recall: 0.903669724770504, f1: 0.5062098500666955\n",
            "epoch: 546, step: 11, Train: label_loss: 0.08878538012504578, precision: 0.31187241582986935, recall: 0.9010238907848291, f1: 0.4633611232614493\n",
            "epoch: 546, step: 12, Train: label_loss: 0.09679434448480606, precision: 0.3130590339892479, recall: 0.8913412563665719, f1: 0.4633715798379201\n",
            "epoch: 546, step: 13, Train: label_loss: 0.08826962113380432, precision: 0.3427370948379146, recall: 0.9049128367668929, f1: 0.49717022198884125\n",
            "epoch: 546, step: 14, Train: label_loss: 0.11171109974384308, precision: 0.318042813455638, recall: 0.8637873754151388, f1: 0.4649083593705443\n",
            "epoch: 546, step: 15, Train: label_loss: 0.11505897343158722, precision: 0.29598051157123656, recall: 0.8541300527239272, f1: 0.4396200813728623\n",
            "epoch: 546, step: 16, Train: label_loss: 0.11520490050315857, precision: 0.30450669914736267, recall: 0.8547008547007086, f1: 0.4490345756235493\n",
            "epoch: 546, step: 17, Train: label_loss: 0.13039875030517578, precision: 0.32078963602712396, recall: 0.8346709470303636, f1: 0.4634581104767825\n",
            "epoch: 546, step: 18, Train: label_loss: 0.10940590500831604, precision: 0.3068526379623828, recall: 0.8861646234674454, f1: 0.45585585581760446\n",
            "epoch: 546, step: 19, Train: label_loss: 0.11056237667798996, precision: 0.32322619769555344, recall: 0.8824503311256816, f1: 0.4731469151848603\n",
            "epoch: 546, step: 20, Train: label_loss: 0.11058640480041504, precision: 0.3219814241485869, recall: 0.8580858085807164, f1: 0.46825754160818367\n",
            "epoch: 546, step: 21, Train: label_loss: 0.11147058010101318, precision: 0.31713244228430637, recall: 0.8656716417909012, f1: 0.464206313878009\n",
            "epoch: 546, step: 22, Train: label_loss: 0.11902117729187012, precision: 0.32797029702968267, recall: 0.871710526315646, f1: 0.47661870499619957\n",
            "epoch: 546, step: 23, Train: label_loss: 0.11067930608987808, precision: 0.32715133531154844, recall: 0.8784860557767175, f1: 0.47675675671716133\n",
            "epoch: 547, step: 0, Train: label_loss: 0.11253361403942108, precision: 0.3060975609755911, recall: 0.8494077834177919, f1: 0.4500224114356888\n",
            "epoch: 547, step: 1, Train: label_loss: 0.10352513194084167, precision: 0.3098847786537107, recall: 0.8617200674534803, f1: 0.4558429972848697\n",
            "epoch: 547, step: 2, Train: label_loss: 0.0959201380610466, precision: 0.3185947910357166, recall: 0.865131578947226, f1: 0.4656927843785015\n",
            "epoch: 547, step: 3, Train: label_loss: 0.10720791667699814, precision: 0.32412965186072484, recall: 0.8709677419353433, f1: 0.47244094484231686\n",
            "epoch: 547, step: 4, Train: label_loss: 0.1148047149181366, precision: 0.3142329020332523, recall: 0.8279220779219435, f1: 0.45556051804850556\n",
            "epoch: 547, step: 5, Train: label_loss: 0.10815465450286865, precision: 0.32604735883422425, recall: 0.8633440514468065, f1: 0.47333627144539747\n",
            "epoch: 547, step: 6, Train: label_loss: 0.10218638181686401, precision: 0.32271634615382677, recall: 0.8861386138612398, f1: 0.47312775326478457\n",
            "epoch: 547, step: 7, Train: label_loss: 0.10729815810918808, precision: 0.328258221680857, recall: 0.8693548387095371, f1: 0.4765694075640549\n",
            "epoch: 547, step: 8, Train: label_loss: 0.11741699278354645, precision: 0.3086797066014481, recall: 0.8516020236086252, f1: 0.4531179900910101\n",
            "epoch: 547, step: 9, Train: label_loss: 0.11883459240198135, precision: 0.31683168316829724, recall: 0.8561872909697564, f1: 0.4625112917401135\n",
            "epoch: 547, step: 10, Train: label_loss: 0.12027417123317719, precision: 0.2998149290561197, recall: 0.8422876949738575, f1: 0.4422202001432235\n",
            "epoch: 547, step: 11, Train: label_loss: 0.11420272290706635, precision: 0.31868811881186143, recall: 0.8526490066223753, f1: 0.4639639639243124\n",
            "epoch: 547, step: 12, Train: label_loss: 0.11364173889160156, precision: 0.316463414634127, recall: 0.863560732113001, f1: 0.4631860776046154\n",
            "epoch: 547, step: 13, Train: label_loss: 0.10664193332195282, precision: 0.31249999999998085, recall: 0.8644067796608704, f1: 0.4590459045514133\n",
            "epoch: 547, step: 14, Train: label_loss: 0.12033739686012268, precision: 0.33004318322021403, recall: 0.8438485804415072, f1: 0.4745011086069868\n",
            "epoch: 547, step: 15, Train: label_loss: 0.10599444806575775, precision: 0.28711056811238317, recall: 0.8483754512633847, f1: 0.4290278411305934\n",
            "epoch: 547, step: 16, Train: label_loss: 0.09979359805583954, precision: 0.31507692307690366, recall: 0.8519134775372957, f1: 0.46001796941247114\n",
            "epoch: 547, step: 17, Train: label_loss: 0.09714243561029434, precision: 0.3108839446782735, recall: 0.8837606837605326, f1: 0.45996441277284467\n",
            "epoch: 547, step: 18, Train: label_loss: 0.1185590848326683, precision: 0.3108614232209544, recall: 0.8084415584414272, f1: 0.4490532010418964\n",
            "epoch: 547, step: 19, Train: label_loss: 0.10760108381509781, precision: 0.31299572910309253, recall: 0.8592964824119163, f1: 0.45885509835079935\n",
            "epoch: 547, step: 20, Train: label_loss: 0.0956929475069046, precision: 0.32653061224487834, recall: 0.8874388254484685, f1: 0.47740236942092185\n",
            "epoch: 547, step: 21, Train: label_loss: 0.10927961766719818, precision: 0.3155015197568197, recall: 0.8578512396692797, f1: 0.4613333332939748\n",
            "epoch: 547, step: 22, Train: label_loss: 0.09571424126625061, precision: 0.3149271844660003, recall: 0.8826530612243396, f1: 0.4642218246481361\n",
            "epoch: 547, step: 23, Train: label_loss: 0.11197279393672943, precision: 0.3139622641509197, recall: 0.8542094455850402, f1: 0.4591611478635131\n",
            "epoch: 548, step: 0, Train: label_loss: 0.0895950049161911, precision: 0.32041187159295453, recall: 0.8743801652891116, f1: 0.4689716311663808\n",
            "epoch: 548, step: 1, Train: label_loss: 0.0925077348947525, precision: 0.3398294762484568, recall: 0.8597842835129645, f1: 0.4871235268035236\n",
            "epoch: 548, step: 2, Train: label_loss: 0.1020045280456543, precision: 0.321494182486202, recall: 0.8564437194125846, f1: 0.4674977737803952\n",
            "epoch: 548, step: 3, Train: label_loss: 0.09744496643543243, precision: 0.30301204819275285, recall: 0.865748709122054, f1: 0.4489067380249157\n",
            "epoch: 548, step: 4, Train: label_loss: 0.09424757957458496, precision: 0.27112462006077376, recall: 0.8320895522386507, f1: 0.40898670330997866\n",
            "epoch: 548, step: 5, Train: label_loss: 0.08740448951721191, precision: 0.32132132132130203, recall: 0.899159663865395, f1: 0.47345132739479423\n",
            "epoch: 548, step: 6, Train: label_loss: 0.10587332397699356, precision: 0.3250303766706971, recall: 0.8727569331156814, f1: 0.47366091186833725\n",
            "epoch: 548, step: 7, Train: label_loss: 0.1045076996088028, precision: 0.32322619769555344, recall: 0.8752052545154556, f1: 0.4720992027949317\n",
            "epoch: 548, step: 8, Train: label_loss: 0.1073264628648758, precision: 0.2981818181818001, recall: 0.8424657534245132, f1: 0.4404655326381581\n",
            "epoch: 548, step: 9, Train: label_loss: 0.10260824859142303, precision: 0.32815301852956796, recall: 0.9014778325121672, f1: 0.48115687989071376\n",
            "epoch: 548, step: 10, Train: label_loss: 0.10603442788124084, precision: 0.3213851761846706, recall: 0.8831385642736421, f1: 0.4712694877113899\n",
            "epoch: 548, step: 11, Train: label_loss: 0.10466589778661728, precision: 0.33578431372546963, recall: 0.8657187993679516, f1: 0.4838852096727082\n",
            "epoch: 548, step: 12, Train: label_loss: 0.09164242446422577, precision: 0.3429256594724015, recall: 0.909379968203353, f1: 0.4980409229031558\n",
            "epoch: 548, step: 13, Train: label_loss: 0.1035776138305664, precision: 0.31483715319660344, recall: 0.8877551020406653, f1: 0.46482635793103055\n",
            "epoch: 548, step: 14, Train: label_loss: 0.11032301932573318, precision: 0.32848484848482856, recall: 0.8943894389437468, f1: 0.4804964538613742\n",
            "epoch: 548, step: 15, Train: label_loss: 0.11785253137350082, precision: 0.3320872274143095, recall: 0.8500797448164513, f1: 0.4775985662678006\n",
            "epoch: 548, step: 16, Train: label_loss: 0.08875051140785217, precision: 0.3327316486161051, recall: 0.8833865814695074, f1: 0.4833916083518173\n",
            "epoch: 548, step: 17, Train: label_loss: 0.09774632751941681, precision: 0.30901287553646173, recall: 0.8484848484847056, f1: 0.4530337078259888\n",
            "epoch: 548, step: 18, Train: label_loss: 0.07686298340559006, precision: 0.3147268408550882, recall: 0.9137931034481183, f1: 0.46819787982050515\n",
            "epoch: 548, step: 19, Train: label_loss: 0.10025757551193237, precision: 0.3182640144665269, recall: 0.8756218905471184, f1: 0.46684350128711577\n",
            "epoch: 548, step: 20, Train: label_loss: 0.10500219464302063, precision: 0.31314984709478205, recall: 0.8448844884487055, f1: 0.4569388665379219\n",
            "epoch: 548, step: 21, Train: label_loss: 0.08690637350082397, precision: 0.308333333333315, recall: 0.9008695652172346, f1: 0.4594235032879077\n",
            "epoch: 548, step: 22, Train: label_loss: 0.1069040298461914, precision: 0.2975970425138449, recall: 0.8444055944054467, f1: 0.44009111613454377\n",
            "epoch: 548, step: 23, Train: label_loss: 0.09895594418048859, precision: 0.3131539611360005, recall: 0.8603696098560862, f1: 0.45917808215260236\n",
            "epoch: 549, step: 0, Train: label_loss: 0.10056740045547485, precision: 0.30867192237717955, recall: 0.8775862068964003, f1: 0.4567070434787315\n",
            "epoch: 549, step: 1, Train: label_loss: 0.09877294301986694, precision: 0.3345345345345144, recall: 0.8883572567781677, f1: 0.4860383943755703\n",
            "epoch: 549, step: 2, Train: label_loss: 0.09496565163135529, precision: 0.32593037214883996, recall: 0.8858075040781589, f1: 0.47652479153588473\n",
            "epoch: 549, step: 3, Train: label_loss: 0.0858086347579956, precision: 0.35442296426477127, recall: 0.9222560975608349, f1: 0.512060939443555\n",
            "epoch: 549, step: 4, Train: label_loss: 0.10101377964019775, precision: 0.3286413708690129, recall: 0.8803278688523146, f1: 0.4786096256288183\n",
            "epoch: 549, step: 5, Train: label_loss: 0.09630905091762543, precision: 0.3236714975845215, recall: 0.8830313014825563, f1: 0.4737074679235829\n",
            "epoch: 549, step: 6, Train: label_loss: 0.09203974157571793, precision: 0.3171753441053072, recall: 0.8803986710961992, f1: 0.4663440386763724\n",
            "epoch: 549, step: 7, Train: label_loss: 0.09284408390522003, precision: 0.31212841854932744, recall: 0.908304498269739, f1: 0.4646017698733947\n",
            "epoch: 549, step: 8, Train: label_loss: 0.09483393281698227, precision: 0.3002436053592996, recall: 0.8725663716812614, f1: 0.44676030807242373\n",
            "epoch: 549, step: 9, Train: label_loss: 0.09207606315612793, precision: 0.30847865303666216, recall: 0.8814432989689206, f1: 0.4570155901619975\n",
            "epoch: 549, step: 10, Train: label_loss: 0.10571043193340302, precision: 0.3220651505838769, recall: 0.8520325203250646, f1: 0.46743978586558715\n",
            "epoch: 549, step: 11, Train: label_loss: 0.09745970368385315, precision: 0.3236539624924184, recall: 0.8713355048858515, f1: 0.4719894132820313\n",
            "epoch: 549, step: 12, Train: label_loss: 0.09343114495277405, precision: 0.31279904306218226, recall: 0.8879456706280325, f1: 0.46262715608703886\n",
            "epoch: 549, step: 13, Train: label_loss: 0.08620201796293259, precision: 0.32110643415512197, recall: 0.8914858096826558, f1: 0.47214854107507936\n",
            "epoch: 549, step: 14, Train: label_loss: 0.10168667137622833, precision: 0.30085261875759434, recall: 0.8606271777001985, f1: 0.44584837541283706\n",
            "epoch: 549, step: 15, Train: label_loss: 0.09696725010871887, precision: 0.3136664659843279, recall: 0.8830508474574774, f1: 0.46290537534999365\n",
            "epoch: 549, step: 16, Train: label_loss: 0.09130586683750153, precision: 0.32048192771082407, recall: 0.8721311475408405, f1: 0.46872246692100894\n",
            "epoch: 549, step: 17, Train: label_loss: 0.10564500093460083, precision: 0.313325330132034, recall: 0.8729096989965095, f1: 0.46113074201055576\n",
            "epoch: 549, step: 18, Train: label_loss: 0.09213720262050629, precision: 0.30773881499393546, recall: 0.8700854700853213, f1: 0.45466726213196895\n",
            "epoch: 549, step: 19, Train: label_loss: 0.10896101593971252, precision: 0.3165024630541677, recall: 0.8440065681443605, f1: 0.46036721894819793\n",
            "epoch: 549, step: 20, Train: label_loss: 0.09807915985584259, precision: 0.32572115384613426, recall: 0.8756058158318456, f1: 0.4748138413971404\n",
            "epoch: 549, step: 21, Train: label_loss: 0.10532648861408234, precision: 0.32645631067959185, recall: 0.8677419354837309, f1: 0.4744268077203716\n",
            "epoch: 549, step: 22, Train: label_loss: 0.08888056874275208, precision: 0.32071005917157863, recall: 0.9063545150500156, f1: 0.4737762237375718\n",
            "epoch: 549, step: 23, Train: label_loss: 0.0989343672990799, precision: 0.30568011958144203, recall: 0.8538622129434543, f1: 0.45019262516750963\n",
            "epoch: 550, step: 0, Train: label_loss: 0.09627048671245575, precision: 0.3383777239709238, recall: 0.8761755485892043, f1: 0.48820960694666016\n",
            "epoch: 550, step: 1, Train: label_loss: 0.09439355880022049, precision: 0.31758373205739726, recall: 0.8969594594593079, f1: 0.4690812720461422\n",
            "epoch: 550, step: 2, Train: label_loss: 0.10286727547645569, precision: 0.2928009679370664, recall: 0.8581560283686421, f1: 0.4366260712295033\n",
            "epoch: 550, step: 3, Train: label_loss: 0.0946616679430008, precision: 0.3379769836462545, recall: 0.8815165876775858, f1: 0.4886164623066502\n",
            "epoch: 550, step: 4, Train: label_loss: 0.09028200805187225, precision: 0.3333333333333134, recall: 0.9014539579966233, f1: 0.48669864801985285\n",
            "epoch: 550, step: 5, Train: label_loss: 0.10335611552000046, precision: 0.3232077764276839, recall: 0.8622366288491309, f1: 0.4701723375652455\n",
            "epoch: 550, step: 6, Train: label_loss: 0.10339844226837158, precision: 0.3239263803680783, recall: 0.8756218905471184, f1: 0.4729064039014207\n",
            "epoch: 550, step: 7, Train: label_loss: 0.08401140570640564, precision: 0.31316725978645826, recall: 0.9025641025639483, f1: 0.46499339494189595\n",
            "epoch: 550, step: 8, Train: label_loss: 0.08648905903100967, precision: 0.33192516596256294, recall: 0.889967637540309, f1: 0.4835164834768699\n",
            "epoch: 550, step: 9, Train: label_loss: 0.1027040183544159, precision: 0.31470230862695536, recall: 0.8662207357858083, f1: 0.46167557928350245\n",
            "epoch: 550, step: 10, Train: label_loss: 0.09856997430324554, precision: 0.3101379724055003, recall: 0.8807495741054717, f1: 0.45874001770766737\n",
            "epoch: 550, step: 11, Train: label_loss: 0.09150263667106628, precision: 0.3228111971411362, recall: 0.9063545150500156, f1: 0.47606499776535566\n",
            "epoch: 550, step: 12, Train: label_loss: 0.11115144938230515, precision: 0.29926108374382393, recall: 0.8571428571427059, f1: 0.4436330442336182\n",
            "epoch: 550, step: 13, Train: label_loss: 0.0927749052643776, precision: 0.3059033989266365, recall: 0.9015817223197009, f1: 0.45681211038064945\n",
            "epoch: 550, step: 14, Train: label_loss: 0.0835404172539711, precision: 0.3132817153067115, recall: 0.8930390492358415, f1: 0.4638447971396384\n",
            "epoch: 550, step: 15, Train: label_loss: 0.09438514709472656, precision: 0.31582125603862826, recall: 0.8731218697828258, f1: 0.46385809308733034\n",
            "epoch: 550, step: 16, Train: label_loss: 0.09295214712619781, precision: 0.31733653269344225, recall: 0.8920741989880451, f1: 0.46814159288160434\n",
            "epoch: 550, step: 17, Train: label_loss: 0.09228234738111496, precision: 0.3256379100850349, recall: 0.8575999999998627, f1: 0.4720387494096463\n",
            "epoch: 550, step: 18, Train: label_loss: 0.0787491649389267, precision: 0.30200945626475756, recall: 0.9012345679010756, f1: 0.45241257189684486\n",
            "epoch: 550, step: 19, Train: label_loss: 0.08623448014259338, precision: 0.34052757793762944, recall: 0.8792569659441363, f1: 0.49092480549125783\n",
            "epoch: 550, step: 20, Train: label_loss: 0.1639057695865631, precision: 0.29993577392419396, recall: 0.7568881685574137, f1: 0.4296228150467047\n",
            "epoch: 550, step: 21, Train: label_loss: 0.2306508719921112, precision: 0.2605442176870571, recall: 0.6436974789914884, f1: 0.3709443098863021\n",
            "epoch: 550, step: 22, Train: label_loss: 0.22432413697242737, precision: 0.2538071065989664, recall: 0.5573248407642424, f1: 0.3487792725030548\n",
            "epoch: 550, step: 23, Train: label_loss: 0.2248387336730957, precision: 0.2625745950553911, recall: 0.6525423728812177, f1: 0.3744680850654172\n",
            "epoch: 551, step: 0, Train: label_loss: 0.22192269563674927, precision: 0.2766990291261944, recall: 0.6694630872482098, f1: 0.39156035324611427\n",
            "epoch: 551, step: 1, Train: label_loss: 0.23251578211784363, precision: 0.27499999999998087, recall: 0.6757679180886218, f1: 0.3909180651118562\n",
            "epoch: 551, step: 2, Train: label_loss: 0.2596004009246826, precision: 0.26988636363634444, recall: 0.6440677966100603, f1: 0.38038038033872307\n",
            "epoch: 551, step: 3, Train: label_loss: 0.2394258975982666, precision: 0.28851540616244475, recall: 0.6776315789472569, f1: 0.40471512765944584\n",
            "epoch: 551, step: 4, Train: label_loss: 0.24989460408687592, precision: 0.294953802416468, recall: 0.6384615384614402, f1: 0.4035002430291679\n",
            "epoch: 551, step: 5, Train: label_loss: 0.23088791966438293, precision: 0.2841302841302644, recall: 0.6765676567655649, f1: 0.40019521713741596\n",
            "epoch: 551, step: 6, Train: label_loss: 0.22986915707588196, precision: 0.28481012658225846, recall: 0.6899488926744991, f1: 0.4031856644683036\n",
            "epoch: 551, step: 7, Train: label_loss: 0.24144229292869568, precision: 0.2930298719772195, recall: 0.6959459459458284, f1: 0.4124124123706701\n",
            "epoch: 551, step: 8, Train: label_loss: 0.23375898599624634, precision: 0.2906894100923745, recall: 0.6839464882941999, f1: 0.40798004983341124\n",
            "epoch: 551, step: 9, Train: label_loss: 0.2392125129699707, precision: 0.27417027417025436, recall: 0.6440677966100603, f1: 0.38461538457345945\n",
            "epoch: 551, step: 10, Train: label_loss: 0.2313169687986374, precision: 0.2601326455416168, recall: 0.6054888507717657, f1: 0.3639175257311172\n",
            "epoch: 551, step: 11, Train: label_loss: 0.23908869922161102, precision: 0.2689257390050275, recall: 0.5958466453673169, f1: 0.37059115743351234\n",
            "epoch: 551, step: 12, Train: label_loss: 0.24414154887199402, precision: 0.2652910832719038, recall: 0.5950413223139512, f1: 0.3669724770215281\n",
            "epoch: 551, step: 13, Train: label_loss: 0.2393956482410431, precision: 0.24874191229329629, recall: 0.581512605041919, f1: 0.3484390734725994\n",
            "epoch: 551, step: 14, Train: label_loss: 0.21616539359092712, precision: 0.2690179806362193, recall: 0.647254575707047, f1: 0.3800683927283902\n",
            "epoch: 551, step: 15, Train: label_loss: 0.2405071258544922, precision: 0.2992398064961783, recall: 0.726510067113972, f1: 0.42388644146622084\n",
            "epoch: 551, step: 16, Train: label_loss: 0.2316913902759552, precision: 0.2778166550034795, recall: 0.6434359805509492, f1: 0.3880742912579352\n",
            "epoch: 551, step: 17, Train: label_loss: 0.2635008990764618, precision: 0.2591792656587286, recall: 0.6020066889631099, f1: 0.36235530946971406\n",
            "epoch: 551, step: 18, Train: label_loss: 0.23530802130699158, precision: 0.2661971830985728, recall: 0.6237623762375207, f1: 0.37314906214954474\n",
            "epoch: 551, step: 19, Train: label_loss: 0.23971286416053772, precision: 0.2957937584803056, recall: 0.7159277504103915, f1: 0.4186269802754329\n",
            "epoch: 551, step: 20, Train: label_loss: 0.2488604187965393, precision: 0.2834261838439914, recall: 0.6738410596025374, f1: 0.3990196078014149\n",
            "epoch: 551, step: 21, Train: label_loss: 0.25432923436164856, precision: 0.2844228094575602, recall: 0.6943972835312913, f1: 0.4035520473193632\n",
            "epoch: 551, step: 22, Train: label_loss: 0.24742001295089722, precision: 0.2845129642606668, recall: 0.6777963272119069, f1: 0.40078973342326724\n",
            "epoch: 551, step: 23, Train: label_loss: 0.2559260129928589, precision: 0.2817147856517689, recall: 0.6598360655736353, f1: 0.39484978536574084\n",
            "epoch: 552, step: 0, Train: label_loss: 0.24299778044223785, precision: 0.24147727272725558, recall: 0.5913043478259841, f1: 0.3429147755513249\n",
            "epoch: 552, step: 1, Train: label_loss: 0.23252633213996887, precision: 0.25793382849424323, recall: 0.6541095890409838, f1: 0.3699757868843381\n",
            "epoch: 552, step: 2, Train: label_loss: 0.23454812169075012, precision: 0.25280112044816155, recall: 0.6097972972971942, f1: 0.3574257425327861\n",
            "epoch: 552, step: 3, Train: label_loss: 0.22696423530578613, precision: 0.2706919945725732, recall: 0.6785714285713131, f1: 0.3870029097555079\n",
            "epoch: 552, step: 4, Train: label_loss: 0.23352038860321045, precision: 0.293539325842676, recall: 0.6709470304974845, f1: 0.40840254026049827\n",
            "epoch: 552, step: 5, Train: label_loss: 0.2558474540710449, precision: 0.2720797720797527, recall: 0.6334991708124985, f1: 0.38066766313680017\n",
            "epoch: 552, step: 6, Train: label_loss: 0.24093908071517944, precision: 0.2975945017181926, recall: 0.67762128325498, f1: 0.41356255965191796\n",
            "epoch: 552, step: 7, Train: label_loss: 0.25499483942985535, precision: 0.26887791107972697, recall: 0.6707746478872058, f1: 0.3838790931581005\n",
            "epoch: 552, step: 8, Train: label_loss: 0.24782854318618774, precision: 0.2776998597475261, recall: 0.6996466431094169, f1: 0.3975903614050626\n",
            "epoch: 552, step: 9, Train: label_loss: 0.24427831172943115, precision: 0.2947937795807779, recall: 0.699839486356228, f1: 0.4148430066185759\n",
            "epoch: 552, step: 10, Train: label_loss: 0.24065805971622467, precision: 0.29203539823006863, recall: 0.6908212560385361, f1: 0.41052631574766574\n",
            "epoch: 552, step: 11, Train: label_loss: 0.2350548505783081, precision: 0.2640990371389089, recall: 0.6530612244896848, f1: 0.37610186087962194\n",
            "epoch: 552, step: 12, Train: label_loss: 0.23203566670417786, precision: 0.2818057455540163, recall: 0.6936026936025768, f1: 0.40077821007560427\n",
            "epoch: 552, step: 13, Train: label_loss: 0.23817330598831177, precision: 0.24732715609406647, recall: 0.5851602023607781, f1: 0.3476953907397624\n",
            "epoch: 552, step: 14, Train: label_loss: 0.22935378551483154, precision: 0.2513850415512291, recall: 0.6280276816607909, f1: 0.3590504450629936\n",
            "epoch: 552, step: 15, Train: label_loss: 0.24145644903182983, precision: 0.30452674897117255, recall: 0.6937499999998915, f1: 0.4232602478126607\n",
            "epoch: 552, step: 16, Train: label_loss: 0.26097244024276733, precision: 0.3011126564672948, recall: 0.6916932907347138, f1: 0.41957364336855063\n",
            "epoch: 552, step: 17, Train: label_loss: 0.23119261860847473, precision: 0.2711631108052119, recall: 0.6948853615519056, f1: 0.3900990098605706\n",
            "epoch: 552, step: 18, Train: label_loss: 0.25370511412620544, precision: 0.30839802399433247, recall: 0.6881889763778444, f1: 0.42592592588314593\n",
            "epoch: 552, step: 19, Train: label_loss: 0.24878793954849243, precision: 0.2833217027215434, recall: 0.6755407653909026, f1: 0.39921337262302675\n",
            "epoch: 552, step: 20, Train: label_loss: 0.2337198108434677, precision: 0.2541208791208617, recall: 0.6401384083043875, f1: 0.36381514253548536\n",
            "epoch: 552, step: 21, Train: label_loss: 0.242660254240036, precision: 0.28086838534597824, recall: 0.6842975206610439, f1: 0.3982683982270957\n",
            "epoch: 552, step: 22, Train: label_loss: 0.23384016752243042, precision: 0.28030833917307074, recall: 0.6441223832527143, f1: 0.3906249999577061\n",
            "epoch: 552, step: 23, Train: label_loss: 0.2259358912706375, precision: 0.29107589658045946, recall: 0.6829745596867548, f1: 0.40818713446097005\n",
            "epoch: 553, step: 0, Train: label_loss: 0.22821736335754395, precision: 0.2798931195724596, recall: 0.7224137931033237, f1: 0.40346653823606743\n",
            "epoch: 553, step: 1, Train: label_loss: 0.24162358045578003, precision: 0.2890252215405393, recall: 0.689430894308831, f1: 0.4073006723886894\n",
            "epoch: 553, step: 2, Train: label_loss: 0.23667913675308228, precision: 0.2843406593406398, recall: 0.7040816326529414, f1: 0.40508806258128627\n",
            "epoch: 553, step: 3, Train: label_loss: 0.238701730966568, precision: 0.2547554347825914, recall: 0.6660746003551214, f1: 0.3685503685103086\n",
            "epoch: 553, step: 4, Train: label_loss: 0.2429642379283905, precision: 0.25716282320054107, recall: 0.613333333333231, f1: 0.36238306248910784\n",
            "epoch: 553, step: 5, Train: label_loss: 0.21515792608261108, precision: 0.28040540540538644, recall: 0.6836902800657851, f1: 0.39770004787437924\n",
            "epoch: 553, step: 6, Train: label_loss: 0.2513212263584137, precision: 0.2736111111110921, recall: 0.6385737439221006, f1: 0.3830821584411946\n",
            "epoch: 553, step: 7, Train: label_loss: 0.2442711591720581, precision: 0.27471751412427436, recall: 0.6125984251967539, f1: 0.3793271574413671\n",
            "epoch: 553, step: 8, Train: label_loss: 0.23770776391029358, precision: 0.2858122001370606, recall: 0.6813725490194965, f1: 0.4027040076840608\n",
            "epoch: 553, step: 9, Train: label_loss: 0.24652817845344543, precision: 0.3258897418003959, recall: 0.6877761413842874, f1: 0.4422348484411793\n",
            "epoch: 553, step: 10, Train: label_loss: 0.23444466292858124, precision: 0.27980364656379525, recall: 0.6638935108151973, f1: 0.39368524909489905\n",
            "epoch: 553, step: 11, Train: label_loss: 0.22788405418395996, precision: 0.2988980716253238, recall: 0.7011308562195959, f1: 0.4191211974471843\n",
            "epoch: 553, step: 12, Train: label_loss: 0.2424394190311432, precision: 0.27863362357667254, recall: 0.7349823321553471, f1: 0.40407965027578274\n",
            "epoch: 553, step: 13, Train: label_loss: 0.23446515202522278, precision: 0.3004791238877275, recall: 0.7103559870549012, f1: 0.4223184222766025\n",
            "epoch: 553, step: 14, Train: label_loss: 0.222695454955101, precision: 0.30258560447237576, recall: 0.6862123613311115, f1: 0.4199806013153903\n",
            "epoch: 553, step: 15, Train: label_loss: 0.2130938023328781, precision: 0.2900976290097427, recall: 0.7062818336161788, f1: 0.41127039046782765\n",
            "epoch: 553, step: 16, Train: label_loss: 0.23269565403461456, precision: 0.2593905031892091, recall: 0.6120401337791618, f1: 0.36436037825581247\n",
            "epoch: 553, step: 17, Train: label_loss: 0.2284003049135208, precision: 0.25913396481730316, recall: 0.6778761061945703, f1: 0.3749388154273987\n",
            "epoch: 553, step: 18, Train: label_loss: 0.2302376627922058, precision: 0.2860082304526553, recall: 0.6714975845409547, f1: 0.4011544011124668\n",
            "epoch: 553, step: 19, Train: label_loss: 0.22294557094573975, precision: 0.28070175438594597, recall: 0.7098976109213805, f1: 0.4023210831314942\n",
            "epoch: 553, step: 20, Train: label_loss: 0.23310032486915588, precision: 0.25594025797690045, recall: 0.6708185053379588, f1: 0.3705159704759543\n",
            "epoch: 553, step: 21, Train: label_loss: 0.21469704806804657, precision: 0.2808174027686038, recall: 0.724489795918244, f1: 0.4047505937839282\n",
            "epoch: 553, step: 22, Train: label_loss: 0.21958132088184357, precision: 0.2660614525139479, recall: 0.6086261980829698, f1: 0.37026239062818717\n",
            "epoch: 553, step: 23, Train: label_loss: 0.20991744101047516, precision: 0.2603648424543731, recall: 0.6931567328916792, f1: 0.37854128989395003\n",
            "epoch: 554, step: 0, Train: label_loss: 0.21905282139778137, precision: 0.3031704095112085, recall: 0.7701342281877902, f1: 0.43507109000681643\n",
            "epoch: 554, step: 1, Train: label_loss: 0.20741808414459229, precision: 0.30115567641058455, recall: 0.7445378151259252, f1: 0.428848015447815\n",
            "epoch: 554, step: 2, Train: label_loss: 0.23796233534812927, precision: 0.2999318336741445, recall: 0.7166123778500461, f1: 0.4228736184110272\n",
            "epoch: 554, step: 3, Train: label_loss: 0.21755708754062653, precision: 0.29587000677046066, recall: 0.7048387096773057, f1: 0.41678588455535454\n",
            "epoch: 554, step: 4, Train: label_loss: 0.21535828709602356, precision: 0.27917771883287273, recall: 0.7147707979625272, f1: 0.40152598946838675\n",
            "epoch: 554, step: 5, Train: label_loss: 0.21341371536254883, precision: 0.2673063742289056, recall: 0.6554621848738393, f1: 0.37974683540184795\n",
            "epoch: 554, step: 6, Train: label_loss: 0.22331827878952026, precision: 0.28325292901445326, recall: 0.6849999999998858, f1: 0.40078010722331775\n",
            "epoch: 554, step: 7, Train: label_loss: 0.22134962677955627, precision: 0.2670807453415965, recall: 0.6660929432012622, f1: 0.38128078813644384\n",
            "epoch: 554, step: 8, Train: label_loss: 0.22226259112358093, precision: 0.23859649122805343, recall: 0.5841924398624425, f1: 0.3388141504321308\n",
            "epoch: 554, step: 9, Train: label_loss: 0.22613903880119324, precision: 0.2601794340924596, recall: 0.6455479452053688, f1: 0.37088047216757386\n",
            "epoch: 554, step: 10, Train: label_loss: 0.2359447181224823, precision: 0.25904486251807096, recall: 0.5628930817609178, f1: 0.35480673930268475\n",
            "epoch: 554, step: 11, Train: label_loss: 0.23557552695274353, precision: 0.291095890410939, recall: 0.693311582381616, f1: 0.4100337674450418\n",
            "epoch: 554, step: 12, Train: label_loss: 0.21342498064041138, precision: 0.279678068410444, recall: 0.7252173913042217, f1: 0.4036786059617258\n",
            "epoch: 554, step: 13, Train: label_loss: 0.22841407358646393, precision: 0.29067392784204965, recall: 0.7057851239668255, f1: 0.41176470584099045\n",
            "epoch: 554, step: 14, Train: label_loss: 0.2166162133216858, precision: 0.2964509394571819, recall: 0.6938110749184537, f1: 0.41540711843680117\n",
            "epoch: 554, step: 15, Train: label_loss: 0.23159337043762207, precision: 0.273054755043208, recall: 0.6337792642139408, f1: 0.3816717018712669\n",
            "epoch: 554, step: 16, Train: label_loss: 0.22302809357643127, precision: 0.3043180260452156, recall: 0.7092651757187365, f1: 0.4258992805334795\n",
            "epoch: 554, step: 17, Train: label_loss: 0.23301386833190918, precision: 0.2883561643835419, recall: 0.6981757877279107, f1: 0.4081434803269844\n",
            "epoch: 554, step: 18, Train: label_loss: 0.2286863625049591, precision: 0.27146814404430253, recall: 0.6782006920414051, f1: 0.38773491588396014\n",
            "epoch: 554, step: 19, Train: label_loss: 0.21648333966732025, precision: 0.29999999999997956, recall: 0.7159090909089746, f1: 0.4228187919046484\n",
            "epoch: 554, step: 20, Train: label_loss: 0.2061171680688858, precision: 0.31447368421050564, recall: 0.7823240589196755, f1: 0.44861567335182895\n",
            "epoch: 554, step: 21, Train: label_loss: 0.212096706032753, precision: 0.29607451763138415, recall: 0.7606837606836306, f1: 0.4262452106875933\n",
            "epoch: 554, step: 22, Train: label_loss: 0.2256171703338623, precision: 0.3056118999323661, recall: 0.7661016949151244, f1: 0.4369260511916683\n",
            "epoch: 554, step: 23, Train: label_loss: 0.2295297384262085, precision: 0.2869415807559891, recall: 0.6510721247562083, f1: 0.39833035177621107\n",
            "epoch: 555, step: 0, Train: label_loss: 0.21057116985321045, precision: 0.28678986995206796, recall: 0.7053872053870865, f1: 0.407785888036719\n",
            "epoch: 555, step: 1, Train: label_loss: 0.20678624510765076, precision: 0.3206666666666453, recall: 0.7647058823528196, f1: 0.4518553310997071\n",
            "epoch: 555, step: 2, Train: label_loss: 0.22038370370864868, precision: 0.2750853242320631, recall: 0.7082601054480301, f1: 0.39626352011698895\n",
            "epoch: 555, step: 3, Train: label_loss: 0.2216191291809082, precision: 0.2962707182320237, recall: 0.6820349761525147, f1: 0.4130958112239839\n",
            "epoch: 555, step: 4, Train: label_loss: 0.20803648233413696, precision: 0.291888297872321, recall: 0.7478705281089015, f1: 0.4198947871427419\n",
            "epoch: 555, step: 5, Train: label_loss: 0.2134772390127182, precision: 0.28360215053761534, recall: 0.7263339070566736, f1: 0.40792653451732663\n",
            "epoch: 555, step: 6, Train: label_loss: 0.20913836359977722, precision: 0.29442970822279213, recall: 0.7437185929646994, f1: 0.42185273155077374\n",
            "epoch: 555, step: 7, Train: label_loss: 0.19956114888191223, precision: 0.2956015523932538, recall: 0.7798634812285358, f1: 0.4287054408606602\n",
            "epoch: 555, step: 8, Train: label_loss: 0.20073780417442322, precision: 0.29208250166332056, recall: 0.7220394736840917, f1: 0.41591662714985295\n",
            "epoch: 555, step: 9, Train: label_loss: 0.20244678854942322, precision: 0.30618892508141327, recall: 0.7704918032785621, f1: 0.4382284381876955\n",
            "epoch: 555, step: 10, Train: label_loss: 0.19048470258712769, precision: 0.2810026385224089, recall: 0.7357512953366604, f1: 0.40668257752559556\n",
            "epoch: 555, step: 11, Train: label_loss: 0.21313899755477905, precision: 0.30865829477856516, recall: 0.7448165869217312, f1: 0.43644859808937086\n",
            "epoch: 555, step: 12, Train: label_loss: 0.1945551633834839, precision: 0.30663164806301335, recall: 0.8051724137929646, f1: 0.4441274369547806\n",
            "epoch: 555, step: 13, Train: label_loss: 0.20975501835346222, precision: 0.3219544846050655, recall: 0.7758064516127781, f1: 0.4550614947550975\n",
            "epoch: 555, step: 14, Train: label_loss: 0.19939079880714417, precision: 0.2943956785955237, recall: 0.7159277504103915, f1: 0.417224880341439\n",
            "epoch: 555, step: 15, Train: label_loss: 0.19187471270561218, precision: 0.3095854922279592, recall: 0.7861842105261865, f1: 0.44423791817503094\n",
            "epoch: 555, step: 16, Train: label_loss: 0.21490097045898438, precision: 0.30177514792897425, recall: 0.7954939341419764, f1: 0.43755958051298866\n",
            "epoch: 555, step: 17, Train: label_loss: 0.20320704579353333, precision: 0.2972793629727739, recall: 0.7308319738987388, f1: 0.42264150939281386\n",
            "epoch: 555, step: 18, Train: label_loss: 0.1906701624393463, precision: 0.29266666666664715, recall: 0.7292358803985499, f1: 0.4176974309771638\n",
            "epoch: 555, step: 19, Train: label_loss: 0.2149205505847931, precision: 0.29301075268815235, recall: 0.7043618739901931, f1: 0.41385856664095283\n",
            "epoch: 555, step: 20, Train: label_loss: 0.19360461831092834, precision: 0.3124174372522911, recall: 0.7883333333332019, f1: 0.4474929044058511\n",
            "epoch: 555, step: 21, Train: label_loss: 0.19906699657440186, precision: 0.3357958361316094, recall: 0.7836990595610056, f1: 0.4701457451389657\n",
            "epoch: 555, step: 22, Train: label_loss: 0.21170827746391296, precision: 0.3013422818791744, recall: 0.7662116040954323, f1: 0.4325626203833313\n",
            "epoch: 555, step: 23, Train: label_loss: 0.20236146450042725, precision: 0.2832512315270703, recall: 0.7324840764329655, f1: 0.4085257548442789\n",
            "epoch: 556, step: 0, Train: label_loss: 0.21239179372787476, precision: 0.3086838534599519, recall: 0.706521739130325, f1: 0.42965061374422897\n",
            "epoch: 556, step: 1, Train: label_loss: 0.19790911674499512, precision: 0.27410832232494886, recall: 0.721739130434657, f1: 0.39731929148711076\n",
            "epoch: 556, step: 2, Train: label_loss: 0.20567452907562256, precision: 0.2754766600920266, recall: 0.7363796133566368, f1: 0.40095693775937885\n",
            "epoch: 556, step: 3, Train: label_loss: 0.19828008115291595, precision: 0.29213483146065483, recall: 0.7478849407782152, f1: 0.4201520912143144\n",
            "epoch: 556, step: 4, Train: label_loss: 0.2024376392364502, precision: 0.2819672131147356, recall: 0.7491289198604966, f1: 0.40971891372868585\n",
            "epoch: 556, step: 5, Train: label_loss: 0.19599218666553497, precision: 0.3139686684072902, recall: 0.780844155844029, f1: 0.4478584729571887\n",
            "epoch: 556, step: 6, Train: label_loss: 0.19177129864692688, precision: 0.3018372703411875, recall: 0.7628524046433228, f1: 0.4325340855258596\n",
            "epoch: 556, step: 7, Train: label_loss: 0.20416304469108582, precision: 0.3142485361092834, recall: 0.7740384615383374, f1: 0.447015270666889\n",
            "epoch: 556, step: 8, Train: label_loss: 0.1968229115009308, precision: 0.3055916775032311, recall: 0.7925801011803048, f1: 0.44110746124557243\n",
            "epoch: 556, step: 9, Train: label_loss: 0.18901078402996063, precision: 0.29021879021877156, recall: 0.7670068027209579, f1: 0.4211017740030804\n",
            "epoch: 556, step: 10, Train: label_loss: 0.20556825399398804, precision: 0.3027461486938846, recall: 0.7583892617448391, f1: 0.4327429391645389\n",
            "epoch: 556, step: 11, Train: label_loss: 0.1982666254043579, precision: 0.3300198807156839, recall: 0.7892234548334723, f1: 0.46542056070603655\n",
            "epoch: 556, step: 12, Train: label_loss: 0.18718484044075012, precision: 0.31164606376055226, recall: 0.7878289473682915, f1: 0.4466200465793838\n",
            "epoch: 556, step: 13, Train: label_loss: 0.18311578035354614, precision: 0.31568627450978326, recall: 0.781553398058126, f1: 0.44972067035003305\n",
            "epoch: 556, step: 14, Train: label_loss: 0.1929243803024292, precision: 0.29656067488641813, recall: 0.8017543859647716, f1: 0.43297015628455465\n",
            "epoch: 556, step: 15, Train: label_loss: 0.19775810837745667, precision: 0.30191166776530637, recall: 0.7937608318889439, f1: 0.4374403055951819\n",
            "epoch: 556, step: 16, Train: label_loss: 0.2024485170841217, precision: 0.2884743504330254, recall: 0.7439862542954048, f1: 0.4157465194028034\n",
            "epoch: 556, step: 17, Train: label_loss: 0.19504314661026, precision: 0.3107491856677322, recall: 0.7871287128711572, f1: 0.445586174644099\n",
            "epoch: 556, step: 18, Train: label_loss: 0.19135916233062744, precision: 0.3107752956635801, recall: 0.7531847133756762, f1: 0.4399999999586041\n",
            "epoch: 556, step: 19, Train: label_loss: 0.1890142858028412, precision: 0.29603122966816553, recall: 0.7711864406778354, f1: 0.4278326280745868\n",
            "epoch: 556, step: 20, Train: label_loss: 0.19387024641036987, precision: 0.3092236230922157, recall: 0.7528271405491513, f1: 0.43838193787025287\n",
            "epoch: 556, step: 21, Train: label_loss: 0.20129787921905518, precision: 0.2690523525513407, recall: 0.7147887323942403, f1: 0.3909484833497295\n",
            "epoch: 556, step: 22, Train: label_loss: 0.17947986721992493, precision: 0.320478723404234, recall: 0.7602523659304794, f1: 0.450888680968527\n",
            "epoch: 556, step: 23, Train: label_loss: 0.1727367788553238, precision: 0.32834645669288753, recall: 0.8097087378639204, f1: 0.46722689071519524\n",
            "epoch: 557, step: 0, Train: label_loss: 0.17215746641159058, precision: 0.31513157894734767, recall: 0.7891268533771352, f1: 0.4503996238425739\n",
            "epoch: 557, step: 1, Train: label_loss: 0.17893044650554657, precision: 0.2894736842105073, recall: 0.7457627118642803, f1: 0.41706161133408143\n",
            "epoch: 557, step: 2, Train: label_loss: 0.21087515354156494, precision: 0.31522468142184334, recall: 0.7544141252005209, f1: 0.4446546830236664\n",
            "epoch: 557, step: 3, Train: label_loss: 0.19497689604759216, precision: 0.2897574123989023, recall: 0.7107438016527751, f1: 0.4116802297338251\n",
            "epoch: 557, step: 4, Train: label_loss: 0.20096024870872498, precision: 0.2867796610169297, recall: 0.6822580645160189, f1: 0.40381861571007927\n",
            "epoch: 557, step: 5, Train: label_loss: 0.18838131427764893, precision: 0.2929226736565994, recall: 0.7667238421954088, f1: 0.42389758175227477\n",
            "epoch: 557, step: 6, Train: label_loss: 0.1930568367242813, precision: 0.2919947506561488, recall: 0.7659208261616581, f1: 0.42280285031628867\n",
            "epoch: 557, step: 7, Train: label_loss: 0.1852542906999588, precision: 0.30858618463522863, recall: 0.7848932676517594, f1: 0.44300278031162377\n",
            "epoch: 557, step: 8, Train: label_loss: 0.17460089921951294, precision: 0.2910737386804469, recall: 0.7614213197968254, f1: 0.42115114642695584\n",
            "epoch: 557, step: 9, Train: label_loss: 0.18112772703170776, precision: 0.28782051282049437, recall: 0.7863397548159743, f1: 0.42139840446565724\n",
            "epoch: 557, step: 10, Train: label_loss: 0.16605046391487122, precision: 0.3063063063062866, recall: 0.7689822294021375, f1: 0.43810400364076296\n",
            "epoch: 557, step: 11, Train: label_loss: 0.18979518115520477, precision: 0.30508474576269196, recall: 0.7560581583197485, f1: 0.43474222011690955\n",
            "epoch: 557, step: 12, Train: label_loss: 0.18569901585578918, precision: 0.29453376205785886, recall: 0.7979094076653661, f1: 0.43024894312638096\n",
            "epoch: 557, step: 13, Train: label_loss: 0.16536825895309448, precision: 0.32882882882880765, recall: 0.8175999999998691, f1: 0.46902248733857715\n",
            "epoch: 557, step: 14, Train: label_loss: 0.1792905628681183, precision: 0.3280051150894931, recall: 0.8327922077920725, f1: 0.4706422017942745\n",
            "epoch: 557, step: 15, Train: label_loss: 0.1927172839641571, precision: 0.3102143757881267, recall: 0.8410256410254972, f1: 0.4532473514115321\n",
            "epoch: 557, step: 16, Train: label_loss: 0.18059198558330536, precision: 0.29255663430418816, recall: 0.7739726027395935, f1: 0.4246124940888465\n",
            "epoch: 557, step: 17, Train: label_loss: 0.1734575480222702, precision: 0.29849812265329795, recall: 0.8098471986416281, f1: 0.4362139917301502\n",
            "epoch: 557, step: 18, Train: label_loss: 0.16976478695869446, precision: 0.3065739570164155, recall: 0.7990115321250743, f1: 0.4431247144413773\n",
            "epoch: 557, step: 19, Train: label_loss: 0.18359467387199402, precision: 0.2782152230970946, recall: 0.7348353552858344, f1: 0.40361732504341347\n",
            "epoch: 557, step: 20, Train: label_loss: 0.1915106177330017, precision: 0.3039027511196223, recall: 0.7838283828381545, f1: 0.4379898570366873\n",
            "epoch: 557, step: 21, Train: label_loss: 0.16273516416549683, precision: 0.3043766578249135, recall: 0.7205651491364645, f1: 0.42797202793023237\n",
            "epoch: 557, step: 22, Train: label_loss: 0.17930054664611816, precision: 0.3112791430371574, recall: 0.8165289256196997, f1: 0.450729926967293\n",
            "epoch: 557, step: 23, Train: label_loss: 0.1731075495481491, precision: 0.3160741885625722, recall: 0.8245967741933822, f1: 0.45698324018334996\n",
            "epoch: 558, step: 0, Train: label_loss: 0.1812555491924286, precision: 0.3177387914229813, recall: 0.7964169381106194, f1: 0.4542498838421411\n",
            "epoch: 558, step: 1, Train: label_loss: 0.16412150859832764, precision: 0.324097938144309, recall: 0.8205546492657715, f1: 0.4646651269801479\n",
            "epoch: 558, step: 2, Train: label_loss: 0.17645129561424255, precision: 0.3085937499999799, recall: 0.780889621087186, f1: 0.44237050859211285\n",
            "epoch: 558, step: 3, Train: label_loss: 0.1785595566034317, precision: 0.31652839821312595, recall: 0.7961476725520391, f1: 0.4529680364889292\n",
            "epoch: 558, step: 4, Train: label_loss: 0.1797402948141098, precision: 0.29063097514338493, recall: 0.798598949211769, f1: 0.4261682242598999\n",
            "epoch: 558, step: 5, Train: label_loss: 0.17892077565193176, precision: 0.31335504885991444, recall: 0.801666666666533, f1: 0.4505854800532241\n",
            "epoch: 558, step: 6, Train: label_loss: 0.18418189883232117, precision: 0.2976653696497861, recall: 0.776649746192762, f1: 0.4303797467953418\n",
            "epoch: 558, step: 7, Train: label_loss: 0.19965240359306335, precision: 0.3022950819671933, recall: 0.7747899159662562, f1: 0.4349056603369394\n",
            "epoch: 558, step: 8, Train: label_loss: 0.18099069595336914, precision: 0.3283966516419621, recall: 0.8121019108278961, f1: 0.4676753782258009\n",
            "epoch: 558, step: 9, Train: label_loss: 0.16523154079914093, precision: 0.29827915869978977, recall: 0.8327402135229834, f1: 0.43923040822015713\n",
            "epoch: 558, step: 10, Train: label_loss: 0.18196088075637817, precision: 0.3068545803971616, recall: 0.8091216216214849, f1: 0.4449605201644528\n",
            "epoch: 558, step: 11, Train: label_loss: 0.1804453730583191, precision: 0.310802274162962, recall: 0.8186356073209952, f1: 0.45054945050951783\n",
            "epoch: 558, step: 12, Train: label_loss: 0.1713997721672058, precision: 0.3037809647978941, recall: 0.7664473684209265, f1: 0.4351073762431506\n",
            "epoch: 558, step: 13, Train: label_loss: 0.18669918179512024, precision: 0.3111821086261782, recall: 0.8143812709028738, f1: 0.45030050851288733\n",
            "epoch: 558, step: 14, Train: label_loss: 0.19187748432159424, precision: 0.29829172141916566, recall: 0.7841105354057367, f1: 0.4321751546482751\n",
            "epoch: 558, step: 15, Train: label_loss: 0.19486534595489502, precision: 0.309291747888219, recall: 0.7777777777776507, f1: 0.44258484421772976\n",
            "epoch: 558, step: 16, Train: label_loss: 0.176763653755188, precision: 0.3079847908745052, recall: 0.7993421052630264, f1: 0.4446477584227503\n",
            "epoch: 558, step: 17, Train: label_loss: 0.18120628595352173, precision: 0.2815099168265975, recall: 0.7692307692306347, f1: 0.4121779859092118\n",
            "epoch: 558, step: 18, Train: label_loss: 0.18501579761505127, precision: 0.3035943517329715, recall: 0.7896494156926894, f1: 0.43857209082678755\n",
            "epoch: 558, step: 19, Train: label_loss: 0.1707032322883606, precision: 0.3024611398963535, recall: 0.769357495881257, f1: 0.4342166433811118\n",
            "epoch: 558, step: 20, Train: label_loss: 0.18137353658676147, precision: 0.30618686868684936, recall: 0.8220338983049453, f1: 0.44618215267430295\n",
            "epoch: 558, step: 21, Train: label_loss: 0.16464222967624664, precision: 0.31149646756581173, recall: 0.8137583892616084, f1: 0.4505341383714385\n",
            "epoch: 558, step: 22, Train: label_loss: 0.19073180854320526, precision: 0.3303399615137697, recall: 0.8110236220471163, f1: 0.46946216951215275\n",
            "epoch: 558, step: 23, Train: label_loss: 0.19695690274238586, precision: 0.32432432432429775, recall: 0.7644787644786168, f1: 0.4554341575199359\n",
            "epoch: 559, step: 0, Train: label_loss: 0.157437264919281, precision: 0.31658291457284443, recall: 0.8289473684209162, f1: 0.45818181814177916\n",
            "epoch: 559, step: 1, Train: label_loss: 0.183515727519989, precision: 0.3017186505410374, recall: 0.8186528497407912, f1: 0.44093023251874275\n",
            "epoch: 559, step: 2, Train: label_loss: 0.1798456907272339, precision: 0.2942332896461144, recall: 0.7675213675212362, f1: 0.4253908100025286\n",
            "epoch: 559, step: 3, Train: label_loss: 0.1849195659160614, precision: 0.3049504950494848, recall: 0.7524429967425484, f1: 0.43400657581612423\n",
            "epoch: 559, step: 4, Train: label_loss: 0.1736428439617157, precision: 0.3116634799234983, recall: 0.814999999999864, f1: 0.45089903177183255\n",
            "epoch: 559, step: 5, Train: label_loss: 0.1955259144306183, precision: 0.29481286933681583, recall: 0.7571669477233124, f1: 0.4243856332299396\n",
            "epoch: 559, step: 6, Train: label_loss: 0.1673634946346283, precision: 0.2864353312302658, recall: 0.8078291814945181, f1: 0.42291569628175935\n",
            "epoch: 559, step: 7, Train: label_loss: 0.1715865433216095, precision: 0.31974110032360387, recall: 0.7878787878786622, f1: 0.45488029461818996\n",
            "epoch: 559, step: 8, Train: label_loss: 0.16817855834960938, precision: 0.3021032504779922, recall: 0.8229166666665237, f1: 0.44195804191871624\n",
            "epoch: 559, step: 9, Train: label_loss: 0.1830415427684784, precision: 0.2934640522875625, recall: 0.7675213675212362, f1: 0.42458628837601736\n",
            "epoch: 559, step: 10, Train: label_loss: 0.17143496870994568, precision: 0.29709228824271194, recall: 0.8145580589253354, f1: 0.43538675308724134\n",
            "epoch: 559, step: 11, Train: label_loss: 0.1562165766954422, precision: 0.3369152970922669, recall: 0.8174846625765617, f1: 0.47717099369183624\n",
            "epoch: 559, step: 12, Train: label_loss: 0.17837414145469666, precision: 0.30947775628624696, recall: 0.7960199004973804, f1: 0.44568245121312544\n",
            "epoch: 559, step: 13, Train: label_loss: 0.16106896102428436, precision: 0.338896020539131, recall: 0.8198757763973882, f1: 0.47956403265611847\n",
            "epoch: 559, step: 14, Train: label_loss: 0.1729530245065689, precision: 0.32531645569618195, recall: 0.8210862619806995, f1: 0.46600181319593603\n",
            "epoch: 559, step: 15, Train: label_loss: 0.1790304183959961, precision: 0.29134860050888733, recall: 0.8049209138838656, f1: 0.4278374590921805\n",
            "epoch: 559, step: 16, Train: label_loss: 0.1830546259880066, precision: 0.30109606705349445, recall: 0.7770382695506194, f1: 0.4340148698481794\n",
            "epoch: 559, step: 17, Train: label_loss: 0.15868526697158813, precision: 0.3233270794246202, recall: 0.843393148450107, f1: 0.46745027120763194\n",
            "epoch: 559, step: 18, Train: label_loss: 0.18066498637199402, precision: 0.3116634799234983, recall: 0.7887096774192276, f1: 0.44677935126132107\n",
            "epoch: 559, step: 19, Train: label_loss: 0.1795232892036438, precision: 0.30838709677417364, recall: 0.7940199335546854, f1: 0.4442379181752751\n",
            "epoch: 559, step: 20, Train: label_loss: 0.1808704137802124, precision: 0.3041269841269648, recall: 0.8104906937392875, f1: 0.4422899353250058\n",
            "epoch: 559, step: 21, Train: label_loss: 0.17363572120666504, precision: 0.2969657843769983, recall: 0.8084358523724413, f1: 0.4343720490635909\n",
            "epoch: 559, step: 22, Train: label_loss: 0.17208510637283325, precision: 0.31688804554077693, recall: 0.8093699515346027, f1: 0.4554545454140644\n",
            "epoch: 559, step: 23, Train: label_loss: 0.1794431358575821, precision: 0.32100708103852704, recall: 0.8095238095236489, f1: 0.4597183098184392\n",
            "epoch: 560, step: 0, Train: label_loss: 0.15964767336845398, precision: 0.31217948717946714, recall: 0.8116666666665313, f1: 0.4509259258857607\n",
            "epoch: 560, step: 1, Train: label_loss: 0.17549234628677368, precision: 0.3116548615582542, recall: 0.8053244592344749, f1: 0.44939647164031926\n",
            "epoch: 560, step: 2, Train: label_loss: 0.15570731461048126, precision: 0.30817610062891143, recall: 0.8291032148898766, f1: 0.4493351673148737\n",
            "epoch: 560, step: 3, Train: label_loss: 0.1508655846118927, precision: 0.30211674150094275, recall: 0.7798013245031821, f1: 0.4355062412911906\n",
            "epoch: 560, step: 4, Train: label_loss: 0.18098877370357513, precision: 0.3159235668789608, recall: 0.7948717948716675, f1: 0.45214220597566285\n",
            "epoch: 560, step: 5, Train: label_loss: 0.1502225399017334, precision: 0.32994923857865927, recall: 0.8049535603713923, f1: 0.46804680463918474\n",
            "epoch: 560, step: 6, Train: label_loss: 0.16763588786125183, precision: 0.3163841807909406, recall: 0.841402337228574, f1: 0.4598540145587798\n",
            "epoch: 560, step: 7, Train: label_loss: 0.16370849311351776, precision: 0.31893265565436346, recall: 0.8408710217754035, f1: 0.46245969595271347\n",
            "epoch: 560, step: 8, Train: label_loss: 0.1636180877685547, precision: 0.3234365129500743, recall: 0.8311688311686962, f1: 0.46566621187413304\n",
            "epoch: 560, step: 9, Train: label_loss: 0.1569785475730896, precision: 0.307883302296691, recall: 0.8626086956520238, f1: 0.45379688925670564\n",
            "epoch: 560, step: 10, Train: label_loss: 0.18105146288871765, precision: 0.3131832797427451, recall: 0.8023064250410539, f1: 0.45050878811868356\n",
            "epoch: 560, step: 11, Train: label_loss: 0.15078091621398926, precision: 0.31518987341770155, recall: 0.790476190476065, f1: 0.4506787329908726\n",
            "epoch: 560, step: 12, Train: label_loss: 0.16104617714881897, precision: 0.3118279569892276, recall: 0.8244147157189257, f1: 0.4525011472754163\n",
            "epoch: 560, step: 13, Train: label_loss: 0.15927231311798096, precision: 0.293601003764097, recall: 0.8082901554402748, f1: 0.43074091114356594\n",
            "epoch: 560, step: 14, Train: label_loss: 0.169345423579216, precision: 0.3024888321633502, recall: 0.8130360205830509, f1: 0.4409302325185718\n",
            "epoch: 560, step: 15, Train: label_loss: 0.17751577496528625, precision: 0.32546266751752867, recall: 0.8279220779219435, f1: 0.4672469078843203\n",
            "epoch: 560, step: 16, Train: label_loss: 0.15858137607574463, precision: 0.3050738599871352, recall: 0.8203799654575439, f1: 0.44475655426755645\n",
            "epoch: 560, step: 17, Train: label_loss: 0.16713941097259521, precision: 0.3105196451203859, recall: 0.8333333333331916, f1: 0.45244690670093907\n",
            "epoch: 560, step: 18, Train: label_loss: 0.17800989747047424, precision: 0.2985359643538957, recall: 0.8030821917806843, f1: 0.4352668213061556\n",
            "epoch: 560, step: 19, Train: label_loss: 0.166400745511055, precision: 0.30496453900707254, recall: 0.7728758169933377, f1: 0.4373555246935481\n",
            "epoch: 560, step: 20, Train: label_loss: 0.15176308155059814, precision: 0.3008233058897846, recall: 0.8246527777776346, f1: 0.440835266782136\n",
            "epoch: 560, step: 21, Train: label_loss: 0.1822817325592041, precision: 0.3378817413904914, recall: 0.7963246554363251, f1: 0.47445255470265096\n",
            "epoch: 560, step: 22, Train: label_loss: 0.1793779581785202, precision: 0.30064102564100637, recall: 0.7949152542371534, f1: 0.43627906972757863\n",
            "epoch: 560, step: 23, Train: label_loss: 0.17283475399017334, precision: 0.2929532858273719, recall: 0.7855626326962238, f1: 0.4267589388300472\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-4a8faa9f8476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n\u001b[0;32m----> 2\u001b[0;31m     ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=1000)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-2bdfda04bc2a>\u001b[0m in \u001b[0;36mtrain_s\u001b[0;34m(model_self, model_ngb, graph, ppi_list, loss_fn, optimizer_self, optimizer_ngb, device, result_file_pathr, summary_writerr, save_path, scheduler1, scheduler2, batch_size, epochs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         torch.save({'epoch': epoch,\n\u001b[1;32m    130\u001b[0m                     'state_dict': model_self.state_dict()},\n\u001b[0;32m--> 131\u001b[0;31m                     os.path.join(save_path, 'gnn_model_self_train.ckpt'))\n\u001b[0m\u001b[1;32m    132\u001b[0m         torch.save({'epoch': epoch,\n\u001b[1;32m    133\u001b[0m                     'state_dict': model_ngb.state_dict()},\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/GNN_PPI/save_model/gnn_test_string_bfs_2022-04-23 07:08:42/gnn_model_self_train.ckpt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n",
        "    ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=1000)\n",
        "summary_writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lo0phgW8tg3v",
        "outputId": "49e89fa7-2df9-4e18-f9f8-4824e1b788df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 561, step: 0, Train: label_loss: 0.17397761344909668, precision: 0.2951959544879712, recall: 0.8294849023089113, f1: 0.4354312353924788\n",
            "epoch: 561, step: 1, Train: label_loss: 0.1490950882434845, precision: 0.3208489388264469, recall: 0.8184713375794874, f1: 0.46098654704469894\n",
            "epoch: 561, step: 2, Train: label_loss: 0.17119356989860535, precision: 0.32111251580276096, recall: 0.8246753246751908, f1: 0.4622383985037465\n",
            "epoch: 561, step: 3, Train: label_loss: 0.18748652935028076, precision: 0.2971729125575084, recall: 0.7793103448274518, f1: 0.430271299341236\n",
            "epoch: 561, step: 4, Train: label_loss: 0.1606064885854721, precision: 0.30459057071958406, recall: 0.8421955403086033, f1: 0.4473804099837266\n",
            "epoch: 561, step: 5, Train: label_loss: 0.17245075106620789, precision: 0.3130990415335263, recall: 0.8193979933108997, f1: 0.45307443361690936\n",
            "epoch: 561, step: 6, Train: label_loss: 0.15824458003044128, precision: 0.302063789868649, recall: 0.838541666666521, f1: 0.4441379309955031\n",
            "epoch: 561, step: 7, Train: label_loss: 0.1645943969488144, precision: 0.3180100755667306, recall: 0.8118971061091942, f1: 0.45701357462014514\n",
            "epoch: 561, step: 8, Train: label_loss: 0.16132572293281555, precision: 0.31202531645567644, recall: 0.8216666666665297, f1: 0.4522935779417142\n",
            "epoch: 561, step: 9, Train: label_loss: 0.15312623977661133, precision: 0.32599118942729227, recall: 0.8183254344390491, f1: 0.4662466246216797\n",
            "epoch: 561, step: 10, Train: label_loss: 0.16011732816696167, precision: 0.31763208147674615, recall: 0.8113821138210062, f1: 0.45654162850480917\n",
            "epoch: 561, step: 11, Train: label_loss: 0.15526555478572845, precision: 0.3034920634920442, recall: 0.8087986463619612, f1: 0.4413665742908416\n",
            "epoch: 561, step: 12, Train: label_loss: 0.16757220029830933, precision: 0.3108709472345638, recall: 0.7990196078430066, f1: 0.44759725396420763\n",
            "epoch: 561, step: 13, Train: label_loss: 0.13163524866104126, precision: 0.3404255319148729, recall: 0.8805031446539495, f1: 0.4910127136817922\n",
            "epoch: 561, step: 14, Train: label_loss: 0.16585476696491241, precision: 0.32478097622025504, recall: 0.8550247116967289, f1: 0.47074829927978473\n",
            "epoch: 561, step: 15, Train: label_loss: 0.16245628893375397, precision: 0.285624211853702, recall: 0.8176895306857729, f1: 0.4233644859428968\n",
            "epoch: 561, step: 16, Train: label_loss: 0.16294750571250916, precision: 0.31164807930605254, recall: 0.8468013468012042, f1: 0.45561594198961447\n",
            "epoch: 561, step: 17, Train: label_loss: 0.15127307176589966, precision: 0.29156327543422506, recall: 0.8348134991117522, f1: 0.43218390800756784\n",
            "epoch: 561, step: 18, Train: label_loss: 0.14194035530090332, precision: 0.3240740740740541, recall: 0.8578431372547617, f1: 0.47043010748703734\n",
            "epoch: 561, step: 19, Train: label_loss: 0.14245346188545227, precision: 0.31238447319776264, recall: 0.8535353535352098, f1: 0.4573748308132335\n",
            "epoch: 561, step: 20, Train: label_loss: 0.14416582882404327, precision: 0.3302063789868461, recall: 0.8328075709777866, f1: 0.47290640390018224\n",
            "epoch: 561, step: 21, Train: label_loss: 0.1506567895412445, precision: 0.32306725329979114, recall: 0.8453947368419662, f1: 0.46748522051474656\n",
            "epoch: 561, step: 22, Train: label_loss: 0.15327417850494385, precision: 0.32124999999997994, recall: 0.8653198653197196, f1: 0.46855059248553793\n",
            "epoch: 561, step: 23, Train: label_loss: 0.1501133143901825, precision: 0.3338509316769927, recall: 0.8498023715413341, f1: 0.47937569672644803\n",
            "epoch: 562, step: 0, Train: label_loss: 0.15385684370994568, precision: 0.30678282513999333, recall: 0.8327702702701295, f1: 0.4483856297923534\n",
            "epoch: 562, step: 1, Train: label_loss: 0.1456858217716217, precision: 0.30212234706614843, recall: 0.8461538461536982, f1: 0.4452621894736019\n",
            "epoch: 562, step: 2, Train: label_loss: 0.16707322001457214, precision: 0.2937817258883062, recall: 0.7834179357020671, f1: 0.42731887397967266\n",
            "epoch: 562, step: 3, Train: label_loss: 0.14033368229866028, precision: 0.30222496909763275, recall: 0.8218487394956602, f1: 0.441934026169411\n",
            "epoch: 562, step: 4, Train: label_loss: 0.1575443148612976, precision: 0.3075941289087232, recall: 0.7875816993462765, f1: 0.4424047727911377\n",
            "epoch: 562, step: 5, Train: label_loss: 0.16439947485923767, precision: 0.30949367088605634, recall: 0.7836538461537205, f1: 0.44373865694666276\n",
            "epoch: 562, step: 6, Train: label_loss: 0.1426522582769394, precision: 0.2899813316739085, recall: 0.8062283737022826, f1: 0.42654462238667934\n",
            "epoch: 562, step: 7, Train: label_loss: 0.1666543185710907, precision: 0.3266205160478083, recall: 0.8225039619650043, f1: 0.4675675675268365\n",
            "epoch: 562, step: 8, Train: label_loss: 0.1564972698688507, precision: 0.3139825218476708, recall: 0.8205546492657715, f1: 0.4541760721946902\n",
            "epoch: 562, step: 9, Train: label_loss: 0.139400452375412, precision: 0.32942628007400804, recall: 0.8599033816423736, f1: 0.4763603924665951\n",
            "epoch: 562, step: 10, Train: label_loss: 0.15245285630226135, precision: 0.31472081218272113, recall: 0.8051948051946745, f1: 0.45255474448509636\n",
            "epoch: 562, step: 11, Train: label_loss: 0.1407943069934845, precision: 0.31871525633104886, recall: 0.8775510204080139, f1: 0.4676030810664422\n",
            "epoch: 562, step: 12, Train: label_loss: 0.15072134137153625, precision: 0.31582238899310094, recall: 0.8617747440271566, f1: 0.4622425628897664\n",
            "epoch: 562, step: 13, Train: label_loss: 0.14947105944156647, precision: 0.3507371007370792, recall: 0.87042682926816, f1: 0.4999999999590116\n",
            "epoch: 562, step: 14, Train: label_loss: 0.1489977240562439, precision: 0.30759573132452556, recall: 0.8263069139964879, f1: 0.44830741075639663\n",
            "epoch: 562, step: 15, Train: label_loss: 0.15175026655197144, precision: 0.30677540777915263, recall: 0.8519163763064718, f1: 0.4511070110311366\n",
            "epoch: 562, step: 16, Train: label_loss: 0.14306950569152832, precision: 0.32188841201714763, recall: 0.8808724832213286, f1: 0.4714863044061996\n",
            "epoch: 562, step: 17, Train: label_loss: 0.17579729855060577, precision: 0.299999999999981, recall: 0.8257839721252916, f1: 0.4401114205736787\n",
            "epoch: 562, step: 18, Train: label_loss: 0.17095109820365906, precision: 0.30107526881718527, recall: 0.8221070811742966, f1: 0.4407407407014596\n",
            "epoch: 562, step: 19, Train: label_loss: 0.16316089034080505, precision: 0.31893265565436346, recall: 0.7917981072553956, f1: 0.4547101448865571\n",
            "epoch: 562, step: 20, Train: label_loss: 0.15920189023017883, precision: 0.3221730890713631, recall: 0.804416403785362, f1: 0.4600811907574962\n",
            "epoch: 562, step: 21, Train: label_loss: 0.167836993932724, precision: 0.3048703352308472, recall: 0.8169491525422343, f1: 0.44403500686963576\n",
            "epoch: 562, step: 22, Train: label_loss: 0.17271772027015686, precision: 0.29798308392971384, recall: 0.7736486486485179, f1: 0.43024894312561607\n",
            "epoch: 562, step: 23, Train: label_loss: 0.16562531888484955, precision: 0.2992187499999766, recall: 0.8012552301253554, f1: 0.4357224117919832\n",
            "epoch: 563, step: 0, Train: label_loss: 0.15896138548851013, precision: 0.29252577319585743, recall: 0.7773972602738394, f1: 0.42509363291903046\n",
            "epoch: 563, step: 1, Train: label_loss: 0.17465734481811523, precision: 0.3067678684376782, recall: 0.8110367892975232, f1: 0.44515832946908385\n",
            "epoch: 563, step: 2, Train: label_loss: 0.17292633652687073, precision: 0.30142302716686276, recall: 0.7715231788078192, f1: 0.43348837205258123\n",
            "epoch: 563, step: 3, Train: label_loss: 0.16560989618301392, precision: 0.30652311589611736, recall: 0.8120805369126154, f1: 0.44505747122454004\n",
            "epoch: 563, step: 4, Train: label_loss: 0.15307646989822388, precision: 0.3341630367143538, recall: 0.8510301109348889, f1: 0.4798927613535683\n",
            "epoch: 563, step: 5, Train: label_loss: 0.1589972823858261, precision: 0.3097514340343971, recall: 0.8059701492535977, f1: 0.4475138121145451\n",
            "epoch: 563, step: 6, Train: label_loss: 0.16204965114593506, precision: 0.31464968152864237, recall: 0.8006482982170501, f1: 0.4517604023371391\n",
            "epoch: 563, step: 7, Train: label_loss: 0.1514628529548645, precision: 0.30656469088589505, recall: 0.8084033613444019, f1: 0.4445471348953931\n",
            "epoch: 563, step: 8, Train: label_loss: 0.14459572732448578, precision: 0.29956222639147595, recall: 0.8216123499140957, f1: 0.43904674606529154\n",
            "epoch: 563, step: 9, Train: label_loss: 0.1581750065088272, precision: 0.32238065716055037, recall: 0.8510638297870947, f1: 0.46762589924068276\n",
            "epoch: 563, step: 10, Train: label_loss: 0.16160345077514648, precision: 0.3104738154613273, recall: 0.8383838383836972, f1: 0.4531392174309439\n",
            "epoch: 563, step: 11, Train: label_loss: 0.15683475136756897, precision: 0.31969792322213214, recall: 0.8382838283826999, f1: 0.4628701594132885\n",
            "epoch: 563, step: 12, Train: label_loss: 0.14428925514221191, precision: 0.3006948831332722, recall: 0.7906976744184733, f1: 0.43569794046347127\n",
            "epoch: 563, step: 13, Train: label_loss: 0.13813528418540955, precision: 0.2983770287140887, recall: 0.8129251700678889, f1: 0.436529680325976\n",
            "epoch: 563, step: 14, Train: label_loss: 0.1750442385673523, precision: 0.33249843456478817, recall: 0.841521394611594, f1: 0.47666068218556834\n",
            "epoch: 563, step: 15, Train: label_loss: 0.1621866077184677, precision: 0.30608365019009465, recall: 0.8242320819111221, f1: 0.44639556373126055\n",
            "epoch: 563, step: 16, Train: label_loss: 0.13180246949195862, precision: 0.30989421281889795, recall: 0.8483816013627175, f1: 0.4539653600336916\n",
            "epoch: 563, step: 17, Train: label_loss: 0.13805019855499268, precision: 0.33477722772275154, recall: 0.8868852459014939, f1: 0.4860736747130885\n",
            "epoch: 563, step: 18, Train: label_loss: 0.14662817120552063, precision: 0.2972972972972786, recall: 0.825479930191828, f1: 0.4371534195543702\n",
            "epoch: 563, step: 19, Train: label_loss: 0.14430730044841766, precision: 0.31192093885112343, recall: 0.8530405405403964, f1: 0.45680687467806896\n",
            "epoch: 563, step: 20, Train: label_loss: 0.1443556845188141, precision: 0.3117610454262407, recall: 0.8015999999998716, f1: 0.44892473114243386\n",
            "epoch: 563, step: 21, Train: label_loss: 0.14847123622894287, precision: 0.2954264524103649, recall: 0.8475177304963035, f1: 0.4381301557819747\n",
            "epoch: 563, step: 22, Train: label_loss: 0.14164671301841736, precision: 0.33123821495912437, recall: 0.8170542635657647, f1: 0.4713774597084603\n",
            "epoch: 563, step: 23, Train: label_loss: 0.14600521326065063, precision: 0.3069230769230533, recall: 0.8076923076921442, f1: 0.44481605347174846\n",
            "epoch: 564, step: 0, Train: label_loss: 0.1280520260334015, precision: 0.3274173806609347, recall: 0.8465189873416381, f1: 0.47219770516714876\n",
            "epoch: 564, step: 1, Train: label_loss: 0.15993955731391907, precision: 0.29956222639147595, recall: 0.8272884283245548, f1: 0.4398530761776383\n",
            "epoch: 564, step: 2, Train: label_loss: 0.14401786029338837, precision: 0.30661577608140544, recall: 0.8006644518271094, f1: 0.4434222630693887\n",
            "epoch: 564, step: 3, Train: label_loss: 0.15466538071632385, precision: 0.3042659974905706, recall: 0.8290598290596872, f1: 0.4451583294696293\n",
            "epoch: 564, step: 4, Train: label_loss: 0.14920511841773987, precision: 0.2995566814439329, recall: 0.7962962962961622, f1: 0.43534284395471123\n",
            "epoch: 564, step: 5, Train: label_loss: 0.16963575780391693, precision: 0.3049967553536467, recall: 0.7667210440455519, f1: 0.4363974001449411\n",
            "epoch: 564, step: 6, Train: label_loss: 0.16102616488933563, precision: 0.32425585813804153, recall: 0.811410459587827, f1: 0.46334841624875106\n",
            "epoch: 564, step: 7, Train: label_loss: 0.16595132648944855, precision: 0.2913782252989118, recall: 0.8094405594404178, f1: 0.4285053215713998\n",
            "epoch: 564, step: 8, Train: label_loss: 0.1549602746963501, precision: 0.32787916928884026, recall: 0.8444084278766865, f1: 0.4723481413921212\n",
            "epoch: 564, step: 9, Train: label_loss: 0.1524619460105896, precision: 0.32227784730911624, recall: 0.8306451612901885, f1: 0.46438232637987775\n",
            "epoch: 564, step: 10, Train: label_loss: 0.1382674276828766, precision: 0.32514177693759766, recall: 0.8445171849425785, f1: 0.4695177433629096\n",
            "epoch: 564, step: 11, Train: label_loss: 0.13231651484966278, precision: 0.3425814234016681, recall: 0.9001584786052456, f1: 0.49628658798972897\n",
            "epoch: 564, step: 12, Train: label_loss: 0.14663317799568176, precision: 0.3039950062421783, recall: 0.836769759450028, f1: 0.44597069593156113\n",
            "epoch: 564, step: 13, Train: label_loss: 0.16723313927650452, precision: 0.3107769423558702, recall: 0.8364249578413429, f1: 0.4531749656982357\n",
            "epoch: 564, step: 14, Train: label_loss: 0.14657652378082275, precision: 0.3154651879235788, recall: 0.8648648648647187, f1: 0.46230248303076843\n",
            "epoch: 564, step: 15, Train: label_loss: 0.14492762088775635, precision: 0.3063291139240312, recall: 0.8120805369126154, f1: 0.4448529411366542\n",
            "epoch: 564, step: 16, Train: label_loss: 0.15261265635490417, precision: 0.29576587795764037, recall: 0.8275261324040369, f1: 0.43577981647492664\n",
            "epoch: 564, step: 17, Train: label_loss: 0.14595209062099457, precision: 0.3154320987654126, recall: 0.8418451400328102, f1: 0.4589133362872014\n",
            "epoch: 564, step: 18, Train: label_loss: 0.14696112275123596, precision: 0.31087762669960994, recall: 0.8525423728812114, f1: 0.45561594198978234\n",
            "epoch: 564, step: 19, Train: label_loss: 0.14794182777404785, precision: 0.2960858585858399, recall: 0.8242530755710326, f1: 0.43567115648685006\n",
            "epoch: 564, step: 20, Train: label_loss: 0.13341523706912994, precision: 0.33557457212711883, recall: 0.8511627906975424, f1: 0.4813678210904783\n",
            "epoch: 564, step: 21, Train: label_loss: 0.13487793505191803, precision: 0.3049159925326506, recall: 0.8277027027025629, f1: 0.44565711683191706\n",
            "epoch: 564, step: 22, Train: label_loss: 0.1339794248342514, precision: 0.3162762022194626, recall: 0.8423645320195661, f1: 0.4598834602919569\n",
            "epoch: 564, step: 23, Train: label_loss: 0.14101791381835938, precision: 0.29663608562688865, recall: 0.8033126293994196, f1: 0.43327749856469266\n",
            "epoch: 565, step: 0, Train: label_loss: 0.1445341259241104, precision: 0.3094645080946258, recall: 0.8311036789296269, f1: 0.4509981850783849\n",
            "epoch: 565, step: 1, Train: label_loss: 0.13909180462360382, precision: 0.31202531645567644, recall: 0.8081967213113429, f1: 0.450228310462051\n",
            "epoch: 565, step: 2, Train: label_loss: 0.14878380298614502, precision: 0.3053670573719737, recall: 0.8476027397258822, f1: 0.4489795917977528\n",
            "epoch: 565, step: 3, Train: label_loss: 0.12812098860740662, precision: 0.2993865030674663, recall: 0.874551971326008, f1: 0.4460694697974276\n",
            "epoch: 565, step: 4, Train: label_loss: 0.13318759202957153, precision: 0.32447466007414555, recall: 0.8578431372547617, f1: 0.47085201789735304\n",
            "epoch: 565, step: 5, Train: label_loss: 0.14121413230895996, precision: 0.30945027794933233, recall: 0.8534923339010471, f1: 0.4542157751195596\n",
            "epoch: 565, step: 6, Train: label_loss: 0.1232510507106781, precision: 0.30923450789791557, recall: 0.8867595818813786, f1: 0.458558558520176\n",
            "epoch: 565, step: 7, Train: label_loss: 0.13033881783485413, precision: 0.3341493268053651, recall: 0.8778135048230099, f1: 0.4840425531515076\n",
            "epoch: 565, step: 8, Train: label_loss: 0.13805121183395386, precision: 0.31500926497836224, recall: 0.8457711442784667, f1: 0.4590459045508714\n",
            "epoch: 565, step: 9, Train: label_loss: 0.13418304920196533, precision: 0.30212234706614843, recall: 0.8273504273502859, f1: 0.4426154549219057\n",
            "epoch: 565, step: 10, Train: label_loss: 0.13230153918266296, precision: 0.303690260133073, recall: 0.8715277777776264, f1: 0.45042620005135886\n",
            "epoch: 565, step: 11, Train: label_loss: 0.1389545351266861, precision: 0.33598045204640586, recall: 0.863422291993585, f1: 0.483729111657076\n",
            "epoch: 565, step: 12, Train: label_loss: 0.13140207529067993, precision: 0.29896278218424044, recall: 0.8566433566432068, f1: 0.4432383536477193\n",
            "epoch: 565, step: 13, Train: label_loss: 0.1440676748752594, precision: 0.3495985176034373, recall: 0.8654434250763202, f1: 0.4980202375304596\n",
            "epoch: 565, step: 14, Train: label_loss: 0.12462975084781647, precision: 0.32269717037927015, recall: 0.881578947368276, f1: 0.47245482587522675\n",
            "epoch: 565, step: 15, Train: label_loss: 0.1332765519618988, precision: 0.31364190012178356, recall: 0.8818493150683421, f1: 0.46271338720294264\n",
            "epoch: 565, step: 16, Train: label_loss: 0.13265511393547058, precision: 0.31391784181481824, recall: 0.8707482993195798, f1: 0.4614691301998512\n",
            "epoch: 565, step: 17, Train: label_loss: 0.13558410108089447, precision: 0.33454766241649453, recall: 0.8858520900320118, f1: 0.4856765094357005\n",
            "epoch: 565, step: 18, Train: label_loss: 0.12679189443588257, precision: 0.33251079580503806, recall: 0.8488188976376615, f1: 0.47783687939213265\n",
            "epoch: 565, step: 19, Train: label_loss: 0.12911581993103027, precision: 0.3337423312883231, recall: 0.871794871794732, f1: 0.48269742675672284\n",
            "epoch: 565, step: 20, Train: label_loss: 0.12412893772125244, precision: 0.32331288343556297, recall: 0.8555194805193416, f1: 0.46927871768054125\n",
            "epoch: 565, step: 21, Train: label_loss: 0.14195285737514496, precision: 0.307836990595592, recall: 0.8129139072846335, f1: 0.4465666211515648\n",
            "epoch: 565, step: 22, Train: label_loss: 0.13924150168895721, precision: 0.3124999999999806, recall: 0.8360927152316496, f1: 0.4549549549153042\n",
            "epoch: 565, step: 23, Train: label_loss: 0.1364353746175766, precision: 0.2893553223388089, recall: 0.8354978354976547, f1: 0.42984409795728445\n",
            "epoch: 566, step: 0, Train: label_loss: 0.12404640763998032, precision: 0.3453670276774762, recall: 0.9213483146065936, f1: 0.5024070021484777\n",
            "epoch: 566, step: 1, Train: label_loss: 0.119045190513134, precision: 0.3203647416413179, recall: 0.881270903009886, f1: 0.469906375350955\n",
            "epoch: 566, step: 2, Train: label_loss: 0.12065628916025162, precision: 0.3086876155267832, recall: 0.8505942275041, f1: 0.45298372509650847\n",
            "epoch: 566, step: 3, Train: label_loss: 0.1172764003276825, precision: 0.3052503052502866, recall: 0.8591065292094743, f1: 0.4504504504117232\n",
            "epoch: 566, step: 4, Train: label_loss: 0.12163244187831879, precision: 0.3261933904528564, recall: 0.876644736841961, f1: 0.4754683318069942\n",
            "epoch: 566, step: 5, Train: label_loss: 0.11735731363296509, precision: 0.3361858190708841, recall: 0.871632329635361, f1: 0.4852227613184073\n",
            "epoch: 566, step: 6, Train: label_loss: 0.13413837552070618, precision: 0.31449631449629517, recall: 0.8605042016805275, f1: 0.4606387763890054\n",
            "epoch: 566, step: 7, Train: label_loss: 0.10235511511564255, precision: 0.3132166566083094, recall: 0.8979238754323705, f1: 0.46442953016295424\n",
            "epoch: 566, step: 8, Train: label_loss: 0.12623271346092224, precision: 0.30577507598782333, recall: 0.8672413793101952, f1: 0.4521348314220888\n",
            "epoch: 566, step: 9, Train: label_loss: 0.13887323439121246, precision: 0.3341553637484381, recall: 0.8589540412043012, f1: 0.4811362627203944\n",
            "epoch: 566, step: 10, Train: label_loss: 0.14998388290405273, precision: 0.31871525633104886, recall: 0.8790459965926951, f1: 0.4678150498249073\n",
            "epoch: 566, step: 11, Train: label_loss: 0.12144924700260162, precision: 0.3094801223241401, recall: 0.8605442176869285, f1: 0.4552406657280319\n",
            "epoch: 566, step: 12, Train: label_loss: 0.11228896677494049, precision: 0.31279904306218226, recall: 0.8804713804712322, f1: 0.46160635477151346\n",
            "epoch: 566, step: 13, Train: label_loss: 0.13334839046001434, precision: 0.3075471698113014, recall: 0.8274111675125503, f1: 0.4484181567692525\n",
            "epoch: 566, step: 14, Train: label_loss: 0.13895124197006226, precision: 0.3105781057810387, recall: 0.8305921052630212, f1: 0.45210384955747723\n",
            "epoch: 566, step: 15, Train: label_loss: 0.14539286494255066, precision: 0.32498472816125074, recall: 0.8580645161288938, f1: 0.47142224187415527\n",
            "epoch: 566, step: 16, Train: label_loss: 0.1491764336824417, precision: 0.30415890751084396, recall: 0.8085808580856751, f1: 0.4420387911194591\n",
            "epoch: 566, step: 17, Train: label_loss: 0.1327441930770874, precision: 0.30806845965768287, recall: 0.8499156829678162, f1: 0.4522207267442178\n",
            "epoch: 566, step: 18, Train: label_loss: 0.1281328797340393, precision: 0.3207776427703329, recall: 0.8557536466773329, f1: 0.46663720720731383\n",
            "epoch: 566, step: 19, Train: label_loss: 0.13179278373718262, precision: 0.33040752351095104, recall: 0.8499999999998629, f1: 0.47584650108831306\n",
            "epoch: 566, step: 20, Train: label_loss: 0.13877996802330017, precision: 0.3074999999999808, recall: 0.8282828282826887, f1: 0.44849589786384414\n",
            "epoch: 566, step: 21, Train: label_loss: 0.13686859607696533, precision: 0.33230958230956187, recall: 0.8796747967478243, f1: 0.482389656669919\n",
            "epoch: 566, step: 22, Train: label_loss: 0.13457800447940826, precision: 0.32078853046593064, recall: 0.9086294416242117, f1: 0.47417218539185285\n",
            "epoch: 566, step: 23, Train: label_loss: 0.12761232256889343, precision: 0.3100600600600368, recall: 0.8604166666664874, f1: 0.4558498895857281\n",
            "epoch: 567, step: 0, Train: label_loss: 0.13477003574371338, precision: 0.3184049079754406, recall: 0.8902229845624544, f1: 0.46904654311523886\n",
            "epoch: 567, step: 1, Train: label_loss: 0.1157679557800293, precision: 0.3230861965038985, recall: 0.8830313014825563, f1: 0.4730803177012467\n",
            "epoch: 567, step: 2, Train: label_loss: 0.11958424746990204, precision: 0.3158216249236215, recall: 0.8718381112983352, f1: 0.46367713000576016\n",
            "epoch: 567, step: 3, Train: label_loss: 0.12487010657787323, precision: 0.3128834355828029, recall: 0.8457711442784667, f1: 0.4567845946761646\n",
            "epoch: 567, step: 4, Train: label_loss: 0.13057665526866913, precision: 0.3283674736188499, recall: 0.8477564102562744, f1: 0.4733780760223485\n",
            "epoch: 567, step: 5, Train: label_loss: 0.15442371368408203, precision: 0.31777493606136076, recall: 0.8042071197409701, f1: 0.45554537117842153\n",
            "epoch: 567, step: 6, Train: label_loss: 0.13893616199493408, precision: 0.307838179519576, recall: 0.793159609120392, f1: 0.4435336975917331\n",
            "epoch: 567, step: 7, Train: label_loss: 0.152622789144516, precision: 0.3143596377748826, recall: 0.7763578274759143, f1: 0.44751381211362556\n",
            "epoch: 567, step: 8, Train: label_loss: 0.16526952385902405, precision: 0.3030112923462796, recall: 0.8145025295108238, f1: 0.44170096017991295\n",
            "epoch: 567, step: 9, Train: label_loss: 0.14674082398414612, precision: 0.28749999999998205, recall: 0.8056042031522231, f1: 0.42376784887874314\n",
            "epoch: 567, step: 10, Train: label_loss: 0.14860710501670837, precision: 0.3078431372548818, recall: 0.7746710526314515, f1: 0.44059869032408433\n",
            "epoch: 567, step: 11, Train: label_loss: 0.14595761895179749, precision: 0.31890515595160285, recall: 0.8028846153844866, f1: 0.45649202729411714\n",
            "epoch: 567, step: 12, Train: label_loss: 0.1619718074798584, precision: 0.299001248439432, recall: 0.8244406196212005, f1: 0.43884562524720044\n",
            "epoch: 567, step: 13, Train: label_loss: 0.1624714881181717, precision: 0.2972453555413006, recall: 0.7811447811446496, f1: 0.4306264500760369\n",
            "epoch: 567, step: 14, Train: label_loss: 0.1622176319360733, precision: 0.3222929936305527, recall: 0.8121990369180077, f1: 0.46146830821281565\n",
            "epoch: 567, step: 15, Train: label_loss: 0.16235098242759705, precision: 0.3104534005037588, recall: 0.8299663299661901, f1: 0.4518790100428277\n",
            "epoch: 567, step: 16, Train: label_loss: 0.1333015412092209, precision: 0.30783466995679776, recall: 0.8443316412858131, f1: 0.45117540683240964\n",
            "epoch: 567, step: 17, Train: label_loss: 0.1697559356689453, precision: 0.3034920634920442, recall: 0.7861842105261865, f1: 0.43792945483837836\n",
            "epoch: 567, step: 18, Train: label_loss: 0.14059871435165405, precision: 0.3198254364089576, recall: 0.8621848739494349, f1: 0.4665757161951366\n",
            "epoch: 567, step: 19, Train: label_loss: 0.13027973473072052, precision: 0.31390977443607054, recall: 0.8349999999998607, f1: 0.4562841529657084\n",
            "epoch: 567, step: 20, Train: label_loss: 0.1472926139831543, precision: 0.3080301129234437, recall: 0.846551724137785, f1: 0.451701931883559\n",
            "epoch: 567, step: 21, Train: label_loss: 0.1432855725288391, precision: 0.3011750154607111, recall: 0.8454861111109643, f1: 0.4441404468376512\n",
            "epoch: 567, step: 22, Train: label_loss: 0.14010310173034668, precision: 0.31692307692305743, recall: 0.8612040133777823, f1: 0.4633378317195144\n",
            "epoch: 567, step: 23, Train: label_loss: 0.15057314932346344, precision: 0.32725892179192656, recall: 0.8368932038833325, f1: 0.4705240174267798\n",
            "epoch: 568, step: 0, Train: label_loss: 0.1368148922920227, precision: 0.3115264797507594, recall: 0.834724540901363, f1: 0.45372050812734493\n",
            "epoch: 568, step: 1, Train: label_loss: 0.13911309838294983, precision: 0.3110285006195594, recall: 0.8436974789914548, f1: 0.45450430054910007\n",
            "epoch: 568, step: 2, Train: label_loss: 0.13104717433452606, precision: 0.31832202344229993, recall: 0.8865979381441775, f1: 0.4684521107191364\n",
            "epoch: 568, step: 3, Train: label_loss: 0.12526148557662964, precision: 0.3113553113552923, recall: 0.8528428093644058, f1: 0.45617173520227855\n",
            "epoch: 568, step: 4, Train: label_loss: 0.1476474404335022, precision: 0.3110698824984347, recall: 0.824590163934291, f1: 0.45172878307648257\n",
            "epoch: 568, step: 5, Train: label_loss: 0.128816619515419, precision: 0.31449631449629517, recall: 0.8476821192051576, f1: 0.4587813619676514\n",
            "epoch: 568, step: 6, Train: label_loss: 0.14442706108093262, precision: 0.3111387678904598, recall: 0.8517887563882705, f1: 0.45578851409020915\n",
            "epoch: 568, step: 7, Train: label_loss: 0.13899171352386475, precision: 0.30098280098278246, recall: 0.8462867012088348, f1: 0.44404168550724554\n",
            "epoch: 568, step: 8, Train: label_loss: 0.14851197600364685, precision: 0.31437499999998036, recall: 0.8383333333331936, f1: 0.4572727272330162\n",
            "epoch: 568, step: 9, Train: label_loss: 0.14066991209983826, precision: 0.309271935283117, recall: 0.8568965517239902, f1: 0.45450388656363633\n",
            "epoch: 568, step: 10, Train: label_loss: 0.14861784875392914, precision: 0.3075941289087232, recall: 0.7901639344260999, f1: 0.44281120804414154\n",
            "epoch: 568, step: 11, Train: label_loss: 0.13128367066383362, precision: 0.34262701363070985, recall: 0.8560371517026538, f1: 0.4893805309325809\n",
            "epoch: 568, step: 12, Train: label_loss: 0.1287178248167038, precision: 0.3266423357664035, recall: 0.8920265780729415, f1: 0.4781834371824468\n",
            "epoch: 568, step: 13, Train: label_loss: 0.12618309259414673, precision: 0.29920294297974864, recall: 0.8501742160277264, f1: 0.4426303854489777\n",
            "epoch: 568, step: 14, Train: label_loss: 0.13838335871696472, precision: 0.313267813267794, recall: 0.857142857142713, f1: 0.45883940616858265\n",
            "epoch: 568, step: 15, Train: label_loss: 0.1387328952550888, precision: 0.3145161290322385, recall: 0.8366336633661985, f1: 0.45716862033896416\n",
            "epoch: 568, step: 16, Train: label_loss: 0.12608003616333008, precision: 0.300123762376219, recall: 0.83333333333319, f1: 0.4413102820356382\n",
            "epoch: 568, step: 17, Train: label_loss: 0.1590755432844162, precision: 0.31786395422757036, recall: 0.8038585209001923, f1: 0.45558086556298877\n",
            "epoch: 568, step: 18, Train: label_loss: 0.1433398723602295, precision: 0.3267813267813067, recall: 0.8539325842695258, f1: 0.4726788093779612\n",
            "epoch: 568, step: 19, Train: label_loss: 0.1280578225851059, precision: 0.32351135666050806, recall: 0.8527508090613506, f1: 0.46906987089911006\n",
            "epoch: 568, step: 20, Train: label_loss: 0.13759663701057434, precision: 0.2959752321981241, recall: 0.8400702987696238, f1: 0.4377289376903667\n",
            "epoch: 568, step: 21, Train: label_loss: 0.13918766379356384, precision: 0.3198001249219038, recall: 0.8311688311686962, f1: 0.46188543072211957\n",
            "epoch: 568, step: 22, Train: label_loss: 0.14583739638328552, precision: 0.3256537982565177, recall: 0.8476499189625855, f1: 0.47053531260043\n",
            "epoch: 568, step: 23, Train: label_loss: 0.14285381138324738, precision: 0.32676269901438004, recall: 0.8534653465344845, f1: 0.47258771925815174\n",
            "epoch: 569, step: 0, Train: label_loss: 0.14054608345031738, precision: 0.3327044025157023, recall: 0.8423566878979549, f1: 0.477006311952149\n",
            "epoch: 569, step: 1, Train: label_loss: 0.13226498663425446, precision: 0.29741379310342997, recall: 0.838541666666521, f1: 0.43909090905221526\n",
            "epoch: 569, step: 2, Train: label_loss: 0.13100138306617737, precision: 0.31089351285187816, recall: 0.8595600676817496, f1: 0.45662921344409196\n",
            "epoch: 569, step: 3, Train: label_loss: 0.11266601830720901, precision: 0.3132236441194203, recall: 0.8801369863012191, f1: 0.4620224718713547\n",
            "epoch: 569, step: 4, Train: label_loss: 0.12937580049037933, precision: 0.3224009900989899, recall: 0.8625827814568108, f1: 0.4693693693297173\n",
            "epoch: 569, step: 5, Train: label_loss: 0.13365226984024048, precision: 0.3337400854179174, recall: 0.8724082934607859, f1: 0.48278905556451956\n",
            "epoch: 569, step: 6, Train: label_loss: 0.13781693577766418, precision: 0.31884944920438685, recall: 0.8771043771042294, f1: 0.4676840215048381\n",
            "epoch: 569, step: 7, Train: label_loss: 0.1293562352657318, precision: 0.33208255159472594, recall: 0.842857142857009, f1: 0.47644683710610897\n",
            "epoch: 569, step: 8, Train: label_loss: 0.14890766143798828, precision: 0.3064415259537019, recall: 0.8193979933108997, f1: 0.4460628128870571\n",
            "epoch: 569, step: 9, Train: label_loss: 0.13582098484039307, precision: 0.3125386040765712, recall: 0.8295081967211755, f1: 0.45401525343710025\n",
            "epoch: 569, step: 10, Train: label_loss: 0.13973990082740784, precision: 0.30740276035129815, recall: 0.8166666666665305, f1: 0.4466727438070772\n",
            "epoch: 569, step: 11, Train: label_loss: 0.1324559450149536, precision: 0.3274282223579519, recall: 0.8645161290321186, f1: 0.4749667700088471\n",
            "epoch: 569, step: 12, Train: label_loss: 0.12592607736587524, precision: 0.30533415082769433, recall: 0.8440677966100264, f1: 0.44844664561605424\n",
            "epoch: 569, step: 13, Train: label_loss: 0.14211279153823853, precision: 0.31160769708253805, recall: 0.8394648829430034, f1: 0.4545043005489751\n",
            "epoch: 569, step: 14, Train: label_loss: 0.12228275835514069, precision: 0.32725060827248614, recall: 0.8762214983711928, f1: 0.4765279007575273\n",
            "epoch: 569, step: 15, Train: label_loss: 0.13168001174926758, precision: 0.2953692115143745, recall: 0.8280701754384512, f1: 0.4354243542047441\n",
            "epoch: 569, step: 16, Train: label_loss: 0.13404233753681183, precision: 0.3101538461538271, recall: 0.8484848484847056, f1: 0.45425867503961714\n",
            "epoch: 569, step: 17, Train: label_loss: 0.13154777884483337, precision: 0.3066418373680753, recall: 0.8344594594593184, f1: 0.448479346306549\n",
            "epoch: 569, step: 18, Train: label_loss: 0.12207130342721939, precision: 0.29741379310342997, recall: 0.8473684210524829, f1: 0.440291704610542\n",
            "epoch: 569, step: 19, Train: label_loss: 0.12323999404907227, precision: 0.34144856968957144, recall: 0.8751950078001755, f1: 0.49124343253401087\n",
            "epoch: 569, step: 20, Train: label_loss: 0.11363005638122559, precision: 0.3279603223806368, recall: 0.8450479233225486, f1: 0.472532380486695\n",
            "epoch: 569, step: 21, Train: label_loss: 0.12550251185894012, precision: 0.3188854489163889, recall: 0.827974276527198, f1: 0.4604380866831012\n",
            "epoch: 569, step: 22, Train: label_loss: 0.12490223348140717, precision: 0.30498177399755133, recall: 0.8625429553263122, f1: 0.45062836620911845\n",
            "epoch: 569, step: 23, Train: label_loss: 0.11923129856586456, precision: 0.2936746987951586, recall: 0.8515283842792901, f1: 0.4367301231421067\n",
            "epoch: 570, step: 0, Train: label_loss: 0.11404630541801453, precision: 0.31473620375983535, recall: 0.8796610169490033, f1: 0.4635998213099604\n",
            "epoch: 570, step: 1, Train: label_loss: 0.11297400295734406, precision: 0.33771667662879035, recall: 0.8954041204435982, f1: 0.49045138884907313\n",
            "epoch: 570, step: 2, Train: label_loss: 0.11481665819883347, precision: 0.3185947910357166, recall: 0.8855218855217364, f1: 0.46859688192095295\n",
            "epoch: 570, step: 3, Train: label_loss: 0.10143913328647614, precision: 0.31591591591589696, recall: 0.8840336134452295, f1: 0.46548672562488347\n",
            "epoch: 570, step: 4, Train: label_loss: 0.12073472142219543, precision: 0.3388379204892759, recall: 0.89354838709663, f1: 0.49135254984922166\n",
            "epoch: 570, step: 5, Train: label_loss: 0.13734248280525208, precision: 0.30896805896803997, recall: 0.865748709122054, f1: 0.4554096876026578\n",
            "epoch: 570, step: 6, Train: label_loss: 0.12308746576309204, precision: 0.31980617807387524, recall: 0.8844221105526157, f1: 0.4697508896406651\n",
            "epoch: 570, step: 7, Train: label_loss: 0.1277885138988495, precision: 0.28846153846152056, recall: 0.8244680851062367, f1: 0.4273897058439114\n",
            "epoch: 570, step: 8, Train: label_loss: 0.11968415230512619, precision: 0.31174334140433946, recall: 0.867003367003221, f1: 0.458593054279843\n",
            "epoch: 570, step: 9, Train: label_loss: 0.11790654808282852, precision: 0.3259036144578117, recall: 0.8854337152208043, f1: 0.4764420959535808\n",
            "epoch: 570, step: 10, Train: label_loss: 0.12217380106449127, precision: 0.32822085889568536, recall: 0.8505564387915976, f1: 0.47366091186769943\n",
            "epoch: 570, step: 11, Train: label_loss: 0.1272987276315689, precision: 0.3259036144578117, recall: 0.8898026315788009, f1: 0.4770723103663593\n",
            "epoch: 570, step: 12, Train: label_loss: 0.11625830829143524, precision: 0.3067150635208526, recall: 0.8726333907055296, f1: 0.4538943598540419\n",
            "epoch: 570, step: 13, Train: label_loss: 0.12218020856380463, precision: 0.3134969325153182, recall: 0.8390804597699771, f1: 0.45645377396660913\n",
            "epoch: 570, step: 14, Train: label_loss: 0.1429220736026764, precision: 0.32278088144007927, recall: 0.8455284552844153, f1: 0.46720575018458627\n",
            "epoch: 570, step: 15, Train: label_loss: 0.13086244463920593, precision: 0.30943627450978495, recall: 0.8632478632477156, f1: 0.4555705908496985\n",
            "epoch: 570, step: 16, Train: label_loss: 0.11885203421115875, precision: 0.3016255267910715, recall: 0.8804920913882459, f1: 0.449327354222039\n",
            "epoch: 570, step: 17, Train: label_loss: 0.11820663511753082, precision: 0.3221271393642835, recall: 0.8710743801651453, f1: 0.47032574739472205\n",
            "epoch: 570, step: 18, Train: label_loss: 0.13766135275363922, precision: 0.3391196528208097, recall: 0.8454404945902866, f1: 0.48407079641926914\n",
            "epoch: 570, step: 19, Train: label_loss: 0.12426634132862091, precision: 0.31661631419937664, recall: 0.8791946308723356, f1: 0.4655708573577377\n",
            "epoch: 570, step: 20, Train: label_loss: 0.1262829303741455, precision: 0.31671732522794427, recall: 0.8712374581938341, f1: 0.46455639764252926\n",
            "epoch: 570, step: 21, Train: label_loss: 0.13297022879123688, precision: 0.3045089561457502, recall: 0.8216666666665297, f1: 0.444344299194393\n",
            "epoch: 570, step: 22, Train: label_loss: 0.1149115189909935, precision: 0.3022974607013118, recall: 0.88028169014069, f1: 0.45004500446235324\n",
            "epoch: 570, step: 23, Train: label_loss: 0.1253965198993683, precision: 0.34539969834084877, recall: 0.8609022556389359, f1: 0.4930032292378724\n",
            "epoch: 571, step: 0, Train: label_loss: 0.11484132707118988, precision: 0.3087697929354258, recall: 0.8637137989777063, f1: 0.4549125167848479\n",
            "epoch: 571, step: 1, Train: label_loss: 0.13374316692352295, precision: 0.3122311001843692, recall: 0.8341543513955937, f1: 0.45438282643617284\n",
            "epoch: 571, step: 2, Train: label_loss: 0.11641380190849304, precision: 0.3107274969173668, recall: 0.841402337228574, f1: 0.45384961725007616\n",
            "epoch: 571, step: 3, Train: label_loss: 0.10819779336452484, precision: 0.3276595744680652, recall: 0.886513157894591, f1: 0.47847314687577436\n",
            "epoch: 571, step: 4, Train: label_loss: 0.11790156364440918, precision: 0.3103864734299329, recall: 0.8741496598637969, f1: 0.45811051689533117\n",
            "epoch: 571, step: 5, Train: label_loss: 0.10298532992601395, precision: 0.3046638400968925, recall: 0.8539898132426393, f1: 0.44910714281834163\n",
            "epoch: 571, step: 6, Train: label_loss: 0.12645545601844788, precision: 0.30637254901958905, recall: 0.850340136054277, f1: 0.4504504504114676\n",
            "epoch: 571, step: 7, Train: label_loss: 0.124410480260849, precision: 0.3228111971411362, recall: 0.9048414023370775, f1: 0.4758560140086067\n",
            "epoch: 571, step: 8, Train: label_loss: 0.11236639320850372, precision: 0.3184049079754406, recall: 0.8522167487683329, f1: 0.4635998213091721\n",
            "epoch: 571, step: 9, Train: label_loss: 0.116029292345047, precision: 0.34617700180612004, recall: 0.8846153846152485, f1: 0.49762007784788603\n",
            "epoch: 571, step: 10, Train: label_loss: 0.11547234654426575, precision: 0.3207776427703329, recall: 0.8799999999998532, f1: 0.47016918963132803\n",
            "epoch: 571, step: 11, Train: label_loss: 0.11424621939659119, precision: 0.330269607843117, recall: 0.8637820512819128, f1: 0.47783687939256364\n",
            "epoch: 571, step: 12, Train: label_loss: 0.11713176965713501, precision: 0.3306797305572363, recall: 0.8517350157727362, f1: 0.4764005292935889\n",
            "epoch: 571, step: 13, Train: label_loss: 0.12041482329368591, precision: 0.313267813267794, recall: 0.8528428093644058, f1: 0.4582210242194241\n",
            "epoch: 571, step: 14, Train: label_loss: 0.11473112553358078, precision: 0.31681957186542403, recall: 0.857615894039593, f1: 0.46270656539155636\n",
            "epoch: 571, step: 15, Train: label_loss: 0.10024099051952362, precision: 0.33393393393391385, recall: 0.8953301127212728, f1: 0.4864391950609982\n",
            "epoch: 571, step: 16, Train: label_loss: 0.1275971680879593, precision: 0.29298572315330274, recall: 0.7972972972971626, f1: 0.42850658189438556\n",
            "epoch: 571, step: 17, Train: label_loss: 0.12700583040714264, precision: 0.29797670141015953, recall: 0.8195615514332513, f1: 0.43705035967308253\n",
            "epoch: 571, step: 18, Train: label_loss: 0.135367751121521, precision: 0.30691823899369136, recall: 0.8299319727889745, f1: 0.4481175389871713\n",
            "epoch: 571, step: 19, Train: label_loss: 0.13571596145629883, precision: 0.32178217821780186, recall: 0.8373590982285285, f1: 0.4649083593697744\n",
            "epoch: 571, step: 20, Train: label_loss: 0.1295020878314972, precision: 0.30839975475166714, recall: 0.8793706293704756, f1: 0.4566500226578357\n",
            "epoch: 571, step: 21, Train: label_loss: 0.11786124110221863, precision: 0.3065296251511302, recall: 0.871134020618407, f1: 0.4534883720544753\n",
            "epoch: 571, step: 22, Train: label_loss: 0.12387688457965851, precision: 0.30079803560464696, recall: 0.858143607705629, f1: 0.44545454541606866\n",
            "epoch: 571, step: 23, Train: label_loss: 0.1240144670009613, precision: 0.33210603829158086, recall: 0.9148073022310518, f1: 0.4873041598744267\n",
            "epoch: 572, step: 0, Train: label_loss: 0.1239197701215744, precision: 0.30095923261389085, recall: 0.8730434782607177, f1: 0.4476148015668262\n",
            "epoch: 572, step: 1, Train: label_loss: 0.10055603086948395, precision: 0.3362936648904478, recall: 0.9117174959870125, f1: 0.491349480929445\n",
            "epoch: 572, step: 2, Train: label_loss: 0.11606886237859726, precision: 0.30066950699937306, recall: 0.8517241379308875, f1: 0.44444444440583736\n",
            "epoch: 572, step: 3, Train: label_loss: 0.12175063043832779, precision: 0.32107843137252934, recall: 0.8478964401293125, f1: 0.46577777773789136\n",
            "epoch: 572, step: 4, Train: label_loss: 0.11001225560903549, precision: 0.31517747858015205, recall: 0.8554817275746086, f1: 0.4606440071162447\n",
            "epoch: 572, step: 5, Train: label_loss: 0.11978225409984589, precision: 0.3204353083433905, recall: 0.877483443708464, f1: 0.4694419840174575\n",
            "epoch: 572, step: 6, Train: label_loss: 0.14378368854522705, precision: 0.29824561403506905, recall: 0.8469750889678208, f1: 0.4411492121949878\n",
            "epoch: 572, step: 7, Train: label_loss: 0.1124117523431778, precision: 0.3163636363636172, recall: 0.8685524126454461, f1: 0.4637938693521989\n",
            "epoch: 572, step: 8, Train: label_loss: 0.11296480894088745, precision: 0.3239436619718111, recall: 0.8758278145693914, f1: 0.4729548502064022\n",
            "epoch: 572, step: 9, Train: label_loss: 0.1161707192659378, precision: 0.28799999999998227, recall: 0.8447653429601363, f1: 0.4295548416325307\n",
            "epoch: 572, step: 10, Train: label_loss: 0.1316777765750885, precision: 0.3100490196078241, recall: 0.8349834983496971, f1: 0.4521894548308881\n",
            "epoch: 572, step: 11, Train: label_loss: 0.12124159187078476, precision: 0.3143032535297536, recall: 0.8462809917353973, f1: 0.458370635591619\n",
            "epoch: 572, step: 12, Train: label_loss: 0.14063315093517303, precision: 0.32812499999997946, recall: 0.822884012539056, f1: 0.46916890076348605\n",
            "epoch: 572, step: 13, Train: label_loss: 0.12521997094154358, precision: 0.324471299093636, recall: 0.8817733990146335, f1: 0.47438162540232703\n",
            "epoch: 572, step: 14, Train: label_loss: 0.11550931632518768, precision: 0.3329268292682724, recall: 0.8778135048230099, f1: 0.48275862064973946\n",
            "epoch: 572, step: 15, Train: label_loss: 0.11609940230846405, precision: 0.319461444308426, recall: 0.8656716417909012, f1: 0.4666964684451565\n",
            "epoch: 572, step: 16, Train: label_loss: 0.12277999520301819, precision: 0.33373786407764966, recall: 0.889967637540309, f1: 0.48543689316417116\n",
            "epoch: 572, step: 17, Train: label_loss: 0.12323567271232605, precision: 0.3177914110429253, recall: 0.8633333333331894, f1: 0.46457399099201535\n",
            "epoch: 572, step: 18, Train: label_loss: 0.10620234906673431, precision: 0.33818181818179766, recall: 0.8759811616953098, f1: 0.4879755137332694\n",
            "epoch: 572, step: 19, Train: label_loss: 0.13560090959072113, precision: 0.30783466995679776, recall: 0.8443316412858131, f1: 0.45117540683240964\n",
            "epoch: 572, step: 20, Train: label_loss: 0.11780758947134018, precision: 0.31479217603910054, recall: 0.8728813559320554, f1: 0.4627133872026878\n",
            "epoch: 572, step: 21, Train: label_loss: 0.11576314270496368, precision: 0.3175757575757383, recall: 0.8718801996670762, f1: 0.46557085735752973\n",
            "epoch: 572, step: 22, Train: label_loss: 0.12249774485826492, precision: 0.3284132841328211, recall: 0.8543999999998633, f1: 0.47445579738321275\n",
            "epoch: 572, step: 23, Train: label_loss: 0.10757933557033539, precision: 0.28949301983833287, recall: 0.8736141906871677, f1: 0.4348785871590306\n",
            "epoch: 573, step: 0, Train: label_loss: 0.10677480697631836, precision: 0.32142857142855197, recall: 0.8592233009707347, f1: 0.4678414096519631\n",
            "epoch: 573, step: 1, Train: label_loss: 0.1278972625732422, precision: 0.30621118012420456, recall: 0.8327702702701295, f1: 0.447774750187712\n",
            "epoch: 573, step: 2, Train: label_loss: 0.09545380622148514, precision: 0.3185947910357166, recall: 0.8795986622072107, f1: 0.4677634503833293\n",
            "epoch: 573, step: 3, Train: label_loss: 0.12089011818170547, precision: 0.30450669914736267, recall: 0.8488964346348303, f1: 0.4482294934617706\n",
            "epoch: 573, step: 4, Train: label_loss: 0.12096470594406128, precision: 0.3101965601965411, recall: 0.8530405405403964, f1: 0.45495495491580284\n",
            "epoch: 573, step: 5, Train: label_loss: 0.112496018409729, precision: 0.31607795371496245, recall: 0.8621262458470328, f1: 0.4625668448804845\n",
            "epoch: 573, step: 6, Train: label_loss: 0.10830003768205643, precision: 0.3076456310679425, recall: 0.8549747048902436, f1: 0.45247657291954163\n",
            "epoch: 573, step: 7, Train: label_loss: 0.11742512881755829, precision: 0.31608133086874207, recall: 0.8437499999998611, f1: 0.45988346029199767\n",
            "epoch: 573, step: 8, Train: label_loss: 0.1240922063589096, precision: 0.3284493284493084, recall: 0.8805237315874171, f1: 0.4784348598981339\n",
            "epoch: 573, step: 9, Train: label_loss: 0.1233873963356018, precision: 0.32924586143468243, recall: 0.8578274760382015, f1: 0.4758529020422818\n",
            "epoch: 573, step: 10, Train: label_loss: 0.11846250295639038, precision: 0.3363471971066705, recall: 0.9014539579966233, f1: 0.48990342401656806\n",
            "epoch: 573, step: 11, Train: label_loss: 0.10531886667013168, precision: 0.3206650831353729, recall: 0.9075630252099315, f1: 0.4738920578815154\n",
            "epoch: 573, step: 12, Train: label_loss: 0.10579578578472137, precision: 0.30787589498804846, recall: 0.8927335640136863, f1: 0.4578527062617356\n",
            "epoch: 573, step: 13, Train: label_loss: 0.11160913854837418, precision: 0.324275362318821, recall: 0.8949999999998508, f1: 0.476063829748147\n",
            "epoch: 573, step: 14, Train: label_loss: 0.09700310230255127, precision: 0.3231597845601243, recall: 0.8985024958401167, f1: 0.47535211263710414\n",
            "epoch: 573, step: 15, Train: label_loss: 0.11811846494674683, precision: 0.30557256582974246, recall: 0.8573883161510554, f1: 0.4505643340469953\n",
            "epoch: 573, step: 16, Train: label_loss: 0.09764957427978516, precision: 0.32277346084875536, recall: 0.8999999999998499, f1: 0.4751429828031593\n",
            "epoch: 573, step: 17, Train: label_loss: 0.11280860006809235, precision: 0.3125763125762935, recall: 0.8576214405358696, f1: 0.45816554805924015\n",
            "epoch: 573, step: 18, Train: label_loss: 0.12751656770706177, precision: 0.3182374541003477, recall: 0.8681135225374176, f1: 0.4657411553570277\n",
            "epoch: 573, step: 19, Train: label_loss: 0.12184470891952515, precision: 0.327947336923978, recall: 0.8852988691436372, f1: 0.4786026200478463\n",
            "epoch: 573, step: 20, Train: label_loss: 0.09713742136955261, precision: 0.2936221419975756, recall: 0.8840579710143325, f1: 0.44083107493994445\n",
            "epoch: 573, step: 21, Train: label_loss: 0.11311221122741699, precision: 0.33030852994553356, recall: 0.8980263157893259, f1: 0.48297213618354823\n",
            "epoch: 573, step: 22, Train: label_loss: 0.12746745347976685, precision: 0.3365676167373962, recall: 0.8823529411763302, f1: 0.48726953463952516\n",
            "epoch: 573, step: 23, Train: label_loss: 0.12603764235973358, precision: 0.32880844645548046, recall: 0.853228962817837, f1: 0.47468698961683947\n",
            "epoch: 574, step: 0, Train: label_loss: 0.10502879321575165, precision: 0.3369304556354714, recall: 0.8920634920633504, f1: 0.4891209747208204\n",
            "epoch: 574, step: 1, Train: label_loss: 0.10400642454624176, precision: 0.323636363636344, recall: 0.8697068403907378, f1: 0.471731448723679\n",
            "epoch: 574, step: 2, Train: label_loss: 0.11246909946203232, precision: 0.3087248322147463, recall: 0.8532883642494344, f1: 0.4534050178820874\n",
            "epoch: 574, step: 3, Train: label_loss: 0.10080817341804504, precision: 0.31670673076921174, recall: 0.881270903009886, f1: 0.46595932798935685\n",
            "epoch: 574, step: 4, Train: label_loss: 0.11176906526088715, precision: 0.3323299217338752, recall: 0.8860353130014629, f1: 0.48336252185170314\n",
            "epoch: 574, step: 5, Train: label_loss: 0.12109166383743286, precision: 0.295955882352923, recall: 0.8473684210524829, f1: 0.4386920980542333\n",
            "epoch: 574, step: 6, Train: label_loss: 0.12419095635414124, precision: 0.3156626506023906, recall: 0.8926746166949074, f1: 0.46639964393109745\n",
            "epoch: 574, step: 7, Train: label_loss: 0.1054353266954422, precision: 0.35483870967739817, recall: 0.9124423963132239, f1: 0.5109677418951198\n",
            "epoch: 574, step: 8, Train: label_loss: 0.10268484055995941, precision: 0.3256379100850349, recall: 0.8673139158574648, f1: 0.4734982331758145\n",
            "epoch: 574, step: 9, Train: label_loss: 0.10582727193832397, precision: 0.3069007263922332, recall: 0.8832752613238879, f1: 0.4555256064306879\n",
            "epoch: 574, step: 10, Train: label_loss: 0.10297296196222305, precision: 0.33353510895881755, recall: 0.9018003273320946, f1: 0.48696420676566327\n",
            "epoch: 574, step: 11, Train: label_loss: 0.09501899778842926, precision: 0.327197149643686, recall: 0.9338983050845874, f1: 0.48460861913479275\n",
            "epoch: 574, step: 12, Train: label_loss: 0.10923624038696289, precision: 0.3259396179913539, recall: 0.8743801652891116, f1: 0.47486535005016234\n",
            "epoch: 574, step: 13, Train: label_loss: 0.09861798584461212, precision: 0.30727600721585646, recall: 0.891797556718867, f1: 0.45706618958617\n",
            "epoch: 574, step: 14, Train: label_loss: 0.10795754194259644, precision: 0.30755064456720027, recall: 0.8789473684208984, f1: 0.4556616643544605\n",
            "epoch: 574, step: 15, Train: label_loss: 0.10814648121595383, precision: 0.3222490931075984, recall: 0.8853820598005173, f1: 0.47251773045728435\n",
            "epoch: 574, step: 16, Train: label_loss: 0.095682293176651, precision: 0.3235117257967334, recall: 0.8892561983469603, f1: 0.4744268077209799\n",
            "epoch: 574, step: 17, Train: label_loss: 0.1114937886595726, precision: 0.3232077764276839, recall: 0.870703764320643, f1: 0.47142224187451787\n",
            "epoch: 574, step: 18, Train: label_loss: 0.13140009343624115, precision: 0.3123486682808528, recall: 0.843137254901823, f1: 0.45583038865309\n",
            "epoch: 574, step: 19, Train: label_loss: 0.11137087643146515, precision: 0.32213557288540356, recall: 0.8803278688523146, f1: 0.4716732542426828\n",
            "epoch: 574, step: 20, Train: label_loss: 0.09656468033790588, precision: 0.32650602409636587, recall: 0.8658146964854846, f1: 0.4741907261194182\n",
            "epoch: 574, step: 21, Train: label_loss: 0.09885429590940475, precision: 0.30847865303666216, recall: 0.884482758620537, f1: 0.4574230940320571\n",
            "epoch: 574, step: 22, Train: label_loss: 0.1082114428281784, precision: 0.29341317365267705, recall: 0.8765652951697894, f1: 0.439659039890601\n",
            "epoch: 574, step: 23, Train: label_loss: 0.1214071661233902, precision: 0.3205417607223235, recall: 0.8402366863903669, f1: 0.46405228754167116\n",
            "epoch: 575, step: 0, Train: label_loss: 0.10209200531244278, precision: 0.3090467516696837, recall: 0.859797297297152, f1: 0.45466726213167236\n",
            "epoch: 575, step: 1, Train: label_loss: 0.11240920424461365, precision: 0.3095238095237906, recall: 0.8578680203044233, f1: 0.4549125167846786\n",
            "epoch: 575, step: 2, Train: label_loss: 0.11009488999843597, precision: 0.31359516616312305, recall: 0.888698630136834, f1: 0.4635998213102154\n",
            "epoch: 575, step: 3, Train: label_loss: 0.10771631449460983, precision: 0.31682577565630565, recall: 0.8939393939392434, f1: 0.46784140965294857\n",
            "epoch: 575, step: 4, Train: label_loss: 0.11332735419273376, precision: 0.3216019417475533, recall: 0.8818635607319664, f1: 0.4713205868883178\n",
            "epoch: 575, step: 5, Train: label_loss: 0.11431843042373657, precision: 0.32650602409636587, recall: 0.8988391376449587, f1: 0.47901016346064484\n",
            "epoch: 575, step: 6, Train: label_loss: 0.09505538642406464, precision: 0.3279569892472922, recall: 0.8970588235292651, f1: 0.48031496059067036\n",
            "epoch: 575, step: 7, Train: label_loss: 0.10024230182170868, precision: 0.3443113772454884, recall: 0.8956386292833495, f1: 0.49740484425049947\n",
            "epoch: 575, step: 8, Train: label_loss: 0.0938064306974411, precision: 0.30946601941745694, recall: 0.8614864864863409, f1: 0.4553571428182145\n",
            "epoch: 575, step: 9, Train: label_loss: 0.10778335481882095, precision: 0.3311298076922878, recall: 0.891585760517655, f1: 0.4829097282689641\n",
            "epoch: 575, step: 10, Train: label_loss: 0.1021154522895813, precision: 0.31696969696967775, recall: 0.8760469011723825, f1: 0.46550956827424567\n",
            "epoch: 575, step: 11, Train: label_loss: 0.09803497791290283, precision: 0.32035928143710657, recall: 0.896147403684942, f1: 0.47198941328273\n",
            "epoch: 575, step: 12, Train: label_loss: 0.10699161887168884, precision: 0.32175502742228385, recall: 0.8756218905471184, f1: 0.47058823525477406\n",
            "epoch: 575, step: 13, Train: label_loss: 0.1040390133857727, precision: 0.32553956834530423, recall: 0.8758064516127619, f1: 0.4746503496107983\n",
            "epoch: 575, step: 14, Train: label_loss: 0.09227342903614044, precision: 0.3355145746579217, recall: 0.9082125603863271, f1: 0.4900086880578657\n",
            "epoch: 575, step: 15, Train: label_loss: 0.11039736866950989, precision: 0.32038834951454365, recall: 0.8814691151918395, f1: 0.46995994655631596\n",
            "epoch: 575, step: 16, Train: label_loss: 0.1003766879439354, precision: 0.31359516616312305, recall: 0.8871794871793355, f1: 0.4633928571042246\n",
            "epoch: 575, step: 17, Train: label_loss: 0.129222571849823, precision: 0.3038912909203024, recall: 0.8571428571427078, f1: 0.4487004103580293\n",
            "epoch: 575, step: 18, Train: label_loss: 0.10677380114793777, precision: 0.319760479041897, recall: 0.8899999999998516, f1: 0.4704845814588652\n",
            "epoch: 575, step: 19, Train: label_loss: 0.10622762143611908, precision: 0.33050847457625115, recall: 0.866666666666529, f1: 0.47852760732194977\n",
            "epoch: 575, step: 20, Train: label_loss: 0.10232090950012207, precision: 0.32534451767523515, recall: 0.8843648208467615, f1: 0.47568988169519544\n",
            "epoch: 575, step: 21, Train: label_loss: 0.10041488707065582, precision: 0.31051051051049183, recall: 0.8960138648178689, f1: 0.46119536124630106\n",
            "epoch: 575, step: 22, Train: label_loss: 0.10290871560573578, precision: 0.30413917216554864, recall: 0.8910369068539734, f1: 0.4534883720550394\n",
            "epoch: 575, step: 23, Train: label_loss: 0.11302739381790161, precision: 0.3217784476262003, recall: 0.8472222222220541, f1: 0.46641179679238265\n",
            "epoch: 576, step: 0, Train: label_loss: 0.0998886227607727, precision: 0.32955223880595047, recall: 0.893203883495001, f1: 0.48146532922355684\n",
            "epoch: 576, step: 1, Train: label_loss: 0.09989151358604431, precision: 0.30149253731341485, recall: 0.8875219683653975, f1: 0.4500891265218207\n",
            "epoch: 576, step: 2, Train: label_loss: 0.11208683252334595, precision: 0.31607465382297917, recall: 0.8959044368599153, f1: 0.4672897195875707\n",
            "epoch: 576, step: 3, Train: label_loss: 0.11215385794639587, precision: 0.3111246943765091, recall: 0.8525963149077298, f1: 0.4558889386083434\n",
            "epoch: 576, step: 4, Train: label_loss: 0.09226389229297638, precision: 0.31350386674596586, recall: 0.8977853492332372, f1: 0.46472663135489073\n",
            "epoch: 576, step: 5, Train: label_loss: 0.1108463853597641, precision: 0.3363858363858158, recall: 0.8622848200311639, f1: 0.48397013610363104\n",
            "epoch: 576, step: 6, Train: label_loss: 0.10179385542869568, precision: 0.3155048076922887, recall: 0.8764607679464312, f1: 0.46398585943960113\n",
            "epoch: 576, step: 7, Train: label_loss: 0.1067001074552536, precision: 0.33780487804875986, recall: 0.8738170347001776, f1: 0.4872471415604463\n",
            "epoch: 576, step: 8, Train: label_loss: 0.09686526656150818, precision: 0.30637254901958905, recall: 0.8561643835614972, f1: 0.4512635378672793\n",
            "epoch: 576, step: 9, Train: label_loss: 0.11634616553783417, precision: 0.302735562310012, recall: 0.8527397260272512, f1: 0.4468371466638458\n",
            "epoch: 576, step: 10, Train: label_loss: 0.10630704462528229, precision: 0.3249850924269335, recall: 0.9083333333331819, f1: 0.4787000438785793\n",
            "epoch: 576, step: 11, Train: label_loss: 0.11738643795251846, precision: 0.31276725717774506, recall: 0.8605042016805275, f1: 0.45878136196802455\n",
            "epoch: 576, step: 12, Train: label_loss: 0.10554058104753494, precision: 0.34382566585954333, recall: 0.8698315467073706, f1: 0.49284164854937096\n",
            "epoch: 576, step: 13, Train: label_loss: 0.11316865682601929, precision: 0.3337408312958231, recall: 0.8639240506327747, f1: 0.4814814814412373\n",
            "epoch: 576, step: 14, Train: label_loss: 0.11942487210035324, precision: 0.3046116504854184, recall: 0.8760907504361473, f1: 0.45204862670638246\n",
            "epoch: 576, step: 15, Train: label_loss: 0.11728425323963165, precision: 0.331464174454808, recall: 0.8172043010751432, f1: 0.47163120563265815\n",
            "epoch: 576, step: 16, Train: label_loss: 0.1210961788892746, precision: 0.3109605911329858, recall: 0.8603066439521532, f1: 0.45680687467828\n",
            "epoch: 576, step: 17, Train: label_loss: 0.12912599742412567, precision: 0.2977562158883992, recall: 0.8614035087717786, f1: 0.44254168540567596\n",
            "epoch: 576, step: 18, Train: label_loss: 0.12497259676456451, precision: 0.3059610705595921, recall: 0.8672413793101952, f1: 0.4523381294578064\n",
            "epoch: 576, step: 19, Train: label_loss: 0.10203589498996735, precision: 0.30843373493974047, recall: 0.8707482993195798, f1: 0.4555160141962051\n",
            "epoch: 576, step: 20, Train: label_loss: 0.10237107425928116, precision: 0.3206521739130241, recall: 0.8969594594593079, f1: 0.4724199287867818\n",
            "epoch: 576, step: 21, Train: label_loss: 0.10854685306549072, precision: 0.3148261134838124, recall: 0.8543046357614479, f1: 0.46009808288525955\n",
            "epoch: 576, step: 22, Train: label_loss: 0.111564502120018, precision: 0.3224043715846799, recall: 0.8791390728475365, f1: 0.4717903153760637\n",
            "epoch: 576, step: 23, Train: label_loss: 0.12527763843536377, precision: 0.31756756756754373, recall: 0.8580121703852215, f1: 0.46356164379613296\n",
            "epoch: 577, step: 0, Train: label_loss: 0.12356606125831604, precision: 0.293071735131803, recall: 0.8550983899819579, f1: 0.4365296803272374\n",
            "epoch: 577, step: 1, Train: label_loss: 0.11481945961713791, precision: 0.31207847946043454, recall: 0.8525963149077298, f1: 0.45691202868604225\n",
            "epoch: 577, step: 2, Train: label_loss: 0.11919780820608139, precision: 0.3024539877300428, recall: 0.8427350427348986, f1: 0.4451467268233912\n",
            "epoch: 577, step: 3, Train: label_loss: 0.10661136358976364, precision: 0.31496062992124074, recall: 0.8813559322032404, f1: 0.46407853632885926\n",
            "epoch: 577, step: 4, Train: label_loss: 0.11509644985198975, precision: 0.33171912832927775, recall: 0.9102990033221079, f1: 0.48624667254288345\n",
            "epoch: 577, step: 5, Train: label_loss: 0.10147631168365479, precision: 0.33293124246077604, recall: 0.9034369885432236, f1: 0.4865579550068792\n",
            "epoch: 577, step: 6, Train: label_loss: 0.11297805607318878, precision: 0.3206979542719422, recall: 0.9033898305083214, f1: 0.47335701594707824\n",
            "epoch: 577, step: 7, Train: label_loss: 0.11704812943935394, precision: 0.31762545899630856, recall: 0.8649999999998558, f1: 0.4646374216258442\n",
            "epoch: 577, step: 8, Train: label_loss: 0.1076243668794632, precision: 0.3097991479001637, recall: 0.8540268456374406, f1: 0.4546672621315046\n",
            "epoch: 577, step: 9, Train: label_loss: 0.1340576708316803, precision: 0.3090234857849005, recall: 0.8250825082506889, f1: 0.4496402877300966\n",
            "epoch: 577, step: 10, Train: label_loss: 0.12380754947662354, precision: 0.32019704433495566, recall: 0.8538587848931274, f1: 0.46574115535661664\n",
            "epoch: 577, step: 11, Train: label_loss: 0.118251271545887, precision: 0.3274173806609347, recall: 0.8587479935793163, f1: 0.4740806379750547\n",
            "epoch: 577, step: 12, Train: label_loss: 0.10341808944940567, precision: 0.3207660083781974, recall: 0.8948247078462612, f1: 0.4722466959963515\n",
            "epoch: 577, step: 13, Train: label_loss: 0.100552998483181, precision: 0.33618059792554383, recall: 0.8555900621116683, f1: 0.4826982040768445\n",
            "epoch: 577, step: 14, Train: label_loss: 0.11714360117912292, precision: 0.27362569487336175, recall: 0.8264925373132785, f1: 0.41113689091386585\n",
            "epoch: 577, step: 15, Train: label_loss: 0.09764016419649124, precision: 0.3228299643281615, recall: 0.9110738255032028, f1: 0.4767339771342806\n",
            "epoch: 577, step: 16, Train: label_loss: 0.09861670434474945, precision: 0.327947336923978, recall: 0.9013157894735359, f1: 0.4809126809612746\n",
            "epoch: 577, step: 17, Train: label_loss: 0.10717593878507614, precision: 0.3273273273273077, recall: 0.9008264462808427, f1: 0.48017621141460476\n",
            "epoch: 577, step: 18, Train: label_loss: 0.11216843128204346, precision: 0.327848872638615, recall: 0.8762214983711928, f1: 0.4771618624880448\n",
            "epoch: 577, step: 19, Train: label_loss: 0.11859648674726486, precision: 0.3349455864570535, recall: 0.8892455858746565, f1: 0.48660518221756427\n",
            "epoch: 577, step: 20, Train: label_loss: 0.11525945365428925, precision: 0.30533415082769433, recall: 0.841216216216074, f1: 0.44804318484617234\n",
            "epoch: 577, step: 21, Train: label_loss: 0.1155494749546051, precision: 0.3145454545454355, recall: 0.8722689075628786, f1: 0.4623608017427379\n",
            "epoch: 577, step: 22, Train: label_loss: 0.10859102010726929, precision: 0.3545069570477704, recall: 0.9085271317828049, f1: 0.5100087031797673\n",
            "epoch: 577, step: 23, Train: label_loss: 0.11234427243471146, precision: 0.3177431328878754, recall: 0.8663967611334279, f1: 0.4649646930622587\n",
            "epoch: 578, step: 0, Train: label_loss: 0.10754258930683136, precision: 0.33071816535906273, recall: 0.8968903436987075, f1: 0.4832451498724092\n",
            "epoch: 578, step: 1, Train: label_loss: 0.11532014608383179, precision: 0.3145654834761129, recall: 0.8538205980065027, f1: 0.4597495527334183\n",
            "epoch: 578, step: 2, Train: label_loss: 0.12893939018249512, precision: 0.3003115264797321, recall: 0.807370184254471, f1: 0.4377838328396384\n",
            "epoch: 578, step: 3, Train: label_loss: 0.10447745025157928, precision: 0.3099878197320152, recall: 0.8612521150590758, f1: 0.4558889386085949\n",
            "epoch: 578, step: 4, Train: label_loss: 0.10939651727676392, precision: 0.3221884498480047, recall: 0.8702791461410722, f1: 0.47027506650887957\n",
            "epoch: 578, step: 5, Train: label_loss: 0.09908302128314972, precision: 0.3130277442701862, recall: 0.8781725888323386, f1: 0.4615384614996748\n",
            "epoch: 578, step: 6, Train: label_loss: 0.10938212275505066, precision: 0.29927007299268255, recall: 0.8497409326423402, f1: 0.44264507418545784\n",
            "epoch: 578, step: 7, Train: label_loss: 0.10529259592294693, precision: 0.31693989071036327, recall: 0.8729096989965095, f1: 0.4650334075332582\n",
            "epoch: 578, step: 8, Train: label_loss: 0.10701291263103485, precision: 0.327848872638615, recall: 0.8635634028891069, f1: 0.4752650176279116\n",
            "epoch: 578, step: 9, Train: label_loss: 0.13696368038654327, precision: 0.2975821450712773, recall: 0.8191126279862083, f1: 0.4365620736307161\n",
            "epoch: 578, step: 10, Train: label_loss: 0.12626522779464722, precision: 0.30577507598782333, recall: 0.8824561403507223, f1: 0.4541760721964991\n",
            "epoch: 578, step: 11, Train: label_loss: 0.1101672500371933, precision: 0.3413897280966561, recall: 0.8705701078581093, f1: 0.49045138884837863\n",
            "epoch: 578, step: 12, Train: label_loss: 0.11326587945222855, precision: 0.3297035692679776, recall: 0.8804523424877414, f1: 0.47975352108707436\n",
            "epoch: 578, step: 13, Train: label_loss: 0.10197818279266357, precision: 0.32121212121210174, recall: 0.8731466227346172, f1: 0.46964997780733514\n",
            "epoch: 578, step: 14, Train: label_loss: 0.11102945357561111, precision: 0.3073140749846154, recall: 0.853242320818967, f1: 0.4518752823830745\n",
            "epoch: 578, step: 15, Train: label_loss: 0.10658672451972961, precision: 0.3083941605839228, recall: 0.8696397941679468, f1: 0.45532105968290665\n",
            "epoch: 578, step: 16, Train: label_loss: 0.11317215859889984, precision: 0.3369763205828575, recall: 0.8823529411763302, f1: 0.4876977152499423\n",
            "epoch: 578, step: 17, Train: label_loss: 0.11982658505439758, precision: 0.3073619631901652, recall: 0.8549488054606049, f1: 0.45216606494300626\n",
            "epoch: 578, step: 18, Train: label_loss: 0.10020076483488083, precision: 0.3233173076922883, recall: 0.886326194398536, f1: 0.4738000880277206\n",
            "epoch: 578, step: 19, Train: label_loss: 0.11425722390413284, precision: 0.3214930764599445, recall: 0.8797364085665765, f1: 0.47089947086022793\n",
            "epoch: 578, step: 20, Train: label_loss: 0.10843974351882935, precision: 0.2963186481593062, recall: 0.8862815884474934, f1: 0.4441429217172654\n",
            "epoch: 578, step: 21, Train: label_loss: 0.11471261829137802, precision: 0.3353658536585161, recall: 0.8661417322833281, f1: 0.4835164834761985\n",
            "epoch: 578, step: 22, Train: label_loss: 0.11802998930215836, precision: 0.3171028606207963, recall: 0.8527004909982238, f1: 0.46228926349194\n",
            "epoch: 578, step: 23, Train: label_loss: 0.11980648338794708, precision: 0.31426448736996176, recall: 0.8650306748464489, f1: 0.4610354223041798\n",
            "epoch: 579, step: 0, Train: label_loss: 0.1013537347316742, precision: 0.3144918821406906, recall: 0.8716666666665214, f1: 0.4622182942605938\n",
            "epoch: 579, step: 1, Train: label_loss: 0.11336137354373932, precision: 0.3188759926694979, recall: 0.8671096345513509, f1: 0.4662795890629203\n",
            "epoch: 579, step: 2, Train: label_loss: 0.10950174927711487, precision: 0.3060370591751162, recall: 0.8797250859105017, f1: 0.45410199552707364\n",
            "epoch: 579, step: 3, Train: label_loss: 0.1192714124917984, precision: 0.33696969696967655, recall: 0.8953301127212728, f1: 0.4896521355832956\n",
            "epoch: 579, step: 4, Train: label_loss: 0.1105261892080307, precision: 0.29889975550120423, recall: 0.8639575971729921, f1: 0.44414168933506265\n",
            "epoch: 579, step: 5, Train: label_loss: 0.111884206533432, precision: 0.33010296789822346, recall: 0.8861788617884737, f1: 0.4810238304988025\n",
            "epoch: 579, step: 6, Train: label_loss: 0.11011952906847, precision: 0.3100120627261574, recall: 0.8846815834766119, f1: 0.459133541721242\n",
            "epoch: 579, step: 7, Train: label_loss: 0.12642763555049896, precision: 0.29130434782606884, recall: 0.8128249566723027, f1: 0.42889803379742125\n",
            "epoch: 579, step: 8, Train: label_loss: 0.10607210546731949, precision: 0.3278985507246179, recall: 0.8945634266884852, f1: 0.4798939460499632\n",
            "epoch: 579, step: 9, Train: label_loss: 0.11377835273742676, precision: 0.3145795523290796, recall: 0.8710217755442426, f1: 0.46222222218319486\n",
            "epoch: 579, step: 10, Train: label_loss: 0.13173183798789978, precision: 0.3128048780487614, recall: 0.8549999999998574, f1: 0.45803571424645145\n",
            "epoch: 579, step: 11, Train: label_loss: 0.11591348052024841, precision: 0.31246200607900837, recall: 0.859531772575107, f1: 0.45831475698269936\n",
            "epoch: 579, step: 12, Train: label_loss: 0.11645914614200592, precision: 0.3104077906268831, recall: 0.8485856905156657, f1: 0.45454545450619505\n",
            "epoch: 579, step: 13, Train: label_loss: 0.11086872220039368, precision: 0.32214765100669174, recall: 0.8684210526314361, f1: 0.4699599465559452\n",
            "epoch: 579, step: 14, Train: label_loss: 0.10172056406736374, precision: 0.32072072072070146, recall: 0.8841059602647542, f1: 0.470691934733919\n",
            "epoch: 579, step: 15, Train: label_loss: 0.10794859379529953, precision: 0.3104077906268831, recall: 0.857142857142713, f1: 0.45576407502794747\n",
            "epoch: 579, step: 16, Train: label_loss: 0.12314458191394806, precision: 0.3001222493887347, recall: 0.8568935427572675, f1: 0.4445450429674231\n",
            "epoch: 579, step: 17, Train: label_loss: 0.12022452801465988, precision: 0.3286153846153644, recall: 0.8396226415093019, f1: 0.4723573639577557\n",
            "epoch: 579, step: 18, Train: label_loss: 0.12780986726284027, precision: 0.31049382716047463, recall: 0.8314049586775485, f1: 0.45213483142103844\n",
            "epoch: 579, step: 19, Train: label_loss: 0.10904695093631744, precision: 0.32487922705312045, recall: 0.8776508972266104, f1: 0.4742177170164949\n",
            "epoch: 579, step: 20, Train: label_loss: 0.11855293810367584, precision: 0.32472324723245233, recall: 0.8712871287127274, f1: 0.47311827953029195\n",
            "epoch: 579, step: 21, Train: label_loss: 0.10223503410816193, precision: 0.3468523002421097, recall: 0.864253393665028, f1: 0.49503239736729016\n",
            "epoch: 579, step: 22, Train: label_loss: 0.10266171395778656, precision: 0.2995169082125423, recall: 0.8794326241133191, f1: 0.44684684680890446\n",
            "epoch: 579, step: 23, Train: label_loss: 0.11167317628860474, precision: 0.33158682634728054, recall: 0.8772277227721036, f1: 0.481260184642373\n",
            "epoch: 580, step: 0, Train: label_loss: 0.10857079923152924, precision: 0.3134777376654444, recall: 0.8905982905981383, f1: 0.4637294169618904\n",
            "epoch: 580, step: 1, Train: label_loss: 0.11236748099327087, precision: 0.32151589242051826, recall: 0.8840336134452295, f1: 0.47153742712355107\n",
            "epoch: 580, step: 2, Train: label_loss: 0.11298184096813202, precision: 0.3251684017146157, recall: 0.8704918032785458, f1: 0.4734730271560785\n",
            "epoch: 580, step: 3, Train: label_loss: 0.10050473362207413, precision: 0.3113377324534906, recall: 0.8826530612243396, f1: 0.46031042124743793\n",
            "epoch: 580, step: 4, Train: label_loss: 0.0939696878194809, precision: 0.33273381294962034, recall: 0.8966074313407275, f1: 0.48535198946637986\n",
            "epoch: 580, step: 5, Train: label_loss: 0.11332142353057861, precision: 0.32451923076921124, recall: 0.8985024958401167, f1: 0.47682119201395085\n",
            "epoch: 580, step: 6, Train: label_loss: 0.1095634251832962, precision: 0.31136638452235116, recall: 0.8833619210976186, f1: 0.46043808668470976\n",
            "epoch: 580, step: 7, Train: label_loss: 0.1052895039319992, precision: 0.32553956834530423, recall: 0.893092105263011, f1: 0.4771528997850564\n",
            "epoch: 580, step: 8, Train: label_loss: 0.11845797300338745, precision: 0.32070861331702377, recall: 0.8522727272725888, f1: 0.4660452729296011\n",
            "epoch: 580, step: 9, Train: label_loss: 0.10349559783935547, precision: 0.3266908212560189, recall: 0.8825448613375395, f1: 0.4768620537287028\n",
            "epoch: 580, step: 10, Train: label_loss: 0.10493827611207962, precision: 0.32870928829913576, recall: 0.887622149836989, f1: 0.4797535210872756\n",
            "epoch: 580, step: 11, Train: label_loss: 0.12265089154243469, precision: 0.33170134638920856, recall: 0.8741935483869557, f1: 0.4809228038642467\n",
            "epoch: 580, step: 12, Train: label_loss: 0.10673162341117859, precision: 0.30139478471799264, recall: 0.8643478260868062, f1: 0.44694244600478555\n",
            "epoch: 580, step: 13, Train: label_loss: 0.10642607510089874, precision: 0.34629404617251847, recall: 0.8782742681046412, f1: 0.4967320261031838\n",
            "epoch: 580, step: 14, Train: label_loss: 0.10918352007865906, precision: 0.32497013142172493, recall: 0.8976897689767495, f1: 0.4771929824170694\n",
            "epoch: 580, step: 15, Train: label_loss: 0.09559324383735657, precision: 0.31575793888554127, recall: 0.8917089678509489, f1: 0.4663716813772639\n",
            "epoch: 580, step: 16, Train: label_loss: 0.11577840894460678, precision: 0.33717404487566177, recall: 0.8924558587478503, f1: 0.4894366196784632\n",
            "epoch: 580, step: 17, Train: label_loss: 0.11290596425533295, precision: 0.3007836045810548, recall: 0.8863232682058816, f1: 0.4491449144535734\n",
            "epoch: 580, step: 18, Train: label_loss: 0.10319439321756363, precision: 0.31452581032411076, recall: 0.8896434634973022, f1: 0.4647450110478386\n",
            "epoch: 580, step: 19, Train: label_loss: 0.09175150096416473, precision: 0.3131313131312945, recall: 0.8977853492332372, f1: 0.4643171805783548\n",
            "epoch: 580, step: 20, Train: label_loss: 0.0882282704114914, precision: 0.30598802395207747, recall: 0.8795180722890051, f1: 0.4540204353237233\n",
            "epoch: 580, step: 21, Train: label_loss: 0.1025894433259964, precision: 0.30476765238380776, recall: 0.8444816053510293, f1: 0.4478935698057769\n",
            "epoch: 580, step: 22, Train: label_loss: 0.09912467747926712, precision: 0.31891891891889973, recall: 0.8924369747897659, f1: 0.4699115043859449\n",
            "epoch: 580, step: 23, Train: label_loss: 0.10548418015241623, precision: 0.33211143695012224, recall: 0.8882352941174729, f1: 0.48345784414389653\n",
            "epoch: 581, step: 0, Train: label_loss: 0.09360963106155396, precision: 0.3290017720023432, recall: 0.9206611570246411, f1: 0.48476936462609177\n",
            "epoch: 581, step: 1, Train: label_loss: 0.10491761565208435, precision: 0.3071776155717575, recall: 0.8444816053510293, f1: 0.4504906333239119\n",
            "epoch: 581, step: 2, Train: label_loss: 0.10802820324897766, precision: 0.32892363199035907, recall: 0.8738019169327677, f1: 0.4779379641367165\n",
            "epoch: 581, step: 3, Train: label_loss: 0.10439041256904602, precision: 0.31055155875297896, recall: 0.886986301369711, f1: 0.46003552394022956\n",
            "epoch: 581, step: 4, Train: label_loss: 0.0974469780921936, precision: 0.31316725978645826, recall: 0.8949152542371364, f1: 0.46397188045364496\n",
            "epoch: 581, step: 5, Train: label_loss: 0.11758571863174438, precision: 0.3237804878048583, recall: 0.8704918032785458, f1: 0.4719999999604361\n",
            "epoch: 581, step: 6, Train: label_loss: 0.10459688305854797, precision: 0.2973462002412366, recall: 0.8664323374339425, f1: 0.4427480915649696\n",
            "epoch: 581, step: 7, Train: label_loss: 0.12260797619819641, precision: 0.3213633597078319, recall: 0.8859060402683077, f1: 0.47163912457009183\n",
            "epoch: 581, step: 8, Train: label_loss: 0.11031549423933029, precision: 0.33925290875686837, recall: 0.8562596599689557, f1: 0.4859649122400099\n",
            "epoch: 581, step: 9, Train: label_loss: 0.11117098480463028, precision: 0.30935251798559293, recall: 0.9036777583185808, f1: 0.46092005355731647\n",
            "epoch: 581, step: 10, Train: label_loss: 0.09985579550266266, precision: 0.32809667673714027, recall: 0.8729903536976088, f1: 0.47694334646881265\n",
            "epoch: 581, step: 11, Train: label_loss: 0.10441121459007263, precision: 0.3285457809694597, recall: 0.9089403973508429, f1: 0.4826373625983188\n",
            "epoch: 581, step: 12, Train: label_loss: 0.11019270122051239, precision: 0.31044957472659107, recall: 0.8765008576327827, f1: 0.4585015701721872\n",
            "epoch: 581, step: 13, Train: label_loss: 0.09441012144088745, precision: 0.3261648745519518, recall: 0.8965517241377837, f1: 0.4783180025889597\n",
            "epoch: 581, step: 14, Train: label_loss: 0.09863217175006866, precision: 0.3193277310924178, recall: 0.8822553897179299, f1: 0.46892904359248844\n",
            "epoch: 581, step: 15, Train: label_loss: 0.09366863965988159, precision: 0.3170878459686933, recall: 0.875415282391881, f1: 0.4655477031411313\n",
            "epoch: 581, step: 16, Train: label_loss: 0.11163179576396942, precision: 0.32252252252250313, recall: 0.896494156928064, f1: 0.474381625402739\n",
            "epoch: 581, step: 17, Train: label_loss: 0.10509976744651794, precision: 0.29690346083786906, recall: 0.8670212765955909, f1: 0.44233378557932407\n",
            "epoch: 581, step: 18, Train: label_loss: 0.09620027244091034, precision: 0.32622853759619147, recall: 0.903278688524442, f1: 0.4793388429361787\n",
            "epoch: 581, step: 19, Train: label_loss: 0.09229636192321777, precision: 0.3046594982078671, recall: 0.8703071672353463, f1: 0.4513274335898667\n",
            "epoch: 581, step: 20, Train: label_loss: 0.10319046676158905, precision: 0.32374100719422516, recall: 0.8809135399672298, f1: 0.4734765453354901\n",
            "epoch: 581, step: 21, Train: label_loss: 0.11523422598838806, precision: 0.30986762936219553, recall: 0.8612040133777823, f1: 0.4557522123504226\n",
            "epoch: 581, step: 22, Train: label_loss: 0.10016599297523499, precision: 0.33232077764275014, recall: 0.8724082934607859, f1: 0.48130224369075886\n",
            "epoch: 581, step: 23, Train: label_loss: 0.11056548357009888, precision: 0.32821637426898187, recall: 0.8926441351886893, f1: 0.47995724207715096\n",
            "epoch: 582, step: 0, Train: label_loss: 0.10212080180644989, precision: 0.3100120627261574, recall: 0.8741496598637969, f1: 0.45770258232996247\n",
            "epoch: 582, step: 1, Train: label_loss: 0.08374875783920288, precision: 0.3229665071770142, recall: 0.8985024958401167, f1: 0.4751429828031178\n",
            "epoch: 582, step: 2, Train: label_loss: 0.10515471547842026, precision: 0.3221556886227352, recall: 0.8981636060098667, f1: 0.47421771701706983\n",
            "epoch: 582, step: 3, Train: label_loss: 0.11592823266983032, precision: 0.3019207683073048, recall: 0.862778730703111, f1: 0.44730991547956256\n",
            "epoch: 582, step: 4, Train: label_loss: 0.09382517635822296, precision: 0.32997032640947593, recall: 0.9084967320259952, f1: 0.48410970827606215\n",
            "epoch: 582, step: 5, Train: label_loss: 0.10233530402183533, precision: 0.3194029850746078, recall: 0.8901830282860415, f1: 0.4701230228081924\n",
            "epoch: 582, step: 6, Train: label_loss: 0.12052790820598602, precision: 0.31498470948010304, recall: 0.8626465661640096, f1: 0.46146953401095153\n",
            "epoch: 582, step: 7, Train: label_loss: 0.09458582103252411, precision: 0.352587244283974, recall: 0.8973966309340126, f1: 0.506263498879541\n",
            "epoch: 582, step: 8, Train: label_loss: 0.11066600680351257, precision: 0.33677184466017374, recall: 0.8865814696484207, f1: 0.4881266490365735\n",
            "epoch: 582, step: 9, Train: label_loss: 0.1034817099571228, precision: 0.3225609756097364, recall: 0.8772802653398213, f1: 0.4716897012535564\n",
            "epoch: 582, step: 10, Train: label_loss: 0.10421881079673767, precision: 0.3277108433734742, recall: 0.8903436988541914, f1: 0.47908410387960426\n",
            "epoch: 582, step: 11, Train: label_loss: 0.1153096854686737, precision: 0.3296703296703095, recall: 0.8639999999998617, f1: 0.47724259828078974\n",
            "epoch: 582, step: 12, Train: label_loss: 0.09478138387203217, precision: 0.31585220500594063, recall: 0.8967851099829277, f1: 0.46716615245151777\n",
            "epoch: 582, step: 13, Train: label_loss: 0.09991678595542908, precision: 0.3154761904761717, recall: 0.9169550173008794, f1: 0.46944198401855497\n",
            "epoch: 582, step: 14, Train: label_loss: 0.09951785206794739, precision: 0.3242092457420727, recall: 0.8752052545154556, f1: 0.47314691518465546\n",
            "epoch: 582, step: 15, Train: label_loss: 0.10664179921150208, precision: 0.296987951807211, recall: 0.8694885361550494, f1: 0.44274809156505757\n",
            "epoch: 582, step: 16, Train: label_loss: 0.09748516976833344, precision: 0.31455961653682957, recall: 0.898972602739572, f1: 0.46604527293092884\n",
            "epoch: 582, step: 17, Train: label_loss: 0.09497863054275513, precision: 0.3345302214242768, recall: 0.8958333333331897, f1: 0.4871459694592745\n",
            "epoch: 582, step: 18, Train: label_loss: 0.11701950430870056, precision: 0.30374396135263865, recall: 0.8554421768706028, f1: 0.44830659532670464\n",
            "epoch: 582, step: 19, Train: label_loss: 0.094027079641819, precision: 0.3056716417910265, recall: 0.8812392426848741, f1: 0.45390070918157566\n",
            "epoch: 582, step: 20, Train: label_loss: 0.10880192369222641, precision: 0.3219927095990084, recall: 0.8562197092082623, f1: 0.4679911699381632\n",
            "epoch: 582, step: 21, Train: label_loss: 0.10013580322265625, precision: 0.3010817307692127, recall: 0.8623063683303163, f1: 0.4463251669994579\n",
            "epoch: 582, step: 22, Train: label_loss: 0.10685551911592484, precision: 0.31713244228430637, recall: 0.8543371522093528, f1: 0.46256092153778844\n",
            "epoch: 582, step: 23, Train: label_loss: 0.11194425821304321, precision: 0.31254585473218544, recall: 0.8747433264885268, f1: 0.4605405405017015\n",
            "epoch: 583, step: 0, Train: label_loss: 0.12869957089424133, precision: 0.3351851851851645, recall: 0.8353846153844868, f1: 0.4784140968753872\n",
            "epoch: 583, step: 1, Train: label_loss: 0.1040356308221817, precision: 0.3165554881746321, recall: 0.8729096989965095, f1: 0.46461949261777324\n",
            "epoch: 583, step: 2, Train: label_loss: 0.1157209575176239, precision: 0.321494182486202, recall: 0.8564437194125846, f1: 0.4674977737803952\n",
            "epoch: 583, step: 3, Train: label_loss: 0.12616868317127228, precision: 0.2959501557632214, recall: 0.8304195804194352, f1: 0.43638033987853514\n",
            "epoch: 583, step: 4, Train: label_loss: 0.11101865768432617, precision: 0.3222289521501925, recall: 0.880794701986609, f1: 0.47184035472792096\n",
            "epoch: 583, step: 5, Train: label_loss: 0.11831009387969971, precision: 0.31040892193306624, recall: 0.8448566610453887, f1: 0.45400996824339646\n",
            "epoch: 583, step: 6, Train: label_loss: 0.09993381053209305, precision: 0.3268529769137104, recall: 0.8705501618121568, f1: 0.4752650176281112\n",
            "epoch: 583, step: 7, Train: label_loss: 0.10000577569007874, precision: 0.3289315726290319, recall: 0.9102990033221079, f1: 0.48324514987277845\n",
            "epoch: 583, step: 8, Train: label_loss: 0.10691662132740021, precision: 0.30024213075058714, recall: 0.8581314878891249, f1: 0.444843049288912\n",
            "epoch: 583, step: 9, Train: label_loss: 0.09922970831394196, precision: 0.3140987507435863, recall: 0.904109589040941, f1: 0.4662251655246013\n",
            "epoch: 583, step: 10, Train: label_loss: 0.10750558972358704, precision: 0.3191105769230577, recall: 0.873355263157751, f1: 0.4674295774255489\n",
            "epoch: 583, step: 11, Train: label_loss: 0.10575499385595322, precision: 0.31311274509802, recall: 0.8675721561967966, f1: 0.4601530841572931\n",
            "epoch: 583, step: 12, Train: label_loss: 0.10918601602315903, precision: 0.3220133414190223, recall: 0.8662316476344426, f1: 0.4694960211806059\n",
            "epoch: 583, step: 13, Train: label_loss: 0.1042388305068016, precision: 0.33012627781116477, recall: 0.9089403973508429, f1: 0.4843405381170216\n",
            "epoch: 583, step: 14, Train: label_loss: 0.10085146129131317, precision: 0.3187274909963794, recall: 0.9015280135821898, f1: 0.47095343676845886\n",
            "epoch: 583, step: 15, Train: label_loss: 0.12377506494522095, precision: 0.3206153846153649, recall: 0.8697829716192204, f1: 0.46852517981671427\n",
            "epoch: 583, step: 16, Train: label_loss: 0.09981445223093033, precision: 0.32072072072070146, recall: 0.9035532994922328, f1: 0.47340425528043883\n",
            "epoch: 583, step: 17, Train: label_loss: 0.1037890613079071, precision: 0.32650602409636587, recall: 0.8841761827078491, f1: 0.47690277162796674\n",
            "epoch: 583, step: 18, Train: label_loss: 0.10480158030986786, precision: 0.33273273273271275, recall: 0.8807631160570936, f1: 0.48299912812057405\n",
            "epoch: 583, step: 19, Train: label_loss: 0.10365666449069977, precision: 0.3317365269460879, recall: 0.8878205128203704, f1: 0.4829991281207719\n",
            "epoch: 583, step: 20, Train: label_loss: 0.10787948966026306, precision: 0.31908488862129325, recall: 0.877483443708464, f1: 0.4679911699387725\n",
            "epoch: 583, step: 21, Train: label_loss: 0.10576095432043076, precision: 0.30315664085763533, recall: 0.8961267605632225, f1: 0.4530485090854586\n",
            "epoch: 583, step: 22, Train: label_loss: 0.09709882736206055, precision: 0.31801909307874, recall: 0.8973063973062462, f1: 0.4696035241903934\n",
            "epoch: 583, step: 23, Train: label_loss: 0.10086353123188019, precision: 0.31314623338254705, recall: 0.8796680497923487, f1: 0.46187363830545497\n",
            "epoch: 584, step: 0, Train: label_loss: 0.11261197924613953, precision: 0.33373786407764966, recall: 0.871632329635361, f1: 0.4826678367304279\n",
            "epoch: 584, step: 1, Train: label_loss: 0.10531838983297348, precision: 0.3347560975609552, recall: 0.8755980861242622, f1: 0.4843405381160943\n",
            "epoch: 584, step: 2, Train: label_loss: 0.08971003443002701, precision: 0.32857142857140903, recall: 0.9108910891087605, f1: 0.4829396325069259\n",
            "epoch: 584, step: 3, Train: label_loss: 0.09634287655353546, precision: 0.3341404358353309, recall: 0.8860353130014629, f1: 0.4852747252349118\n",
            "epoch: 584, step: 4, Train: label_loss: 0.09730209410190582, precision: 0.34182464454974276, recall: 0.9202551834129313, f1: 0.49848812091078354\n",
            "epoch: 584, step: 5, Train: label_loss: 0.10156670212745667, precision: 0.3155015197568197, recall: 0.8781725888323386, f1: 0.4642218246480093\n",
            "epoch: 584, step: 6, Train: label_loss: 0.11080861836671829, precision: 0.31373725254947127, recall: 0.8804713804712322, f1: 0.4626271560868279\n",
            "epoch: 584, step: 7, Train: label_loss: 0.10505214333534241, precision: 0.3154402895054092, recall: 0.8804713804712322, f1: 0.4644760212755073\n",
            "epoch: 584, step: 8, Train: label_loss: 0.12389764934778214, precision: 0.31737262124000504, recall: 0.8645484949831329, f1: 0.46430175119551964\n",
            "epoch: 584, step: 9, Train: label_loss: 0.1243751049041748, precision: 0.3096259963212563, recall: 0.8559322033896853, f1: 0.4547501125228524\n",
            "epoch: 584, step: 10, Train: label_loss: 0.10840263217687607, precision: 0.3187537447573206, recall: 0.8911222780568021, f1: 0.4695498675692688\n",
            "epoch: 584, step: 11, Train: label_loss: 0.1108708381652832, precision: 0.31662591687039626, recall: 0.8547854785477137, f1: 0.4620874219052039\n",
            "epoch: 584, step: 12, Train: label_loss: 0.11585386842489243, precision: 0.30726939523516755, recall: 0.8383333333331936, f1: 0.4497094322360733\n",
            "epoch: 584, step: 13, Train: label_loss: 0.11880955100059509, precision: 0.2872793670115467, recall: 0.8597449908923752, f1: 0.43065693426898444\n",
            "epoch: 584, step: 14, Train: label_loss: 0.10901130735874176, precision: 0.30992736077479965, recall: 0.8476821192051576, f1: 0.4539007091806077\n",
            "epoch: 584, step: 15, Train: label_loss: 0.11687362939119339, precision: 0.31093463653021924, recall: 0.8760757314972674, f1: 0.4589720468503816\n",
            "epoch: 584, step: 16, Train: label_loss: 0.1034226045012474, precision: 0.31832014607423503, recall: 0.8658940397349559, f1: 0.46550956827395557\n",
            "epoch: 584, step: 17, Train: label_loss: 0.10727925598621368, precision: 0.3057090239410494, recall: 0.827242524916806, f1: 0.44643657548722493\n",
            "epoch: 584, step: 18, Train: label_loss: 0.11582513898611069, precision: 0.3343446601941545, recall: 0.8704581358608419, f1: 0.48312143792566253\n",
            "epoch: 584, step: 19, Train: label_loss: 0.10674408823251724, precision: 0.31265206812650165, recall: 0.8495867768593637, f1: 0.45709204086770056\n",
            "epoch: 584, step: 20, Train: label_loss: 0.10039660334587097, precision: 0.3112305854241152, recall: 0.8921232876710801, f1: 0.4614703276852597\n",
            "epoch: 584, step: 21, Train: label_loss: 0.10395576059818268, precision: 0.3407318536292537, recall: 0.9059011164272877, f1: 0.49520488226188997\n",
            "epoch: 584, step: 22, Train: label_loss: 0.10927131772041321, precision: 0.286062081558108, recall: 0.8438061041291124, f1: 0.42727272723487225\n",
            "epoch: 584, step: 23, Train: label_loss: 0.11225499957799911, precision: 0.3191011235954817, recall: 0.871165644171601, f1: 0.46710526311859984\n",
            "epoch: 585, step: 0, Train: label_loss: 0.10597600787878036, precision: 0.3191358024691161, recall: 0.843393148450107, f1: 0.4630541871522451\n",
            "epoch: 585, step: 1, Train: label_loss: 0.11781001091003418, precision: 0.30142945929146664, recall: 0.8262350936966224, f1: 0.44171220396807515\n",
            "epoch: 585, step: 2, Train: label_loss: 0.10792433470487595, precision: 0.30321406913278937, recall: 0.8833922261482537, f1: 0.45146726858493713\n",
            "epoch: 585, step: 3, Train: label_loss: 0.1112726479768753, precision: 0.30613496932513456, recall: 0.8414839797637703, f1: 0.44894286995634164\n",
            "epoch: 585, step: 4, Train: label_loss: 0.09475354850292206, precision: 0.3199037883343163, recall: 0.9063032367971198, f1: 0.4728888888502817\n",
            "epoch: 585, step: 5, Train: label_loss: 0.10806416720151901, precision: 0.3337408312958231, recall: 0.8584905660376008, f1: 0.4806338027765452\n",
            "epoch: 585, step: 6, Train: label_loss: 0.10698650777339935, precision: 0.32498472816125074, recall: 0.8553054662378046, f1: 0.47100486937129626\n",
            "epoch: 585, step: 7, Train: label_loss: 0.09583254158496857, precision: 0.3170441001191706, recall: 0.9001692047375803, f1: 0.46892904359298954\n",
            "epoch: 585, step: 8, Train: label_loss: 0.12109042704105377, precision: 0.3085889570551958, recall: 0.8468013468012042, f1: 0.4523381294572119\n",
            "epoch: 585, step: 9, Train: label_loss: 0.11333492398262024, precision: 0.3114852675886764, recall: 0.886986301369711, f1: 0.46105918999264106\n",
            "epoch: 585, step: 10, Train: label_loss: 0.1103728860616684, precision: 0.3216867469879324, recall: 0.8626817447494567, f1: 0.46862659057030787\n",
            "epoch: 585, step: 11, Train: label_loss: 0.10396990180015564, precision: 0.3137847642079617, recall: 0.850819672131008, f1: 0.4584805653316163\n",
            "epoch: 585, step: 12, Train: label_loss: 0.09863726794719696, precision: 0.32329921733893296, recall: 0.8774509803920134, f1: 0.4725032995646552\n",
            "epoch: 585, step: 13, Train: label_loss: 0.101763054728508, precision: 0.3176119402984885, recall: 0.9032258064514594, f1: 0.46996466427241723\n",
            "epoch: 585, step: 14, Train: label_loss: 0.11043369024991989, precision: 0.3038130381303626, recall: 0.8387096774192124, f1: 0.4460496613604675\n",
            "epoch: 585, step: 15, Train: label_loss: 0.11222214996814728, precision: 0.3083886541943085, recall: 0.8488372093021845, f1: 0.4524125718953497\n",
            "epoch: 585, step: 16, Train: label_loss: 0.11249023675918579, precision: 0.3174019607842943, recall: 0.861896838602186, f1: 0.46394984322080535\n",
            "epoch: 585, step: 17, Train: label_loss: 0.10527770221233368, precision: 0.3385354141656459, recall: 0.8938193343897156, f1: 0.49107531558919\n",
            "epoch: 585, step: 18, Train: label_loss: 0.10045378655195236, precision: 0.311711711711693, recall: 0.8811544991509539, f1: 0.46051464060021763\n",
            "epoch: 585, step: 19, Train: label_loss: 0.10453353077173233, precision: 0.3182640144665269, recall: 0.8785357737103363, f1: 0.467256637129058\n",
            "epoch: 585, step: 20, Train: label_loss: 0.09900733828544617, precision: 0.33615990308901655, recall: 0.8879999999998579, f1: 0.4876977152501001\n",
            "epoch: 585, step: 21, Train: label_loss: 0.0962199792265892, precision: 0.3161720169593994, recall: 0.8758389261743497, f1: 0.4646194926178567\n",
            "epoch: 585, step: 22, Train: label_loss: 0.09442496299743652, precision: 0.3349225268176201, recall: 0.9049919484700636, f1: 0.4889082209261639\n",
            "epoch: 585, step: 23, Train: label_loss: 0.11253882944583893, precision: 0.29926470588233095, recall: 0.8828633405637998, f1: 0.4470071388967884\n",
            "epoch: 586, step: 0, Train: label_loss: 0.1014426052570343, precision: 0.3380281690140638, recall: 0.8734177215188491, f1: 0.487417218502769\n",
            "epoch: 586, step: 1, Train: label_loss: 0.10872197151184082, precision: 0.34459867229931535, recall: 0.9006309148263563, f1: 0.49847228280584477\n",
            "epoch: 586, step: 2, Train: label_loss: 0.09511864930391312, precision: 0.32780082987549924, recall: 0.9006514657978989, f1: 0.4806605823163285\n",
            "epoch: 586, step: 3, Train: label_loss: 0.09415969252586365, precision: 0.30198915009039773, recall: 0.8713043478259354, f1: 0.44852282896799894\n",
            "epoch: 586, step: 4, Train: label_loss: 0.10060887038707733, precision: 0.327848872638615, recall: 0.8677419354837309, f1: 0.47589562136661095\n",
            "epoch: 586, step: 5, Train: label_loss: 0.09552378952503204, precision: 0.32267792521107824, recall: 0.8756137479540301, f1: 0.4715733803043684\n",
            "epoch: 586, step: 6, Train: label_loss: 0.09735234826803207, precision: 0.3107617896009486, recall: 0.8741496598637969, f1: 0.45851917926545527\n",
            "epoch: 586, step: 7, Train: label_loss: 0.10838807374238968, precision: 0.3072252580449115, recall: 0.864957264957117, f1: 0.4534050178824259\n",
            "epoch: 586, step: 8, Train: label_loss: 0.10899057984352112, precision: 0.3212560386473236, recall: 0.8837209302324113, f1: 0.47121346320265955\n",
            "epoch: 586, step: 9, Train: label_loss: 0.09933874011039734, precision: 0.32248342374922706, recall: 0.8872305140960386, f1: 0.47303271437288\n",
            "epoch: 586, step: 10, Train: label_loss: 0.09166379272937775, precision: 0.3370919881305438, recall: 0.9131832797426184, f1: 0.4924143909445347\n",
            "epoch: 586, step: 11, Train: label_loss: 0.1029808521270752, precision: 0.3153753026634192, recall: 0.8654485049832449, f1: 0.46228926349230887\n",
            "epoch: 586, step: 12, Train: label_loss: 0.1044464111328125, precision: 0.2969406118776067, recall: 0.8839285714284135, f1: 0.4445442298680174\n",
            "epoch: 586, step: 13, Train: label_loss: 0.09501325339078903, precision: 0.3109243697478805, recall: 0.893103448275708, f1: 0.46126447013083854\n",
            "epoch: 586, step: 14, Train: label_loss: 0.09441664814949036, precision: 0.3110447761193844, recall: 0.8951890034362723, f1: 0.4616747895053271\n",
            "epoch: 586, step: 15, Train: label_loss: 0.12401296943426132, precision: 0.30288166768851604, recall: 0.8681898066782304, f1: 0.44909090905251947\n",
            "epoch: 586, step: 16, Train: label_loss: 0.09907856583595276, precision: 0.3467306538692053, recall: 0.8906009244990923, f1: 0.49913644210124064\n",
            "epoch: 586, step: 17, Train: label_loss: 0.08793596178293228, precision: 0.33808674985143566, recall: 0.8904538341156666, f1: 0.49009474586876484\n",
            "epoch: 586, step: 18, Train: label_loss: 0.0962604284286499, precision: 0.30870083432656087, recall: 0.9103690685411404, f1: 0.4610591899932911\n",
            "epoch: 586, step: 19, Train: label_loss: 0.09468894451856613, precision: 0.32939787485240085, recall: 0.9192751235583329, f1: 0.4850065188659401\n",
            "epoch: 586, step: 20, Train: label_loss: 0.09276843816041946, precision: 0.3174984966927049, recall: 0.8918918918917411, f1: 0.46829268288806636\n",
            "epoch: 586, step: 21, Train: label_loss: 0.09551368653774261, precision: 0.3234761617380613, recall: 0.9054054054052524, f1: 0.47665629164636314\n",
            "epoch: 586, step: 22, Train: label_loss: 0.09430642426013947, precision: 0.31174334140433946, recall: 0.878839590443536, f1: 0.46023235027408205\n",
            "epoch: 586, step: 23, Train: label_loss: 0.09295760095119476, precision: 0.32446415373242243, recall: 0.8675889328061527, f1: 0.4722969337957242\n",
            "epoch: 587, step: 0, Train: label_loss: 0.09604483842849731, precision: 0.3146067415730151, recall: 0.9156626506022519, f1: 0.46830985911682277\n",
            "epoch: 587, step: 1, Train: label_loss: 0.10144928097724915, precision: 0.34227787716157765, recall: 0.8968749999998598, f1: 0.49546827790559206\n",
            "epoch: 587, step: 2, Train: label_loss: 0.09515774250030518, precision: 0.30542168674696957, recall: 0.8817391304346291, f1: 0.4536912751295281\n",
            "epoch: 587, step: 3, Train: label_loss: 0.09530359506607056, precision: 0.3085680047932709, recall: 0.878839590443536, f1: 0.45676274940716854\n",
            "epoch: 587, step: 4, Train: label_loss: 0.09372568130493164, precision: 0.31212484993995726, recall: 0.890410958903957, f1: 0.46222222218374387\n",
            "epoch: 587, step: 5, Train: label_loss: 0.10180169343948364, precision: 0.3385260635110642, recall: 0.8939873417720103, f1: 0.49109083003399345\n",
            "epoch: 587, step: 6, Train: label_loss: 0.09013694524765015, precision: 0.32236842105261226, recall: 0.9104729729728192, f1: 0.47614840985532875\n",
            "epoch: 587, step: 7, Train: label_loss: 0.10568390041589737, precision: 0.3078787878787692, recall: 0.8788927335638617, f1: 0.4560143626186259\n",
            "epoch: 587, step: 8, Train: label_loss: 0.09019745141267776, precision: 0.30113297555156227, recall: 0.8782608695650646, f1: 0.44849023086779444\n",
            "epoch: 587, step: 9, Train: label_loss: 0.09123169630765915, precision: 0.3248945147679129, recall: 0.8665594855304073, f1: 0.4725997369177676\n",
            "epoch: 587, step: 10, Train: label_loss: 0.09262759238481522, precision: 0.30548926014317984, recall: 0.8842832469773947, f1: 0.45410199552720276\n",
            "epoch: 587, step: 11, Train: label_loss: 0.09107905626296997, precision: 0.3046357615893856, recall: 0.8754325259514055, f1: 0.45198749437880825\n",
            "epoch: 587, step: 12, Train: label_loss: 0.1284431517124176, precision: 0.3133414932680347, recall: 0.8677966101693444, f1: 0.4604316546372355\n",
            "epoch: 587, step: 13, Train: label_loss: 0.0915759801864624, precision: 0.3281343731253552, recall: 0.8865478119933733, f1: 0.4789842381391591\n",
            "epoch: 587, step: 14, Train: label_loss: 0.09244617819786072, precision: 0.32597014925371187, recall: 0.88206785137304, f1: 0.47602441146883623\n",
            "epoch: 587, step: 15, Train: label_loss: 0.08707034587860107, precision: 0.3191105769230577, recall: 0.8969594594593079, f1: 0.4707446808123118\n",
            "epoch: 587, step: 16, Train: label_loss: 0.10005895793437958, precision: 0.3333333333333132, recall: 0.8890675241156126, f1: 0.48487505476081777\n",
            "epoch: 587, step: 17, Train: label_loss: 0.086921826004982, precision: 0.30764671013631845, recall: 0.8917525773194344, f1: 0.4574702511738057\n",
            "epoch: 587, step: 18, Train: label_loss: 0.1089622750878334, precision: 0.32093581283741324, recall: 0.8887043189367294, f1: 0.4715733803047376\n",
            "epoch: 587, step: 19, Train: label_loss: 0.09901073575019836, precision: 0.3305389221556688, recall: 0.893203883495001, f1: 0.4825174824780107\n",
            "epoch: 587, step: 20, Train: label_loss: 0.09552004933357239, precision: 0.3178016726403633, recall: 0.8822553897179299, f1: 0.4672815107207922\n",
            "epoch: 587, step: 21, Train: label_loss: 0.1030491515994072, precision: 0.3494558645707165, recall: 0.8810975609754754, f1: 0.5004329003921898\n",
            "epoch: 587, step: 22, Train: label_loss: 0.10879732668399811, precision: 0.32653061224487834, recall: 0.8845528455283114, f1: 0.47698377900485206\n",
            "epoch: 587, step: 23, Train: label_loss: 0.10026393830776215, precision: 0.32210834553438344, recall: 0.9147609147607246, f1: 0.47644829449310083\n",
            "epoch: 588, step: 0, Train: label_loss: 0.09089413285255432, precision: 0.30946745562128347, recall: 0.9064124783360646, f1: 0.4614027348539389\n",
            "epoch: 588, step: 1, Train: label_loss: 0.08531080931425095, precision: 0.33493686109438753, recall: 0.8969404186794047, f1: 0.4877408055645671\n",
            "epoch: 588, step: 2, Train: label_loss: 0.10586874186992645, precision: 0.3119047619047433, recall: 0.9097222222220642, f1: 0.4645390070541311\n",
            "epoch: 588, step: 3, Train: label_loss: 0.08838687837123871, precision: 0.30602409638552375, recall: 0.8743545611013985, f1: 0.4533690316438354\n",
            "epoch: 588, step: 4, Train: label_loss: 0.10821692645549774, precision: 0.3406727828745969, recall: 0.8676012461057838, f1: 0.48924022833012937\n",
            "epoch: 588, step: 5, Train: label_loss: 0.10285302996635437, precision: 0.32548309178741996, recall: 0.8836065573769043, f1: 0.47572815530041795\n",
            "epoch: 588, step: 6, Train: label_loss: 0.09345816820859909, precision: 0.3033033033032851, recall: 0.8875219683653975, f1: 0.452103849559129\n",
            "epoch: 588, step: 7, Train: label_loss: 0.08705407381057739, precision: 0.33313432835818907, recall: 0.9147540983605057, f1: 0.4884026257813879\n",
            "epoch: 588, step: 8, Train: label_loss: 0.0824216902256012, precision: 0.33116499112948955, recall: 0.9210526315787958, f1: 0.48716833401933934\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-4a8faa9f8476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n\u001b[0;32m----> 2\u001b[0;31m     ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=1000)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-f252055cc8f7>\u001b[0m in \u001b[0;36mtrain_s\u001b[0;34m(model_self, model_ngb, graph, ppi_list, loss_fn, optimizer_self, optimizer_ngb, device, result_file_pathr, summary_writerr, save_path, scheduler1, scheduler2, batch_size, epochs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mngb_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# self_loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_self.state_dict(), '/content/drive/My Drive/GNN_PPI/self_train.ckpt')\n",
        "torch.save(model_ngb.state_dict(), '/content/drive/My Drive/GNN_PPI/ngb_train.ckpt')"
      ],
      "metadata": {
        "id": "s_dDTsnxvFT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ngb.state_dict(), '/content/drive/My Drive/GNN_PPI/ngb_train.ckpt')"
      ],
      "metadata": {
        "id": "AQI-A-ftvE2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s(model_self, model_ngb, graph, ppi_list, loss_fn_s, optimizer_self, optimizer_ngb, device\n",
        "    ,result_file_path, summary_writer, save_path, scheduler_1, scheduler_2,batch_size=256, epochs=1000)\n",
        "summary_writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Advu19l4yRCw",
        "outputId": "7c4c5baa-1def-427b-db60-225418f57b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch: 735, step: 6, Train: label_loss: 0.08646564930677414, precision: 0.3101604278074682, recall: 0.8938356164382031, f1: 0.4605205116511675\n",
            "epoch: 735, step: 7, Train: label_loss: 0.07856622338294983, precision: 0.33827893175072177, recall: 0.8948194662478971, f1: 0.49095607231156396\n",
            "epoch: 735, step: 8, Train: label_loss: 0.09700731933116913, precision: 0.32273545290939876, recall: 0.8996655518393144, f1: 0.47505518759906473\n",
            "epoch: 735, step: 9, Train: label_loss: 0.08238112181425095, precision: 0.3129051266941477, recall: 0.9315789473682575, f1: 0.46846052047400516\n",
            "epoch: 735, step: 10, Train: label_loss: 0.08041632175445557, precision: 0.30970815961880227, recall: 0.8996539792385986, f1: 0.46078865747182635\n",
            "epoch: 735, step: 11, Train: label_loss: 0.0885726660490036, precision: 0.3239352129573891, recall: 0.8794788273614202, f1: 0.47347654533544964\n",
            "epoch: 735, step: 12, Train: label_loss: 0.08499903976917267, precision: 0.3194527067221702, recall: 0.8890728476819719, f1: 0.4700218817991411\n",
            "epoch: 735, step: 13, Train: label_loss: 0.0968928188085556, precision: 0.2937649880095747, recall: 0.864197530864045, f1: 0.4384787471656737\n",
            "epoch: 735, step: 14, Train: label_loss: 0.08820590376853943, precision: 0.32398568019091145, recall: 0.8843648208467615, f1: 0.4742358078209741\n",
            "epoch: 735, step: 15, Train: label_loss: 0.10485648363828659, precision: 0.3069069069068885, recall: 0.8749999999998501, f1: 0.4544241884897459\n",
            "epoch: 735, step: 16, Train: label_loss: 0.08597569167613983, precision: 0.3070539419086955, recall: 0.9024390243900866, f1: 0.4582043343274005\n",
            "epoch: 735, step: 17, Train: label_loss: 0.0997273176908493, precision: 0.3202179176755254, recall: 0.8831385642736421, f1: 0.47001332737093965\n",
            "epoch: 735, step: 18, Train: label_loss: 0.09175747632980347, precision: 0.3254577672770038, recall: 0.9183333333331802, f1: 0.4805931094249035\n",
            "epoch: 735, step: 19, Train: label_loss: 0.08660323172807693, precision: 0.3121629718394061, recall: 0.8785834738615719, f1: 0.46065428820176824\n",
            "epoch: 735, step: 20, Train: label_loss: 0.0830090269446373, precision: 0.3287425149700402, recall: 0.888349514562963, f1: 0.4798951048556333\n",
            "epoch: 735, step: 21, Train: label_loss: 0.10064908862113953, precision: 0.3365442504515149, recall: 0.89012738853489, f1: 0.4884228920527572\n",
            "epoch: 735, step: 22, Train: label_loss: 0.09699931740760803, precision: 0.3249850924269335, recall: 0.8818770226535789, f1: 0.4749455337296681\n",
            "epoch: 735, step: 23, Train: label_loss: 0.08100351691246033, precision: 0.3041907514450647, recall: 0.9073275862067011, f1: 0.4556277055900483\n",
            "epoch: 736, step: 0, Train: label_loss: 0.10285861790180206, precision: 0.31364190012178356, recall: 0.8803418803417298, f1: 0.4625056128934178\n",
            "epoch: 736, step: 1, Train: label_loss: 0.11038926988840103, precision: 0.29379562043793833, recall: 0.8488576449910634, f1: 0.4365115227814607\n",
            "epoch: 736, step: 2, Train: label_loss: 0.07194659858942032, precision: 0.33432304038002764, recall: 0.8936507936506517, f1: 0.4866032843164247\n",
            "epoch: 736, step: 3, Train: label_loss: 0.0806359201669693, precision: 0.3279569892472922, recall: 0.9014778325121672, f1: 0.48094612348252047\n",
            "epoch: 736, step: 4, Train: label_loss: 0.10362625122070312, precision: 0.32608695652171943, recall: 0.8809135399672298, f1: 0.47598060815796683\n",
            "epoch: 736, step: 5, Train: label_loss: 0.09142163395881653, precision: 0.32632211538459577, recall: 0.8945634266884852, f1: 0.4782034345710931\n",
            "epoch: 736, step: 6, Train: label_loss: 0.09838235378265381, precision: 0.29151515151513385, recall: 0.871376811594045, f1: 0.4368755676281507\n",
            "epoch: 736, step: 7, Train: label_loss: 0.10132361948490143, precision: 0.3270477312904934, recall: 0.9128289473682708, f1: 0.48156182208693216\n",
            "epoch: 736, step: 8, Train: label_loss: 0.08556435257196426, precision: 0.32934847579197074, recall: 0.903278688524442, f1: 0.4826982040781869\n",
            "epoch: 736, step: 9, Train: label_loss: 0.09723468124866486, precision: 0.31683765841881006, recall: 0.8749999999998541, f1: 0.4652193176392591\n",
            "epoch: 736, step: 10, Train: label_loss: 0.08974939584732056, precision: 0.3212560386473236, recall: 0.8580645161288938, f1: 0.4674868189409864\n",
            "epoch: 736, step: 11, Train: label_loss: 0.0832710713148117, precision: 0.3646144650328533, recall: 0.9077380952379601, f1: 0.5202558634985119\n",
            "epoch: 736, step: 12, Train: label_loss: 0.09264037013053894, precision: 0.3405146618790939, recall: 0.8946540880501738, f1: 0.4932813176886728\n",
            "epoch: 736, step: 13, Train: label_loss: 0.08980114758014679, precision: 0.2964943553178671, recall: 0.8723776223774697, f1: 0.44257206204635474\n",
            "epoch: 736, step: 14, Train: label_loss: 0.0921936109662056, precision: 0.2928009679370664, recall: 0.8658318425758736, f1: 0.43761301985369155\n",
            "epoch: 736, step: 15, Train: label_loss: 0.09790009260177612, precision: 0.2980652962514935, recall: 0.8603839441534274, f1: 0.44274809156479467\n",
            "epoch: 736, step: 16, Train: label_loss: 0.10911018401384354, precision: 0.32748184019368476, recall: 0.8655999999998615, f1: 0.4751866490598224\n",
            "epoch: 736, step: 17, Train: label_loss: 0.09051969647407532, precision: 0.30769230769228917, recall: 0.872231686541589, f1: 0.4549089293261322\n",
            "epoch: 736, step: 18, Train: label_loss: 0.09072624146938324, precision: 0.2980251346498924, recall: 0.8814159292033837, f1: 0.4454382826097782\n",
            "epoch: 736, step: 19, Train: label_loss: 0.09486789256334305, precision: 0.32733812949638325, recall: 0.8892508143321026, f1: 0.4785276073225877\n",
            "epoch: 736, step: 20, Train: label_loss: 0.09237167239189148, precision: 0.3144918821406906, recall: 0.8716666666665214, f1: 0.4622182942605938\n",
            "epoch: 736, step: 21, Train: label_loss: 0.08772343397140503, precision: 0.31790865384613476, recall: 0.8729372937292288, f1: 0.4660792951150055\n",
            "epoch: 736, step: 22, Train: label_loss: 0.08728088438510895, precision: 0.3273488928784963, recall: 0.8952536824875784, f1: 0.47940403151201705\n",
            "epoch: 736, step: 23, Train: label_loss: 0.09527544677257538, precision: 0.31929046563190544, recall: 0.8709677419353083, f1: 0.4672796105610153\n",
            "epoch: 737, step: 0, Train: label_loss: 0.08510222285985947, precision: 0.3259964306959949, recall: 0.9028006589784344, f1: 0.47902097898195417\n",
            "epoch: 737, step: 1, Train: label_loss: 0.08645141124725342, precision: 0.3218116805720905, recall: 0.9075630252099315, f1: 0.475142982803368\n",
            "epoch: 737, step: 2, Train: label_loss: 0.08653155714273453, precision: 0.29982259018330576, recall: 0.8989361702126065, f1: 0.44966740572741576\n",
            "epoch: 737, step: 3, Train: label_loss: 0.0882868617773056, precision: 0.30214541120379607, recall: 0.8910369068539734, f1: 0.45126835777255314\n",
            "epoch: 737, step: 4, Train: label_loss: 0.08889435231685638, precision: 0.3347255369928201, recall: 0.8947368421051204, f1: 0.48719062088955417\n",
            "epoch: 737, step: 5, Train: label_loss: 0.09714160859584808, precision: 0.3301088270858325, recall: 0.88206785137304, f1: 0.4804223492784065\n",
            "epoch: 737, step: 6, Train: label_loss: 0.074154794216156, precision: 0.3165769000598255, recall: 0.8772802653398213, f1: 0.465259454666353\n",
            "epoch: 737, step: 7, Train: label_loss: 0.10297112166881561, precision: 0.32989064398539913, recall: 0.8743961352655596, f1: 0.47904719890151143\n",
            "epoch: 737, step: 8, Train: label_loss: 0.08838063478469849, precision: 0.31997607655500476, recall: 0.900673400673249, f1: 0.47219770516868814\n",
            "epoch: 737, step: 9, Train: label_loss: 0.08543318510055542, precision: 0.3260355029585606, recall: 0.9214046822740933, f1: 0.48164335660470403\n",
            "epoch: 737, step: 10, Train: label_loss: 0.09233160316944122, precision: 0.32153569286140843, recall: 0.8963210702339638, f1: 0.4732891831840538\n",
            "epoch: 737, step: 11, Train: label_loss: 0.08852387964725494, precision: 0.3194278903456305, recall: 0.9008403361343024, f1: 0.47162340515268636\n",
            "epoch: 737, step: 12, Train: label_loss: 0.09869426488876343, precision: 0.2933657942787405, recall: 0.877959927140095, f1: 0.43978102186022444\n",
            "epoch: 737, step: 13, Train: label_loss: 0.08133366703987122, precision: 0.3301775147928799, recall: 0.8956661316210439, f1: 0.48249027233413927\n",
            "epoch: 737, step: 14, Train: label_loss: 0.09247851371765137, precision: 0.3291442250149414, recall: 0.8928571428569978, f1: 0.4809794490205017\n",
            "epoch: 737, step: 15, Train: label_loss: 0.10487355291843414, precision: 0.324275362318821, recall: 0.8605769230767851, f1: 0.4710526315391498\n",
            "epoch: 737, step: 16, Train: label_loss: 0.09286744892597198, precision: 0.30614729153984743, recall: 0.848229342327007, f1: 0.44991055452270273\n",
            "epoch: 737, step: 17, Train: label_loss: 0.09986746311187744, precision: 0.3379434756464018, recall: 0.8892405063289731, f1: 0.489760348543926\n",
            "epoch: 737, step: 18, Train: label_loss: 0.10351096838712692, precision: 0.3212560386473236, recall: 0.8650406504063634, f1: 0.468516072175348\n",
            "epoch: 737, step: 19, Train: label_loss: 0.08035615086555481, precision: 0.30805970149251893, recall: 0.8896551724136397, f1: 0.4576496673675142\n",
            "epoch: 737, step: 20, Train: label_loss: 0.09450088441371918, precision: 0.32932692307690326, recall: 0.8782051282049874, f1: 0.47902097898126766\n",
            "epoch: 737, step: 21, Train: label_loss: 0.09989848732948303, precision: 0.32660332541565756, recall: 0.9075907590757577, f1: 0.4803493449392039\n",
            "epoch: 737, step: 22, Train: label_loss: 0.09768617898225784, precision: 0.3156007172743386, recall: 0.8949152542371364, f1: 0.46663720720842744\n",
            "epoch: 737, step: 23, Train: label_loss: 0.0928608700633049, precision: 0.3135095447870548, recall: 0.8951781970648018, f1: 0.4643828167097618\n",
            "epoch: 738, step: 0, Train: label_loss: 0.08292935788631439, precision: 0.33133971291864045, recall: 0.89354838709663, f1: 0.4834205933287286\n",
            "epoch: 738, step: 1, Train: label_loss: 0.08478972315788269, precision: 0.3117893476959718, recall: 0.8951890034362723, f1: 0.462494451803629\n",
            "epoch: 738, step: 2, Train: label_loss: 0.0777490884065628, precision: 0.3114949374627569, recall: 0.8986254295531101, f1: 0.46262715608733745\n",
            "epoch: 738, step: 3, Train: label_loss: 0.09286519140005112, precision: 0.314859926918373, recall: 0.8545454545453133, f1: 0.46016911433533014\n",
            "epoch: 738, step: 4, Train: label_loss: 0.08629626035690308, precision: 0.3161367726454519, recall: 0.8917089678509489, f1: 0.46678476524032053\n",
            "epoch: 738, step: 5, Train: label_loss: 0.09272268414497375, precision: 0.32758620689653223, recall: 0.9003267973854737, f1: 0.4803836093767036\n",
            "epoch: 738, step: 6, Train: label_loss: 0.07883371412754059, precision: 0.3181279620852892, recall: 0.9148211243610025, f1: 0.4720879120495812\n",
            "epoch: 738, step: 7, Train: label_loss: 0.09655319154262543, precision: 0.3159784560143437, recall: 0.8918918918917411, f1: 0.4666372072083429\n",
            "epoch: 738, step: 8, Train: label_loss: 0.08853043615818024, precision: 0.32875894988064863, recall: 0.8930307941651713, f1: 0.48059310942420774\n",
            "epoch: 738, step: 9, Train: label_loss: 0.07248998433351517, precision: 0.33569739952716693, recall: 0.9117174959870125, f1: 0.49071274294118084\n",
            "epoch: 738, step: 10, Train: label_loss: 0.08753368258476257, precision: 0.3128358208955037, recall: 0.8941979522182774, f1: 0.46351172043922284\n",
            "epoch: 738, step: 11, Train: label_loss: 0.11302462965250015, precision: 0.3300911854103143, recall: 0.8872549019606393, f1: 0.48116969424487965\n",
            "epoch: 738, step: 12, Train: label_loss: 0.08626757562160492, precision: 0.32962529274002755, recall: 0.9290429042902757, f1: 0.48660328431739114\n",
            "epoch: 738, step: 13, Train: label_loss: 0.08240357041358948, precision: 0.334525939177082, recall: 0.8975999999998563, f1: 0.4874022588656995\n",
            "epoch: 738, step: 14, Train: label_loss: 0.10061889886856079, precision: 0.3082066869300724, recall: 0.8637137989777063, f1: 0.4543010752300109\n",
            "epoch: 738, step: 15, Train: label_loss: 0.08650480210781097, precision: 0.3171462829736021, recall: 0.8875838926173006, f1: 0.4673144875936775\n",
            "epoch: 738, step: 16, Train: label_loss: 0.08849714696407318, precision: 0.32442067736183455, recall: 0.9009900990097522, f1: 0.4770642201445136\n",
            "epoch: 738, step: 17, Train: label_loss: 0.10474880039691925, precision: 0.30935251798559293, recall: 0.870151770657526, f1: 0.4564352056224743\n",
            "epoch: 738, step: 18, Train: label_loss: 0.10776420682668686, precision: 0.30290205562271444, recall: 0.8697916666665156, f1: 0.4493273542217336\n",
            "epoch: 738, step: 19, Train: label_loss: 0.1073240339756012, precision: 0.3013447432762652, recall: 0.8327702702701295, f1: 0.44254937159469093\n",
            "epoch: 738, step: 20, Train: label_loss: 0.09704698622226715, precision: 0.30517549077927986, recall: 0.8875432525950021, f1: 0.45418326689415106\n",
            "epoch: 738, step: 21, Train: label_loss: 0.10090415179729462, precision: 0.32897085068409704, recall: 0.8862179487178067, f1: 0.47982646416871555\n",
            "epoch: 738, step: 22, Train: label_loss: 0.10024845600128174, precision: 0.3359516616313996, recall: 0.8982229402260261, f1: 0.4890061565126655\n",
            "epoch: 738, step: 23, Train: label_loss: 0.10466168820858002, precision: 0.32317979197620184, recall: 0.8562992125982567, f1: 0.4692556633905851\n",
            "epoch: 739, step: 0, Train: label_loss: 0.0925261601805687, precision: 0.33174224343673436, recall: 0.8953301127212728, f1: 0.4841097082756991\n",
            "epoch: 739, step: 1, Train: label_loss: 0.08642664551734924, precision: 0.3221238938052907, recall: 0.9054726368157702, f1: 0.47519582241555725\n",
            "epoch: 739, step: 2, Train: label_loss: 0.08791004121303558, precision: 0.3250591016548271, recall: 0.9090909090907587, f1: 0.4788855027909334\n",
            "epoch: 739, step: 3, Train: label_loss: 0.07022219151258469, precision: 0.34658753709196755, recall: 0.9124999999998573, f1: 0.502365591357907\n",
            "epoch: 739, step: 4, Train: label_loss: 0.09842395782470703, precision: 0.30277442702048835, recall: 0.8791593695269914, f1: 0.45042620005157663\n",
            "epoch: 739, step: 5, Train: label_loss: 0.08489568531513214, precision: 0.3299401197604593, recall: 0.9003267973854737, f1: 0.48290972826920653\n",
            "epoch: 739, step: 6, Train: label_loss: 0.0866544172167778, precision: 0.3239012642985958, recall: 0.8936877076410475, f1: 0.4754750331027545\n",
            "epoch: 739, step: 7, Train: label_loss: 0.08483032137155533, precision: 0.31771771771769863, recall: 0.8890756302519514, f1: 0.4681415928815204\n",
            "epoch: 739, step: 8, Train: label_loss: 0.0934671014547348, precision: 0.3111243307554842, recall: 0.8970840480272904, f1: 0.46201413423733795\n",
            "epoch: 739, step: 9, Train: label_loss: 0.09377019852399826, precision: 0.31812725090034105, recall: 0.8892617449662937, f1: 0.4686118478833393\n",
            "epoch: 739, step: 10, Train: label_loss: 0.08508630841970444, precision: 0.33412745681951556, recall: 0.8975999999998563, f1: 0.4869791666270881\n",
            "epoch: 739, step: 11, Train: label_loss: 0.09156673401594162, precision: 0.3214716525934667, recall: 0.8638573743920803, f1: 0.4685714285318564\n",
            "epoch: 739, step: 12, Train: label_loss: 0.0931144505739212, precision: 0.3329334133173166, recall: 0.9143327841843633, f1: 0.48812664903733843\n",
            "epoch: 739, step: 13, Train: label_loss: 0.08786974102258682, precision: 0.3113095238095053, recall: 0.8986254295531101, f1: 0.4624226347981682\n",
            "epoch: 739, step: 14, Train: label_loss: 0.09440439939498901, precision: 0.3201201201201009, recall: 0.8780889621085868, f1: 0.4691901408058715\n",
            "epoch: 739, step: 15, Train: label_loss: 0.10015100985765457, precision: 0.3147815679233803, recall: 0.8840336134452295, f1: 0.4642541923707652\n",
            "epoch: 739, step: 16, Train: label_loss: 0.09016897529363632, precision: 0.32516437537356097, recall: 0.8903436988541914, f1: 0.4763572679117315\n",
            "epoch: 739, step: 17, Train: label_loss: 0.09500148892402649, precision: 0.31350386674596586, recall: 0.9086206896550156, f1: 0.46616541349564944\n",
            "epoch: 739, step: 18, Train: label_loss: 0.07745428383350372, precision: 0.33293768545992086, recall: 0.9151712887437332, f1: 0.4882506527023526\n",
            "epoch: 739, step: 19, Train: label_loss: 0.09089043736457825, precision: 0.31708749265999314, recall: 0.9215017064844843, f1: 0.47182175618729116\n",
            "epoch: 739, step: 20, Train: label_loss: 0.09845596551895142, precision: 0.3075528700906158, recall: 0.8671209540032594, f1: 0.45405887596487365\n",
            "epoch: 739, step: 21, Train: label_loss: 0.08236335217952728, precision: 0.3214920071047767, recall: 0.9080267558526909, f1: 0.47485789239684206\n",
            "epoch: 739, step: 22, Train: label_loss: 0.09458078444004059, precision: 0.32078853046593064, recall: 0.8920265780729415, f1: 0.47188049205243904\n",
            "epoch: 739, step: 23, Train: label_loss: 0.10427471250295639, precision: 0.3122703894195215, recall: 0.8835758835756999, f1: 0.4614549402436636\n",
            "epoch: 740, step: 0, Train: label_loss: 0.08852604031562805, precision: 0.3176400476757856, recall: 0.8839137645106327, f1: 0.4673388864143744\n",
            "epoch: 740, step: 1, Train: label_loss: 0.06787719577550888, precision: 0.330597889800684, recall: 0.935323383084422, f1: 0.4885231701649187\n",
            "epoch: 740, step: 2, Train: label_loss: 0.08700871467590332, precision: 0.3349282296650517, recall: 0.8945686900957037, f1: 0.48738033068268416\n",
            "epoch: 740, step: 3, Train: label_loss: 0.09579446911811829, precision: 0.3060370591751162, recall: 0.885813148788774, f1: 0.45490892932651805\n",
            "epoch: 740, step: 4, Train: label_loss: 0.0808778926730156, precision: 0.32269503546097383, recall: 0.9130434782607169, f1: 0.47685589515787613\n",
            "epoch: 740, step: 5, Train: label_loss: 0.08085867017507553, precision: 0.3161328588374664, recall: 0.8973063973062462, f1: 0.4675438596105512\n",
            "epoch: 740, step: 6, Train: label_loss: 0.08132478594779968, precision: 0.32208407341620354, recall: 0.9096989966553662, f1: 0.47573240048604176\n",
            "epoch: 740, step: 7, Train: label_loss: 0.0815899521112442, precision: 0.3173758865248039, recall: 0.897993311036639, f1: 0.46899563314914317\n",
            "epoch: 740, step: 8, Train: label_loss: 0.08223207294940948, precision: 0.31563245823387137, recall: 0.9152249134946513, f1: 0.46938775506386404\n",
            "epoch: 740, step: 9, Train: label_loss: 0.09491723775863647, precision: 0.33012048192769095, recall: 0.8782051282049874, f1: 0.479859894881436\n",
            "epoch: 740, step: 10, Train: label_loss: 0.08752427995204926, precision: 0.3179640718562684, recall: 0.8849999999998525, f1: 0.4678414096526981\n",
            "epoch: 740, step: 11, Train: label_loss: 0.08858218789100647, precision: 0.32657926102501034, recall: 0.8954248366011608, f1: 0.478602620048129\n",
            "epoch: 740, step: 12, Train: label_loss: 0.10631713271141052, precision: 0.311711711711693, recall: 0.869346733668196, f1: 0.4588859416056679\n",
            "epoch: 740, step: 13, Train: label_loss: 0.09004050493240356, precision: 0.32976827094472194, recall: 0.9143327841843633, f1: 0.48471615716623667\n",
            "epoch: 740, step: 14, Train: label_loss: 0.09755994379520416, precision: 0.31442365721180965, recall: 0.8771043771042294, f1: 0.46290537534982523\n",
            "epoch: 740, step: 15, Train: label_loss: 0.09081504493951797, precision: 0.34494979326637065, recall: 0.9211356466875518, f1: 0.5019338203298868\n",
            "epoch: 740, step: 16, Train: label_loss: 0.09356239438056946, precision: 0.30955188679243456, recall: 0.9178321678320073, f1: 0.4629629629252026\n",
            "epoch: 740, step: 17, Train: label_loss: 0.09630279242992401, precision: 0.3010817307692127, recall: 0.8804920913882459, f1: 0.4487236900649835\n",
            "epoch: 740, step: 18, Train: label_loss: 0.08678257465362549, precision: 0.3206330597889613, recall: 0.9193277310922824, f1: 0.4754454584579211\n",
            "epoch: 740, step: 19, Train: label_loss: 0.09169106930494308, precision: 0.3178016726403633, recall: 0.8896321070232626, f1: 0.4683098591161028\n",
            "epoch: 740, step: 20, Train: label_loss: 0.07807281613349915, precision: 0.3222416812609269, recall: 0.9230769230767687, f1: 0.47771527473442343\n",
            "epoch: 740, step: 21, Train: label_loss: 0.09024431556463242, precision: 0.3156640857653177, recall: 0.8967851099829277, f1: 0.46696035238435246\n",
            "epoch: 740, step: 22, Train: label_loss: 0.09391966462135315, precision: 0.34415584415582384, recall: 0.9239302694134827, f1: 0.5015053763044947\n",
            "epoch: 740, step: 23, Train: label_loss: 0.08947210013866425, precision: 0.3442982456140099, recall: 0.9040307101725711, f1: 0.4986765483983268\n",
            "epoch: 741, step: 0, Train: label_loss: 0.07872828841209412, precision: 0.31588447653427704, recall: 0.8692052980131011, f1: 0.46337157983729327\n",
            "epoch: 741, step: 1, Train: label_loss: 0.07870540022850037, precision: 0.30213270142178306, recall: 0.9042553191487758, f1: 0.4529307282039785\n",
            "epoch: 741, step: 2, Train: label_loss: 0.09599092602729797, precision: 0.33634175691935403, recall: 0.8817034700314066, f1: 0.48693379786938856\n",
            "epoch: 741, step: 3, Train: label_loss: 0.09262987971305847, precision: 0.3196915776986762, recall: 0.8998330550916694, f1: 0.47177242884529996\n",
            "epoch: 741, step: 4, Train: label_loss: 0.08882257342338562, precision: 0.33472803347278335, recall: 0.8818897637793887, f1: 0.48526863080929133\n",
            "epoch: 741, step: 5, Train: label_loss: 0.0908743143081665, precision: 0.3103037522334538, recall: 0.8982758620688106, f1: 0.4612660468852106\n",
            "epoch: 741, step: 6, Train: label_loss: 0.07289474457502365, precision: 0.3399882560187704, recall: 0.9263999999998517, f1: 0.49742268037304954\n",
            "epoch: 741, step: 7, Train: label_loss: 0.09356901049613953, precision: 0.3217910447761002, recall: 0.9074074074072546, f1: 0.47509916258801477\n",
            "epoch: 741, step: 8, Train: label_loss: 0.08637457340955734, precision: 0.3301775147928799, recall: 0.8956661316210439, f1: 0.48249027233413927\n",
            "epoch: 741, step: 9, Train: label_loss: 0.08251956105232239, precision: 0.33114558472551725, recall: 0.8922829581992134, f1: 0.4830287205871082\n",
            "epoch: 741, step: 10, Train: label_loss: 0.0955188125371933, precision: 0.30346475507764015, recall: 0.9055258467021559, f1: 0.45458612971627377\n",
            "epoch: 741, step: 11, Train: label_loss: 0.08036352694034576, precision: 0.3201675643327157, recall: 0.8946488294312884, f1: 0.47157338030490364\n",
            "epoch: 741, step: 12, Train: label_loss: 0.09443877637386322, precision: 0.33471810089018783, recall: 0.91856677524415, f1: 0.4906481078337966\n",
            "epoch: 741, step: 13, Train: label_loss: 0.08696667104959488, precision: 0.3381037567083877, recall: 0.9043062200955495, f1: 0.4921874999603417\n",
            "epoch: 741, step: 14, Train: label_loss: 0.08615370094776154, precision: 0.3281249999999803, recall: 0.8863636363634924, f1: 0.4789473683815745\n",
            "epoch: 741, step: 15, Train: label_loss: 0.11328665167093277, precision: 0.30643203883493286, recall: 0.8813263525303872, f1: 0.4547501125235816\n",
            "epoch: 741, step: 16, Train: label_loss: 0.09503018110990524, precision: 0.3053527980535094, recall: 0.8566552901022428, f1: 0.450224215207851\n",
            "epoch: 741, step: 17, Train: label_loss: 0.08444661647081375, precision: 0.3268321513002171, recall: 0.9201331114807121, f1: 0.48233754902364073\n",
            "epoch: 741, step: 18, Train: label_loss: 0.08059179037809372, precision: 0.30673758865246414, recall: 0.8932874354559563, f1: 0.45666520013788403\n",
            "epoch: 741, step: 19, Train: label_loss: 0.09007357060909271, precision: 0.3390736342042554, recall: 0.9106858054225022, f1: 0.49415837295911874\n",
            "epoch: 741, step: 20, Train: label_loss: 0.09817744791507721, precision: 0.3185096153845962, recall: 0.8789386401325242, f1: 0.46757829727013\n",
            "epoch: 741, step: 21, Train: label_loss: 0.08596180379390717, precision: 0.30113297555156227, recall: 0.9148550724636023, f1: 0.4531179900927992\n",
            "epoch: 741, step: 22, Train: label_loss: 0.09347879141569138, precision: 0.32342449464920786, recall: 0.894736842105116, f1: 0.4751091702666332\n",
            "epoch: 741, step: 23, Train: label_loss: 0.09561435878276825, precision: 0.3157110945643845, recall: 0.8617886178860037, f1: 0.46212534056015836\n",
            "epoch: 742, step: 0, Train: label_loss: 0.07356462627649307, precision: 0.33788598574819845, recall: 0.9147909967844188, f1: 0.4934952297957745\n",
            "epoch: 742, step: 1, Train: label_loss: 0.09303134679794312, precision: 0.31729598051155194, recall: 0.8540983606555976, f1: 0.4626998223405656\n",
            "epoch: 742, step: 2, Train: label_loss: 0.08869937807321548, precision: 0.32194244604314615, recall: 0.897993311036639, f1: 0.47396293023471664\n",
            "epoch: 742, step: 3, Train: label_loss: 0.08091042190790176, precision: 0.34297520661155, recall: 0.9178515007897443, f1: 0.49935539317049354\n",
            "epoch: 742, step: 4, Train: label_loss: 0.09532348811626434, precision: 0.31440526001193575, recall: 0.8915254237286624, f1: 0.4648696420294615\n",
            "epoch: 742, step: 5, Train: label_loss: 0.10660538077354431, precision: 0.30778588807784013, recall: 0.8576271186439224, f1: 0.4529991047059414\n",
            "epoch: 742, step: 6, Train: label_loss: 0.09093275666236877, precision: 0.3138424821002199, recall: 0.903780068728367, f1: 0.4658990256481439\n",
            "epoch: 742, step: 7, Train: label_loss: 0.08758626878261566, precision: 0.32342449464920786, recall: 0.9251700680270535, f1: 0.47929515414659296\n",
            "epoch: 742, step: 8, Train: label_loss: 0.09976908564567566, precision: 0.33212341197820133, recall: 0.8970588235292651, f1: 0.48476821188104874\n",
            "epoch: 742, step: 9, Train: label_loss: 0.09090718626976013, precision: 0.32240762812870544, recall: 0.9001663893509317, f1: 0.47476963576630243\n",
            "epoch: 742, step: 10, Train: label_loss: 0.10067852586507797, precision: 0.3297101449275163, recall: 0.8849270664504237, f1: 0.48042234927848676\n",
            "epoch: 742, step: 11, Train: label_loss: 0.09626562893390656, precision: 0.3293341331733456, recall: 0.8912337662336215, f1: 0.4809461234822364\n",
            "epoch: 742, step: 12, Train: label_loss: 0.08753585815429688, precision: 0.30912364945976534, recall: 0.8699324324322855, f1: 0.45615589012956187\n",
            "epoch: 742, step: 13, Train: label_loss: 0.0933452621102333, precision: 0.31005917159761476, recall: 0.9144851657939066, f1: 0.463102076851226\n",
            "epoch: 742, step: 14, Train: label_loss: 0.07406596839427948, precision: 0.3116805721096358, recall: 0.8909710391821309, f1: 0.46181015448694623\n",
            "epoch: 742, step: 15, Train: label_loss: 0.09231910109519958, precision: 0.3266272189348919, recall: 0.9108910891087605, f1: 0.48083623689490107\n",
            "epoch: 742, step: 16, Train: label_loss: 0.08462376147508621, precision: 0.31901118304883347, recall: 0.9217687074828363, f1: 0.47398338430806325\n",
            "epoch: 742, step: 17, Train: label_loss: 0.0808301791548729, precision: 0.3475935828876799, recall: 0.9027777777776383, f1: 0.5019305018903164\n",
            "epoch: 742, step: 18, Train: label_loss: 0.09051907807588577, precision: 0.32552552552550595, recall: 0.9018302828617467, f1: 0.4783759929000813\n",
            "epoch: 742, step: 19, Train: label_loss: 0.10194087028503418, precision: 0.3184257602862064, recall: 0.8974789915964877, f1: 0.47007042249650977\n",
            "epoch: 742, step: 20, Train: label_loss: 0.09199013561010361, precision: 0.3120865904990792, recall: 0.8649999999998558, f1: 0.4586831639026621\n",
            "epoch: 742, step: 21, Train: label_loss: 0.12238658964633942, precision: 0.2960444993819347, recall: 0.8344947735190184, f1: 0.43704379558174006\n",
            "epoch: 742, step: 22, Train: label_loss: 0.08006338775157928, precision: 0.3202614379084777, recall: 0.9104729729728192, f1: 0.4738461538076111\n",
            "epoch: 742, step: 23, Train: label_loss: 0.08380351215600967, precision: 0.3328488372092781, recall: 0.9087301587299784, f1: 0.4872340425138965\n",
            "epoch: 743, step: 0, Train: label_loss: 0.08239569514989853, precision: 0.3222891566264866, recall: 0.8784893267650445, f1: 0.4715733803044499\n",
            "epoch: 743, step: 1, Train: label_loss: 0.08592944592237473, precision: 0.3327359617682, recall: 0.8954983922828141, f1: 0.4851916375911166\n",
            "epoch: 743, step: 2, Train: label_loss: 0.08326815068721771, precision: 0.33943329397872846, recall: 0.9156050955412555, f1: 0.4952627045255255\n",
            "epoch: 743, step: 3, Train: label_loss: 0.08387871086597443, precision: 0.32115038945474406, recall: 0.881578947368276, f1: 0.470794905538329\n",
            "epoch: 743, step: 4, Train: label_loss: 0.07957467436790466, precision: 0.32720806164787625, recall: 0.9093904448103938, f1: 0.4812554489584248\n",
            "epoch: 743, step: 5, Train: label_loss: 0.08843985199928284, precision: 0.3239352129573891, recall: 0.8881578947366959, f1: 0.4747252746860672\n",
            "epoch: 743, step: 6, Train: label_loss: 0.09018558263778687, precision: 0.31801692865778003, recall: 0.8840336134452295, f1: 0.46776345038345457\n",
            "epoch: 743, step: 7, Train: label_loss: 0.09645502269268036, precision: 0.298391899940423, recall: 0.8804920913882459, f1: 0.44572953732869897\n",
            "epoch: 743, step: 8, Train: label_loss: 0.08694857358932495, precision: 0.3159784560143437, recall: 0.8949152542371364, f1: 0.46704997784727914\n",
            "epoch: 743, step: 9, Train: label_loss: 0.08656604588031769, precision: 0.3329383886255727, recall: 0.9138211382112335, f1: 0.48805905336940886\n",
            "epoch: 743, step: 10, Train: label_loss: 0.10831421613693237, precision: 0.3218390804597506, recall: 0.8735632183906611, f1: 0.4703801944787349\n",
            "epoch: 743, step: 11, Train: label_loss: 0.08024533092975616, precision: 0.31644077784323416, recall: 0.9117147707978078, f1: 0.4698162729275843\n",
            "epoch: 743, step: 12, Train: label_loss: 0.09030555188655853, precision: 0.3225419664268392, recall: 0.8936877076410475, f1: 0.47400881053367194\n",
            "epoch: 743, step: 13, Train: label_loss: 0.09195303916931152, precision: 0.32597014925371187, recall: 0.9024793388428259, f1: 0.4789473683820227\n",
            "epoch: 743, step: 14, Train: label_loss: 0.0927896499633789, precision: 0.3046116504854184, recall: 0.8869257950528467, f1: 0.45347786807391516\n",
            "epoch: 743, step: 15, Train: label_loss: 0.10363369435071945, precision: 0.31864204883857544, recall: 0.891666666666518, f1: 0.46950416845612064\n",
            "epoch: 743, step: 16, Train: label_loss: 0.09228339791297913, precision: 0.34285714285712243, recall: 0.9085173501575854, f1: 0.4978392393724467\n",
            "epoch: 743, step: 17, Train: label_loss: 0.0857822448015213, precision: 0.32776119402983117, recall: 0.8955954323000169, f1: 0.47989510485583514\n",
            "epoch: 743, step: 18, Train: label_loss: 0.08033667504787445, precision: 0.31671554252197553, recall: 0.932642487046471, f1: 0.4728546409428463\n",
            "epoch: 743, step: 19, Train: label_loss: 0.07542522251605988, precision: 0.32863849765256287, recall: 0.9150326797384125, f1: 0.48359240065192016\n",
            "epoch: 743, step: 20, Train: label_loss: 0.09814123809337616, precision: 0.311711711711693, recall: 0.8826530612243396, f1: 0.4607190412396802\n",
            "epoch: 743, step: 21, Train: label_loss: 0.08400517702102661, precision: 0.3171462829736021, recall: 0.9073756432245441, f1: 0.47001332737161483\n",
            "epoch: 743, step: 22, Train: label_loss: 0.10789825022220612, precision: 0.31480362537762446, recall: 0.8654485049832449, f1: 0.46167478950448443\n",
            "epoch: 743, step: 23, Train: label_loss: 0.07904107123613358, precision: 0.32710280373829426, recall: 0.9362139917693547, f1: 0.4848161960191105\n",
            "epoch: 744, step: 0, Train: label_loss: 0.08597278594970703, precision: 0.3190591073582437, recall: 0.8920741989880451, f1: 0.47001332737119045\n",
            "epoch: 744, step: 1, Train: label_loss: 0.07527723163366318, precision: 0.35082547169809253, recall: 0.9070121951218129, f1: 0.5059523809121139\n",
            "epoch: 744, step: 2, Train: label_loss: 0.06952302157878876, precision: 0.3370654095462382, recall: 0.9007874015746612, f1: 0.4905660376961765\n",
            "epoch: 744, step: 3, Train: label_loss: 0.09713678807020187, precision: 0.30612244897957347, recall: 0.865874363327527, f1: 0.452328159606598\n",
            "epoch: 744, step: 4, Train: label_loss: 0.08271191269159317, precision: 0.3148911124190515, recall: 0.9114139693354494, f1: 0.46806649165032904\n",
            "epoch: 744, step: 5, Train: label_loss: 0.07307762652635574, precision: 0.30552291421854844, recall: 0.8950086058518252, f1: 0.45554095484593976\n",
            "epoch: 744, step: 6, Train: label_loss: 0.09593215584754944, precision: 0.32304900181486246, recall: 0.8929765886286132, f1: 0.47445579738430826\n",
            "epoch: 744, step: 7, Train: label_loss: 0.09632602334022522, precision: 0.3020214030915397, recall: 0.8850174216026332, f1: 0.45035460989109877\n",
            "epoch: 744, step: 8, Train: label_loss: 0.07919703423976898, precision: 0.32106824925814115, recall: 0.9031719532552749, f1: 0.47373029768455505\n",
            "epoch: 744, step: 9, Train: label_loss: 0.10071729123592377, precision: 0.3119376124774858, recall: 0.875420875420728, f1: 0.4599734630306584\n",
            "epoch: 744, step: 10, Train: label_loss: 0.0723826065659523, precision: 0.32525133057360583, recall: 0.9090909090907587, f1: 0.4790940766161968\n",
            "epoch: 744, step: 11, Train: label_loss: 0.0794384777545929, precision: 0.33077830188677293, recall: 0.9077669902911152, f1: 0.48487467584672117\n",
            "epoch: 744, step: 12, Train: label_loss: 0.08887067437171936, precision: 0.3315539739027087, recall: 0.9148936170211268, f1: 0.4867218110188105\n",
            "epoch: 744, step: 13, Train: label_loss: 0.09000615775585175, precision: 0.315444245676785, recall: 0.8743801652891116, f1: 0.46362839610472667\n",
            "epoch: 744, step: 14, Train: label_loss: 0.09758418798446655, precision: 0.30997624703086046, recall: 0.9031141868510547, f1: 0.46153846150037425\n",
            "epoch: 744, step: 15, Train: label_loss: 0.08721327781677246, precision: 0.3205430932703471, recall: 0.9203389830506914, f1: 0.47548161117004667\n",
            "epoch: 744, step: 16, Train: label_loss: 0.08374619483947754, precision: 0.32525133057360583, recall: 0.9151414309482669, f1: 0.47993019193334313\n",
            "epoch: 744, step: 17, Train: label_loss: 0.09213460236787796, precision: 0.3258293838862366, recall: 0.8972267536703267, f1: 0.47805302038677355\n",
            "epoch: 744, step: 18, Train: label_loss: 0.08129939436912537, precision: 0.3382613837965501, recall: 0.9079365079363637, f1: 0.49289099522106944\n",
            "epoch: 744, step: 19, Train: label_loss: 0.10205481946468353, precision: 0.2989195678271129, recall: 0.898916967508863, f1: 0.4486486486111533\n",
            "epoch: 744, step: 20, Train: label_loss: 0.08343790471553802, precision: 0.3174224343675228, recall: 0.9047619047617508, f1: 0.4699646642724597\n",
            "epoch: 744, step: 21, Train: label_loss: 0.09118475019931793, precision: 0.33313468414777514, recall: 0.898713826366415, f1: 0.4860869564822369\n",
            "epoch: 744, step: 22, Train: label_loss: 0.09243932366371155, precision: 0.32930513595164174, recall: 0.8678343949043203, f1: 0.47744196229034347\n",
            "epoch: 744, step: 23, Train: label_loss: 0.09491109848022461, precision: 0.2914798206277809, recall: 0.8297872340423766, f1: 0.4314159291650163\n",
            "epoch: 745, step: 0, Train: label_loss: 0.08271468430757523, precision: 0.34472598703592544, recall: 0.924170616113598, f1: 0.5021459227071645\n",
            "epoch: 745, step: 1, Train: label_loss: 0.08874789625406265, precision: 0.3080168776371122, recall: 0.8735042735041241, f1: 0.45543672010401526\n",
            "epoch: 745, step: 2, Train: label_loss: 0.08973024040460587, precision: 0.3357271095152402, recall: 0.9004815409308345, f1: 0.48910200519143016\n",
            "epoch: 745, step: 3, Train: label_loss: 0.1025247871875763, precision: 0.2860606060605887, recall: 0.8597449908923752, f1: 0.4292860390711808\n",
            "epoch: 745, step: 4, Train: label_loss: 0.06738139688968658, precision: 0.3321575543797571, recall: 0.923202614378934, f1: 0.4885430176869383\n",
            "epoch: 745, step: 5, Train: label_loss: 0.10246014595031738, precision: 0.31671732522794427, recall: 0.8611570247932461, f1: 0.4631111110717524\n",
            "epoch: 745, step: 6, Train: label_loss: 0.09375311434268951, precision: 0.30769230769228917, recall: 0.8707482993195798, f1: 0.4547069271372178\n",
            "epoch: 745, step: 7, Train: label_loss: 0.0890500545501709, precision: 0.2982768865121629, recall: 0.9127272727271067, f1: 0.4496193461339022\n",
            "epoch: 745, step: 8, Train: label_loss: 0.08877518028020859, precision: 0.2994620442319008, recall: 0.8882978723402679, f1: 0.44792132316296374\n",
            "epoch: 745, step: 9, Train: label_loss: 0.08998730778694153, precision: 0.3192627824018835, recall: 0.8949999999998508, f1: 0.470639789619394\n",
            "epoch: 745, step: 10, Train: label_loss: 0.09062261134386063, precision: 0.32757593805834856, recall: 0.9046052631577459, f1: 0.48097944902082695\n",
            "epoch: 745, step: 11, Train: label_loss: 0.08601905405521393, precision: 0.3229665071770142, recall: 0.8925619834709267, f1: 0.47430830035619453\n",
            "epoch: 745, step: 12, Train: label_loss: 0.09926377236843109, precision: 0.32512019230767275, recall: 0.873990306946547, f1: 0.4739378010992867\n",
            "epoch: 745, step: 13, Train: label_loss: 0.09305932372808456, precision: 0.3297619047618851, recall: 0.884984025558964, f1: 0.4804856894660413\n",
            "epoch: 745, step: 14, Train: label_loss: 0.07130105048418045, precision: 0.3158208955223692, recall: 0.8981324278436505, f1: 0.4673144875939722\n",
            "epoch: 745, step: 15, Train: label_loss: 0.09572070837020874, precision: 0.3347255369928201, recall: 0.8947368421051204, f1: 0.48719062088955417\n",
            "epoch: 745, step: 16, Train: label_loss: 0.08219600468873978, precision: 0.32573485302937455, recall: 0.8990066225164074, f1: 0.4782034345712164\n",
            "epoch: 745, step: 17, Train: label_loss: 0.08689455687999725, precision: 0.3434523809523605, recall: 0.9100946372238311, f1: 0.4987035436075373\n",
            "epoch: 745, step: 18, Train: label_loss: 0.09944916516542435, precision: 0.34476534296026806, recall: 0.8995290423860439, f1: 0.4984775989159634\n",
            "epoch: 745, step: 19, Train: label_loss: 0.09110655635595322, precision: 0.3156640857653177, recall: 0.907534246575187, f1: 0.4684047723876483\n",
            "epoch: 745, step: 20, Train: label_loss: 0.08349630236625671, precision: 0.32438878950504924, recall: 0.8932676518881948, f1: 0.4759405073974422\n",
            "epoch: 745, step: 21, Train: label_loss: 0.08721531927585602, precision: 0.3188578227245497, recall: 0.9146757679179326, f1: 0.47287163648566416\n",
            "epoch: 745, step: 22, Train: label_loss: 0.08246337622404099, precision: 0.30701754385963115, recall: 0.93250444049717, f1: 0.4619445666146931\n",
            "epoch: 745, step: 23, Train: label_loss: 0.07225684076547623, precision: 0.34368231046928926, recall: 0.9171483622348906, f1: 0.4999999999602911\n",
            "epoch: 746, step: 0, Train: label_loss: 0.07937785983085632, precision: 0.3117960877296792, recall: 0.9100346020759671, f1: 0.4644591611098485\n",
            "epoch: 746, step: 1, Train: label_loss: 0.08733368664979935, precision: 0.32894736842103295, recall: 0.8943089430892854, f1: 0.4809794490205422\n",
            "epoch: 746, step: 2, Train: label_loss: 0.08658595383167267, precision: 0.3313361294187938, recall: 0.8904991948468775, f1: 0.4829694322748401\n",
            "epoch: 746, step: 3, Train: label_loss: 0.10180970281362534, precision: 0.3254257907542381, recall: 0.8587479935793163, f1: 0.47198941328167054\n",
            "epoch: 746, step: 4, Train: label_loss: 0.09861843287944794, precision: 0.30548926014317984, recall: 0.8951048951047386, f1: 0.45551601419689397\n",
            "epoch: 746, step: 5, Train: label_loss: 0.08331149816513062, precision: 0.3038805970149072, recall: 0.883680555555402, f1: 0.4522434473186084\n",
            "epoch: 746, step: 6, Train: label_loss: 0.0760975033044815, precision: 0.3372641509433763, recall: 0.9331158238171398, f1: 0.4954525768340619\n",
            "epoch: 746, step: 7, Train: label_loss: 0.07711988687515259, precision: 0.31694312796206653, recall: 0.9114139693354494, f1: 0.47032967029133954\n",
            "epoch: 746, step: 8, Train: label_loss: 0.0906599760055542, precision: 0.3127229488703738, recall: 0.8810720268005223, f1: 0.4616059674909106\n",
            "epoch: 746, step: 9, Train: label_loss: 0.07304272800683975, precision: 0.32328605200943716, recall: 0.9193277310922824, f1: 0.4783559247537666\n",
            "epoch: 746, step: 10, Train: label_loss: 0.0807613730430603, precision: 0.34610849056601733, recall: 0.9157566302650677, f1: 0.5023534445472241\n",
            "epoch: 746, step: 11, Train: label_loss: 0.09202093631029129, precision: 0.31625967837996927, recall: 0.8969594594593079, f1: 0.4676354028676225\n",
            "epoch: 746, step: 12, Train: label_loss: 0.0849839597940445, precision: 0.32724056603771656, recall: 0.9113300492609341, f1: 0.48156182208689124\n",
            "epoch: 746, step: 13, Train: label_loss: 0.08826952427625656, precision: 0.30279595478879817, recall: 0.9138240574504642, f1: 0.4548704199804444\n",
            "epoch: 746, step: 14, Train: label_loss: 0.0925380289554596, precision: 0.30617136009584744, recall: 0.8780068728520828, f1: 0.4540204353236804\n",
            "epoch: 746, step: 15, Train: label_loss: 0.08383692800998688, precision: 0.3269689737469972, recall: 0.8954248366011608, f1: 0.47902097898174995\n",
            "epoch: 746, step: 16, Train: label_loss: 0.07307064533233643, precision: 0.31775147928992203, recall: 0.9055649241145184, f1: 0.4704336399089408\n",
            "epoch: 746, step: 17, Train: label_loss: 0.08911275863647461, precision: 0.3313539192398853, recall: 0.9058441558440087, f1: 0.4852173912650865\n",
            "epoch: 746, step: 18, Train: label_loss: 0.10113096237182617, precision: 0.3349455864570535, recall: 0.8892455858746565, f1: 0.48660518221756427\n",
            "epoch: 746, step: 19, Train: label_loss: 0.09282173961400986, precision: 0.33116499112948955, recall: 0.9105691056909088, f1: 0.4856895055983115\n",
            "epoch: 746, step: 20, Train: label_loss: 0.0946948230266571, precision: 0.33254297569648295, recall: 0.9019292604500158, f1: 0.48592464266306357\n",
            "epoch: 746, step: 21, Train: label_loss: 0.08097456395626068, precision: 0.3277310924369551, recall: 0.8965517241377837, f1: 0.4799999999607511\n",
            "epoch: 746, step: 22, Train: label_loss: 0.08164083957672119, precision: 0.3177737881507889, recall: 0.8999999999998474, f1: 0.4697036709034488\n",
            "epoch: 746, step: 23, Train: label_loss: 0.09530915319919586, precision: 0.30803242446571055, recall: 0.8690228690226883, f1: 0.45484221976544303\n",
            "epoch: 747, step: 0, Train: label_loss: 0.09684781730175018, precision: 0.3138201569100595, recall: 0.8950086058518252, f1: 0.4647006255200506\n",
            "epoch: 747, step: 1, Train: label_loss: 0.08568227291107178, precision: 0.3289786223277714, recall: 0.9067103109654816, f1: 0.4827886709848526\n",
            "epoch: 747, step: 2, Train: label_loss: 0.09056727588176727, precision: 0.3141831238778986, recall: 0.8823529411763222, f1: 0.4633715798376673\n",
            "epoch: 747, step: 3, Train: label_loss: 0.09031054377555847, precision: 0.31600955794502295, recall: 0.8920741989880451, f1: 0.4666960740680767\n",
            "epoch: 747, step: 4, Train: label_loss: 0.08199704438447952, precision: 0.33175355450235, recall: 0.9032258064514671, f1: 0.48526863080988436\n",
            "epoch: 747, step: 5, Train: label_loss: 0.08396263420581818, precision: 0.33451746595616727, recall: 0.9142394822004992, f1: 0.489813610710625\n",
            "epoch: 747, step: 6, Train: label_loss: 0.08426083624362946, precision: 0.3114949374627569, recall: 0.8894557823127738, f1: 0.4614027348534671\n",
            "epoch: 747, step: 7, Train: label_loss: 0.0924893170595169, precision: 0.30903614457829465, recall: 0.8906249999998453, f1: 0.4588550983516923\n",
            "epoch: 747, step: 8, Train: label_loss: 0.08873452246189117, precision: 0.31119090365049007, recall: 0.8950086058518252, f1: 0.46181172287463873\n",
            "epoch: 747, step: 9, Train: label_loss: 0.10536522418260574, precision: 0.3260738052026421, recall: 0.8651685393257038, f1: 0.473637961295875\n",
            "epoch: 747, step: 10, Train: label_loss: 0.0767945945262909, precision: 0.30755608028333487, recall: 0.8951890034362723, f1: 0.4578207380989777\n",
            "epoch: 747, step: 11, Train: label_loss: 0.08138363808393478, precision: 0.327197149643686, recall: 0.9018003273320946, f1: 0.48017429189988553\n",
            "epoch: 747, step: 12, Train: label_loss: 0.08142686635255814, precision: 0.3360995850622207, recall: 0.899999999999857, f1: 0.4894259818334751\n",
            "epoch: 747, step: 13, Train: label_loss: 0.08138011395931244, precision: 0.3177790903721017, recall: 0.8922056384741471, f1: 0.46864111494380645\n",
            "epoch: 747, step: 14, Train: label_loss: 0.08907550573348999, precision: 0.33096506808760623, recall: 0.9119086460031138, f1: 0.48566463940484367\n",
            "epoch: 747, step: 15, Train: label_loss: 0.07822157442569733, precision: 0.3236514522821385, recall: 0.9115191986642885, f1: 0.4776902886751949\n",
            "epoch: 747, step: 16, Train: label_loss: 0.07515624910593033, precision: 0.30946745562128347, recall: 0.9175438596489618, f1: 0.4628318583693184\n",
            "epoch: 747, step: 17, Train: label_loss: 0.08306105434894562, precision: 0.3135846798324169, recall: 0.8851351351349855, f1: 0.4631020768504112\n",
            "epoch: 747, step: 18, Train: label_loss: 0.07560879737138748, precision: 0.32309509746011084, recall: 0.9086378737540018, f1: 0.47668845312029917\n",
            "epoch: 747, step: 19, Train: label_loss: 0.07812145352363586, precision: 0.33175355450235, recall: 0.9032258064514671, f1: 0.48526863080988436\n",
            "epoch: 747, step: 20, Train: label_loss: 0.10002370178699493, precision: 0.3283935981031222, recall: 0.9157024793386915, f1: 0.483420593329338\n",
            "epoch: 747, step: 21, Train: label_loss: 0.08450207114219666, precision: 0.3229777256740725, recall: 0.916805324459082, f1: 0.47767663628566015\n",
            "epoch: 747, step: 22, Train: label_loss: 0.09710059314966202, precision: 0.32049763033173456, recall: 0.8956953642382622, f1: 0.4720767887918584\n",
            "epoch: 747, step: 23, Train: label_loss: 0.08138880878686905, precision: 0.33068592057759344, recall: 0.9141716566864443, f1: 0.4856839872355886\n",
            "epoch: 748, step: 0, Train: label_loss: 0.07813563197851181, precision: 0.3156966490299638, recall: 0.9117147707978078, f1: 0.46899563314952175\n",
            "epoch: 748, step: 1, Train: label_loss: 0.08584420382976532, precision: 0.30257639304971223, recall: 0.8828671328669785, f1: 0.45069165547287354\n",
            "epoch: 748, step: 2, Train: label_loss: 0.0951886996626854, precision: 0.3176400476757856, recall: 0.9033898305083214, f1: 0.4700176366457684\n",
            "epoch: 748, step: 3, Train: label_loss: 0.08725619316101074, precision: 0.32819905213268197, recall: 0.9233333333331794, f1: 0.4842657342269981\n",
            "epoch: 748, step: 4, Train: label_loss: 0.07572104036808014, precision: 0.3443786982248317, recall: 0.9208860759492213, f1: 0.5012919896244199\n",
            "epoch: 748, step: 5, Train: label_loss: 0.08066985756158829, precision: 0.32857142857140903, recall: 0.9019607843135781, f1: 0.48167539263097137\n",
            "epoch: 748, step: 6, Train: label_loss: 0.08229245245456696, precision: 0.306085918854397, recall: 0.899999999999842, f1: 0.4568121103806056\n",
            "epoch: 748, step: 7, Train: label_loss: 0.09040902554988861, precision: 0.31528279181706886, recall: 0.8911564625848823, f1: 0.4657777777391287\n",
            "epoch: 748, step: 8, Train: label_loss: 0.0905461311340332, precision: 0.30626865671639963, recall: 0.8739352640543655, f1: 0.45358090181829147\n",
            "epoch: 748, step: 9, Train: label_loss: 0.0746905729174614, precision: 0.3075103489059546, recall: 0.902777777777621, f1: 0.45875606524657175\n",
            "epoch: 748, step: 10, Train: label_loss: 0.08654649555683136, precision: 0.33273273273271275, recall: 0.8993506493505032, f1: 0.485751863178419\n",
            "epoch: 748, step: 11, Train: label_loss: 0.07919425517320633, precision: 0.32321428571426647, recall: 0.8901639344260835, f1: 0.47423580782113667\n",
            "epoch: 748, step: 12, Train: label_loss: 0.08759759366512299, precision: 0.31380753138073436, recall: 0.8868243243241745, f1: 0.4635761589017454\n",
            "epoch: 748, step: 13, Train: label_loss: 0.08822619169950485, precision: 0.3096658711216999, recall: 0.8917525773194344, f1: 0.4596988485002259\n",
            "epoch: 748, step: 14, Train: label_loss: 0.07750307768583298, precision: 0.3421516754849887, recall: 0.9208860759492213, f1: 0.4989284183059328\n",
            "epoch: 748, step: 15, Train: label_loss: 0.08920545876026154, precision: 0.33454106280191215, recall: 0.8793650793649397, f1: 0.4846894137833016\n",
            "epoch: 748, step: 16, Train: label_loss: 0.08320309221744537, precision: 0.339212228101097, recall: 0.9100946372238311, f1: 0.49421841537795713\n",
            "epoch: 748, step: 17, Train: label_loss: 0.09141619503498077, precision: 0.3240521327014026, recall: 0.9071310116084731, f1: 0.4775207332654067\n",
            "epoch: 748, step: 18, Train: label_loss: 0.10064283013343811, precision: 0.3148479427549007, recall: 0.8934010152282752, f1: 0.4656084655698887\n",
            "epoch: 748, step: 19, Train: label_loss: 0.07245533168315887, precision: 0.3189504373177657, recall: 0.9414802065402854, f1: 0.4764808361990894\n",
            "epoch: 748, step: 20, Train: label_loss: 0.07548137754201889, precision: 0.3249850924269335, recall: 0.9038142620230672, f1: 0.4780701753996491\n",
            "epoch: 748, step: 21, Train: label_loss: 0.1034390926361084, precision: 0.30935251798559293, recall: 0.8643216080400562, f1: 0.45562913903398666\n",
            "epoch: 748, step: 22, Train: label_loss: 0.09043040871620178, precision: 0.3369175627239942, recall: 0.8854003139716035, f1: 0.48810038940182543\n",
            "epoch: 748, step: 23, Train: label_loss: 0.09649930149316788, precision: 0.32503660322105965, recall: 0.8969696969695158, f1: 0.4771628156513902\n",
            "epoch: 749, step: 0, Train: label_loss: 0.09139883518218994, precision: 0.29957805907171187, recall: 0.8843416370105187, f1: 0.44754615034486805\n",
            "epoch: 749, step: 1, Train: label_loss: 0.08174159377813339, precision: 0.33809523809521796, recall: 0.9073482428113566, f1: 0.49262792710697695\n",
            "epoch: 749, step: 2, Train: label_loss: 0.09273038804531097, precision: 0.30186410102223077, recall: 0.8853615520280624, f1: 0.45022421520867395\n",
            "epoch: 749, step: 3, Train: label_loss: 0.08734623342752457, precision: 0.3091988130563615, recall: 0.9092495636996667, f1: 0.4614703276857348\n",
            "epoch: 749, step: 4, Train: label_loss: 0.07308999449014664, precision: 0.3351095322675941, recall: 0.8927444794951273, f1: 0.48730090396371467\n",
            "epoch: 749, step: 5, Train: label_loss: 0.0825822502374649, precision: 0.3158834027364476, recall: 0.8954468802696635, f1: 0.4670184696183969\n",
            "epoch: 749, step: 6, Train: label_loss: 0.08098046481609344, precision: 0.3255131964809193, recall: 0.9219269102988501, f1: 0.48114434326437866\n",
            "epoch: 749, step: 7, Train: label_loss: 0.08885423839092255, precision: 0.31209053007740845, recall: 0.8941979522182774, f1: 0.4626931566944941\n",
            "epoch: 749, step: 8, Train: label_loss: 0.08910412341356277, precision: 0.3361244019138555, recall: 0.8781249999998627, f1: 0.48615916951009314\n",
            "epoch: 749, step: 9, Train: label_loss: 0.09182173013687134, precision: 0.34130304841599873, recall: 0.9006309148263563, f1: 0.49501517117813076\n",
            "epoch: 749, step: 10, Train: label_loss: 0.09178359806537628, precision: 0.3309481216457763, recall: 0.9098360655736213, f1: 0.48535198946674385\n",
            "epoch: 749, step: 11, Train: label_loss: 0.08587492257356644, precision: 0.32096584216723667, recall: 0.9144295302011888, f1: 0.4751525718882625\n",
            "epoch: 749, step: 12, Train: label_loss: 0.11312203109264374, precision: 0.3211900425014984, recall: 0.8890756302519514, f1: 0.47190008916703247\n",
            "epoch: 749, step: 13, Train: label_loss: 0.09874936938285828, precision: 0.31346841477948073, recall: 0.8960817717204606, f1: 0.46445916110946245\n",
            "epoch: 749, step: 14, Train: label_loss: 0.10321934521198273, precision: 0.33554216867467856, recall: 0.9071661237783538, f1: 0.4898856639886803\n",
            "epoch: 749, step: 15, Train: label_loss: 0.08582894504070282, precision: 0.31428571428569557, recall: 0.904109589040941, f1: 0.4664310953680368\n",
            "epoch: 749, step: 16, Train: label_loss: 0.09205307066440582, precision: 0.3504531722054169, recall: 0.8868501529050631, f1: 0.5023819835020127\n",
            "epoch: 749, step: 17, Train: label_loss: 0.09207846224308014, precision: 0.3176829268292489, recall: 0.8845500848894933, f1: 0.467474203639854\n",
            "epoch: 749, step: 18, Train: label_loss: 0.09711107611656189, precision: 0.3223289315726097, recall: 0.896494156928064, f1: 0.4741721853915177\n",
            "epoch: 749, step: 19, Train: label_loss: 0.09505797177553177, precision: 0.2909638554216692, recall: 0.8594306049820534, f1: 0.4347434743096047\n",
            "epoch: 749, step: 20, Train: label_loss: 0.10908645391464233, precision: 0.3182367149758262, recall: 0.8639344262293666, f1: 0.46513680490324316\n",
            "epoch: 749, step: 21, Train: label_loss: 0.11323841661214828, precision: 0.33050847457625115, recall: 0.8708133971290477, f1: 0.47915752519043625\n",
            "epoch: 749, step: 22, Train: label_loss: 0.1006605327129364, precision: 0.3289315726290319, recall: 0.8968903436987075, f1: 0.48133508999143365\n",
            "epoch: 749, step: 23, Train: label_loss: 0.10100838541984558, precision: 0.30037174721187354, recall: 0.8706896551722262, f1: 0.4466556107965248\n",
            "epoch: 750, step: 0, Train: label_loss: 0.08174371719360352, precision: 0.3269916765754859, recall: 0.906095551894414, f1: 0.4805591961165123\n",
            "epoch: 750, step: 1, Train: label_loss: 0.08937358856201172, precision: 0.32651834034874766, recall: 0.8887070376430624, f1: 0.4775725593274135\n",
            "epoch: 750, step: 2, Train: label_loss: 0.09310497343540192, precision: 0.3228726614363112, recall: 0.877049180327725, f1: 0.47198941328219374\n",
            "epoch: 750, step: 3, Train: label_loss: 0.09300316125154495, precision: 0.3429256594724015, recall: 0.8993710691822485, f1: 0.49652777773776613\n",
            "epoch: 750, step: 4, Train: label_loss: 0.0912897139787674, precision: 0.3256364712847646, recall: 0.9228187919461538, f1: 0.48140043759815965\n",
            "epoch: 750, step: 5, Train: label_loss: 0.08635515719652176, precision: 0.33413173652692607, recall: 0.9029126213590771, f1: 0.4877622377227655\n",
            "epoch: 750, step: 6, Train: label_loss: 0.07953839004039764, precision: 0.30810488676994585, recall: 0.90701754385949, f1: 0.45996441277349365\n",
            "epoch: 750, step: 7, Train: label_loss: 0.08836410194635391, precision: 0.346107784431117, recall: 0.8975155279501711, f1: 0.49956784784224106\n",
            "epoch: 750, step: 8, Train: label_loss: 0.08967326581478119, precision: 0.3055222088835351, recall: 0.8806228373700898, f1: 0.45365418891002\n",
            "epoch: 750, step: 9, Train: label_loss: 0.10144643485546112, precision: 0.3361294188136407, recall: 0.9048387096772733, f1: 0.490170380039095\n",
            "epoch: 750, step: 10, Train: label_loss: 0.10839244723320007, precision: 0.31768953068590144, recall: 0.9056603773583352, f1: 0.4703786191151829\n",
            "epoch: 750, step: 11, Train: label_loss: 0.09701041132211685, precision: 0.3080625752105711, recall: 0.8797250859105017, f1: 0.45632798570129146\n",
            "epoch: 750, step: 12, Train: label_loss: 0.0910005271434784, precision: 0.3170149253731154, recall: 0.8835274542427813, f1: 0.46660808431961626\n",
            "epoch: 750, step: 13, Train: label_loss: 0.08832785487174988, precision: 0.3285543608124057, recall: 0.8986928104573695, f1: 0.4811898512293404\n",
            "epoch: 750, step: 14, Train: label_loss: 0.10591183602809906, precision: 0.3221556886227352, recall: 0.886326194398536, f1: 0.47255160294724113\n",
            "epoch: 750, step: 15, Train: label_loss: 0.07906335592269897, precision: 0.30236686390530754, recall: 0.898066783831125, f1: 0.45241257189675677\n",
            "epoch: 750, step: 16, Train: label_loss: 0.09568697214126587, precision: 0.3025516403402003, recall: 0.8426395939084868, f1: 0.44523915954981597\n",
            "epoch: 750, step: 17, Train: label_loss: 0.10699310898780823, precision: 0.3144615384615191, recall: 0.8502495840264808, f1: 0.45911949681588543\n",
            "epoch: 750, step: 18, Train: label_loss: 0.09976528584957123, precision: 0.32635983263596374, recall: 0.9069767441858958, f1: 0.479999999961039\n",
            "epoch: 750, step: 19, Train: label_loss: 0.08920960128307343, precision: 0.3380614657210202, recall: 0.9151999999998535, f1: 0.49374190759974945\n",
            "epoch: 750, step: 20, Train: label_loss: 0.08540359139442444, precision: 0.3233532934131543, recall: 0.904522613065175, f1: 0.47640052929508064\n",
            "epoch: 750, step: 21, Train: label_loss: 0.09179329872131348, precision: 0.3123877917414535, recall: 0.8892674616693544, f1: 0.4623560672776914\n",
            "epoch: 750, step: 22, Train: label_loss: 0.08884680271148682, precision: 0.32537313432833875, recall: 0.8949096880129893, f1: 0.47723292465437\n",
            "epoch: 750, step: 23, Train: label_loss: 0.07710717618465424, precision: 0.3090909090908866, recall: 0.9179265658745318, f1: 0.46245919473919145\n",
            "epoch: 751, step: 0, Train: label_loss: 0.08912418782711029, precision: 0.31279620853078716, recall: 0.9134948096884232, f1: 0.46601941743768466\n",
            "epoch: 751, step: 1, Train: label_loss: 0.09415704011917114, precision: 0.3247607655502198, recall: 0.9004975124376615, f1: 0.4773626373236352\n",
            "epoch: 751, step: 2, Train: label_loss: 0.0858316496014595, precision: 0.32781065088755457, recall: 0.9217970049915271, f1: 0.48363160188181376\n",
            "epoch: 751, step: 3, Train: label_loss: 0.07980372756719589, precision: 0.3149038461538272, recall: 0.8747913188646285, f1: 0.46310207685011817\n",
            "epoch: 751, step: 4, Train: label_loss: 0.0967668890953064, precision: 0.3039755351681771, recall: 0.8719298245612505, f1: 0.45079365075527394\n",
            "epoch: 751, step: 5, Train: label_loss: 0.08349181711673737, precision: 0.3202846975088778, recall: 0.9060402684562238, f1: 0.4732690621874834\n",
            "epoch: 751, step: 6, Train: label_loss: 0.09238988161087036, precision: 0.3059523809523627, recall: 0.8877374784109001, f1: 0.45506861439300106\n",
            "epoch: 751, step: 7, Train: label_loss: 0.07765624672174454, precision: 0.32665094339620715, recall: 0.9157024793386915, f1: 0.4815297696265616\n",
            "epoch: 751, step: 8, Train: label_loss: 0.09703734517097473, precision: 0.3182629387269293, recall: 0.9052453468695592, f1: 0.4709507041868187\n",
            "epoch: 751, step: 9, Train: label_loss: 0.09904377162456512, precision: 0.32252252252250313, recall: 0.9040404040402518, f1: 0.47543160686690705\n",
            "epoch: 751, step: 10, Train: label_loss: 0.0868040919303894, precision: 0.313829787234024, recall: 0.8954468802696635, f1: 0.4647702406617443\n",
            "epoch: 751, step: 11, Train: label_loss: 0.08096709847450256, precision: 0.3254855797527766, recall: 0.9140495867767083, f1: 0.4800347221834535\n",
            "epoch: 751, step: 12, Train: label_loss: 0.09019230306148529, precision: 0.31290898274834544, recall: 0.8840336134452295, f1: 0.46221441120914625\n",
            "epoch: 751, step: 13, Train: label_loss: 0.08627796173095703, precision: 0.3215780035863526, recall: 0.8936877076410475, f1: 0.4729670329280725\n",
            "epoch: 751, step: 14, Train: label_loss: 0.07771262526512146, precision: 0.32438878950504924, recall: 0.8962108731464751, f1: 0.476357267911895\n",
            "epoch: 751, step: 15, Train: label_loss: 0.09355172514915466, precision: 0.31610576923075023, recall: 0.8825503355703217, f1: 0.4654867256248415\n",
            "epoch: 751, step: 16, Train: label_loss: 0.08483786135911942, precision: 0.3224271267102723, recall: 0.9033333333331827, f1: 0.47523016217074526\n",
            "epoch: 751, step: 17, Train: label_loss: 0.09388859570026398, precision: 0.32048192771082407, recall: 0.8881469115190503, f1: 0.471004869372232\n",
            "epoch: 751, step: 18, Train: label_loss: 0.07472801208496094, precision: 0.327002967359031, recall: 0.9047619047617561, f1: 0.48038360937682595\n",
            "epoch: 751, step: 19, Train: label_loss: 0.08417873829603195, precision: 0.32758620689653223, recall: 0.8872785829306139, f1: 0.47850629609604634\n",
            "epoch: 751, step: 20, Train: label_loss: 0.08520694077014923, precision: 0.3514970059880029, recall: 0.8975535168194345, f1: 0.5051635111471203\n",
            "epoch: 751, step: 21, Train: label_loss: 0.090899258852005, precision: 0.31666666666664783, recall: 0.9032258064514594, f1: 0.4689290435930742\n",
            "epoch: 751, step: 22, Train: label_loss: 0.08948595821857452, precision: 0.3398230088495375, recall: 0.9085173501575854, f1: 0.4946328896125455\n",
            "epoch: 751, step: 23, Train: label_loss: 0.10959819704294205, precision: 0.3201196709049873, recall: 0.8577154308615516, f1: 0.46623093677953764\n",
            "epoch: 752, step: 0, Train: label_loss: 0.08392129838466644, precision: 0.3313748531139641, recall: 0.9291598023062719, f1: 0.48852317016475366\n",
            "epoch: 752, step: 1, Train: label_loss: 0.07580411434173584, precision: 0.33880422039857333, recall: 0.9459901800325783, f1: 0.498921018519605\n",
            "epoch: 752, step: 2, Train: label_loss: 0.08734117448329926, precision: 0.3297491039426326, recall: 0.9034369885432236, f1: 0.48315098464349193\n",
            "epoch: 752, step: 3, Train: label_loss: 0.08528677374124527, precision: 0.3200475907197906, recall: 0.9149659863944022, f1: 0.4742177170175322\n",
            "epoch: 752, step: 4, Train: label_loss: 0.09112086892127991, precision: 0.32916666666664707, recall: 0.9341216216214637, f1: 0.48679577460931034\n",
            "epoch: 752, step: 5, Train: label_loss: 0.08996881544589996, precision: 0.33730631704408, recall: 0.9099678456590177, f1: 0.49217391300397545\n",
            "epoch: 752, step: 6, Train: label_loss: 0.08352980762720108, precision: 0.3234946871310317, recall: 0.9210084033611897, f1: 0.4788117081309904\n",
            "epoch: 752, step: 7, Train: label_loss: 0.0836576595902443, precision: 0.327002967359031, recall: 0.9077429983524039, f1: 0.4808027922821355\n",
            "epoch: 752, step: 8, Train: label_loss: 0.08555126935243607, precision: 0.3238265002970693, recall: 0.8934426229506731, f1: 0.4753597906281553\n",
            "epoch: 752, step: 9, Train: label_loss: 0.09381355345249176, precision: 0.30382775119615407, recall: 0.8683760683759199, f1: 0.45015507306745045\n",
            "epoch: 752, step: 10, Train: label_loss: 0.08475551754236221, precision: 0.33451327433626343, recall: 0.9159935379643107, f1: 0.4900605012572251\n",
            "epoch: 752, step: 11, Train: label_loss: 0.07885697484016418, precision: 0.31176470588233457, recall: 0.9028960817715668, f1: 0.4634892872377088\n",
            "epoch: 752, step: 12, Train: label_loss: 0.08164452016353607, precision: 0.3143712574850111, recall: 0.8868243243241745, f1: 0.4641909813936756\n",
            "epoch: 752, step: 13, Train: label_loss: 0.09420187771320343, precision: 0.32329921733893296, recall: 0.8591999999998625, f1: 0.4698162729261074\n",
            "epoch: 752, step: 14, Train: label_loss: 0.09766490757465363, precision: 0.31369047619045753, recall: 0.8932203389828994, f1: 0.4643171805782277\n",
            "epoch: 752, step: 15, Train: label_loss: 0.07253183424472809, precision: 0.34228971962614824, recall: 0.9331210191081316, f1: 0.500854700815388\n",
            "epoch: 752, step: 16, Train: label_loss: 0.08351466059684753, precision: 0.3160682754561321, recall: 0.9163822525595705, f1: 0.47002188179989607\n",
            "epoch: 752, step: 17, Train: label_loss: 0.08859250694513321, precision: 0.3223487118034558, recall: 0.8922056384741471, f1: 0.4735915492567399\n",
            "epoch: 752, step: 18, Train: label_loss: 0.09763262420892715, precision: 0.30017867778437757, recall: 0.9081081081079444, f1: 0.4512085944120348\n",
            "epoch: 752, step: 19, Train: label_loss: 0.07309705764055252, precision: 0.32098765432096876, recall: 0.9145728643214548, f1: 0.4751958224158067\n",
            "epoch: 752, step: 20, Train: label_loss: 0.0869971215724945, precision: 0.3141330166270597, recall: 0.9042735042733496, f1: 0.4662847068810366\n",
            "epoch: 752, step: 21, Train: label_loss: 0.0819404125213623, precision: 0.32938388625590465, recall: 0.90553745928324, f1: 0.48305821021279627\n",
            "epoch: 752, step: 22, Train: label_loss: 0.08469822257757187, precision: 0.33373277411621727, recall: 0.9012944983817311, f1: 0.4871010056448195\n",
            "epoch: 752, step: 23, Train: label_loss: 0.09241391718387604, precision: 0.33040935672512206, recall: 0.9186991869916832, f1: 0.4860215053373823\n",
            "epoch: 753, step: 0, Train: label_loss: 0.08090047538280487, precision: 0.3112817483756461, recall: 0.9070567986229074, f1: 0.46350043971565347\n",
            "epoch: 753, step: 1, Train: label_loss: 0.07832176983356476, precision: 0.3163204747774293, recall: 0.8883333333331852, f1: 0.4665207877074033\n",
            "epoch: 753, step: 2, Train: label_loss: 0.09435763210058212, precision: 0.3237063778579829, recall: 0.8907284768210445, f1: 0.4748455427675658\n",
            "epoch: 753, step: 3, Train: label_loss: 0.08626623451709747, precision: 0.30600118835411133, recall: 0.8833619210976186, f1: 0.45454545450719686\n",
            "epoch: 753, step: 4, Train: label_loss: 0.08540260791778564, precision: 0.3289863663307452, recall: 0.9113300492609341, f1: 0.48344947731289634\n",
            "epoch: 753, step: 5, Train: label_loss: 0.08036889135837555, precision: 0.3388724035608107, recall: 0.9150641025639559, f1: 0.4945864009999255\n",
            "epoch: 753, step: 6, Train: label_loss: 0.08214996010065079, precision: 0.3175270108043027, recall: 0.8996598639454252, f1: 0.4693877550634359\n",
            "epoch: 753, step: 7, Train: label_loss: 0.0706128180027008, precision: 0.3205204021288988, recall: 0.9186440677964544, f1: 0.4752301621711646\n",
            "epoch: 753, step: 8, Train: label_loss: 0.09245868027210236, precision: 0.3203359328134181, recall: 0.9020270270268745, f1: 0.4727755643703115\n",
            "epoch: 753, step: 9, Train: label_loss: 0.08644971251487732, precision: 0.32194244604314615, recall: 0.8703403565638783, f1: 0.4700218817986112\n",
            "epoch: 753, step: 10, Train: label_loss: 0.0805000588297844, precision: 0.3152302243211148, recall: 0.8974789915964877, f1: 0.46657929222885075\n",
            "epoch: 753, step: 11, Train: label_loss: 0.09648601710796356, precision: 0.32328605200943716, recall: 0.9116666666665146, f1: 0.4773123908862644\n",
            "epoch: 753, step: 12, Train: label_loss: 0.10059449076652527, precision: 0.3200483091787246, recall: 0.8660130718952833, f1: 0.4673721339993541\n",
            "epoch: 753, step: 13, Train: label_loss: 0.08485353738069534, precision: 0.3201675643327157, recall: 0.8842975206610107, f1: 0.47012302280802715\n",
            "epoch: 753, step: 14, Train: label_loss: 0.09195718169212341, precision: 0.30505415162453037, recall: 0.8802083333331805, f1: 0.45308310988130407\n",
            "epoch: 753, step: 15, Train: label_loss: 0.0913514792919159, precision: 0.3489892984542004, recall: 0.9129082426126107, f1: 0.5049462365190814\n",
            "epoch: 753, step: 16, Train: label_loss: 0.09612183272838593, precision: 0.32897085068409704, recall: 0.9006514657978989, f1: 0.48191721128974174\n",
            "epoch: 753, step: 17, Train: label_loss: 0.09757654368877411, precision: 0.298140371925597, recall: 0.8643478260868062, f1: 0.44335414804389167\n",
            "epoch: 753, step: 18, Train: label_loss: 0.09331236779689789, precision: 0.31397459165152364, recall: 0.8678929765884835, f1: 0.46112838734432726\n",
            "epoch: 753, step: 19, Train: label_loss: 0.10624419152736664, precision: 0.3195195195195003, recall: 0.880794701986609, f1: 0.4689290435924472\n",
            "epoch: 753, step: 20, Train: label_loss: 0.09465093910694122, precision: 0.3144391408114371, recall: 0.8932203389828994, f1: 0.4651368049040736\n",
            "epoch: 753, step: 21, Train: label_loss: 0.0866062343120575, precision: 0.33293697978594927, recall: 0.9003215434082154, f1: 0.48611111107165206\n",
            "epoch: 753, step: 22, Train: label_loss: 0.0976933091878891, precision: 0.3170134638922695, recall: 0.8764805414550124, f1: 0.46561797748903494\n",
            "epoch: 753, step: 23, Train: label_loss: 0.06714193522930145, precision: 0.33285198555954276, recall: 0.9110671936757093, f1: 0.4875727128110957\n",
            "epoch: 754, step: 0, Train: label_loss: 0.06771626323461533, precision: 0.3390129259694278, recall: 0.9306451612901724, f1: 0.49698535741128763\n",
            "epoch: 754, step: 1, Train: label_loss: 0.08833405375480652, precision: 0.3162650602409448, recall: 0.898972602739572, f1: 0.46791443846412817\n",
            "epoch: 754, step: 2, Train: label_loss: 0.08734699338674545, precision: 0.32193396226413196, recall: 0.9145728643214548, f1: 0.4762320104280817\n",
            "epoch: 754, step: 3, Train: label_loss: 0.0928155928850174, precision: 0.31540785498487517, recall: 0.8613861386137192, f1: 0.4617425917342733\n",
            "epoch: 754, step: 4, Train: label_loss: 0.08562175929546356, precision: 0.3297491039426326, recall: 0.9064039408865506, f1: 0.4835742443760814\n",
            "epoch: 754, step: 5, Train: label_loss: 0.08268433809280396, precision: 0.3203769140164711, recall: 0.908180300500683, f1: 0.4736612973057666\n",
            "epoch: 754, step: 6, Train: label_loss: 0.07912316918373108, precision: 0.31513353115725135, recall: 0.8879598662205872, f1: 0.4651773981216095\n",
            "epoch: 754, step: 7, Train: label_loss: 0.09272495657205582, precision: 0.3029394121175583, recall: 0.8875219683653975, f1: 0.4516994632893867\n",
            "epoch: 754, step: 8, Train: label_loss: 0.07769569009542465, precision: 0.3284371327849396, recall: 0.9316666666665113, f1: 0.48566463940537796\n",
            "epoch: 754, step: 9, Train: label_loss: 0.07716378569602966, precision: 0.3168552709946208, recall: 0.8911222780568021, f1: 0.4674868189419268\n",
            "epoch: 754, step: 10, Train: label_loss: 0.09060709178447723, precision: 0.3251497005987829, recall: 0.8945634266884852, f1: 0.476943346469419\n",
            "epoch: 754, step: 11, Train: label_loss: 0.07872607558965683, precision: 0.31578947368419186, recall: 0.8989898989897476, f1: 0.46739606123062993\n",
            "epoch: 754, step: 12, Train: label_loss: 0.08216088265180588, precision: 0.3148809523809336, recall: 0.8920741989880451, f1: 0.46546414426407756\n",
            "epoch: 754, step: 13, Train: label_loss: 0.0991600751876831, precision: 0.3055222088835351, recall: 0.8627118644066334, f1: 0.45124113471310706\n",
            "epoch: 754, step: 14, Train: label_loss: 0.0886072888970375, precision: 0.3183722321962706, recall: 0.880794701986609, f1: 0.4676923076532651\n",
            "epoch: 754, step: 15, Train: label_loss: 0.08554641902446747, precision: 0.3369239976062037, recall: 0.8838304552588879, f1: 0.48786828418876277\n",
            "epoch: 754, step: 16, Train: label_loss: 0.09612839668989182, precision: 0.32959243945656647, recall: 0.9132569558099978, f1: 0.48437499996098504\n",
            "epoch: 754, step: 17, Train: label_loss: 0.08441971987485886, precision: 0.3343355381839847, recall: 0.8825396825395424, f1: 0.4849542084206373\n",
            "epoch: 754, step: 18, Train: label_loss: 0.0858214721083641, precision: 0.3210900473933459, recall: 0.9155405405403858, f1: 0.47543859645274006\n",
            "epoch: 754, step: 19, Train: label_loss: 0.08780057728290558, precision: 0.31610576923075023, recall: 0.8737541528237751, f1: 0.4642541923704736\n",
            "epoch: 754, step: 20, Train: label_loss: 0.0892162173986435, precision: 0.32021466905185925, recall: 0.8905472636814443, f1: 0.47105263154000054\n",
            "epoch: 754, step: 21, Train: label_loss: 0.0964098647236824, precision: 0.32657926102501034, recall: 0.9057851239667923, f1: 0.480070083184831\n",
            "epoch: 754, step: 22, Train: label_loss: 0.09040986001491547, precision: 0.31466030989271065, recall: 0.8979591836733166, f1: 0.46601941743725617\n",
            "epoch: 754, step: 23, Train: label_loss: 0.09201297163963318, precision: 0.3165680473372547, recall: 0.8842975206609743, f1: 0.4662309367802968\n",
            "epoch: 755, step: 0, Train: label_loss: 0.09455308318138123, precision: 0.3183431952662533, recall: 0.910321489001538, f1: 0.47172292850167946\n",
            "epoch: 755, step: 1, Train: label_loss: 0.08778989315032959, precision: 0.34411764705880327, recall: 0.9198113207545723, f1: 0.5008561643438918\n",
            "epoch: 755, step: 2, Train: label_loss: 0.07721306383609772, precision: 0.3154761904761717, recall: 0.877483443708464, f1: 0.46409807351622273\n",
            "epoch: 755, step: 3, Train: label_loss: 0.08197172731161118, precision: 0.34056271981240677, recall: 0.9416531604536561, f1: 0.5002152388761409\n",
            "epoch: 755, step: 4, Train: label_loss: 0.09572569280862808, precision: 0.3170878459686933, recall: 0.8872053872052378, f1: 0.46719858152144783\n",
            "epoch: 755, step: 5, Train: label_loss: 0.0743858814239502, precision: 0.3098758131283081, recall: 0.9003436426115291, f1: 0.4610646722011931\n",
            "epoch: 755, step: 6, Train: label_loss: 0.0949258804321289, precision: 0.31682577565630565, recall: 0.9061433447097429, f1: 0.4694960211817277\n",
            "epoch: 755, step: 7, Train: label_loss: 0.07533018290996552, precision: 0.31349440188566213, recall: 0.8941176470586731, f1: 0.46422338565087223\n",
            "epoch: 755, step: 8, Train: label_loss: 0.08876468241214752, precision: 0.3246987951807033, recall: 0.8894389438942426, f1: 0.4757281553005814\n",
            "epoch: 755, step: 9, Train: label_loss: 0.10592144727706909, precision: 0.31404460518382676, recall: 0.8756302521006931, f1: 0.4622892634926\n",
            "epoch: 755, step: 10, Train: label_loss: 0.07562731206417084, precision: 0.3317674691720298, recall: 0.9011164274320731, f1: 0.4849785407331536\n",
            "epoch: 755, step: 11, Train: label_loss: 0.09962739050388336, precision: 0.3021582733812768, recall: 0.8795811518323071, f1: 0.4497991967490459\n",
            "epoch: 755, step: 12, Train: label_loss: 0.08790389448404312, precision: 0.31997607655500476, recall: 0.8842975206610107, f1: 0.46991655683401656\n",
            "epoch: 755, step: 13, Train: label_loss: 0.09511314332485199, precision: 0.3157894736841914, recall: 0.8656716417909012, f1: 0.46276595740759846\n",
            "epoch: 755, step: 14, Train: label_loss: 0.09726367145776749, precision: 0.3136308805789919, recall: 0.8710217755442426, f1: 0.4611973392071478\n",
            "epoch: 755, step: 15, Train: label_loss: 0.09189216792583466, precision: 0.3188578227245497, recall: 0.8918469217968565, f1: 0.4697633654300449\n",
            "epoch: 755, step: 16, Train: label_loss: 0.09981052577495575, precision: 0.3463619963920417, recall: 0.9028213166142784, f1: 0.500651890442277\n",
            "epoch: 755, step: 17, Train: label_loss: 0.08638553321361542, precision: 0.32021151586367097, recall: 0.9252971137519651, f1: 0.47577477080418606\n",
            "epoch: 755, step: 18, Train: label_loss: 0.0827450379729271, precision: 0.3251935675997424, recall: 0.9130434782607169, f1: 0.479578392583098\n",
            "epoch: 755, step: 19, Train: label_loss: 0.0841812789440155, precision: 0.3331339712918461, recall: 0.9267886855239722, f1: 0.49010118781851464\n",
            "epoch: 755, step: 20, Train: label_loss: 0.08980140089988708, precision: 0.3052378085490484, recall: 0.8817391304346291, f1: 0.4534883720547773\n",
            "epoch: 755, step: 21, Train: label_loss: 0.09189803898334503, precision: 0.3208459214501317, recall: 0.877685950413078, f1: 0.4699115043855299\n",
            "epoch: 755, step: 22, Train: label_loss: 0.08557847142219543, precision: 0.32901706886401827, recall: 0.9301164725456023, f1: 0.4860869564830919\n",
            "epoch: 755, step: 23, Train: label_loss: 0.08922428637742996, precision: 0.32074074074071696, recall: 0.8659999999998268, f1: 0.46810810806861264\n",
            "epoch: 756, step: 0, Train: label_loss: 0.0784219354391098, precision: 0.30137807070100053, recall: 0.8763066202089065, f1: 0.4485064645182739\n",
            "epoch: 756, step: 1, Train: label_loss: 0.07833468168973923, precision: 0.3335297583971518, recall: 0.9129032258063043, f1: 0.4885627966806574\n",
            "epoch: 756, step: 2, Train: label_loss: 0.08150333911180496, precision: 0.32068761114402367, recall: 0.9016666666665163, f1: 0.47310887621835923\n",
            "epoch: 756, step: 3, Train: label_loss: 0.08609430491924286, precision: 0.33154121863797303, recall: 0.8922829581992134, f1: 0.4834494773123711\n",
            "epoch: 756, step: 4, Train: label_loss: 0.0936783105134964, precision: 0.306586826347287, recall: 0.8873483535527058, f1: 0.45571873605435775\n",
            "epoch: 756, step: 5, Train: label_loss: 0.08087818324565887, precision: 0.33234946871308546, recall: 0.9199346405227254, f1: 0.48829141366434803\n",
            "epoch: 756, step: 6, Train: label_loss: 0.09542487561702728, precision: 0.29358897543437423, recall: 0.8860759493669284, f1: 0.44104410437301417\n",
            "epoch: 756, step: 7, Train: label_loss: 0.08176200091838837, precision: 0.32559523809521873, recall: 0.9086378737540018, f1: 0.4794040315123865\n",
            "epoch: 756, step: 8, Train: label_loss: 0.07486578077077866, precision: 0.3071051086318081, recall: 0.9207746478871618, f1: 0.4605900483992603\n",
            "epoch: 756, step: 9, Train: label_loss: 0.09920304268598557, precision: 0.33234244946490293, recall: 0.9119086460031138, f1: 0.4871459694597164\n",
            "epoch: 756, step: 10, Train: label_loss: 0.09064189344644547, precision: 0.3327391562685483, recall: 0.9003215434082154, f1: 0.48590021688029156\n",
            "epoch: 756, step: 11, Train: label_loss: 0.08272351324558258, precision: 0.3408820023837699, recall: 0.9151999999998535, f1: 0.49674337816275455\n",
            "epoch: 756, step: 12, Train: label_loss: 0.07782923430204391, precision: 0.3394117647058624, recall: 0.9336569579286514, f1: 0.4978429680367788\n",
            "epoch: 756, step: 13, Train: label_loss: 0.08720523118972778, precision: 0.3059523809523627, recall: 0.890814558058771, f1: 0.45547186526983197\n",
            "epoch: 756, step: 14, Train: label_loss: 0.08284194767475128, precision: 0.31404958677684097, recall: 0.9001692047375803, f1: 0.46564551418480454\n",
            "epoch: 756, step: 15, Train: label_loss: 0.0837102010846138, precision: 0.3153206650831167, recall: 0.8924369747897659, f1: 0.46599385691618045\n",
            "epoch: 756, step: 16, Train: label_loss: 0.0941348522901535, precision: 0.3226761397276304, recall: 0.8934426229506731, f1: 0.474119182214126\n",
            "epoch: 756, step: 17, Train: label_loss: 0.08973170071840286, precision: 0.3171021377672021, recall: 0.9081632653059679, f1: 0.4700704224968051\n",
            "epoch: 756, step: 18, Train: label_loss: 0.06980433315038681, precision: 0.32823529411762775, recall: 0.9132569558099978, f1: 0.4829078320683737\n",
            "epoch: 756, step: 19, Train: label_loss: 0.0939628928899765, precision: 0.34292425132117776, recall: 0.9240506329112461, f1: 0.5002141327227888\n",
            "epoch: 756, step: 20, Train: label_loss: 0.09030310064554214, precision: 0.3239352129573891, recall: 0.8881578947366959, f1: 0.4747252746860672\n",
            "epoch: 756, step: 21, Train: label_loss: 0.08401917666196823, precision: 0.31622911694508854, recall: 0.877483443708464, f1: 0.4649122806627668\n",
            "epoch: 756, step: 22, Train: label_loss: 0.08508626371622086, precision: 0.33274336283183875, recall: 0.9082125603863271, f1: 0.4870466320850625\n",
            "epoch: 756, step: 23, Train: label_loss: 0.09077049791812897, precision: 0.3156363636363407, recall: 0.9117647058821614, f1: 0.4689357103885401\n",
            "epoch: 757, step: 0, Train: label_loss: 0.07842565327882767, precision: 0.3506800709639059, recall: 0.9251170046800428, f1: 0.5085763292911392\n",
            "epoch: 757, step: 1, Train: label_loss: 0.08069387078285217, precision: 0.329404832056551, recall: 0.9270315091209076, f1: 0.48608695648300915\n",
            "epoch: 757, step: 2, Train: label_loss: 0.08228033781051636, precision: 0.3335297583971518, recall: 0.9248366013070384, f1: 0.49025552183193766\n",
            "epoch: 757, step: 3, Train: label_loss: 0.08326023817062378, precision: 0.3354952830188481, recall: 0.919224555734908, f1: 0.49157667382687004\n",
            "epoch: 757, step: 4, Train: label_loss: 0.09043616056442261, precision: 0.29579134558385917, recall: 0.9072727272725623, f1: 0.44613321408893875\n",
            "epoch: 757, step: 5, Train: label_loss: 0.07682901620864868, precision: 0.31249999999998157, recall: 0.895270270270119, f1: 0.463286713248314\n",
            "epoch: 757, step: 6, Train: label_loss: 0.08378289639949799, precision: 0.3266152934202533, recall: 0.9018003273320946, f1: 0.479547432510964\n",
            "epoch: 757, step: 7, Train: label_loss: 0.09340175241231918, precision: 0.3335336538461338, recall: 0.8951612903224362, f1: 0.4859894920794935\n",
            "epoch: 757, step: 8, Train: label_loss: 0.07819630950689316, precision: 0.3163808397397802, recall: 0.9129692832762947, f1: 0.46991655683481254\n",
            "epoch: 757, step: 9, Train: label_loss: 0.08938686549663544, precision: 0.30572109654348595, recall: 0.8984238178632401, f1: 0.45620275674286487\n",
            "epoch: 757, step: 10, Train: label_loss: 0.0812205970287323, precision: 0.3240685984624291, recall: 0.9013157894735359, f1: 0.4767290125752341\n",
            "epoch: 757, step: 11, Train: label_loss: 0.08886712789535522, precision: 0.33254015466981957, recall: 0.9030694668819219, f1: 0.486086956482357\n",
            "epoch: 757, step: 12, Train: label_loss: 0.0885062888264656, precision: 0.3219628964691609, recall: 0.886326194398536, f1: 0.4723441615060816\n",
            "epoch: 757, step: 13, Train: label_loss: 0.08611878752708435, precision: 0.33912522468542006, recall: 0.8816199376945667, f1: 0.48983124184646115\n",
            "epoch: 757, step: 14, Train: label_loss: 0.09485654532909393, precision: 0.3026474127556978, recall: 0.8732638888887372, f1: 0.44950848968470036\n",
            "epoch: 757, step: 15, Train: label_loss: 0.0949476957321167, precision: 0.3106910809214229, recall: 0.8991452991451454, f1: 0.4618086040004187\n",
            "epoch: 757, step: 16, Train: label_loss: 0.09684222936630249, precision: 0.3011397720455728, recall: 0.8715277777776264, f1: 0.44761480156678274\n",
            "epoch: 757, step: 17, Train: label_loss: 0.0936800092458725, precision: 0.31985731272292983, recall: 0.8981636060098667, f1: 0.4717229285013439\n",
            "epoch: 757, step: 18, Train: label_loss: 0.08177096396684647, precision: 0.3126120741183316, recall: 0.8909710391821309, f1: 0.46283185836858426\n",
            "epoch: 757, step: 19, Train: label_loss: 0.07452907413244247, precision: 0.3291888691533257, recall: 0.8967741935482424, f1: 0.48159376349467276\n",
            "epoch: 757, step: 20, Train: label_loss: 0.0867224931716919, precision: 0.3327380952380754, recall: 0.9030694668819219, f1: 0.4862983905652177\n",
            "epoch: 757, step: 21, Train: label_loss: 0.09626202285289764, precision: 0.30675593426656683, recall: 0.842809364548354, f1: 0.4497991967479807\n",
            "epoch: 757, step: 22, Train: label_loss: 0.09576341509819031, precision: 0.3096107055960882, recall: 0.865646258503254, f1: 0.4560931899253089\n",
            "epoch: 757, step: 23, Train: label_loss: 0.12689881026744843, precision: 0.31084154662620844, recall: 0.8367346938773803, f1: 0.4532891099659781\n",
            "epoch: 758, step: 0, Train: label_loss: 0.163150355219841, precision: 0.2833008447043351, recall: 0.7427597955705719, f1: 0.41015992470128537\n",
            "epoch: 758, step: 1, Train: label_loss: 0.18277990818023682, precision: 0.2806652806652612, recall: 0.6532258064515075, f1: 0.3926320891484186\n",
            "epoch: 758, step: 2, Train: label_loss: 0.18387901782989502, precision: 0.28112449799194905, recall: 0.6851549755300677, f1: 0.3986710963042187\n",
            "epoch: 758, step: 3, Train: label_loss: 0.17931483685970306, precision: 0.2627637848876608, recall: 0.6655172413791955, f1: 0.3767691556450757\n",
            "epoch: 758, step: 4, Train: label_loss: 0.16410037875175476, precision: 0.28815789473682313, recall: 0.7215815485995516, f1: 0.4118476727377351\n",
            "epoch: 758, step: 5, Train: label_loss: 0.16913561522960663, precision: 0.306148867313896, recall: 0.7741407528640304, f1: 0.4387755101634244\n",
            "epoch: 758, step: 6, Train: label_loss: 0.17845198512077332, precision: 0.29032258064514177, recall: 0.7297297297296064, f1: 0.4153846153438535\n",
            "epoch: 758, step: 7, Train: label_loss: 0.1645371913909912, precision: 0.30045721750487914, recall: 0.733652312599564, f1: 0.4263206672432573\n",
            "epoch: 758, step: 8, Train: label_loss: 0.17533646523952484, precision: 0.28532608695650236, recall: 0.7167235494879323, f1: 0.4081632652653499\n",
            "epoch: 758, step: 9, Train: label_loss: 0.1703474074602127, precision: 0.28965053763438914, recall: 0.7008130081299673, f1: 0.40989063238843937\n",
            "epoch: 758, step: 10, Train: label_loss: 0.15832851827144623, precision: 0.3078418664938232, recall: 0.7575757575756367, f1: 0.4377880183920486\n",
            "epoch: 758, step: 11, Train: label_loss: 0.16089218854904175, precision: 0.27410832232494886, recall: 0.6951423785593475, f1: 0.3931785883061526\n",
            "epoch: 758, step: 12, Train: label_loss: 0.16116759181022644, precision: 0.2689345314505604, recall: 0.7535971223020227, f1: 0.396404919544923\n",
            "epoch: 758, step: 13, Train: label_loss: 0.20384535193443298, precision: 0.28918918918916964, recall: 0.700490998363224, f1: 0.40937350545835743\n",
            "epoch: 758, step: 14, Train: label_loss: 0.16236339509487152, precision: 0.30162866449509435, recall: 0.7691029900330948, f1: 0.4333177351022136\n",
            "epoch: 758, step: 15, Train: label_loss: 0.1602131426334381, precision: 0.29557640750668257, recall: 0.6955835962144012, f1: 0.4148635935611149\n",
            "epoch: 758, step: 16, Train: label_loss: 0.16479584574699402, precision: 0.28628762541804104, recall: 0.7169179229479535, f1: 0.4091778202268603\n",
            "epoch: 758, step: 17, Train: label_loss: 0.15917113423347473, precision: 0.2951365756162362, recall: 0.7395659432386077, f1: 0.42190476186394626\n",
            "epoch: 758, step: 18, Train: label_loss: 0.1550692617893219, precision: 0.3150231634678812, recall: 0.7555555555554355, f1: 0.444652031719284\n",
            "epoch: 758, step: 19, Train: label_loss: 0.16563954949378967, precision: 0.26589986468198473, recall: 0.6882661996496167, f1: 0.3836017569143717\n",
            "epoch: 758, step: 20, Train: label_loss: 0.1439138948917389, precision: 0.30675241157554295, recall: 0.7963272120199004, f1: 0.44289693589295553\n",
            "epoch: 758, step: 21, Train: label_loss: 0.15496642887592316, precision: 0.31282383419687093, recall: 0.7777777777776524, f1: 0.44618937640246453\n",
            "epoch: 758, step: 22, Train: label_loss: 0.15160760283470154, precision: 0.27684346701162504, recall: 0.7521968365552281, f1: 0.4047281323483379\n",
            "epoch: 758, step: 23, Train: label_loss: 0.1428556889295578, precision: 0.2781350482314889, recall: 0.7393162393160814, f1: 0.404205607436861\n",
            "epoch: 759, step: 0, Train: label_loss: 0.1540524959564209, precision: 0.28839922229421333, recall: 0.7504215851600757, f1: 0.4166666666265181\n",
            "epoch: 759, step: 1, Train: label_loss: 0.1518448442220688, precision: 0.30293367346936845, recall: 0.7624398073835051, f1: 0.4335919670975548\n",
            "epoch: 759, step: 2, Train: label_loss: 0.15194672346115112, precision: 0.2916120576670844, recall: 0.735537190082523, f1: 0.4176442984107315\n",
            "epoch: 759, step: 3, Train: label_loss: 0.13309535384178162, precision: 0.28259473346176733, recall: 0.7773851590104633, f1: 0.4145077719815811\n",
            "epoch: 759, step: 4, Train: label_loss: 0.13062402606010437, precision: 0.2982345523328942, recall: 0.7962962962961622, f1: 0.4339449540887539\n",
            "epoch: 759, step: 5, Train: label_loss: 0.11777697503566742, precision: 0.271924290220803, recall: 0.7710196779962842, f1: 0.4020522387673829\n",
            "epoch: 759, step: 6, Train: label_loss: 0.11176268011331558, precision: 0.3119950279676624, recall: 0.8175895765470981, f1: 0.45164192528611224\n",
            "epoch: 759, step: 7, Train: label_loss: 0.1307334303855896, precision: 0.30677540777915263, recall: 0.7990196078430066, f1: 0.4433363553542467\n",
            "epoch: 759, step: 8, Train: label_loss: 0.13527929782867432, precision: 0.31555834378918973, recall: 0.8099838969402882, f1: 0.4541760721943701\n",
            "epoch: 759, step: 9, Train: label_loss: 0.12172037363052368, precision: 0.2943058221368973, recall: 0.7718120805367832, f1: 0.42612320514757773\n",
            "epoch: 759, step: 10, Train: label_loss: 0.13922646641731262, precision: 0.3075483468496377, recall: 0.8216666666665297, f1: 0.44757149337839003\n",
            "epoch: 759, step: 11, Train: label_loss: 0.11042579263448715, precision: 0.3110698824984347, recall: 0.830033003300193, f1: 0.4525416103966482\n",
            "epoch: 759, step: 12, Train: label_loss: 0.129824697971344, precision: 0.3070669168229952, recall: 0.8196994991651385, f1: 0.446769790679144\n",
            "epoch: 759, step: 13, Train: label_loss: 0.1439480185508728, precision: 0.3191222570532715, recall: 0.8612521150590758, f1: 0.4656907593383637\n",
            "epoch: 759, step: 14, Train: label_loss: 0.16355067491531372, precision: 0.3228295819935484, recall: 0.7856025039122401, f1: 0.45761166814463544\n",
            "epoch: 759, step: 15, Train: label_loss: 0.1545294225215912, precision: 0.31289111389234586, recall: 0.816993464052154, f1: 0.45248868774271706\n",
            "epoch: 759, step: 16, Train: label_loss: 0.16337941586971283, precision: 0.3045717965228394, recall: 0.7922948073700515, f1: 0.4399999999598448\n",
            "epoch: 759, step: 17, Train: label_loss: 0.16102896630764008, precision: 0.3161533626649707, recall: 0.8411371237456787, f1: 0.4595705801338423\n",
            "epoch: 759, step: 18, Train: label_loss: 0.1649373173713684, precision: 0.32868904369852253, recall: 0.8173228346455406, f1: 0.4688346883059309\n",
            "epoch: 759, step: 19, Train: label_loss: 0.18731826543807983, precision: 0.3049095607234945, recall: 0.7919463087246993, f1: 0.4402985074225036\n",
            "epoch: 759, step: 20, Train: label_loss: 0.14461970329284668, precision: 0.2917951881554416, recall: 0.8446428571427063, f1: 0.43374598804065595\n",
            "epoch: 759, step: 21, Train: label_loss: 0.15534129738807678, precision: 0.2997432605904814, recall: 0.7928692699489316, f1: 0.4350256171003399\n",
            "epoch: 759, step: 22, Train: label_loss: 0.1543801724910736, precision: 0.3007566204287326, recall: 0.8238341968910493, f1: 0.44064665123098423\n",
            "epoch: 759, step: 23, Train: label_loss: 0.17582197487354279, precision: 0.3343923749006883, recall: 0.7869158878503202, f1: 0.46934225190903855\n",
            "epoch: 760, step: 0, Train: label_loss: 0.14452657103538513, precision: 0.30112219451369693, recall: 0.8399999999998539, f1: 0.4433226250184754\n",
            "epoch: 760, step: 1, Train: label_loss: 0.14587576687335968, precision: 0.319014529374585, recall: 0.8319604612848711, f1: 0.46118721457176065\n",
            "epoch: 760, step: 2, Train: label_loss: 0.1433412730693817, precision: 0.3145510835913118, recall: 0.8581081081079631, f1: 0.4603534208940947\n",
            "epoch: 760, step: 3, Train: label_loss: 0.14589127898216248, precision: 0.3208020050125112, recall: 0.8231511254017969, f1: 0.4616771866142442\n",
            "epoch: 760, step: 4, Train: label_loss: 0.1572553813457489, precision: 0.3188228080931748, recall: 0.8538587848931274, f1: 0.46428571424608106\n",
            "epoch: 760, step: 5, Train: label_loss: 0.15023961663246155, precision: 0.3163841807909406, recall: 0.8600682593855187, f1: 0.46259752175962643\n",
            "epoch: 760, step: 6, Train: label_loss: 0.1661452353000641, precision: 0.310191082802528, recall: 0.8116666666665313, f1: 0.4488479262272303\n",
            "epoch: 760, step: 7, Train: label_loss: 0.13120108842849731, precision: 0.32964329643294404, recall: 0.8589743589742213, f1: 0.4764444444043182\n",
            "epoch: 760, step: 8, Train: label_loss: 0.11962101608514786, precision: 0.31837738168406154, recall: 0.8436482084689179, f1: 0.4622936188803002\n",
            "epoch: 760, step: 9, Train: label_loss: 0.14042150974273682, precision: 0.3069245165314843, recall: 0.8227424749162503, f1: 0.44706951381772153\n",
            "epoch: 760, step: 10, Train: label_loss: 0.1503554880619049, precision: 0.30510585305103954, recall: 0.8492201039859879, f1: 0.4489234997320257\n",
            "epoch: 760, step: 11, Train: label_loss: 0.13764186203479767, precision: 0.32729544034976094, recall: 0.841091492776751, f1: 0.4712230215423603\n",
            "epoch: 760, step: 12, Train: label_loss: 0.15468350052833557, precision: 0.31323803604721484, recall: 0.8484848484847056, f1: 0.45755787558472116\n",
            "epoch: 760, step: 13, Train: label_loss: 0.17213673889636993, precision: 0.28580645161288476, recall: 0.777192982456004, f1: 0.4179245282625317\n",
            "epoch: 760, step: 14, Train: label_loss: 0.1720135509967804, precision: 0.30744544287546166, recall: 0.8010033444814714, f1: 0.4443413728726735\n",
            "epoch: 760, step: 15, Train: label_loss: 0.1457686573266983, precision: 0.308370044052844, recall: 0.8153078202993651, f1: 0.4474885844350213\n",
            "epoch: 760, step: 16, Train: label_loss: 0.14242154359817505, precision: 0.3194706994328721, recall: 0.8257328990226668, f1: 0.4606996819224736\n",
            "epoch: 760, step: 17, Train: label_loss: 0.14970949292182922, precision: 0.30232558139532983, recall: 0.8124999999998627, f1: 0.4406779660621256\n",
            "epoch: 760, step: 18, Train: label_loss: 0.15742842853069305, precision: 0.2854418308963582, recall: 0.7688356164382244, f1: 0.4163189614811033\n",
            "epoch: 760, step: 19, Train: label_loss: 0.12606181204319, precision: 0.320489296636066, recall: 0.8576104746316108, f1: 0.46660730183034277\n",
            "epoch: 760, step: 20, Train: label_loss: 0.1393623799085617, precision: 0.318238213399484, recall: 0.8564273789647985, f1: 0.4640434192277535\n",
            "epoch: 760, step: 21, Train: label_loss: 0.156438410282135, precision: 0.3329113924050422, recall: 0.8335974643421816, f1: 0.47580280412018144\n",
            "epoch: 760, step: 22, Train: label_loss: 0.14407624304294586, precision: 0.3329207920791873, recall: 0.8762214983711928, f1: 0.48251121072238323\n",
            "epoch: 760, step: 23, Train: label_loss: 0.1314619779586792, precision: 0.3193403298350585, recall: 0.8801652892560166, f1: 0.46864686464734706\n",
            "epoch: 761, step: 0, Train: label_loss: 0.1372947245836258, precision: 0.3093299937382399, recall: 0.8151815181516806, f1: 0.4484793463059691\n",
            "epoch: 761, step: 1, Train: label_loss: 0.1394222527742386, precision: 0.30496894409935993, recall: 0.8279932546372971, f1: 0.44575578752303013\n",
            "epoch: 761, step: 2, Train: label_loss: 0.11666074395179749, precision: 0.3189550425273196, recall: 0.8550488599347141, f1: 0.46460176987188917\n",
            "epoch: 761, step: 3, Train: label_loss: 0.12778154015541077, precision: 0.308943089430875, recall: 0.8247078464105467, f1: 0.44949954500125483\n",
            "epoch: 761, step: 4, Train: label_loss: 0.12962526082992554, precision: 0.31153608883403383, recall: 0.8265139116201593, f1: 0.45250896053367434\n",
            "epoch: 761, step: 5, Train: label_loss: 0.12155510485172272, precision: 0.3042944785275887, recall: 0.8566493955093512, f1: 0.4490719782319884\n",
            "epoch: 761, step: 6, Train: label_loss: 0.1440805345773697, precision: 0.3161810291382321, recall: 0.8485856905156657, f1: 0.4607046070064754\n",
            "epoch: 761, step: 7, Train: label_loss: 0.12074245512485504, precision: 0.3101965601965411, recall: 0.8573853989811786, f1: 0.45557059084952883\n",
            "epoch: 761, step: 8, Train: label_loss: 0.14088106155395508, precision: 0.3238916256157436, recall: 0.8525121555914339, f1: 0.46943328867045114\n",
            "epoch: 761, step: 9, Train: label_loss: 0.12798252701759338, precision: 0.31908302354397033, recall: 0.8239999999998681, f1: 0.4600267976372492\n",
            "epoch: 761, step: 10, Train: label_loss: 0.1320096254348755, precision: 0.32545454545452573, recall: 0.8817733990146335, f1: 0.4754316068662863\n",
            "epoch: 761, step: 11, Train: label_loss: 0.12437205016613007, precision: 0.31722054380662734, recall: 0.8764607679464312, f1: 0.46583850927770337\n",
            "epoch: 761, step: 12, Train: label_loss: 0.13659445941448212, precision: 0.31081926203875476, recall: 0.8255813953487, f1: 0.4516129031860247\n",
            "epoch: 761, step: 13, Train: label_loss: 0.12044744193553925, precision: 0.3177914110429253, recall: 0.861896838602186, f1: 0.46436575522729145\n",
            "epoch: 761, step: 14, Train: label_loss: 0.11612250655889511, precision: 0.3260073260073061, recall: 0.878289473684066, f1: 0.47551202133179976\n",
            "epoch: 761, step: 15, Train: label_loss: 0.11830432713031769, precision: 0.3185947910357166, recall: 0.8737541528237751, f1: 0.46693297821201835\n",
            "epoch: 761, step: 16, Train: label_loss: 0.11808408796787262, precision: 0.31044957472659107, recall: 0.8795180722890051, f1: 0.45891333628829073\n",
            "epoch: 761, step: 17, Train: label_loss: 0.11705736070871353, precision: 0.32966360856267096, recall: 0.8749999999998579, f1: 0.47889826739689856\n",
            "epoch: 761, step: 18, Train: label_loss: 0.10276414453983307, precision: 0.29376135675346493, recall: 0.8479020979019496, f1: 0.436347278414282\n",
            "epoch: 761, step: 19, Train: label_loss: 0.11847414076328278, precision: 0.3208358942839385, recall: 0.8474025974024598, f1: 0.46544806059319727\n",
            "epoch: 761, step: 20, Train: label_loss: 0.14897096157073975, precision: 0.3215174129353034, recall: 0.843393148450107, f1: 0.4655560557907\n",
            "epoch: 761, step: 21, Train: label_loss: 0.11401652544736862, precision: 0.30310407790625055, recall: 0.8483816013627175, f1: 0.4466367712616205\n",
            "epoch: 761, step: 22, Train: label_loss: 0.1446906179189682, precision: 0.3036848792884178, recall: 0.7979966611017031, f1: 0.43994477676628424\n",
            "epoch: 761, step: 23, Train: label_loss: 0.10572507232427597, precision: 0.31240768094532406, recall: 0.8812499999998165, f1: 0.46128680475956013\n",
            "epoch: 762, step: 0, Train: label_loss: 0.10170713067054749, precision: 0.31639443436174736, recall: 0.8716666666665214, f1: 0.4642698623665622\n",
            "epoch: 762, step: 1, Train: label_loss: 0.11922202259302139, precision: 0.3101538461538271, recall: 0.8630136986299891, f1: 0.4563150746554946\n",
            "epoch: 762, step: 2, Train: label_loss: 0.11140084266662598, precision: 0.3039950062421783, recall: 0.8396551724136483, f1: 0.4463794683385631\n",
            "epoch: 762, step: 3, Train: label_loss: 0.09306292235851288, precision: 0.309079975947065, recall: 0.8939130434781053, f1: 0.45933869522540416\n",
            "epoch: 762, step: 4, Train: label_loss: 0.10889924317598343, precision: 0.3152439024390052, recall: 0.8489326765187439, f1: 0.4597598932463716\n",
            "epoch: 762, step: 5, Train: label_loss: 0.10647794604301453, precision: 0.3143203883494955, recall: 0.8662207357858083, f1: 0.4612644701300764\n",
            "epoch: 762, step: 6, Train: label_loss: 0.11353699117898941, precision: 0.3090234857849005, recall: 0.8605851979344473, f1: 0.4547521600338382\n",
            "epoch: 762, step: 7, Train: label_loss: 0.11108297109603882, precision: 0.30717351318207803, recall: 0.8363939899831658, f1: 0.44932735422075765\n",
            "epoch: 762, step: 8, Train: label_loss: 0.1087179109454155, precision: 0.30599755201956513, recall: 0.8517887563882705, f1: 0.4502476361609808\n",
            "epoch: 762, step: 9, Train: label_loss: 0.1180972009897232, precision: 0.3276492082825623, recall: 0.8747967479673374, f1: 0.4767390340763936\n",
            "epoch: 762, step: 10, Train: label_loss: 0.10664793103933334, precision: 0.3229737964655501, recall: 0.886287625417912, f1: 0.4734256364056491\n",
            "epoch: 762, step: 11, Train: label_loss: 0.10429733246564865, precision: 0.3319200484554614, recall: 0.8796147672550755, f1: 0.4819700967059982\n",
            "epoch: 762, step: 12, Train: label_loss: 0.10265389829874039, precision: 0.31598285364358136, recall: 0.8514851485147109, f1: 0.4609200535558336\n",
            "epoch: 762, step: 13, Train: label_loss: 0.12971557676792145, precision: 0.31520395550059854, recall: 0.8429752066114309, f1: 0.4588394061681686\n",
            "epoch: 762, step: 14, Train: label_loss: 0.10337674617767334, precision: 0.31566118220595274, recall: 0.8720538720537252, f1: 0.46353467557614364\n",
            "epoch: 762, step: 15, Train: label_loss: 0.10980547964572906, precision: 0.31491712707180386, recall: 0.8564273789647985, f1: 0.4605026929588493\n",
            "epoch: 762, step: 16, Train: label_loss: 0.10291310399770737, precision: 0.3256379100850349, recall: 0.8743882544859911, f1: 0.47454625936723055\n",
            "epoch: 762, step: 17, Train: label_loss: 0.11002245545387268, precision: 0.3244390539720846, recall: 0.8713355048858515, f1: 0.4728236853338152\n",
            "epoch: 762, step: 18, Train: label_loss: 0.11313866823911667, precision: 0.3153988868274387, recall: 0.8401976935748203, f1: 0.4586330934854506\n",
            "epoch: 762, step: 19, Train: label_loss: 0.12535665929317474, precision: 0.326654523375815, recall: 0.8663446054749007, f1: 0.4744268077203316\n",
            "epoch: 762, step: 20, Train: label_loss: 0.1249709352850914, precision: 0.31874229346483857, recall: 0.8461538461537076, f1: 0.4630541871523261\n",
            "epoch: 762, step: 21, Train: label_loss: 0.12869581580162048, precision: 0.3129629629629436, recall: 0.8506711409394545, f1: 0.4575812273974584\n",
            "epoch: 762, step: 22, Train: label_loss: 0.12653431296348572, precision: 0.31091918568782784, recall: 0.8456375838924755, f1: 0.45466847086727735\n",
            "epoch: 762, step: 23, Train: label_loss: 0.11075885593891144, precision: 0.3353204172876054, recall: 0.885826771653369, f1: 0.48648648644659537\n",
            "epoch: 763, step: 0, Train: label_loss: 0.11607761681079865, precision: 0.3157262905161875, recall: 0.8870151770656176, f1: 0.4656927843791235\n",
            "epoch: 763, step: 1, Train: label_loss: 0.1221180111169815, precision: 0.30152905198774915, recall: 0.8588850174214531, f1: 0.4463558170733097\n",
            "epoch: 763, step: 2, Train: label_loss: 0.10026010870933533, precision: 0.3208333333333142, recall: 0.9043624161072308, f1: 0.47363796129697683\n",
            "epoch: 763, step: 3, Train: label_loss: 0.12550829350948334, precision: 0.3343596059113095, recall: 0.8524332810045757, f1: 0.48031844312622596\n",
            "epoch: 763, step: 4, Train: label_loss: 0.11944910883903503, precision: 0.2998149290561197, recall: 0.8336192109775585, f1: 0.4410163338993442\n",
            "epoch: 763, step: 5, Train: label_loss: 0.12218889594078064, precision: 0.3076923076922887, recall: 0.8375209380233103, f1: 0.4500450044611116\n",
            "epoch: 763, step: 6, Train: label_loss: 0.11073564738035202, precision: 0.303648732220142, recall: 0.8378839590442255, f1: 0.44575578752332545\n",
            "epoch: 763, step: 7, Train: label_loss: 0.13150519132614136, precision: 0.31339563862926395, recall: 0.8165584415583089, f1: 0.45294912197698295\n",
            "epoch: 763, step: 8, Train: label_loss: 0.11906693875789642, precision: 0.31013051584833373, recall: 0.8429054054052629, f1: 0.4534302589338279\n",
            "epoch: 763, step: 9, Train: label_loss: 0.1021888479590416, precision: 0.33091787439611525, recall: 0.874003189792524, f1: 0.48007008318394373\n",
            "epoch: 763, step: 10, Train: label_loss: 0.1031716912984848, precision: 0.31246237206500227, recall: 0.876689189189041, f1: 0.4607190412395112\n",
            "epoch: 763, step: 11, Train: label_loss: 0.0921124666929245, precision: 0.3236539624924184, recall: 0.879934210526171, f1: 0.4732419283109263\n",
            "epoch: 763, step: 12, Train: label_loss: 0.10589681565761566, precision: 0.3218390804597506, recall: 0.8721311475408405, f1: 0.47017233756552873\n",
            "epoch: 763, step: 13, Train: label_loss: 0.11127878725528717, precision: 0.31273176761431937, recall: 0.8547297297295853, f1: 0.4579185519969342\n",
            "epoch: 763, step: 14, Train: label_loss: 0.09621457010507584, precision: 0.31200487507615404, recall: 0.8590604026844195, f1: 0.45775592307218\n",
            "epoch: 763, step: 15, Train: label_loss: 0.11076963692903519, precision: 0.32748184019368476, recall: 0.873990306946547, f1: 0.47644209595325776\n",
            "epoch: 763, step: 16, Train: label_loss: 0.10317528992891312, precision: 0.31291291291289414, recall: 0.8845500848894933, f1: 0.4622892634928529\n",
            "epoch: 763, step: 17, Train: label_loss: 0.11175937205553055, precision: 0.3251833740831097, recall: 0.8539325842695258, f1: 0.4710048693712567\n",
            "epoch: 763, step: 18, Train: label_loss: 0.09457168728113174, precision: 0.3210463733650225, recall: 0.9015025041734721, f1: 0.4734765453360655\n",
            "epoch: 763, step: 19, Train: label_loss: 0.105202816426754, precision: 0.3297426690604231, recall: 0.9003267973854737, f1: 0.4826982040781055\n",
            "epoch: 763, step: 20, Train: label_loss: 0.11082811653614044, precision: 0.3237237237237043, recall: 0.8850574712642224, f1: 0.47405452942424114\n",
            "epoch: 763, step: 21, Train: label_loss: 0.09928607940673828, precision: 0.31661631419937664, recall: 0.8747913188646285, f1: 0.46495119783138583\n",
            "epoch: 763, step: 22, Train: label_loss: 0.10495490580797195, precision: 0.3065296251511302, recall: 0.871134020618407, f1: 0.4534883720544753\n",
            "epoch: 763, step: 23, Train: label_loss: 0.12949931621551514, precision: 0.31268656716415577, recall: 0.8586065573768733, f1: 0.4584245076194549\n",
            "epoch: 764, step: 0, Train: label_loss: 0.10461835563182831, precision: 0.3089820359281252, recall: 0.8835616438354651, f1: 0.45785270626147767\n",
            "epoch: 764, step: 1, Train: label_loss: 0.10395008325576782, precision: 0.30741190765490234, recall: 0.8709122203096608, f1: 0.4544229905316679\n",
            "epoch: 764, step: 2, Train: label_loss: 0.10877944529056549, precision: 0.3471563981042448, recall: 0.9199372056513468, f1: 0.50408602146555\n",
            "epoch: 764, step: 3, Train: label_loss: 0.09336669743061066, precision: 0.2948948948948772, recall: 0.8927272727271104, f1: 0.44334085775044024\n",
            "epoch: 764, step: 4, Train: label_loss: 0.09586754441261292, precision: 0.31506024096383645, recall: 0.8658940397349559, f1: 0.46201413423645543\n",
            "epoch: 764, step: 5, Train: label_loss: 0.09820811450481415, precision: 0.3149939540507669, recall: 0.8625827814568108, f1: 0.4614703276844202\n",
            "epoch: 764, step: 6, Train: label_loss: 0.1074455976486206, precision: 0.3219832735961576, recall: 0.886513157894591, f1: 0.4723926379976791\n",
            "epoch: 764, step: 7, Train: label_loss: 0.1099669560790062, precision: 0.29663056558361633, recall: 0.8741134751771499, f1: 0.44294699007892696\n",
            "epoch: 764, step: 8, Train: label_loss: 0.09689313173294067, precision: 0.33129584352076213, recall: 0.8713826366558084, f1: 0.4800708591274454\n",
            "epoch: 764, step: 9, Train: label_loss: 0.0971512570977211, precision: 0.32620647525960134, recall: 0.8396226415093019, f1: 0.4698636163256918\n",
            "epoch: 764, step: 10, Train: label_loss: 0.09815415740013123, precision: 0.3183475091129819, recall: 0.8576104746316108, f1: 0.4643331856051344\n",
            "epoch: 764, step: 11, Train: label_loss: 0.10021820664405823, precision: 0.29867788461536665, recall: 0.8859180035649044, f1: 0.4467415729959551\n",
            "epoch: 764, step: 12, Train: label_loss: 0.09688442945480347, precision: 0.3139255702280724, recall: 0.8940170940169411, f1: 0.4646823633555368\n",
            "epoch: 764, step: 13, Train: label_loss: 0.11080431938171387, precision: 0.3286327406498879, recall: 0.8617363344050061, f1: 0.47581003102967107\n",
            "epoch: 764, step: 14, Train: label_loss: 0.09006580710411072, precision: 0.3441053261519842, recall: 0.8970358814351174, f1: 0.49740484425053794\n",
            "epoch: 764, step: 15, Train: label_loss: 0.09186062216758728, precision: 0.3327348892878317, recall: 0.9084967320259952, f1: 0.4870784055673736\n",
            "epoch: 764, step: 16, Train: label_loss: 0.1023033857345581, precision: 0.31758373205739726, recall: 0.898477157360254, f1: 0.4692885549768338\n",
            "epoch: 764, step: 17, Train: label_loss: 0.11532469093799591, precision: 0.3001852995676158, recall: 0.849650349650201, f1: 0.44363304423339917\n",
            "epoch: 764, step: 18, Train: label_loss: 0.09201943874359131, precision: 0.33273273273271275, recall: 0.8892455858746565, f1: 0.4842657342260623\n",
            "epoch: 764, step: 19, Train: label_loss: 0.10017944872379303, precision: 0.32078853046593064, recall: 0.883223684210381, f1: 0.470639789619064\n",
            "epoch: 764, step: 20, Train: label_loss: 0.1014443039894104, precision: 0.3162031438935722, recall: 0.8731218697828258, f1: 0.46426986236660367\n",
            "epoch: 764, step: 21, Train: label_loss: 0.09908477216959, precision: 0.3371325734852827, recall: 0.897763578274617, f1: 0.4901875272171312\n",
            "epoch: 764, step: 22, Train: label_loss: 0.09764312952756882, precision: 0.3349455864570535, recall: 0.8835725677829531, f1: 0.4857518631779802\n",
            "epoch: 764, step: 23, Train: label_loss: 0.10810279101133347, precision: 0.2805059523809315, recall: 0.8359201773834067, f1: 0.42005571026873484\n",
            "epoch: 765, step: 0, Train: label_loss: 0.08733831346035004, precision: 0.3109243697478805, recall: 0.8839590443684497, f1: 0.4600355239401443\n",
            "epoch: 765, step: 1, Train: label_loss: 0.10100388526916504, precision: 0.3097398669086322, recall: 0.8590604026844195, f1: 0.45531347261551697\n",
            "epoch: 765, step: 2, Train: label_loss: 0.10005687177181244, precision: 0.3190970103721587, recall: 0.867330016583604, f1: 0.46654772520595134\n",
            "epoch: 765, step: 3, Train: label_loss: 0.08584488183259964, precision: 0.3186157517899571, recall: 0.8841059602647542, f1: 0.46842105259259104\n",
            "epoch: 765, step: 4, Train: label_loss: 0.09311562031507492, precision: 0.31212484993995726, recall: 0.8652246256238161, f1: 0.45875606524551144\n",
            "epoch: 765, step: 5, Train: label_loss: 0.09888892620801926, precision: 0.3294691885295711, recall: 0.8557844690965363, f1: 0.4757709250699494\n",
            "epoch: 765, step: 6, Train: label_loss: 0.11342660337686539, precision: 0.3138201569100595, recall: 0.8595041322312629, f1: 0.4597701149033027\n",
            "epoch: 765, step: 7, Train: label_loss: 0.13878585398197174, precision: 0.30068621334995005, recall: 0.7966942148759013, f1: 0.43659420285872597\n",
            "epoch: 765, step: 8, Train: label_loss: 0.09846360981464386, precision: 0.33474065138719333, recall: 0.8922829581992134, f1: 0.48684210522343857\n",
            "epoch: 765, step: 9, Train: label_loss: 0.11150555312633514, precision: 0.28658166363082654, recall: 0.8660550458714007, f1: 0.4306569342691673\n",
            "epoch: 765, step: 10, Train: label_loss: 0.11129312217235565, precision: 0.31386861313866704, recall: 0.870151770657526, f1: 0.4613321412216125\n",
            "epoch: 765, step: 11, Train: label_loss: 0.1135219931602478, precision: 0.3341493268053651, recall: 0.879227053139955, f1: 0.4842572061684728\n",
            "epoch: 765, step: 12, Train: label_loss: 0.11084955930709839, precision: 0.30735930735928835, recall: 0.8367003367001957, f1: 0.4495703301280083\n",
            "epoch: 765, step: 13, Train: label_loss: 0.09690183401107788, precision: 0.3425314937012392, recall: 0.9006309148263563, f1: 0.49630595389310656\n",
            "epoch: 765, step: 14, Train: label_loss: 0.10942927747964859, precision: 0.30816831683166407, recall: 0.84693877551006, f1: 0.45190562609513785\n",
            "epoch: 765, step: 15, Train: label_loss: 0.1180386021733284, precision: 0.32496940024477816, recall: 0.8648208469053965, f1: 0.4724199287858746\n",
            "epoch: 765, step: 16, Train: label_loss: 0.09310534596443176, precision: 0.32756563245821435, recall: 0.9074380165287755, f1: 0.48136782109206366\n",
            "epoch: 765, step: 17, Train: label_loss: 0.10406436026096344, precision: 0.3306942752740359, recall: 0.893092105263011, f1: 0.4826666666271834\n",
            "epoch: 765, step: 18, Train: label_loss: 0.10281398892402649, precision: 0.3185679611650292, recall: 0.863486842105121, f1: 0.4654255318754781\n",
            "epoch: 765, step: 19, Train: label_loss: 0.10158561170101166, precision: 0.300543150271557, recall: 0.8783068783067234, f1: 0.447841726580675\n",
            "epoch: 765, step: 20, Train: label_loss: 0.1101914644241333, precision: 0.3108433734939572, recall: 0.870151770657526, f1: 0.4580559253939301\n",
            "epoch: 765, step: 21, Train: label_loss: 0.10828263312578201, precision: 0.3112623762376045, recall: 0.8205546492657715, f1: 0.4513234633966021\n",
            "epoch: 765, step: 22, Train: label_loss: 0.11177177727222443, precision: 0.3041079092581052, recall: 0.8406779661015523, f1: 0.44664565507125475\n",
            "epoch: 765, step: 23, Train: label_loss: 0.09685549139976501, precision: 0.3215339233038111, recall: 0.8843813387422141, f1: 0.47160627362227986\n",
            "epoch: 766, step: 0, Train: label_loss: 0.099123515188694, precision: 0.3229927007299074, recall: 0.869067103109514, f1: 0.4709534367675461\n",
            "epoch: 766, step: 1, Train: label_loss: 0.09041668474674225, precision: 0.30476765238380776, recall: 0.8632478632477156, f1: 0.4504906333244596\n",
            "epoch: 766, step: 2, Train: label_loss: 0.09185051918029785, precision: 0.33233711894797774, recall: 0.8881789137378773, f1: 0.4836885602039122\n",
            "epoch: 766, step: 3, Train: label_loss: 0.092344731092453, precision: 0.31125827814567664, recall: 0.8807495741054717, f1: 0.4599644127727597\n",
            "epoch: 766, step: 4, Train: label_loss: 0.10421141237020493, precision: 0.3199999999999806, recall: 0.864157119476127, f1: 0.4670499778464083\n",
            "epoch: 766, step: 5, Train: label_loss: 0.08744743466377258, precision: 0.3279569892472922, recall: 0.8941368078174439, f1: 0.4798951048557947\n",
            "epoch: 766, step: 6, Train: label_loss: 0.10722383856773376, precision: 0.29726443768995153, recall: 0.8670212765955909, f1: 0.4427342688618883\n",
            "epoch: 766, step: 7, Train: label_loss: 0.10049320757389069, precision: 0.3150183150182958, recall: 0.8745762711862923, f1: 0.46319569116389375\n",
            "epoch: 766, step: 8, Train: label_loss: 0.104104183614254, precision: 0.31670673076921174, recall: 0.8932203389828994, f1: 0.46761313217071593\n",
            "epoch: 766, step: 9, Train: label_loss: 0.09047268331050873, precision: 0.324275362318821, recall: 0.897993311036639, f1: 0.476486246633556\n",
            "epoch: 766, step: 10, Train: label_loss: 0.10108767449855804, precision: 0.3177399756986441, recall: 0.8601973684209111, f1: 0.4640638863846974\n",
            "epoch: 766, step: 11, Train: label_loss: 0.10009771585464478, precision: 0.33554216867467856, recall: 0.8983870967740486, f1: 0.48859649118843046\n",
            "epoch: 766, step: 12, Train: label_loss: 0.10378967225551605, precision: 0.3179864947820554, recall: 0.8533772652387391, f1: 0.46332737026451853\n",
            "epoch: 766, step: 13, Train: label_loss: 0.09915192425251007, precision: 0.32072072072070146, recall: 0.9005059021920909, f1: 0.47298494238815425\n",
            "epoch: 766, step: 14, Train: label_loss: 0.09555962681770325, precision: 0.31793641271743744, recall: 0.895270270270119, f1: 0.4692341743747386\n",
            "epoch: 766, step: 15, Train: label_loss: 0.10909590125083923, precision: 0.3048259010384664, recall: 0.850085178875494, f1: 0.4487410071553492\n",
            "epoch: 766, step: 16, Train: label_loss: 0.10686294734477997, precision: 0.33095238095236124, recall: 0.9144736842103759, f1: 0.4860139859749196\n",
            "epoch: 766, step: 17, Train: label_loss: 0.09716498851776123, precision: 0.33551847437423504, recall: 0.8838304552588879, f1: 0.4863930885129841\n",
            "epoch: 766, step: 18, Train: label_loss: 0.09567980468273163, precision: 0.31474820143883003, recall: 0.8706467661690098, f1: 0.4623513870151164\n",
            "epoch: 766, step: 19, Train: label_loss: 0.0899297297000885, precision: 0.3126120741183316, recall: 0.8716666666665214, f1: 0.4601847777877625\n",
            "epoch: 766, step: 20, Train: label_loss: 0.1046430692076683, precision: 0.31261425959778716, recall: 0.8535773710481108, f1: 0.4576271186047858\n",
            "epoch: 766, step: 21, Train: label_loss: 0.1006544828414917, precision: 0.3208333333333142, recall: 0.8998330550916694, f1: 0.473014479996311\n",
            "epoch: 766, step: 22, Train: label_loss: 0.10588721185922623, precision: 0.30829800121136836, recall: 0.8730703259003647, f1: 0.45568487014939013\n",
            "epoch: 766, step: 23, Train: label_loss: 0.11521448194980621, precision: 0.3129251700680035, recall: 0.8198019801978574, f1: 0.4529540481000062\n",
            "epoch: 767, step: 0, Train: label_loss: 0.09411987662315369, precision: 0.31057401812686947, recall: 0.8697123519457073, f1: 0.45770258232983574\n",
            "epoch: 767, step: 1, Train: label_loss: 0.08409683406352997, precision: 0.3266152934202533, recall: 0.916805324459082, f1: 0.48164335660457924\n",
            "epoch: 767, step: 2, Train: label_loss: 0.0908118486404419, precision: 0.3118664281454793, recall: 0.9032815198616747, f1: 0.4636524822313064\n",
            "epoch: 767, step: 3, Train: label_loss: 0.10575182735919952, precision: 0.3196319018404712, recall: 0.8683333333331885, f1: 0.4672645739516562\n",
            "epoch: 767, step: 4, Train: label_loss: 0.09351220726966858, precision: 0.3193529059316765, recall: 0.8868552412644114, f1: 0.4696035241901013\n",
            "epoch: 767, step: 5, Train: label_loss: 0.09587326645851135, precision: 0.3177458033572951, recall: 0.8892617449662937, f1: 0.4681978798198259\n",
            "epoch: 767, step: 6, Train: label_loss: 0.10664375126361847, precision: 0.31057401812686947, recall: 0.8846815834766119, f1: 0.45974955273430296\n",
            "epoch: 767, step: 7, Train: label_loss: 0.09561565518379211, precision: 0.29669669669667886, recall: 0.87744227353448, f1: 0.4434470376641672\n",
            "epoch: 767, step: 8, Train: label_loss: 0.09457264840602875, precision: 0.327947336923978, recall: 0.8954248366011608, f1: 0.4800700831845447\n",
            "epoch: 767, step: 9, Train: label_loss: 0.09379222244024277, precision: 0.3122743682310281, recall: 0.8752107925799535, f1: 0.46031042124722676\n",
            "epoch: 767, step: 10, Train: label_loss: 0.09333832561969757, precision: 0.30510510510508676, recall: 0.8773747841103838, f1: 0.45276292331282897\n",
            "epoch: 767, step: 11, Train: label_loss: 0.09798401594161987, precision: 0.33413751507838757, recall: 0.8724409448817523, f1: 0.48320976882166305\n",
            "epoch: 767, step: 12, Train: label_loss: 0.11051718890666962, precision: 0.3216019417475533, recall: 0.8760330578510948, f1: 0.47048379933928003\n",
            "epoch: 767, step: 13, Train: label_loss: 0.1053164079785347, precision: 0.3249999999999802, recall: 0.869494290375062, f1: 0.473146915184493\n",
            "epoch: 767, step: 14, Train: label_loss: 0.09953205287456512, precision: 0.3317249698431645, recall: 0.8785942492011375, f1: 0.4816112083664705\n",
            "epoch: 767, step: 15, Train: label_loss: 0.08840198814868927, precision: 0.3253012048192575, recall: 0.885245901639199, f1: 0.47577092507078805\n",
            "epoch: 767, step: 16, Train: label_loss: 0.09211339056491852, precision: 0.3258901629450618, recall: 0.8737864077668488, f1: 0.47472527468566184\n",
            "epoch: 767, step: 17, Train: label_loss: 0.0962289571762085, precision: 0.3267973856208956, recall: 0.9121061359865816, f1: 0.4811898512297093\n",
            "epoch: 767, step: 18, Train: label_loss: 0.0963461697101593, precision: 0.31746987951805317, recall: 0.8527508090613506, f1: 0.4626865671246001\n",
            "epoch: 767, step: 19, Train: label_loss: 0.09060071408748627, precision: 0.33071342200723514, recall: 0.9071310116084731, f1: 0.4847142223799396\n",
            "epoch: 767, step: 20, Train: label_loss: 0.09170152992010117, precision: 0.3030484160191092, recall: 0.8817391304346291, f1: 0.45106761562025127\n",
            "epoch: 767, step: 21, Train: label_loss: 0.10055215656757355, precision: 0.3185096153845962, recall: 0.8907563025208586, f1: 0.46923417437461246\n",
            "epoch: 767, step: 22, Train: label_loss: 0.0995481014251709, precision: 0.34868421052629495, recall: 0.9109374999998576, f1: 0.5043252594754895\n",
            "epoch: 767, step: 23, Train: label_loss: 0.10083331912755966, precision: 0.3167883211678601, recall: 0.9004149377591493, f1: 0.4686825053610125\n",
            "epoch: 768, step: 0, Train: label_loss: 0.07746075093746185, precision: 0.33452380952378963, recall: 0.9093851132684612, f1: 0.48912097472129756\n",
            "epoch: 768, step: 1, Train: label_loss: 0.079960897564888, precision: 0.33293627159021244, recall: 0.9074675324673851, f1: 0.48714596945959504\n",
            "epoch: 768, step: 2, Train: label_loss: 0.10954830795526505, precision: 0.3057090239410494, recall: 0.8498293515356911, f1: 0.4496613995095785\n",
            "epoch: 768, step: 3, Train: label_loss: 0.08906436711549759, precision: 0.33493109646492897, recall: 0.8929712460062471, f1: 0.4871459694591951\n",
            "epoch: 768, step: 4, Train: label_loss: 0.09087054431438446, precision: 0.32174955062909993, recall: 0.896494156928064, f1: 0.4735449735060606\n",
            "epoch: 768, step: 5, Train: label_loss: 0.09636321663856506, precision: 0.32527206771461153, recall: 0.8877887788777412, f1: 0.47610619465097503\n",
            "epoch: 768, step: 6, Train: label_loss: 0.07714768499135971, precision: 0.30950974601297637, recall: 0.9225352112674431, f1: 0.46351172044000233\n",
            "epoch: 768, step: 7, Train: label_loss: 0.09937119483947754, precision: 0.30306674684303647, recall: 0.874999999999848, f1: 0.4502009825432541\n",
            "epoch: 768, step: 8, Train: label_loss: 0.09071677178144455, precision: 0.3309395571513865, recall: 0.908045977011345, f1: 0.48508771925905103\n",
            "epoch: 768, step: 9, Train: label_loss: 0.09190386533737183, precision: 0.314759928867794, recall: 0.898477157360254, f1: 0.466198419627907\n",
            "epoch: 768, step: 10, Train: label_loss: 0.09576771408319473, precision: 0.3126506024096197, recall: 0.876689189189041, f1: 0.4609236234070304\n",
            "epoch: 768, step: 11, Train: label_loss: 0.08833335340023041, precision: 0.3384164222873702, recall: 0.9187898089170511, f1: 0.49464209168800266\n",
            "epoch: 768, step: 12, Train: label_loss: 0.10090960562229156, precision: 0.3004239854633373, recall: 0.8701754385963385, f1: 0.4466456550721152\n",
            "epoch: 768, step: 13, Train: label_loss: 0.10565721988677979, precision: 0.32080048514249115, recall: 0.8672131147539561, f1: 0.46834882687509954\n",
            "epoch: 768, step: 14, Train: label_loss: 0.1049996018409729, precision: 0.3271308523409167, recall: 0.8905228758168479, f1: 0.47848990338471803\n",
            "epoch: 768, step: 15, Train: label_loss: 0.10016489028930664, precision: 0.31433713257346646, recall: 0.8836424957839993, f1: 0.4637168141205428\n",
            "epoch: 768, step: 16, Train: label_loss: 0.10009786486625671, precision: 0.3220747889022725, recall: 0.8989898989897476, f1: 0.47424511541405\n",
            "epoch: 768, step: 17, Train: label_loss: 0.09692074358463287, precision: 0.30513595166161295, recall: 0.8662092624355289, f1: 0.45129579978270057\n",
            "epoch: 768, step: 18, Train: label_loss: 0.10518589615821838, precision: 0.29515151515149723, recall: 0.8573943661970321, f1: 0.43913435523688166\n",
            "epoch: 768, step: 19, Train: label_loss: 0.09195275604724884, precision: 0.3185362927414326, recall: 0.9015280135821898, f1: 0.47074468081243853\n",
            "epoch: 768, step: 20, Train: label_loss: 0.10383450984954834, precision: 0.3137847642079617, recall: 0.8649999999998558, f1: 0.4605146405997565\n",
            "epoch: 768, step: 21, Train: label_loss: 0.10491599887609482, precision: 0.342822531798889, recall: 0.8748068006181028, f1: 0.49260226279675107\n",
            "epoch: 768, step: 22, Train: label_loss: 0.08343832194805145, precision: 0.33888228299641265, recall: 0.9033280507130105, f1: 0.49286640722357516\n",
            "epoch: 768, step: 23, Train: label_loss: 0.08967974781990051, precision: 0.33210603829158086, recall: 0.8895463510846372, f1: 0.48364611256089485\n",
            "epoch: 769, step: 0, Train: label_loss: 0.08921603858470917, precision: 0.32859680284189885, recall: 0.9083469721766106, f1: 0.48260869561311576\n",
            "epoch: 769, step: 1, Train: label_loss: 0.08851303905248642, precision: 0.31227651966625075, recall: 0.9113043478259284, f1: 0.4651575676494704\n",
            "epoch: 769, step: 2, Train: label_loss: 0.08790843188762665, precision: 0.32542975696500737, recall: 0.9119601328902139, f1: 0.4796854521237085\n",
            "epoch: 769, step: 3, Train: label_loss: 0.0884496346116066, precision: 0.31369047619045753, recall: 0.8827470686765689, f1: 0.4628897671988636\n",
            "epoch: 769, step: 4, Train: label_loss: 0.09863243252038956, precision: 0.31404460518382676, recall: 0.8890784982933636, f1: 0.4641425389368816\n",
            "epoch: 769, step: 5, Train: label_loss: 0.09433018416166306, precision: 0.3351416515973276, recall: 0.8953301127212728, f1: 0.48771929820593446\n",
            "epoch: 769, step: 6, Train: label_loss: 0.10605786740779877, precision: 0.324275362318821, recall: 0.8817733990146335, f1: 0.4741721853911055\n",
            "epoch: 769, step: 7, Train: label_loss: 0.11216575652360916, precision: 0.327097163548562, recall: 0.8885245901637887, f1: 0.47816497569948463\n",
            "epoch: 769, step: 8, Train: label_loss: 0.11461848020553589, precision: 0.32361870066786136, recall: 0.8988195615512817, f1: 0.47589285710388485\n",
            "epoch: 769, step: 9, Train: label_loss: 0.11797023564577103, precision: 0.29534313725488387, recall: 0.8561278863231161, f1: 0.4391799544037327\n",
            "epoch: 769, step: 10, Train: label_loss: 0.09142225980758667, precision: 0.3156640857653177, recall: 0.8907563025208586, f1: 0.4661389621424994\n",
            "epoch: 769, step: 11, Train: label_loss: 0.10507924854755402, precision: 0.30982519590112656, recall: 0.8786324786323284, f1: 0.45811051689545884\n",
            "epoch: 769, step: 12, Train: label_loss: 0.11309453099966049, precision: 0.31327543424315674, recall: 0.850168350168207, f1: 0.45784224837402404\n",
            "epoch: 769, step: 13, Train: label_loss: 0.10318073630332947, precision: 0.32396891811115813, recall: 0.9033333333331827, f1: 0.47690277162850014\n",
            "epoch: 769, step: 14, Train: label_loss: 0.10479951649904251, precision: 0.3073200241984085, recall: 0.8819444444442912, f1: 0.45580978013211204\n",
            "epoch: 769, step: 15, Train: label_loss: 0.09065830707550049, precision: 0.33807829181492655, recall: 0.913461538461392, f1: 0.4935064934670188\n",
            "epoch: 769, step: 16, Train: label_loss: 0.1298958957195282, precision: 0.3118932038834762, recall: 0.8697123519457073, f1: 0.4591335417208164\n",
            "epoch: 769, step: 17, Train: label_loss: 0.10485287755727768, precision: 0.3287176399758983, recall: 0.8849270664504237, f1: 0.4793678665100646\n",
            "epoch: 769, step: 18, Train: label_loss: 0.11118222773075104, precision: 0.3029375764993695, recall: 0.8222591362124879, f1: 0.44275491945971684\n",
            "epoch: 769, step: 19, Train: label_loss: 0.1360783725976944, precision: 0.30327362569485466, recall: 0.8583916083914582, f1: 0.44819717020327543\n",
            "epoch: 769, step: 20, Train: label_loss: 0.1216711550951004, precision: 0.329871716554653, recall: 0.8463949843258861, f1: 0.4747252746848743\n",
            "epoch: 769, step: 21, Train: label_loss: 0.11323665082454681, precision: 0.35090909090906963, recall: 0.8962848297212235, f1: 0.504355400656381\n",
            "epoch: 769, step: 22, Train: label_loss: 0.12468364834785461, precision: 0.31288723667903884, recall: 0.8458961474035434, f1: 0.4568068746778598\n",
            "epoch: 769, step: 23, Train: label_loss: 0.12623991072177887, precision: 0.3335832083957771, recall: 0.8640776699027448, f1: 0.48134126550870326\n",
            "epoch: 770, step: 0, Train: label_loss: 0.14245368540287018, precision: 0.2984520123838824, recall: 0.8485915492956252, f1: 0.44159413647085183\n",
            "epoch: 770, step: 1, Train: label_loss: 0.11530324071645737, precision: 0.3111653447223727, recall: 0.8869565217389761, f1: 0.4607046070075766\n",
            "epoch: 770, step: 2, Train: label_loss: 0.1275477558374405, precision: 0.28640776699027387, recall: 0.8309859154928114, f1: 0.42599277974523125\n",
            "epoch: 770, step: 3, Train: label_loss: 0.13800927996635437, precision: 0.3243902439024192, recall: 0.8735632183906611, f1: 0.4730991551405456\n",
            "epoch: 770, step: 4, Train: label_loss: 0.12148638069629669, precision: 0.3206621704475585, recall: 0.8573770491801872, f1: 0.466755912499382\n",
            "epoch: 770, step: 5, Train: label_loss: 0.1250673234462738, precision: 0.31368937998770324, recall: 0.8502495840264808, f1: 0.4582959640861448\n",
            "epoch: 770, step: 6, Train: label_loss: 0.11977791041135788, precision: 0.30564166150029104, recall: 0.8603839441534274, f1: 0.4510521500070214\n",
            "epoch: 770, step: 7, Train: label_loss: 0.10707738995552063, precision: 0.3193430656934112, recall: 0.8663366336632233, f1: 0.4666666666272665\n",
            "epoch: 770, step: 8, Train: label_loss: 0.10907575488090515, precision: 0.31966726084371244, recall: 0.8951747088184866, f1: 0.4711033274568015\n",
            "epoch: 770, step: 9, Train: label_loss: 0.11409049481153488, precision: 0.3171619163128977, recall: 0.8716666666665214, f1: 0.46509559800441147\n",
            "epoch: 770, step: 10, Train: label_loss: 0.0951499193906784, precision: 0.3425149700598597, recall: 0.8979591836733284, f1: 0.495882097922704\n",
            "epoch: 770, step: 11, Train: label_loss: 0.12273934483528137, precision: 0.3224009900989899, recall: 0.8296178343947723, f1: 0.46434937607373317\n",
            "epoch: 770, step: 12, Train: label_loss: 0.09804226458072662, precision: 0.32677400119258637, recall: 0.9013157894735359, f1: 0.47964989055171114\n",
            "epoch: 770, step: 13, Train: label_loss: 0.1267012655735016, precision: 0.3075980392156674, recall: 0.8581196581195114, f1: 0.452864230903826\n",
            "epoch: 770, step: 14, Train: label_loss: 0.10939370095729828, precision: 0.3373277411623525, recall: 0.8894154818324028, f1: 0.4891398783267222\n",
            "epoch: 770, step: 15, Train: label_loss: 0.10678388178348541, precision: 0.30708661417320976, recall: 0.8535353535352098, f1: 0.45167037858019726\n",
            "epoch: 770, step: 16, Train: label_loss: 0.11791177839040756, precision: 0.29125615763545004, recall: 0.828371278458699, f1: 0.43097949882251546\n",
            "epoch: 770, step: 17, Train: label_loss: 0.10728715360164642, precision: 0.3068944478340264, recall: 0.8583617747438808, f1: 0.4521348314218322\n",
            "epoch: 770, step: 18, Train: label_loss: 0.11403194814920425, precision: 0.3271490414347355, recall: 0.8370253164555637, f1: 0.47043130276079415\n",
            "epoch: 770, step: 19, Train: label_loss: 0.10513886064291, precision: 0.31534263189810097, recall: 0.8623548922054954, f1: 0.46181172287371225\n",
            "epoch: 770, step: 20, Train: label_loss: 0.11917836219072342, precision: 0.323874151758154, recall: 0.8481421647817692, f1: 0.468749999959963\n",
            "epoch: 770, step: 21, Train: label_loss: 0.09959843754768372, precision: 0.326678765880198, recall: 0.878048780487662, f1: 0.47619047615090737\n",
            "epoch: 770, step: 22, Train: label_loss: 0.10259003192186356, precision: 0.3266423357664035, recall: 0.8861386138612398, f1: 0.47733333329393224\n",
            "epoch: 770, step: 23, Train: label_loss: 0.10942059010267258, precision: 0.31743666169893314, recall: 0.8676171079427969, f1: 0.46481178392144656\n",
            "epoch: 771, step: 0, Train: label_loss: 0.10781869292259216, precision: 0.3159490600363665, recall: 0.8597359735972178, f1: 0.462084257166864\n",
            "epoch: 771, step: 1, Train: label_loss: 0.09224539250135422, precision: 0.30870870870869016, recall: 0.8816466552314096, f1: 0.4572953736270231\n",
            "epoch: 771, step: 2, Train: label_loss: 0.10871132463216782, precision: 0.33154121863797303, recall: 0.906862745097891, f1: 0.48556430442269094\n",
            "epoch: 771, step: 3, Train: label_loss: 0.09909024834632874, precision: 0.32170775706552485, recall: 0.891666666666518, f1: 0.4728236853343887\n",
            "epoch: 771, step: 4, Train: label_loss: 0.1039264053106308, precision: 0.30066145520142507, recall: 0.8880994671401619, f1: 0.4492362982550714\n",
            "epoch: 771, step: 5, Train: label_loss: 0.09847252815961838, precision: 0.3019654556283322, recall: 0.8973451327432039, f1: 0.4518716577162928\n",
            "epoch: 771, step: 6, Train: label_loss: 0.09514601528644562, precision: 0.3133414932680347, recall: 0.8476821192051576, f1: 0.45755138512587595\n",
            "epoch: 771, step: 7, Train: label_loss: 0.08888256549835205, precision: 0.32064247471741103, recall: 0.9104729729728192, f1: 0.4742630883908237\n",
            "epoch: 771, step: 8, Train: label_loss: 0.09222423285245895, precision: 0.3206979542719422, recall: 0.8883333333331852, f1: 0.4712643677770716\n",
            "epoch: 771, step: 9, Train: label_loss: 0.10616761445999146, precision: 0.3286499694563025, recall: 0.862179487179349, f1: 0.47589562136645186\n",
            "epoch: 771, step: 10, Train: label_loss: 0.09539922326803207, precision: 0.3191361727654278, recall: 0.8822553897179299, f1: 0.46872246692129615\n",
            "epoch: 771, step: 11, Train: label_loss: 0.10620056092739105, precision: 0.31364190012178356, recall: 0.8583333333331902, f1: 0.45941123992507676\n",
            "epoch: 771, step: 12, Train: label_loss: 0.10840567946434021, precision: 0.3165165165164975, recall: 0.8887015177064268, f1: 0.4667847652402362\n",
            "epoch: 771, step: 13, Train: label_loss: 0.10090476274490356, precision: 0.33613950691519323, recall: 0.8929712460062471, f1: 0.4884228920528363\n",
            "epoch: 771, step: 14, Train: label_loss: 0.10990890860557556, precision: 0.31862745098037265, recall: 0.8739495798317858, f1: 0.46699595864961857\n",
            "epoch: 771, step: 15, Train: label_loss: 0.12460896372795105, precision: 0.3280098280098079, recall: 0.8599033816423736, f1: 0.47487772339261874\n",
            "epoch: 771, step: 16, Train: label_loss: 0.11646371334791183, precision: 0.33861144945186733, recall: 0.870109546165748, f1: 0.4875054800122334\n",
            "epoch: 771, step: 17, Train: label_loss: 0.10894078016281128, precision: 0.33051359516614315, recall: 0.871019108280116, f1: 0.4791940428860507\n",
            "epoch: 771, step: 18, Train: label_loss: 0.09540344774723053, precision: 0.332129963898897, recall: 0.8888888888887457, f1: 0.48357424437559654\n",
            "epoch: 771, step: 19, Train: label_loss: 0.10821618884801865, precision: 0.3158216249236215, recall: 0.8517298187807493, f1: 0.4607843136859832\n",
            "epoch: 771, step: 20, Train: label_loss: 0.10547807812690735, precision: 0.30614729153984743, recall: 0.8642611683847312, f1: 0.452134831422003\n",
            "epoch: 771, step: 21, Train: label_loss: 0.10107538849115372, precision: 0.30932203389828633, recall: 0.8545150501670811, f1: 0.45422222218315383\n",
            "epoch: 771, step: 22, Train: label_loss: 0.10570073872804642, precision: 0.3197815533980388, recall: 0.8917089678509489, f1: 0.4707458686524812\n",
            "epoch: 771, step: 23, Train: label_loss: 0.09848561882972717, precision: 0.31031922791385963, recall: 0.896995708154314, f1: 0.46111417536164534\n",
            "epoch: 772, step: 0, Train: label_loss: 0.10068997740745544, precision: 0.33111782477339385, recall: 0.8968903436987075, f1: 0.4836716680982581\n",
            "epoch: 772, step: 1, Train: label_loss: 0.1112012267112732, precision: 0.33000623830316095, recall: 0.8330708661416011, f1: 0.4727435209602055\n",
            "epoch: 772, step: 2, Train: label_loss: 0.09766818583011627, precision: 0.2996960486322006, recall: 0.857391304347677, f1: 0.44414414410571945\n",
            "epoch: 772, step: 3, Train: label_loss: 0.09982913732528687, precision: 0.3299340131973407, recall: 0.8972267536703267, f1: 0.48245614031152\n",
            "epoch: 772, step: 4, Train: label_loss: 0.1100214272737503, precision: 0.29681762545897816, recall: 0.861456483125957, f1: 0.4415111515321649\n",
            "epoch: 772, step: 5, Train: label_loss: 0.1067635715007782, precision: 0.3018867924528118, recall: 0.8747795414460537, f1: 0.4488687782423549\n",
            "epoch: 772, step: 6, Train: label_loss: 0.09130319207906723, precision: 0.3216232586311132, recall: 0.869067103109514, f1: 0.469496021180687\n",
            "epoch: 772, step: 7, Train: label_loss: 0.09181376546621323, precision: 0.3096695226437999, recall: 0.8605442176869285, f1: 0.45544554451549457\n",
            "epoch: 772, step: 8, Train: label_loss: 0.0849408432841301, precision: 0.3365212193663875, recall: 0.9051446945336165, f1: 0.4906318082393103\n",
            "epoch: 772, step: 9, Train: label_loss: 0.09060470759868622, precision: 0.32870090634439103, recall: 0.8874388254484685, f1: 0.4797178130116581\n",
            "epoch: 772, step: 10, Train: label_loss: 0.09856729954481125, precision: 0.3249551166965694, recall: 0.8960396039602481, f1: 0.4769433464694601\n",
            "epoch: 772, step: 11, Train: label_loss: 0.11368807405233383, precision: 0.286585365853641, recall: 0.8333333333331855, f1: 0.4264972776388294\n",
            "epoch: 772, step: 12, Train: label_loss: 0.08233125507831573, precision: 0.33392645314351516, recall: 0.9036918138040282, f1: 0.487656994330412\n",
            "epoch: 772, step: 13, Train: label_loss: 0.10116017609834671, precision: 0.31506024096383645, recall: 0.8702163061562611, f1: 0.462627156086536\n",
            "epoch: 772, step: 14, Train: label_loss: 0.0932287871837616, precision: 0.30447941888618013, recall: 0.8642611683847312, f1: 0.45031333926313083\n",
            "epoch: 772, step: 15, Train: label_loss: 0.09712061285972595, precision: 0.31197604790417294, recall: 0.8967297762476941, f1: 0.4629053753503774\n",
            "epoch: 772, step: 16, Train: label_loss: 0.10225975513458252, precision: 0.3451746595618505, recall: 0.9010819165377277, f1: 0.4991438355763441\n",
            "epoch: 772, step: 17, Train: label_loss: 0.10947003960609436, precision: 0.3123486682808528, recall: 0.8557213930346839, f1: 0.45764966736654444\n",
            "epoch: 772, step: 18, Train: label_loss: 0.09514087438583374, precision: 0.313173652694592, recall: 0.8804713804712322, f1: 0.4620141342368714\n",
            "epoch: 772, step: 19, Train: label_loss: 0.10516251623630524, precision: 0.33070388349512553, recall: 0.8733974358972959, f1: 0.47975352108687497\n",
            "epoch: 772, step: 20, Train: label_loss: 0.09885916113853455, precision: 0.3155688622754302, recall: 0.8947368421051112, f1: 0.46657813187818553\n",
            "epoch: 772, step: 21, Train: label_loss: 0.09842261672019958, precision: 0.3215780035863526, recall: 0.9072512647553276, f1: 0.4748455427680239\n",
            "epoch: 772, step: 22, Train: label_loss: 0.09560619294643402, precision: 0.3303411131059048, recall: 0.9019607843135781, f1: 0.4835742443759592\n",
            "epoch: 772, step: 23, Train: label_loss: 0.10870492458343506, precision: 0.3236607142856902, recall: 0.86653386454166, f1: 0.47128927406652676\n",
            "epoch: 773, step: 0, Train: label_loss: 0.0911816880106926, precision: 0.3369175627239942, recall: 0.9052969502406251, f1: 0.4910753155895063\n",
            "epoch: 773, step: 1, Train: label_loss: 0.09789341688156128, precision: 0.3099099099098913, recall: 0.9036777583185808, f1: 0.4615384615003894\n",
            "epoch: 773, step: 2, Train: label_loss: 0.09863493591547012, precision: 0.3293124246079415, recall: 0.8863636363634924, f1: 0.4802110817546514\n",
            "epoch: 773, step: 3, Train: label_loss: 0.09702710807323456, precision: 0.32409638554214915, recall: 0.8819672131146095, f1: 0.47400881053334326\n",
            "epoch: 773, step: 4, Train: label_loss: 0.0890725702047348, precision: 0.3363363363363161, recall: 0.8917197452227879, f1: 0.4884430876182735\n",
            "epoch: 773, step: 5, Train: label_loss: 0.08658970892429352, precision: 0.3110307414104695, recall: 0.8775510204080139, f1: 0.4592790386796092\n",
            "epoch: 773, step: 6, Train: label_loss: 0.09855048358440399, precision: 0.31627056672758586, recall: 0.8564356435642151, f1: 0.46194926564815064\n",
            "epoch: 773, step: 7, Train: label_loss: 0.090748131275177, precision: 0.29461077844309613, recall: 0.8738898756659194, f1: 0.44066278545262044\n",
            "epoch: 773, step: 8, Train: label_loss: 0.09954530000686646, precision: 0.32153752287978515, recall: 0.8783333333331869, f1: 0.470745868652105\n",
            "epoch: 773, step: 9, Train: label_loss: 0.09532482922077179, precision: 0.31917475728153405, recall: 0.8708609271521737, f1: 0.46714031967651237\n",
            "epoch: 773, step: 10, Train: label_loss: 0.08652563393115997, precision: 0.3185893604303456, recall: 0.9111111111109553, f1: 0.4720992027959335\n",
            "epoch: 773, step: 11, Train: label_loss: 0.09008531272411346, precision: 0.313173652694592, recall: 0.8864406779659514, f1: 0.46283185836845697\n",
            "epoch: 773, step: 12, Train: label_loss: 0.0831865444779396, precision: 0.3206197854588605, recall: 0.8733766233764816, f1: 0.46904969481682157\n",
            "epoch: 773, step: 13, Train: label_loss: 0.0956805869936943, precision: 0.3228346456692718, recall: 0.8737704918031354, f1: 0.47147279960673166\n",
            "epoch: 773, step: 14, Train: label_loss: 0.09228655695915222, precision: 0.31836975782632493, recall: 0.9028475711891284, f1: 0.47074235804001446\n",
            "epoch: 773, step: 15, Train: label_loss: 0.08199983835220337, precision: 0.3538098050797192, recall: 0.9089529590286936, f1: 0.5093537414562188\n",
            "epoch: 773, step: 16, Train: label_loss: 0.09872666001319885, precision: 0.31925165962581054, recall: 0.8801996672211513, f1: 0.46855624442502186\n",
            "epoch: 773, step: 17, Train: label_loss: 0.08710572123527527, precision: 0.31186032510533945, recall: 0.8900343642610153, f1: 0.46188140878899253\n",
            "epoch: 773, step: 18, Train: label_loss: 0.08331640064716339, precision: 0.3082840236686208, recall: 0.9029462738299994, f1: 0.45963828844899857\n",
            "epoch: 773, step: 19, Train: label_loss: 0.08558984100818634, precision: 0.3399162178336122, recall: 0.8902821316613024, f1: 0.49198787349829304\n",
            "epoch: 773, step: 20, Train: label_loss: 0.10619416832923889, precision: 0.3058894230769047, recall: 0.8671209540032594, f1: 0.45224344731813604\n",
            "epoch: 773, step: 21, Train: label_loss: 0.09871181845664978, precision: 0.3071776155717575, recall: 0.8844133099823319, f1: 0.4559819412709472\n",
            "epoch: 773, step: 22, Train: label_loss: 0.09396808594465256, precision: 0.33353293413171653, recall: 0.9101307189540996, f1: 0.48816827340505187\n",
            "epoch: 773, step: 23, Train: label_loss: 0.09033000469207764, precision: 0.31401320616285294, recall: 0.8824742268039418, f1: 0.4632034631646995\n",
            "epoch: 774, step: 0, Train: label_loss: 0.07875633984804153, precision: 0.3455621301774943, recall: 0.9139280125194187, f1: 0.5015027908575198\n",
            "epoch: 774, step: 1, Train: label_loss: 0.08322863280773163, precision: 0.3135642982971043, recall: 0.9066213921899988, f1: 0.4659685863492055\n",
            "epoch: 774, step: 2, Train: label_loss: 0.10907299071550369, precision: 0.3206979542719422, recall: 0.8624595469254267, f1: 0.4675438596095651\n",
            "epoch: 774, step: 3, Train: label_loss: 0.1013985127210617, precision: 0.3213633597078319, recall: 0.8613376835235136, f1: 0.46808510634335965\n",
            "epoch: 774, step: 4, Train: label_loss: 0.10805273056030273, precision: 0.3110976349302419, recall: 0.8650927487350986, f1: 0.4576271186051194\n",
            "epoch: 774, step: 5, Train: label_loss: 0.0972495824098587, precision: 0.29729729729727944, recall: 0.8839285714284135, f1: 0.4449438201870112\n",
            "epoch: 774, step: 6, Train: label_loss: 0.09560926258563995, precision: 0.3247761194029657, recall: 0.8816855753645247, f1: 0.4746945898384485\n",
            "epoch: 774, step: 7, Train: label_loss: 0.08956467360258102, precision: 0.30218446601939913, recall: 0.8829787234040987, f1: 0.4502712477015692\n",
            "epoch: 774, step: 8, Train: label_loss: 0.09908755123615265, precision: 0.31729598051155194, recall: 0.8540983606555976, f1: 0.4626998223405656\n",
            "epoch: 774, step: 9, Train: label_loss: 0.10300551354885101, precision: 0.29326047358832463, recall: 0.8609625668447662, f1: 0.437499999962056\n",
            "epoch: 774, step: 10, Train: label_loss: 0.09116239845752716, precision: 0.3276595744680652, recall: 0.8679549114330325, f1: 0.4757281552999744\n",
            "epoch: 774, step: 11, Train: label_loss: 0.08918336033821106, precision: 0.3107617896009486, recall: 0.859531772575107, f1: 0.456483126071078\n",
            "epoch: 774, step: 12, Train: label_loss: 0.1028418019413948, precision: 0.3113553113552923, recall: 0.8629441624364022, f1: 0.4576043068250552\n",
            "epoch: 774, step: 13, Train: label_loss: 0.0900442898273468, precision: 0.3295249549007619, recall: 0.8810289389066107, f1: 0.4796498905511453\n",
            "epoch: 774, step: 14, Train: label_loss: 0.09422799944877625, precision: 0.31125827814567664, recall: 0.8718381112983352, f1: 0.45874001770741374\n",
            "epoch: 774, step: 15, Train: label_loss: 0.10289140045642853, precision: 0.31848688224525207, recall: 0.8515497553016554, f1: 0.463587921807584\n",
            "epoch: 774, step: 16, Train: label_loss: 0.10629809647798538, precision: 0.3315184513006454, recall: 0.8925081433223302, f1: 0.4834583149141432\n",
            "epoch: 774, step: 17, Train: label_loss: 0.09760862588882446, precision: 0.3335325762103805, recall: 0.8956661316210439, f1: 0.48606271773044946\n",
            "epoch: 774, step: 18, Train: label_loss: 0.10952559858560562, precision: 0.32098027495515113, recall: 0.896494156928064, f1: 0.4727112675667649\n",
            "epoch: 774, step: 19, Train: label_loss: 0.08292750269174576, precision: 0.3305439330543735, recall: 0.8847999999998584, f1: 0.48128807654869477\n",
            "epoch: 774, step: 20, Train: label_loss: 0.11964815109968185, precision: 0.31692307692305743, recall: 0.8346839546189895, f1: 0.4594112399243835\n",
            "epoch: 774, step: 21, Train: label_loss: 0.10234420001506805, precision: 0.3023679417121856, recall: 0.8440677966100264, f1: 0.44523915954985827\n",
            "epoch: 774, step: 22, Train: label_loss: 0.09911653399467468, precision: 0.30538922155686793, recall: 0.8838821490466405, f1: 0.45393858474149634\n",
            "epoch: 774, step: 23, Train: label_loss: 0.08682659268379211, precision: 0.3114992721979395, recall: 0.9067796610167571, f1: 0.4637053087376188\n",
            "epoch: 775, step: 0, Train: label_loss: 0.09932822734117508, precision: 0.32931968693556113, recall: 0.8952536824875784, f1: 0.48151408446767885\n",
            "epoch: 775, step: 1, Train: label_loss: 0.09018898010253906, precision: 0.3030484160191092, recall: 0.874137931034332, f1: 0.45006657785786613\n",
            "epoch: 775, step: 2, Train: label_loss: 0.11041191220283508, precision: 0.3053204353083249, recall: 0.8752166377814774, f1: 0.4527117883972905\n",
            "epoch: 775, step: 3, Train: label_loss: 0.0881352573633194, precision: 0.32893948472137036, recall: 0.9029605263156409, f1: 0.48221343869599165\n",
            "epoch: 775, step: 4, Train: label_loss: 0.09670868515968323, precision: 0.2997557997557814, recall: 0.8436426116837038, f1: 0.44234234230361574\n",
            "epoch: 775, step: 5, Train: label_loss: 0.09639440476894379, precision: 0.3451168364289787, recall: 0.9070866141730854, f1: 0.4999999999600269\n",
            "epoch: 775, step: 6, Train: label_loss: 0.08519381284713745, precision: 0.3133612941881178, recall: 0.9032815198616747, f1: 0.46530249106491667\n",
            "epoch: 775, step: 7, Train: label_loss: 0.09229694306850433, precision: 0.30727600721585646, recall: 0.8675721561967966, f1: 0.45381882767003523\n",
            "epoch: 775, step: 8, Train: label_loss: 0.10579027235507965, precision: 0.30679730557254703, recall: 0.8294701986753593, f1: 0.44792132316125477\n",
            "epoch: 775, step: 9, Train: label_loss: 0.10369621217250824, precision: 0.30890369473044765, recall: 0.8600337268126711, f1: 0.45454545450652867\n",
            "epoch: 775, step: 10, Train: label_loss: 0.10152021795511246, precision: 0.3118148599268994, recall: 0.8547579298829958, f1: 0.4569388665382106\n",
            "epoch: 775, step: 11, Train: label_loss: 0.10589025914669037, precision: 0.32889158086006487, recall: 0.8887070376430624, f1: 0.48010610075628296\n",
            "epoch: 775, step: 12, Train: label_loss: 0.11326052248477936, precision: 0.3037214885954199, recall: 0.8830715532284671, f1: 0.45198749437902536\n",
            "epoch: 775, step: 13, Train: label_loss: 0.08598470687866211, precision: 0.3244837758111903, recall: 0.9001636661209655, f1: 0.47701647871209146\n",
            "epoch: 775, step: 14, Train: label_loss: 0.08604671061038971, precision: 0.3319377990430423, recall: 0.9039087947881264, f1: 0.4855643044226098\n",
            "epoch: 775, step: 15, Train: label_loss: 0.08912529051303864, precision: 0.3170149253731154, recall: 0.8939393939392434, f1: 0.4680475980221273\n",
            "epoch: 775, step: 16, Train: label_loss: 0.09539815783500671, precision: 0.3264311814859728, recall: 0.8729641693809652, f1: 0.4751773049248788\n",
            "epoch: 775, step: 17, Train: label_loss: 0.1064726859331131, precision: 0.3100679431747801, recall: 0.8380634390649685, f1: 0.45266005406332865\n",
            "epoch: 775, step: 18, Train: label_loss: 0.0814807116985321, precision: 0.3325387365911601, recall: 0.9014539579966233, f1: 0.485851110104251\n",
            "epoch: 775, step: 19, Train: label_loss: 0.11421612650156021, precision: 0.3285371702637693, recall: 0.8852988691436372, f1: 0.4792304328419816\n",
            "epoch: 775, step: 20, Train: label_loss: 0.10125732421875, precision: 0.3240796620398115, recall: 0.8788870703762882, f1: 0.473544973505567\n",
            "epoch: 775, step: 21, Train: label_loss: 0.09878973662853241, precision: 0.3319302465423733, recall: 0.8846153846152428, f1: 0.482728465198581\n",
            "epoch: 775, step: 22, Train: label_loss: 0.09889709949493408, precision: 0.3082886106141736, recall: 0.8807495741054717, f1: 0.4567137808802772\n",
            "epoch: 775, step: 23, Train: label_loss: 0.07692597806453705, precision: 0.31548480463094675, recall: 0.8971193415636014, f1: 0.46680942180299523\n",
            "epoch: 776, step: 0, Train: label_loss: 0.08159217238426208, precision: 0.3238265002970693, recall: 0.9144295302011888, f1: 0.4782799473066597\n",
            "epoch: 776, step: 1, Train: label_loss: 0.0905175507068634, precision: 0.31591591591589696, recall: 0.8840336134452295, f1: 0.46548672562488347\n",
            "epoch: 776, step: 2, Train: label_loss: 0.09111439436674118, precision: 0.3347305389221356, recall: 0.9001610305956682, f1: 0.4879965080355164\n",
            "epoch: 776, step: 3, Train: label_loss: 0.09721846878528595, precision: 0.3072289156626321, recall: 0.8777969018931363, f1: 0.45515394909140333\n",
            "epoch: 776, step: 4, Train: label_loss: 0.09251727163791656, precision: 0.3386430678465877, recall: 0.908227848101122, f1: 0.4933390631318569\n",
            "epoch: 776, step: 5, Train: label_loss: 0.0781262069940567, precision: 0.34297520661155, recall: 0.9135220125784727, f1: 0.49871244631219785\n",
            "epoch: 776, step: 6, Train: label_loss: 0.09530717134475708, precision: 0.31373725254947127, recall: 0.8834459459457966, f1: 0.4630367418824859\n",
            "epoch: 776, step: 7, Train: label_loss: 0.0770113617181778, precision: 0.32729398012856065, recall: 0.9333333333331777, f1: 0.4846386845136557\n",
            "epoch: 776, step: 8, Train: label_loss: 0.10151173919439316, precision: 0.3192771084337157, recall: 0.8877721943047089, f1: 0.4696499778077486\n",
            "epoch: 776, step: 9, Train: label_loss: 0.0916772186756134, precision: 0.30598802395207747, recall: 0.8765008576327827, f1: 0.4536173989851227\n",
            "epoch: 776, step: 10, Train: label_loss: 0.08134053647518158, precision: 0.3343212803793518, recall: 0.9009584664535302, f1: 0.48767833977889624\n",
            "epoch: 776, step: 11, Train: label_loss: 0.0941157117486, precision: 0.3303140096618158, recall: 0.8981937602625782, f1: 0.48300220746615996\n",
            "epoch: 776, step: 12, Train: label_loss: 0.08364765346050262, precision: 0.29550827423166104, recall: 0.8865248226948782, f1: 0.4432624113099784\n",
            "epoch: 776, step: 13, Train: label_loss: 0.08985817432403564, precision: 0.30487071557424505, recall: 0.8637137989777063, f1: 0.45066666662806143\n",
            "epoch: 776, step: 14, Train: label_loss: 0.09027184545993805, precision: 0.29461077844309613, recall: 0.8913043478259254, f1: 0.44284428439106094\n",
            "epoch: 776, step: 15, Train: label_loss: 0.0844215378165245, precision: 0.3343248066626809, recall: 0.9093851132684612, f1: 0.4889082209262842\n",
            "epoch: 776, step: 16, Train: label_loss: 0.07816478610038757, precision: 0.3384798099762269, recall: 0.9047619047617611, f1: 0.4926534139620595\n",
            "epoch: 776, step: 17, Train: label_loss: 0.09794642776250839, precision: 0.31689717378230203, recall: 0.8842281879193147, f1: 0.46657813187789093\n",
            "epoch: 776, step: 18, Train: label_loss: 0.08017508685588837, precision: 0.3225806451612714, recall: 0.9243697478990043, f1: 0.4782608695268213\n",
            "epoch: 776, step: 19, Train: label_loss: 0.10051007568836212, precision: 0.3224043715846799, recall: 0.862012987012847, f1: 0.46928855497580285\n",
            "epoch: 776, step: 20, Train: label_loss: 0.08727537095546722, precision: 0.31731909845786965, recall: 0.8813838550245664, f1: 0.4666375926343844\n",
            "epoch: 776, step: 21, Train: label_loss: 0.08344672620296478, precision: 0.3148809523809336, recall: 0.8966101694913734, f1: 0.4660792951156723\n",
            "epoch: 776, step: 22, Train: label_loss: 0.09372594952583313, precision: 0.3130590339892479, recall: 0.8779264214045354, f1: 0.4615384614996683\n",
            "epoch: 776, step: 23, Train: label_loss: 0.08923999965190887, precision: 0.3333333333333093, recall: 0.9277108433733077, f1: 0.49044585983366734\n",
            "epoch: 777, step: 0, Train: label_loss: 0.08493556082248688, precision: 0.33670434265316257, recall: 0.9070512820511366, f1: 0.49110629063292277\n",
            "epoch: 777, step: 1, Train: label_loss: 0.08995430916547775, precision: 0.3122388059701306, recall: 0.8849407783416438, f1: 0.4616063547716397\n",
            "epoch: 777, step: 2, Train: label_loss: 0.07893820106983185, precision: 0.34500875656740543, recall: 0.935126582278333, f1: 0.5040511726684713\n",
            "epoch: 777, step: 3, Train: label_loss: 0.09405285120010376, precision: 0.309952038369286, recall: 0.8762711864405294, f1: 0.45792736931476574\n",
            "epoch: 777, step: 4, Train: label_loss: 0.08373675495386124, precision: 0.3277711561382403, recall: 0.9046052631577459, f1: 0.4811898512295036\n",
            "epoch: 777, step: 5, Train: label_loss: 0.09613297879695892, precision: 0.3132892363198849, recall: 0.8683333333331885, f1: 0.46045072908162793\n",
            "epoch: 777, step: 6, Train: label_loss: 0.07981940358877182, precision: 0.33787788974508964, recall: 0.913461538461392, f1: 0.49329294673682345\n",
            "epoch: 777, step: 7, Train: label_loss: 0.09630803763866425, precision: 0.3129169193450386, recall: 0.8745762711862923, f1: 0.4609200535564993\n",
            "epoch: 777, step: 8, Train: label_loss: 0.08512003719806671, precision: 0.3480597014925165, recall: 0.8941717791409671, f1: 0.5010743446093839\n",
            "epoch: 777, step: 9, Train: label_loss: 0.08759194612503052, precision: 0.31793641271743744, recall: 0.886287625417912, f1: 0.4679911699390211\n",
            "epoch: 777, step: 10, Train: label_loss: 0.08681395649909973, precision: 0.2947494033412712, recall: 0.8933092224229848, f1: 0.44324809327803966\n",
            "epoch: 777, step: 11, Train: label_loss: 0.08500660955905914, precision: 0.3178016726403633, recall: 0.8986486486484968, f1: 0.4695498675694786\n",
            "epoch: 777, step: 12, Train: label_loss: 0.09226775169372559, precision: 0.3046080191501912, recall: 0.8852173913041939, f1: 0.4532502225798533\n",
            "epoch: 777, step: 13, Train: label_loss: 0.08751198649406433, precision: 0.3225998807393964, recall: 0.8971807628522558, f1: 0.47456140346982484\n",
            "epoch: 777, step: 14, Train: label_loss: 0.09649671614170074, precision: 0.3147268408550882, recall: 0.892255892255742, f1: 0.46532045650223197\n",
            "epoch: 777, step: 15, Train: label_loss: 0.10427699983119965, precision: 0.32897085068409704, recall: 0.9125412541252619, f1: 0.4836029732885082\n",
            "epoch: 777, step: 16, Train: label_loss: 0.08350814878940582, precision: 0.30496453900707415, recall: 0.905263157894578, f1: 0.4562334217129246\n",
            "epoch: 777, step: 17, Train: label_loss: 0.08003693073987961, precision: 0.3313289236319705, recall: 0.8872785829306139, f1: 0.4824868651092261\n",
            "epoch: 777, step: 18, Train: label_loss: 0.1045275554060936, precision: 0.30445393532639997, recall: 0.8559176672382751, f1: 0.4491449144527017\n",
            "epoch: 777, step: 19, Train: label_loss: 0.08393168449401855, precision: 0.327947336923978, recall: 0.9072847682117703, f1: 0.48175824171919795\n",
            "epoch: 777, step: 20, Train: label_loss: 0.09003844857215881, precision: 0.33708530805685205, recall: 0.9222042139382621, f1: 0.4937093275095587\n",
            "epoch: 777, step: 21, Train: label_loss: 0.09868977963924408, precision: 0.3254688445250862, recall: 0.8762214983711928, f1: 0.47463608288944176\n",
            "epoch: 777, step: 22, Train: label_loss: 0.09506665170192719, precision: 0.3079213817748476, recall: 0.8944636678199144, f1: 0.4581302613708075\n",
            "epoch: 777, step: 23, Train: label_loss: 0.06723400950431824, precision: 0.33019551049961404, recall: 0.9119999999998176, f1: 0.4848484848094017\n",
            "epoch: 778, step: 0, Train: label_loss: 0.07455604523420334, precision: 0.33116499112948955, recall: 0.9165302782322559, f1: 0.4865334491355939\n",
            "epoch: 778, step: 1, Train: label_loss: 0.0894325003027916, precision: 0.33252866626431304, recall: 0.8815999999998588, f1: 0.4829097282686848\n",
            "epoch: 778, step: 2, Train: label_loss: 0.08653220534324646, precision: 0.3307555026769583, recall: 0.902597402597256, f1: 0.48410970827590005\n",
            "epoch: 778, step: 3, Train: label_loss: 0.09156810492277145, precision: 0.3023952095808202, recall: 0.8767361111109588, f1: 0.449688334779276\n",
            "epoch: 778, step: 4, Train: label_loss: 0.08505865931510925, precision: 0.3119376124774858, recall: 0.8710217755442426, f1: 0.4593639575583008\n",
            "epoch: 778, step: 5, Train: label_loss: 0.07873541116714478, precision: 0.3424494649226907, recall: 0.9056603773583481, f1: 0.496980155266437\n",
            "epoch: 778, step: 6, Train: label_loss: 0.08584895730018616, precision: 0.3147268408550882, recall: 0.8983050847456104, f1: 0.46613896214270983\n",
            "epoch: 778, step: 7, Train: label_loss: 0.08527468144893646, precision: 0.31978481769274836, recall: 0.891666666666518, f1: 0.47074351073980725\n",
            "epoch: 778, step: 8, Train: label_loss: 0.09911194443702698, precision: 0.31253749250148094, recall: 0.8785834738615719, f1: 0.4610619468639058\n",
            "epoch: 778, step: 9, Train: label_loss: 0.100709468126297, precision: 0.3214930764599445, recall: 0.8711256117453717, f1: 0.4696569920450111\n",
            "epoch: 778, step: 10, Train: label_loss: 0.106015145778656, precision: 0.32989690721647486, recall: 0.8831168831167396, f1: 0.4803532008433598\n",
            "epoch: 778, step: 11, Train: label_loss: 0.08625228703022003, precision: 0.30979228486645044, recall: 0.9031141868510547, f1: 0.46133451167204304\n",
            "epoch: 778, step: 12, Train: label_loss: 0.09532033652067184, precision: 0.3154121863799095, recall: 0.8770764119599871, f1: 0.4639718804531427\n",
            "epoch: 778, step: 13, Train: label_loss: 0.08751024305820465, precision: 0.3214072748956278, recall: 0.9028475711891284, f1: 0.47405452942473686\n",
            "epoch: 778, step: 14, Train: label_loss: 0.08304525911808014, precision: 0.326048434731227, recall: 0.9324324324322748, f1: 0.48315098464427936\n",
            "epoch: 778, step: 15, Train: label_loss: 0.08648549765348434, precision: 0.3104693140794037, recall: 0.8775510204080139, f1: 0.4586666666280182\n",
            "epoch: 778, step: 16, Train: label_loss: 0.0745241791009903, precision: 0.3297872340425337, recall: 0.9192751235583329, f1: 0.48542844711202954\n",
            "epoch: 778, step: 17, Train: label_loss: 0.08971327543258667, precision: 0.30623145400591656, recall: 0.89739130434767, f1: 0.456637168103614\n",
            "epoch: 778, step: 18, Train: label_loss: 0.10063349455595016, precision: 0.32815301852956796, recall: 0.8798076923075513, f1: 0.4780148018759283\n",
            "epoch: 778, step: 19, Train: label_loss: 0.09580908715724945, precision: 0.3223880597014733, recall: 0.8985024958401167, f1: 0.47451669591891255\n",
            "epoch: 778, step: 20, Train: label_loss: 0.0786958634853363, precision: 0.3219137625516644, recall: 0.9113712374580415, f1: 0.4757747708038075\n",
            "epoch: 778, step: 21, Train: label_loss: 0.08787895739078522, precision: 0.3325358851674442, recall: 0.902597402597256, f1: 0.4860139859745944\n",
            "epoch: 778, step: 22, Train: label_loss: 0.09047374129295349, precision: 0.30915576694409574, recall: 0.9059233449475773, f1: 0.4609929077634382\n",
            "epoch: 778, step: 23, Train: label_loss: 0.07975032180547714, precision: 0.3215859030836768, recall: 0.8866396761131808, f1: 0.47198275858157457\n",
            "epoch: 779, step: 0, Train: label_loss: 0.089023157954216, precision: 0.3148809523809336, recall: 0.9042735042733496, f1: 0.467108167732064\n",
            "epoch: 779, step: 1, Train: label_loss: 0.07610306143760681, precision: 0.3349140486069748, recall: 0.9025559105429868, f1: 0.4885430176863757\n",
            "epoch: 779, step: 2, Train: label_loss: 0.1043858677148819, precision: 0.30718165359080823, recall: 0.8686006825937084, f1: 0.45385644222618304\n",
            "epoch: 779, step: 3, Train: label_loss: 0.07960602641105652, precision: 0.3437684583579242, recall: 0.9107981220655851, f1: 0.4991423670270665\n",
            "epoch: 779, step: 4, Train: label_loss: 0.08558601886034012, precision: 0.29216867469877755, recall: 0.8629893238432628, f1: 0.4365436543276064\n",
            "epoch: 779, step: 5, Train: label_loss: 0.09343089163303375, precision: 0.3194278903456305, recall: 0.8918469217968565, f1: 0.4703817463411163\n",
            "epoch: 779, step: 6, Train: label_loss: 0.09466497600078583, precision: 0.3271861986912357, recall: 0.9016393442621472, f1: 0.4801396769578295\n",
            "epoch: 779, step: 7, Train: label_loss: 0.08186420798301697, precision: 0.312056737588634, recall: 0.8949152542371364, f1: 0.4627519719160454\n",
            "epoch: 779, step: 8, Train: label_loss: 0.09428343176841736, precision: 0.3199999999999809, recall: 0.8933333333331844, f1: 0.471208791169914\n",
            "epoch: 779, step: 9, Train: label_loss: 0.08017081022262573, precision: 0.31750741839760727, recall: 0.899159663865395, f1: 0.4692982455754215\n",
            "epoch: 779, step: 10, Train: label_loss: 0.08294142782688141, precision: 0.313829787234024, recall: 0.9155172413791525, f1: 0.46742957742672503\n",
            "epoch: 779, step: 11, Train: label_loss: 0.08697635680437088, precision: 0.31957547169809436, recall: 0.910924369747746, f1: 0.47315582711122267\n",
            "epoch: 779, step: 12, Train: label_loss: 0.08416946232318878, precision: 0.32896305125147024, recall: 0.8961038961037505, f1: 0.4812554489580585\n",
            "epoch: 779, step: 13, Train: label_loss: 0.08563922345638275, precision: 0.30960854092524853, recall: 0.8953687821610813, f1: 0.4601145878859706\n",
            "epoch: 779, step: 14, Train: label_loss: 0.08063970506191254, precision: 0.3158208955223692, recall: 0.8950930626056014, f1: 0.46690202997022706\n",
            "epoch: 779, step: 15, Train: label_loss: 0.0754377692937851, precision: 0.3190984578884745, recall: 0.8966666666665172, f1: 0.4706911635657926\n",
            "epoch: 779, step: 16, Train: label_loss: 0.08155398815870285, precision: 0.33729216152017, recall: 0.9131832797426184, f1: 0.4926279271071362\n",
            "epoch: 779, step: 17, Train: label_loss: 0.08796508610248566, precision: 0.3495548961424125, recall: 0.9160186625192976, f1: 0.5060137456644409\n",
            "epoch: 779, step: 18, Train: label_loss: 0.08826054632663727, precision: 0.31272509003599563, recall: 0.8726968174202893, f1: 0.46045072908175283\n",
            "epoch: 779, step: 19, Train: label_loss: 0.0830199122428894, precision: 0.3287671232876516, recall: 0.9123966942147251, f1: 0.48336252185243195\n",
            "epoch: 779, step: 20, Train: label_loss: 0.10001945495605469, precision: 0.3229850746268464, recall: 0.9001663893509317, f1: 0.47539543054105665\n",
            "epoch: 779, step: 21, Train: label_loss: 0.09472818672657013, precision: 0.3273273273273077, recall: 0.8861788617884737, f1: 0.47807017539915875\n",
            "epoch: 779, step: 22, Train: label_loss: 0.0857846811413765, precision: 0.32168246445495724, recall: 0.9187817258881693, f1: 0.47652479153679544\n",
            "epoch: 779, step: 23, Train: label_loss: 0.09358835965394974, precision: 0.31831610044310793, recall: 0.8868312757199821, f1: 0.4684782608306412\n",
            "epoch: 780, step: 0, Train: label_loss: 0.08505775034427643, precision: 0.31912374185906933, recall: 0.9197952218428463, f1: 0.4738461538078655\n",
            "epoch: 780, step: 1, Train: label_loss: 0.07260140776634216, precision: 0.33528037383175613, recall: 0.9348534201952874, f1: 0.4935511607521569\n",
            "epoch: 780, step: 2, Train: label_loss: 0.10621330142021179, precision: 0.305854241338094, recall: 0.885813148788774, f1: 0.45470692713764616\n",
            "epoch: 780, step: 3, Train: label_loss: 0.09302394837141037, precision: 0.324471299093636, recall: 0.8619582664525101, f1: 0.47146619837988674\n",
            "epoch: 780, step: 4, Train: label_loss: 0.09435522556304932, precision: 0.3167281672816533, recall: 0.867003367003221, f1: 0.46396396392472705\n",
            "epoch: 780, step: 5, Train: label_loss: 0.09351126849651337, precision: 0.3213859020310441, recall: 0.8907284768210445, f1: 0.47234416150620506\n",
            "epoch: 780, step: 6, Train: label_loss: 0.10027918219566345, precision: 0.3176119402984885, recall: 0.8941176470586731, f1: 0.468722466921629\n",
            "epoch: 780, step: 7, Train: label_loss: 0.09484577924013138, precision: 0.2983293556085741, recall: 0.89766606822246, f1: 0.4478280339974465\n",
            "epoch: 780, step: 8, Train: label_loss: 0.07495173811912537, precision: 0.34628975265015627, recall: 0.9116279069766028, f1: 0.5019206145567272\n",
            "epoch: 780, step: 9, Train: label_loss: 0.08534862846136093, precision: 0.3140643623360957, recall: 0.8725165562912462, f1: 0.4618755477261529\n",
            "epoch: 780, step: 10, Train: label_loss: 0.07740616053342819, precision: 0.32516437537356097, recall: 0.9036544850496837, f1: 0.4782417582027974\n",
            "epoch: 780, step: 11, Train: label_loss: 0.09712715446949005, precision: 0.3016255267910715, recall: 0.8898756660744422, f1: 0.45053956830747044\n",
            "epoch: 780, step: 12, Train: label_loss: 0.07826585322618484, precision: 0.3390229546792031, recall: 0.9186602870811932, f1: 0.49527085120735337\n",
            "epoch: 780, step: 13, Train: label_loss: 0.09705357998609543, precision: 0.3081570996978666, recall: 0.858585858585714, f1: 0.45353490436304417\n",
            "epoch: 780, step: 14, Train: label_loss: 0.07339128106832504, precision: 0.31333721607453036, recall: 0.9228130360204249, f1: 0.46782608691863564\n",
            "epoch: 780, step: 15, Train: label_loss: 0.07723227143287659, precision: 0.31279620853078716, recall: 0.9010238907848291, f1: 0.4643799471912529\n",
            "epoch: 780, step: 16, Train: label_loss: 0.09713231772184372, precision: 0.3420427553443977, recall: 0.9099526066349273, f1: 0.497194648212295\n",
            "epoch: 780, step: 17, Train: label_loss: 0.08319299668073654, precision: 0.3375451263537703, recall: 0.8724727838256807, f1: 0.4867678958382546\n",
            "epoch: 780, step: 18, Train: label_loss: 0.0901111364364624, precision: 0.3406921241049916, recall: 0.8977987421382235, f1: 0.4939446366382752\n",
            "epoch: 780, step: 19, Train: label_loss: 0.07759930938482285, precision: 0.34027364663888515, recall: 0.9007874015746612, f1: 0.49395509495152073\n",
            "epoch: 780, step: 20, Train: label_loss: 0.0975806936621666, precision: 0.2980484920165406, recall: 0.9064748201437218, f1: 0.44859813080383865\n",
            "epoch: 780, step: 21, Train: label_loss: 0.09127533435821533, precision: 0.31454005934716234, recall: 0.904436860068105, f1: 0.46675473355920233\n",
            "epoch: 780, step: 22, Train: label_loss: 0.08507478982210159, precision: 0.3199052132701232, recall: 0.9183673469386192, f1: 0.4745166959194582\n",
            "epoch: 780, step: 23, Train: label_loss: 0.10087981075048447, precision: 0.32085168869307484, recall: 0.8973305954823619, f1: 0.4726879393878633\n",
            "epoch: 781, step: 0, Train: label_loss: 0.0805898904800415, precision: 0.34081512108680795, recall: 0.9129746835441592, f1: 0.49634408598187507\n",
            "epoch: 781, step: 1, Train: label_loss: 0.09581311047077179, precision: 0.32861356932151453, recall: 0.9086460032624945, f1: 0.48266897743061776\n",
            "epoch: 781, step: 2, Train: label_loss: 0.0875006914138794, precision: 0.32562277580069243, recall: 0.9211409395971608, f1: 0.48115687989125144\n",
            "epoch: 781, step: 3, Train: label_loss: 0.09067736566066742, precision: 0.3393285371702434, recall: 0.8998410174879332, f1: 0.4928167174177404\n",
            "epoch: 781, step: 4, Train: label_loss: 0.09365009516477585, precision: 0.3240023823704393, recall: 0.8903436988541914, f1: 0.47510917026651067\n",
            "epoch: 781, step: 5, Train: label_loss: 0.09191277623176575, precision: 0.32856290995823917, recall: 0.8944805194803742, f1: 0.48059310942424793\n",
            "epoch: 781, step: 6, Train: label_loss: 0.08686548471450806, precision: 0.31656804733725935, recall: 0.9052453468695592, f1: 0.4690925032495972\n",
            "epoch: 781, step: 7, Train: label_loss: 0.08565330505371094, precision: 0.3417498532002148, recall: 0.9387096774192034, f1: 0.5010761945368036\n",
            "epoch: 781, step: 8, Train: label_loss: 0.07817267626523972, precision: 0.3158205430932517, recall: 0.917667238421798, f1: 0.46991655683494066\n",
            "epoch: 781, step: 9, Train: label_loss: 0.09866581857204437, precision: 0.30210210210208394, recall: 0.8598290598289128, f1: 0.4471111110725914\n",
            "epoch: 781, step: 10, Train: label_loss: 0.09011812508106232, precision: 0.3222156045264847, recall: 0.8854337152208043, f1: 0.4724890829302663\n",
            "epoch: 781, step: 11, Train: label_loss: 0.07212953269481659, precision: 0.3260355029585606, recall: 0.912251655628988, f1: 0.48038360937703145\n",
            "epoch: 781, step: 12, Train: label_loss: 0.074819415807724, precision: 0.3087802003535469, recall: 0.8941979522182774, f1: 0.45904511603714016\n",
            "epoch: 781, step: 13, Train: label_loss: 0.07474656403064728, precision: 0.31349440188566213, recall: 0.910958904109433, f1: 0.4664620779978127\n",
            "epoch: 781, step: 14, Train: label_loss: 0.0828203558921814, precision: 0.3214285714285523, recall: 0.9060402684562238, f1: 0.47451669591912093\n",
            "epoch: 781, step: 15, Train: label_loss: 0.090232253074646, precision: 0.3248369887373844, recall: 0.9057851239667923, f1: 0.4781849912350976\n",
            "epoch: 781, step: 16, Train: label_loss: 0.07939797639846802, precision: 0.3201650943396038, recall: 0.9156829679593733, f1: 0.4744429881660245\n",
            "epoch: 781, step: 17, Train: label_loss: 0.09432993829250336, precision: 0.3177737881507889, recall: 0.8820598006643052, f1: 0.4672239330890428\n",
            "epoch: 781, step: 18, Train: label_loss: 0.09180758148431778, precision: 0.3131009615384427, recall: 0.9045138888887317, f1: 0.46517857139032576\n",
            "epoch: 781, step: 19, Train: label_loss: 0.08010980486869812, precision: 0.3230220107078927, recall: 0.9004975124376615, f1: 0.4754816111695029\n",
            "epoch: 781, step: 20, Train: label_loss: 0.08181416243314743, precision: 0.3233532934131543, recall: 0.8940397350991897, f1: 0.47493403690025976\n",
            "epoch: 781, step: 21, Train: label_loss: 0.0907706767320633, precision: 0.3315315315315116, recall: 0.8803827751194767, f1: 0.48167539263037\n",
            "epoch: 781, step: 22, Train: label_loss: 0.09089680761098862, precision: 0.303337306317026, recall: 0.8992932862189223, f1: 0.4536541889105443\n",
            "epoch: 781, step: 23, Train: label_loss: 0.09021005034446716, precision: 0.32286340394446145, recall: 0.9094650205759446, f1: 0.4765498651903885\n",
            "epoch: 782, step: 0, Train: label_loss: 0.08321309089660645, precision: 0.32430841671569605, recall: 0.9183333333331802, f1: 0.4793388429365908\n",
            "epoch: 782, step: 1, Train: label_loss: 0.09172232449054718, precision: 0.3198813056379632, recall: 0.8998330550916694, f1: 0.4719789841994414\n",
            "epoch: 782, step: 2, Train: label_loss: 0.08413594216108322, precision: 0.3246290801186751, recall: 0.9071310116084731, f1: 0.4781468531079932\n",
            "epoch: 782, step: 3, Train: label_loss: 0.07879991084337234, precision: 0.338305489260123, recall: 0.9249592169655912, f1: 0.495412843997437\n",
            "epoch: 782, step: 4, Train: label_loss: 0.08328549563884735, precision: 0.32290436835889474, recall: 0.92242833052261, f1: 0.4783559247538506\n",
            "epoch: 782, step: 5, Train: label_loss: 0.08466746658086777, precision: 0.30496453900707415, recall: 0.9020979020977443, f1: 0.4558303886547756\n",
            "epoch: 782, step: 6, Train: label_loss: 0.09266917407512665, precision: 0.29771908763503613, recall: 0.8611111111109615, f1: 0.44246208738372333\n",
            "epoch: 782, step: 7, Train: label_loss: 0.1085553914308548, precision: 0.33232077764275014, recall: 0.8780096308184786, f1: 0.48215072715271706\n",
            "epoch: 782, step: 8, Train: label_loss: 0.08334216475486755, precision: 0.34415584415582384, recall: 0.9181102362203278, f1: 0.5006440532020294\n",
            "epoch: 782, step: 9, Train: label_loss: 0.09277214854955673, precision: 0.32337118947995674, recall: 0.8883415435138113, f1: 0.4741454863762533\n",
            "epoch: 782, step: 10, Train: label_loss: 0.07617302238941193, precision: 0.31995277449821014, recall: 0.9093959731542097, f1: 0.4733624453763007\n",
            "epoch: 782, step: 11, Train: label_loss: 0.08879289031028748, precision: 0.3261520047875328, recall: 0.9008264462808427, f1: 0.4789103690294675\n",
            "epoch: 782, step: 12, Train: label_loss: 0.11133474111557007, precision: 0.30006013229102224, recall: 0.87697715289967, f1: 0.44713261644942714\n",
            "epoch: 782, step: 13, Train: label_loss: 0.07360710203647614, precision: 0.3274853801169399, recall: 0.9165302782322559, f1: 0.48255062469188814\n",
            "epoch: 782, step: 14, Train: label_loss: 0.08119098842144012, precision: 0.33451746595616727, recall: 0.9083601286172173, f1: 0.4889658156248308\n",
            "epoch: 782, step: 15, Train: label_loss: 0.08550697565078735, precision: 0.32438878950504924, recall: 0.908180300500683, f1: 0.47803163440757185\n",
            "epoch: 782, step: 16, Train: label_loss: 0.07635432481765747, precision: 0.32816229116943146, recall: 0.889967637540309, f1: 0.4795117697949441\n",
            "epoch: 782, step: 17, Train: label_loss: 0.09051133692264557, precision: 0.31771771771769863, recall: 0.8981324278436505, f1: 0.4693877550633934\n",
            "epoch: 782, step: 18, Train: label_loss: 0.08541329950094223, precision: 0.330351818723892, recall: 0.9052287581697867, f1: 0.48405417208834794\n",
            "epoch: 782, step: 19, Train: label_loss: 0.06800791621208191, precision: 0.3278399058269377, recall: 0.9027552674228682, f1: 0.4810017270765882\n",
            "epoch: 782, step: 20, Train: label_loss: 0.08217455446720123, precision: 0.32491186839011016, recall: 0.924749163879444, f1: 0.4808695651788695\n",
            "epoch: 782, step: 21, Train: label_loss: 0.09899930655956268, precision: 0.32548309178741996, recall: 0.8879736408565259, f1: 0.47635881569203165\n",
            "epoch: 782, step: 22, Train: label_loss: 0.09230294823646545, precision: 0.30220107079117775, recall: 0.9153153153151503, f1: 0.45438282643848865\n",
            "epoch: 782, step: 23, Train: label_loss: 0.08035290241241455, precision: 0.3218475073313547, recall: 0.8815261044174937, f1: 0.47153598277494313\n",
            "epoch: 783, step: 0, Train: label_loss: 0.07558076083660126, precision: 0.33727111636146856, recall: 0.9209677419353353, f1: 0.49373108513149133\n",
            "epoch: 783, step: 1, Train: label_loss: 0.07578868418931961, precision: 0.3331371394938003, recall: 0.92635024549903, f1: 0.4900432900043395\n",
            "epoch: 783, step: 2, Train: label_loss: 0.08031444251537323, precision: 0.33588685916320943, recall: 0.9178743961351178, f1: 0.49180327864925594\n",
            "epoch: 783, step: 3, Train: label_loss: 0.08568444848060608, precision: 0.34070531978479734, recall: 0.8962264150941986, f1: 0.49372022516575903\n",
            "epoch: 783, step: 4, Train: label_loss: 0.08171958476305008, precision: 0.34096244131453396, recall: 0.926634768739884, f1: 0.49849849845912947\n",
            "epoch: 783, step: 5, Train: label_loss: 0.08765298128128052, precision: 0.34005934718098874, recall: 0.9182692307690835, f1: 0.49631875266731373\n",
            "epoch: 783, step: 6, Train: label_loss: 0.08742454648017883, precision: 0.29453262786594386, recall: 0.9109090909089252, f1: 0.4451354952984397\n",
            "epoch: 783, step: 7, Train: label_loss: 0.09688293188810349, precision: 0.31268612269206, recall: 0.894378194207684, f1: 0.4633715798380049\n",
            "epoch: 783, step: 8, Train: label_loss: 0.07867750525474548, precision: 0.31566548881034656, recall: 0.9069373942468854, f1: 0.4683267802150391\n",
            "epoch: 783, step: 9, Train: label_loss: 0.08043532818555832, precision: 0.32035928143710657, recall: 0.8946488294312884, f1: 0.4717813050757674\n",
            "epoch: 783, step: 10, Train: label_loss: 0.100796177983284, precision: 0.3135846798324169, recall: 0.8926746166949074, f1: 0.4641275464628109\n",
            "epoch: 783, step: 11, Train: label_loss: 0.087176114320755, precision: 0.31525625744932567, recall: 0.8875838926173006, f1: 0.465259454666644\n",
            "epoch: 783, step: 12, Train: label_loss: 0.07967844605445862, precision: 0.3114268798105203, recall: 0.8870151770656176, f1: 0.46099912353730366\n",
            "epoch: 783, step: 13, Train: label_loss: 0.08704854547977448, precision: 0.32213557288540356, recall: 0.8717532467531052, f1: 0.4704336399079929\n",
            "epoch: 783, step: 14, Train: label_loss: 0.07139883935451508, precision: 0.33255813953486435, recall: 0.9331158238171398, f1: 0.49035576507051665\n",
            "epoch: 783, step: 15, Train: label_loss: 0.08696777373552322, precision: 0.3350970017636487, recall: 0.9163987138262192, f1: 0.49074472660732277\n",
            "epoch: 783, step: 16, Train: label_loss: 0.08585767447948456, precision: 0.34173505275496235, recall: 0.9224683544302337, f1: 0.49871685197077337\n",
            "epoch: 783, step: 17, Train: label_loss: 0.08633057773113251, precision: 0.3136444181925391, recall: 0.90924657534231, f1: 0.4664031620171556\n",
            "epoch: 783, step: 18, Train: label_loss: 0.07984770089387894, precision: 0.2982352941176295, recall: 0.9086021505374715, f1: 0.449069973390562\n",
            "epoch: 783, step: 19, Train: label_loss: 0.08259604126214981, precision: 0.3016157989227827, recall: 0.8704663212433729, f1: 0.4479999999617376\n",
            "epoch: 783, step: 20, Train: label_loss: 0.0917314738035202, precision: 0.30089552238804174, recall: 0.8888888888887321, f1: 0.44959857266511544\n",
            "epoch: 783, step: 21, Train: label_loss: 0.08039316534996033, precision: 0.31052944675786376, recall: 0.8877551020406653, f1: 0.4601145878857574\n",
            "epoch: 783, step: 22, Train: label_loss: 0.08540740609169006, precision: 0.3281715306730001, recall: 0.903278688524442, f1: 0.4814329401093996\n",
            "epoch: 783, step: 23, Train: label_loss: 0.0849745124578476, precision: 0.33235077376563504, recall: 0.8860510805499242, f1: 0.4833869238616677\n",
            "epoch: 784, step: 0, Train: label_loss: 0.0908527821302414, precision: 0.3432480666269873, recall: 0.9001560062401092, f1: 0.4969853574104611\n",
            "epoch: 784, step: 1, Train: label_loss: 0.08546854555606842, precision: 0.315444245676785, recall: 0.9104991394146453, f1: 0.46855624442586596\n",
            "epoch: 784, step: 2, Train: label_loss: 0.0793694257736206, precision: 0.32411764705880447, recall: 0.916805324459082, f1: 0.47892220769713145\n",
            "epoch: 784, step: 3, Train: label_loss: 0.06536423414945602, precision: 0.3358823529411567, recall: 0.9239482200645753, f1: 0.4926660914190053\n",
            "epoch: 784, step: 4, Train: label_loss: 0.06653905659914017, precision: 0.32342657342655456, recall: 0.9280936454847946, f1: 0.4796888504369973\n",
            "epoch: 784, step: 5, Train: label_loss: 0.09398510307073593, precision: 0.30938242280283196, recall: 0.9076655052263226, f1: 0.46147032768569113\n",
            "epoch: 784, step: 6, Train: label_loss: 0.0873001217842102, precision: 0.32670283303192726, recall: 0.8741935483869557, f1: 0.4756472136505656\n",
            "epoch: 784, step: 7, Train: label_loss: 0.08603896200656891, precision: 0.3248969982342363, recall: 0.9093904448103938, f1: 0.4787510840895316\n",
            "epoch: 784, step: 8, Train: label_loss: 0.08434009552001953, precision: 0.3301492537313236, recall: 0.9050736497543527, f1: 0.4838145231453914\n",
            "epoch: 784, step: 9, Train: label_loss: 0.09615956246852875, precision: 0.3145065398335128, recall: 0.9089347079036239, f1: 0.4673144875942708\n",
            "epoch: 784, step: 10, Train: label_loss: 0.07976667582988739, precision: 0.3402366863905124, recall: 0.9141494435610629, f1: 0.4959034066012171\n",
            "epoch: 784, step: 11, Train: label_loss: 0.07248605787754059, precision: 0.3207324276432179, recall: 0.9034941763725618, f1: 0.4734088927250202\n",
            "epoch: 784, step: 12, Train: label_loss: 0.07587026059627533, precision: 0.3104265402843418, recall: 0.9018932874353008, f1: 0.46187747902752835\n",
            "epoch: 784, step: 13, Train: label_loss: 0.07923658937215805, precision: 0.3093955715140449, recall: 0.8777589134124145, f1: 0.4575221238552254\n",
            "epoch: 784, step: 14, Train: label_loss: 0.08647165447473526, precision: 0.3137951450562277, recall: 0.8983050847456104, f1: 0.46511627903135383\n",
            "epoch: 784, step: 15, Train: label_loss: 0.08285034447908401, precision: 0.33511586452760933, recall: 0.91856677524415, f1: 0.491075315589868\n",
            "epoch: 784, step: 16, Train: label_loss: 0.09029646217823029, precision: 0.32321428571426647, recall: 0.9034941763725618, f1: 0.47610697058806456\n",
            "epoch: 784, step: 17, Train: label_loss: 0.08299323916435242, precision: 0.3302217036172503, recall: 0.943333333333176, f1: 0.4891961970229115\n",
            "epoch: 784, step: 18, Train: label_loss: 0.09701329469680786, precision: 0.3317479191438566, recall: 0.9117647058822039, f1: 0.48648648644732206\n",
            "epoch: 784, step: 19, Train: label_loss: 0.09439773112535477, precision: 0.31398104265400983, recall: 0.9122203098105142, f1: 0.46716615245194393\n",
            "epoch: 784, step: 20, Train: label_loss: 0.08092229068279266, precision: 0.30983412322273046, recall: 0.9001721170394319, f1: 0.4609960334567924\n",
            "epoch: 784, step: 21, Train: label_loss: 0.0825943797826767, precision: 0.3233890214796943, recall: 0.8988391376449587, f1: 0.47564721365125684\n",
            "epoch: 784, step: 22, Train: label_loss: 0.09192381799221039, precision: 0.3285457809694597, recall: 0.8912337662336215, f1: 0.480104940931302\n",
            "epoch: 784, step: 23, Train: label_loss: 0.09213827550411224, precision: 0.3186490455212688, recall: 0.8893442622948997, f1: 0.469189189150298\n",
            "epoch: 785, step: 0, Train: label_loss: 0.08451949059963226, precision: 0.3079646017698933, recall: 0.9173989455182922, f1: 0.46113074201179705\n",
            "epoch: 785, step: 1, Train: label_loss: 0.08274716138839722, precision: 0.3271752085816253, recall: 0.9059405940592564, f1: 0.48073555162472026\n",
            "epoch: 785, step: 2, Train: label_loss: 0.091794453561306, precision: 0.33175355450235, recall: 0.9076175040517167, f1: 0.4859002168804922\n",
            "epoch: 785, step: 3, Train: label_loss: 0.07516437768936157, precision: 0.3266152934202533, recall: 0.916805324459082, f1: 0.48164335660457924\n",
            "epoch: 785, step: 4, Train: label_loss: 0.08726352453231812, precision: 0.3104886769964058, recall: 0.8967297762476941, f1: 0.46126604688516765\n",
            "epoch: 785, step: 5, Train: label_loss: 0.07707616686820984, precision: 0.31316725978645826, recall: 0.9025641025639483, f1: 0.46499339494189595\n",
            "epoch: 785, step: 6, Train: label_loss: 0.09096755087375641, precision: 0.3261390887289972, recall: 0.8816855753645247, f1: 0.47614879645944225\n",
            "epoch: 785, step: 7, Train: label_loss: 0.09147521108388901, precision: 0.3494047619047411, recall: 0.9072642967541101, f1: 0.5045122474888172\n",
            "epoch: 785, step: 8, Train: label_loss: 0.06786956638097763, precision: 0.31634446397186194, recall: 0.9278350515462322, f1: 0.47182175618746236\n",
            "epoch: 785, step: 9, Train: label_loss: 0.0874171182513237, precision: 0.3245666467423596, recall: 0.8887070376430624, f1: 0.4754816111691747\n",
            "epoch: 785, step: 10, Train: label_loss: 0.08939231932163239, precision: 0.3225998807393964, recall: 0.9061976549412216, f1: 0.47581354437636375\n",
            "epoch: 785, step: 11, Train: label_loss: 0.08537250757217407, precision: 0.3270365997638532, recall: 0.9052287581697867, f1: 0.48048568946660375\n",
            "epoch: 785, step: 12, Train: label_loss: 0.09190938621759415, precision: 0.2942925089179373, recall: 0.8792184724687603, f1: 0.440979955418953\n",
            "epoch: 785, step: 13, Train: label_loss: 0.08409513533115387, precision: 0.3126879134094821, recall: 0.8996539792385986, f1: 0.46407853632937207\n",
            "epoch: 785, step: 14, Train: label_loss: 0.07891469448804855, precision: 0.33076467101361406, recall: 0.9073170731705841, f1: 0.48479582967409374\n",
            "epoch: 785, step: 15, Train: label_loss: 0.09891675412654877, precision: 0.31884057971012564, recall: 0.8756218905471184, f1: 0.46746347937649335\n",
            "epoch: 785, step: 16, Train: label_loss: 0.0926605761051178, precision: 0.312949640287751, recall: 0.8862478777587629, f1: 0.4625609215387015\n",
            "epoch: 785, step: 17, Train: label_loss: 0.08411838859319687, precision: 0.33076467101361406, recall: 0.9162561576353174, f1: 0.48606271773101456\n",
            "epoch: 785, step: 18, Train: label_loss: 0.0956391841173172, precision: 0.3323335332933214, recall: 0.884984025558964, f1: 0.4832097688220164\n",
            "epoch: 785, step: 19, Train: label_loss: 0.09392738342285156, precision: 0.31918708906154697, recall: 0.8885191347752265, f1: 0.46965699204550304\n",
            "epoch: 785, step: 20, Train: label_loss: 0.08141844719648361, precision: 0.31093935790723476, recall: 0.9001721170394319, f1: 0.46221829426139655\n",
            "epoch: 785, step: 21, Train: label_loss: 0.09157411754131317, precision: 0.3267267267267071, recall: 0.9021558872303644, f1: 0.47971781301206723\n",
            "epoch: 785, step: 22, Train: label_loss: 0.0782516747713089, precision: 0.328605200945607, recall: 0.9144736842103759, f1: 0.48347826083062956\n",
            "epoch: 785, step: 23, Train: label_loss: 0.0866069346666336, precision: 0.33357558139532456, recall: 0.8861003861002149, f1: 0.4846884899285306\n",
            "epoch: 786, step: 0, Train: label_loss: 0.07389703392982483, precision: 0.31726190476188587, recall: 0.9158075601372996, f1: 0.4712643677778315\n",
            "epoch: 786, step: 1, Train: label_loss: 0.0898657888174057, precision: 0.3341204250294962, recall: 0.9055999999998551, f1: 0.4881414402365638\n",
            "epoch: 786, step: 2, Train: label_loss: 0.08870452642440796, precision: 0.31339712918658413, recall: 0.9003436426115291, f1: 0.464951197832104\n",
            "epoch: 786, step: 3, Train: label_loss: 0.08684230595827103, precision: 0.2931343283581914, recall: 0.8878842676309424, f1: 0.4407540394599475\n",
            "epoch: 786, step: 4, Train: label_loss: 0.08954364061355591, precision: 0.32569077013519543, recall: 0.9248747913187103, f1: 0.481739130396219\n",
            "epoch: 786, step: 5, Train: label_loss: 0.08922276645898819, precision: 0.3169856459329954, recall: 0.9122203098105142, f1: 0.47048379934028906\n",
            "epoch: 786, step: 6, Train: label_loss: 0.09379668533802032, precision: 0.29887106357692816, recall: 0.8982142857141252, f1: 0.4485064645188911\n",
            "epoch: 786, step: 7, Train: label_loss: 0.08709083497524261, precision: 0.3484757919904155, recall: 0.9066874027992369, f1: 0.5034542313933519\n",
            "epoch: 786, step: 8, Train: label_loss: 0.08487465977668762, precision: 0.32803297997642356, recall: 0.9071661237783538, f1: 0.4818339099955518\n",
            "epoch: 786, step: 9, Train: label_loss: 0.09421706199645996, precision: 0.3222156045264847, recall: 0.9001663893509317, f1: 0.47456140346990766\n",
            "epoch: 786, step: 10, Train: label_loss: 0.08889724314212799, precision: 0.31249999999998124, recall: 0.8768971332207627, f1: 0.4607886574711868\n",
            "epoch: 786, step: 11, Train: label_loss: 0.08195583522319794, precision: 0.3140643623360957, recall: 0.9054982817867859, f1: 0.466371681377647\n",
            "epoch: 786, step: 12, Train: label_loss: 0.09443064033985138, precision: 0.32517899761334573, recall: 0.9038142620230672, f1: 0.4782799473063684\n",
            "epoch: 786, step: 13, Train: label_loss: 0.07452602684497833, precision: 0.35136741973838576, recall: 0.892749244712856, f1: 0.5042662115635204\n",
            "epoch: 786, step: 14, Train: label_loss: 0.08684390783309937, precision: 0.32992788461536476, recall: 0.8897893030792723, f1: 0.4813678210915751\n",
            "epoch: 786, step: 15, Train: label_loss: 0.07872042059898376, precision: 0.31283264340625, recall: 0.913644214162191, f1: 0.4660792951161425\n",
            "epoch: 786, step: 16, Train: label_loss: 0.0786924809217453, precision: 0.31100478468897663, recall: 0.8828522920202235, f1: 0.4599734630308692\n",
            "epoch: 786, step: 17, Train: label_loss: 0.10099471360445023, precision: 0.31096464949069436, recall: 0.863560732113001, f1: 0.45726872242798783\n",
            "epoch: 786, step: 18, Train: label_loss: 0.08891871571540833, precision: 0.33532219570403726, recall: 0.9138211382112335, f1: 0.49061545172846804\n",
            "epoch: 786, step: 19, Train: label_loss: 0.08097384870052338, precision: 0.31883194278901555, recall: 0.8887043189367294, f1: 0.4692982455751298\n",
            "epoch: 786, step: 20, Train: label_loss: 0.08690295368432999, precision: 0.32562277580069243, recall: 0.888349514562963, f1: 0.47656249996070216\n",
            "epoch: 786, step: 21, Train: label_loss: 0.09315904229879379, precision: 0.3174123337363774, recall: 0.864909390444668, f1: 0.4643962847904019\n",
            "epoch: 786, step: 22, Train: label_loss: 0.08324813842773438, precision: 0.31528279181706886, recall: 0.8718801996670762, f1: 0.4631020768500352\n",
            "epoch: 786, step: 23, Train: label_loss: 0.08490055799484253, precision: 0.33479853479851024, recall: 0.8960784313723733, f1: 0.4874666666270114\n",
            "epoch: 787, step: 0, Train: label_loss: 0.07835841178894043, precision: 0.32125890736340135, recall: 0.8898026315788009, f1: 0.47207678879169385\n",
            "epoch: 787, step: 1, Train: label_loss: 0.08173028379678726, precision: 0.3354952830188481, recall: 0.9133226324236093, f1: 0.49072876235824736\n",
            "epoch: 787, step: 2, Train: label_loss: 0.08561433106660843, precision: 0.3100961538461352, recall: 0.8911917098444055, f1: 0.4600980828863131\n",
            "epoch: 787, step: 3, Train: label_loss: 0.074382483959198, precision: 0.32014176018899465, recall: 0.9155405405403858, f1: 0.47439824941452086\n",
            "epoch: 787, step: 4, Train: label_loss: 0.07920683920383453, precision: 0.32606132075469774, recall: 0.924749163879444, f1: 0.4821272885403142\n",
            "epoch: 787, step: 5, Train: label_loss: 0.08699780702590942, precision: 0.33709869203327364, recall: 0.9159935379643107, f1: 0.49282920465423957\n",
            "epoch: 787, step: 6, Train: label_loss: 0.08552294224500656, precision: 0.3111243307554842, recall: 0.9127399650958267, f1: 0.4640638863861758\n",
            "epoch: 787, step: 7, Train: label_loss: 0.08627163618803024, precision: 0.30805970149251893, recall: 0.9100529100527495, f1: 0.46030330058661323\n",
            "epoch: 787, step: 8, Train: label_loss: 0.07783753424882889, precision: 0.3299522673030829, recall: 0.908045977011345, f1: 0.4840262581665494\n",
            "epoch: 787, step: 9, Train: label_loss: 0.07645374536514282, precision: 0.3530106257378776, recall: 0.92141756548522, f1: 0.5104566794306665\n",
            "epoch: 787, step: 10, Train: label_loss: 0.07793767750263214, precision: 0.31569560047560546, recall: 0.898477157360254, f1: 0.4672239330895027\n",
            "epoch: 787, step: 11, Train: label_loss: 0.09029819071292877, precision: 0.312611012433374, recall: 0.9056603773583352, f1: 0.46478873235617374\n",
            "epoch: 787, step: 12, Train: label_loss: 0.08413691073656082, precision: 0.3238602723504841, recall: 0.8981937602625782, f1: 0.4760661444344575\n",
            "epoch: 787, step: 13, Train: label_loss: 0.08487764745950699, precision: 0.3321470937129103, recall: 0.9195402298849064, f1: 0.4880174291548685\n",
            "epoch: 787, step: 14, Train: label_loss: 0.09011662751436234, precision: 0.3323406789755609, recall: 0.9087947882734676, f1: 0.4866986480200546\n",
            "epoch: 787, step: 15, Train: label_loss: 0.09117589890956879, precision: 0.32219570405726, recall: 0.8925619834709267, f1: 0.473476545335817\n",
            "epoch: 787, step: 16, Train: label_loss: 0.08220501244068146, precision: 0.3307873090481592, recall: 0.9095315024231163, f1: 0.48513571732404986\n",
            "epoch: 787, step: 17, Train: label_loss: 0.10434406995773315, precision: 0.298372513562369, recall: 0.8745583038867712, f1: 0.4449438201867447\n",
            "epoch: 787, step: 18, Train: label_loss: 0.0833524540066719, precision: 0.30805687203789645, recall: 0.9059233449475773, f1: 0.4597701149046151\n",
            "epoch: 787, step: 19, Train: label_loss: 0.07757869362831116, precision: 0.32023809523807617, recall: 0.910321489001538, f1: 0.4738000880283863\n",
            "epoch: 787, step: 20, Train: label_loss: 0.07426606118679047, precision: 0.34710743801650845, recall: 0.910216718266113, f1: 0.5025641025240887\n",
            "epoch: 787, step: 21, Train: label_loss: 0.08407904952764511, precision: 0.3242603550295666, recall: 0.9102990033221079, f1: 0.47818499123522157\n",
            "epoch: 787, step: 22, Train: label_loss: 0.08995649963617325, precision: 0.303933253873641, recall: 0.8688245315160359, f1: 0.4503311257893755\n",
            "epoch: 787, step: 23, Train: label_loss: 0.0914887860417366, precision: 0.3220836390315244, recall: 0.8675889328061527, f1: 0.46976993040455023\n",
            "epoch: 788, step: 0, Train: label_loss: 0.07699625194072723, precision: 0.32581602373885304, recall: 0.8999999999998524, f1: 0.4784313725099482\n",
            "epoch: 788, step: 1, Train: label_loss: 0.08698698878288269, precision: 0.320597014925354, recall: 0.8890728476819719, f1: 0.47125932422602945\n",
            "epoch: 788, step: 2, Train: label_loss: 0.08368802070617676, precision: 0.34790313053748684, recall: 0.9188767550700594, f1: 0.5047129391203544\n",
            "epoch: 788, step: 3, Train: label_loss: 0.08537231385707855, precision: 0.32653061224487834, recall: 0.8962108731464751, f1: 0.47866256045355204\n",
            "epoch: 788, step: 4, Train: label_loss: 0.08436568826436996, precision: 0.30976632714198266, recall: 0.9022687609073469, f1: 0.46119536124647487\n",
            "epoch: 788, step: 5, Train: label_loss: 0.07369790226221085, precision: 0.30922986478540215, recall: 0.9131944444442859, f1: 0.4620114184953224\n",
            "epoch: 788, step: 6, Train: label_loss: 0.08597496151924133, precision: 0.33235294117645103, recall: 0.9054487179485727, f1: 0.4862306367937228\n",
            "epoch: 788, step: 7, Train: label_loss: 0.08394988626241684, precision: 0.33432304038002764, recall: 0.9080645161288857, f1: 0.4887152777383985\n",
            "epoch: 788, step: 8, Train: label_loss: 0.08596864342689514, precision: 0.3200948429164007, recall: 0.903010033444665, f1: 0.4726477023683176\n",
            "epoch: 788, step: 9, Train: label_loss: 0.09401769191026688, precision: 0.30805687203789645, recall: 0.8919382504286634, f1: 0.45794804047258536\n",
            "epoch: 788, step: 10, Train: label_loss: 0.0807361900806427, precision: 0.3258426966291942, recall: 0.9137645107792846, f1: 0.4803836093770727\n",
            "epoch: 788, step: 11, Train: label_loss: 0.08843043446540833, precision: 0.33850746268654697, recall: 0.8943217665613731, f1: 0.49112169766475455\n",
            "epoch: 788, step: 12, Train: label_loss: 0.08819013833999634, precision: 0.3223487118034558, recall: 0.8733766233764816, f1: 0.47089715532162735\n",
            "epoch: 788, step: 13, Train: label_loss: 0.08479861915111542, precision: 0.32841110454812, recall: 0.9114754098359161, f1: 0.4828484584933643\n",
            "epoch: 788, step: 14, Train: label_loss: 0.0969303548336029, precision: 0.31144578313251137, recall: 0.8792517006801225, f1: 0.45996441277271716\n",
            "epoch: 788, step: 15, Train: label_loss: 0.0918019711971283, precision: 0.3103448275861884, recall: 0.9157894736840498, f1: 0.46358792180939684\n",
            "epoch: 788, step: 16, Train: label_loss: 0.08103322237730026, precision: 0.32875894988064863, recall: 0.9047619047617561, f1: 0.48227571112059764\n",
            "epoch: 788, step: 17, Train: label_loss: 0.09962660074234009, precision: 0.3108591885441342, recall: 0.9108391608390015, f1: 0.4635231316346158\n",
            "epoch: 788, step: 18, Train: label_loss: 0.08362975716590881, precision: 0.307236061684442, recall: 0.8885077186962455, f1: 0.4565888056030269\n",
            "epoch: 788, step: 19, Train: label_loss: 0.08921680599451065, precision: 0.3289315726290319, recall: 0.8910569105689607, f1: 0.48049101267429506\n",
            "epoch: 788, step: 20, Train: label_loss: 0.08470454812049866, precision: 0.310262529832917, recall: 0.8843537414964482, f1: 0.4593639575586797\n",
            "epoch: 788, step: 21, Train: label_loss: 0.10127568244934082, precision: 0.3240460327074304, recall: 0.8813838550245664, f1: 0.4738706819801329\n",
            "epoch: 788, step: 22, Train: label_loss: 0.07656742632389069, precision: 0.3128724672228657, recall: 0.883838383838235, f1: 0.4621478872852847\n",
            "epoch: 788, step: 23, Train: label_loss: 0.07891662418842316, precision: 0.3270485859318109, recall: 0.9129554655868597, f1: 0.48158035233697916\n",
            "epoch: 789, step: 0, Train: label_loss: 0.09143464267253876, precision: 0.33984606275900886, recall: 0.9198717948716474, f1: 0.4963251188537696\n",
            "epoch: 789, step: 1, Train: label_loss: 0.0903809666633606, precision: 0.30222757375073434, recall: 0.8869257950528467, f1: 0.45083071392702284\n",
            "epoch: 789, step: 2, Train: label_loss: 0.07824444770812988, precision: 0.32560903149136505, recall: 0.8968903436987075, f1: 0.47776809063219355\n",
            "epoch: 789, step: 3, Train: label_loss: 0.07644691318273544, precision: 0.3351063829787036, recall: 0.8971518987340352, f1: 0.48795180718927555\n",
            "epoch: 789, step: 4, Train: label_loss: 0.0817587673664093, precision: 0.3198118753674121, recall: 0.9158249158247616, f1: 0.474074074035666\n",
            "epoch: 789, step: 5, Train: label_loss: 0.0897461324930191, precision: 0.34029850746266627, recall: 0.9033280507130105, f1: 0.4943625324840563\n",
            "epoch: 789, step: 6, Train: label_loss: 0.08178158104419708, precision: 0.3211117681844872, recall: 0.9049999999998491, f1: 0.4740288083419173\n",
            "epoch: 789, step: 7, Train: label_loss: 0.08931168913841248, precision: 0.2998812351543765, recall: 0.8875219683653975, f1: 0.4482911672946518\n",
            "epoch: 789, step: 8, Train: label_loss: 0.0924491211771965, precision: 0.3273488928784963, recall: 0.8937908496730566, f1: 0.4791940428866911\n",
            "epoch: 789, step: 9, Train: label_loss: 0.07813306897878647, precision: 0.3240356083085861, recall: 0.8936170212764494, f1: 0.4756097560584599\n",
            "epoch: 789, step: 10, Train: label_loss: 0.07086508721113205, precision: 0.31492361927142687, recall: 0.917808219177925, f1: 0.46894138228912724\n",
            "epoch: 789, step: 11, Train: label_loss: 0.08244669437408447, precision: 0.3231046931407748, recall: 0.8774509803920134, f1: 0.47229551447249196\n",
            "epoch: 789, step: 12, Train: label_loss: 0.08833280205726624, precision: 0.2983091787439433, recall: 0.8821428571426996, f1: 0.445848375413454\n",
            "epoch: 789, step: 13, Train: label_loss: 0.07838146388530731, precision: 0.32225519287831916, recall: 0.9172297297295747, f1: 0.47694334647004283\n",
            "epoch: 789, step: 14, Train: label_loss: 0.09921833872795105, precision: 0.31890243902437077, recall: 0.8804713804712322, f1: 0.4682184422169624\n",
            "epoch: 789, step: 15, Train: label_loss: 0.08106333017349243, precision: 0.3223289315726097, recall: 0.897993311036639, f1: 0.4743816254027807\n",
            "epoch: 789, step: 16, Train: label_loss: 0.09081586450338364, precision: 0.3050239234449578, recall: 0.8793103448274345, f1: 0.45293072820327934\n",
            "epoch: 789, step: 17, Train: label_loss: 0.09044352173805237, precision: 0.3311298076922878, recall: 0.8973941368076713, f1: 0.4837576821379289\n",
            "epoch: 789, step: 18, Train: label_loss: 0.084034264087677, precision: 0.34452296819785955, recall: 0.9315286624202338, f1: 0.5030094582580439\n",
            "epoch: 789, step: 19, Train: label_loss: 0.09701315313577652, precision: 0.31661631419937664, recall: 0.870431893687563, f1: 0.46433318560550335\n",
            "epoch: 789, step: 20, Train: label_loss: 0.09039781987667084, precision: 0.317383403997558, recall: 0.859016393442482, f1: 0.46351172043822286\n",
            "epoch: 789, step: 21, Train: label_loss: 0.08893807232379913, precision: 0.3143028846153657, recall: 0.8864406779659514, f1: 0.46406388638544555\n",
            "epoch: 789, step: 22, Train: label_loss: 0.0888986736536026, precision: 0.32622853759619147, recall: 0.9137645107792846, f1: 0.48080279228230033\n",
            "epoch: 789, step: 23, Train: label_loss: 0.08360322564840317, precision: 0.334051724137907, recall: 0.926294820716947, f1: 0.49102428718379754\n",
            "epoch: 790, step: 0, Train: label_loss: 0.08322207629680634, precision: 0.3268551236748924, recall: 0.9173553719006747, f1: 0.4819800260141947\n",
            "epoch: 790, step: 1, Train: label_loss: 0.08244568109512329, precision: 0.3289786223277714, recall: 0.8993506493505032, f1: 0.48173913039552163\n",
            "epoch: 790, step: 2, Train: label_loss: 0.09465819597244263, precision: 0.3243566726510877, recall: 0.9018302828617467, f1: 0.4771126760173857\n",
            "epoch: 790, step: 3, Train: label_loss: 0.08042211830615997, precision: 0.33586892919834194, recall: 0.9303079416530096, f1: 0.49355116075203553\n",
            "epoch: 790, step: 4, Train: label_loss: 0.08724553883075714, precision: 0.3122388059701306, recall: 0.8909710391821309, f1: 0.4624226347979546\n",
            "epoch: 790, step: 5, Train: label_loss: 0.07204197347164154, precision: 0.3107710417892695, recall: 0.9087779690187764, f1: 0.4631578946988237\n",
            "epoch: 790, step: 6, Train: label_loss: 0.08714443445205688, precision: 0.3105700712588889, recall: 0.9111498257838133, f1: 0.4632418068708107\n",
            "epoch: 790, step: 7, Train: label_loss: 0.07085831463336945, precision: 0.3184750733137643, recall: 0.9329896907214891, f1: 0.4748578923975193\n",
            "epoch: 790, step: 8, Train: label_loss: 0.10070064663887024, precision: 0.32236842105261226, recall: 0.8998330550916694, f1: 0.4746807573367255\n",
            "epoch: 790, step: 9, Train: label_loss: 0.07736814022064209, precision: 0.3106508875739461, recall: 0.8974358974357439, f1: 0.4615384615002168\n",
            "epoch: 790, step: 10, Train: label_loss: 0.09481025487184525, precision: 0.3211284513805329, recall: 0.8813838550245664, f1: 0.4707435107395185\n",
            "epoch: 790, step: 11, Train: label_loss: 0.08737435191869736, precision: 0.33974744437761034, recall: 0.8841940532079993, f1: 0.4908774977878267\n",
            "epoch: 790, step: 12, Train: label_loss: 0.08262210339307785, precision: 0.3303834808259392, recall: 0.9271523178806411, f1: 0.48716833401950393\n",
            "epoch: 790, step: 13, Train: label_loss: 0.08670340478420258, precision: 0.3046874999999817, recall: 0.8756476683936311, f1: 0.4520731163236744\n",
            "epoch: 790, step: 14, Train: label_loss: 0.07170407474040985, precision: 0.3395565927654411, recall: 0.9402261712437899, f1: 0.49892841830644974\n",
            "epoch: 790, step: 15, Train: label_loss: 0.08308043330907822, precision: 0.308656716417892, recall: 0.8944636678199144, f1: 0.45894363067641586\n",
            "epoch: 790, step: 16, Train: label_loss: 0.08715897798538208, precision: 0.3327359617682, recall: 0.8940609951844471, f1: 0.4849804091898552\n",
            "epoch: 790, step: 17, Train: label_loss: 0.09581625461578369, precision: 0.3458823529411561, recall: 0.9230769230767781, f1: 0.5032092425790436\n",
            "epoch: 790, step: 18, Train: label_loss: 0.08651729673147202, precision: 0.3447037701974659, recall: 0.9014084507040843, f1: 0.49870129866123497\n",
            "epoch: 790, step: 19, Train: label_loss: 0.08578958362340927, precision: 0.30548926014317984, recall: 0.9014084507040666, f1: 0.45632798570189975\n",
            "epoch: 790, step: 20, Train: label_loss: 0.08579608798027039, precision: 0.32875894988064863, recall: 0.9003267973854737, f1: 0.48164335660412744\n",
            "epoch: 790, step: 21, Train: label_loss: 0.08697681874036789, precision: 0.29366028708132214, recall: 0.8783542039354421, f1: 0.4401613625800648\n",
            "epoch: 790, step: 22, Train: label_loss: 0.08825045824050903, precision: 0.3311258278145496, recall: 0.889967637540309, f1: 0.4826678367309435\n",
            "epoch: 790, step: 23, Train: label_loss: 0.0902303084731102, precision: 0.3223021582733581, recall: 0.9142857142855277, f1: 0.4765957446422591\n",
            "epoch: 791, step: 0, Train: label_loss: 0.08551126718521118, precision: 0.3046874999999817, recall: 0.8651877133104325, f1: 0.45066666662810395\n",
            "epoch: 791, step: 1, Train: label_loss: 0.08300571143627167, precision: 0.3254716981131883, recall: 0.9049180327867369, f1: 0.4787510840894087\n",
            "epoch: 791, step: 2, Train: label_loss: 0.0951150432229042, precision: 0.32031249999998074, recall: 0.8868552412644114, f1: 0.4706401765614127\n",
            "epoch: 791, step: 3, Train: label_loss: 0.08282951265573502, precision: 0.33751493428910767, recall: 0.8897637795274189, f1: 0.4893893459973272\n",
            "epoch: 791, step: 4, Train: label_loss: 0.0724114403128624, precision: 0.3091988130563615, recall: 0.9076655052263226, f1: 0.46126604688547046\n",
            "epoch: 791, step: 5, Train: label_loss: 0.08807450532913208, precision: 0.3149466192170632, recall: 0.9123711340204618, f1: 0.4682539682157743\n",
            "epoch: 791, step: 6, Train: label_loss: 0.07296758145093918, precision: 0.3362936648904478, recall: 0.9102564102562644, f1: 0.4911370514088933\n",
            "epoch: 791, step: 7, Train: label_loss: 0.0928591638803482, precision: 0.3104066985645747, recall: 0.8917525773194344, f1: 0.4605146406005161\n",
            "epoch: 791, step: 8, Train: label_loss: 0.08752655982971191, precision: 0.3183431952662533, recall: 0.9149659863944022, f1: 0.47234416150687464\n",
            "epoch: 791, step: 9, Train: label_loss: 0.08672608435153961, precision: 0.3283223090799562, recall: 0.8907014681890879, f1: 0.4797891036512847\n",
            "epoch: 791, step: 10, Train: label_loss: 0.08651569485664368, precision: 0.33273703041142916, recall: 0.8843106180664209, f1: 0.4835355285564151\n",
            "epoch: 791, step: 11, Train: label_loss: 0.0802745372056961, precision: 0.32168246445495724, recall: 0.9034941763725618, f1: 0.47444298816569014\n",
            "epoch: 791, step: 12, Train: label_loss: 0.0821562111377716, precision: 0.3246290801186751, recall: 0.9162479061975014, f1: 0.47940403151259453\n",
            "epoch: 791, step: 13, Train: label_loss: 0.09734484553337097, precision: 0.30190930787587694, recall: 0.8924162257494016, f1: 0.4511814533727934\n",
            "epoch: 791, step: 14, Train: label_loss: 0.09869343042373657, precision: 0.33927510398096616, recall: 0.8949843260186684, f1: 0.49202929767659476\n",
            "epoch: 791, step: 15, Train: label_loss: 0.08066752552986145, precision: 0.32747510251902007, recall: 0.9030694668819219, f1: 0.48065348233407124\n",
            "epoch: 791, step: 16, Train: label_loss: 0.08723223209381104, precision: 0.3199052132701232, recall: 0.8999999999998499, f1: 0.472027971989237\n",
            "epoch: 791, step: 17, Train: label_loss: 0.07897091656923294, precision: 0.31796690307326725, recall: 0.8981636060098667, f1: 0.46966390218744153\n",
            "epoch: 791, step: 18, Train: label_loss: 0.06662887334823608, precision: 0.3206775700934392, recall: 0.9044481054364243, f1: 0.47347994821486933\n",
            "epoch: 791, step: 19, Train: label_loss: 0.08308063447475433, precision: 0.32057416267940664, recall: 0.8933333333331844, f1: 0.47183098587658256\n",
            "epoch: 791, step: 20, Train: label_loss: 0.07186999917030334, precision: 0.3333333333333135, recall: 0.9063004846525191, f1: 0.4874022588659391\n",
            "epoch: 791, step: 21, Train: label_loss: 0.09162221848964691, precision: 0.3020895522387879, recall: 0.8955752212387795, f1: 0.4517857142479517\n",
            "epoch: 791, step: 22, Train: label_loss: 0.08416521549224854, precision: 0.3303624480094872, recall: 0.902597402597256, f1: 0.4836885602043122\n",
            "epoch: 791, step: 23, Train: label_loss: 0.09173949807882309, precision: 0.3078045222465129, recall: 0.907526881720235, f1: 0.45969498906887896\n",
            "epoch: 792, step: 0, Train: label_loss: 0.073424331843853, precision: 0.30641330166268965, recall: 0.8958333333331777, f1: 0.4566371681035705\n",
            "epoch: 792, step: 1, Train: label_loss: 0.07859598845243454, precision: 0.34168157423969336, recall: 0.908082408874658, f1: 0.4965337954541609\n",
            "epoch: 792, step: 2, Train: label_loss: 0.0754508450627327, precision: 0.3438967136150033, recall: 0.9141965678625719, f1: 0.49978678034402696\n",
            "epoch: 792, step: 3, Train: label_loss: 0.0836532860994339, precision: 0.31452581032411076, recall: 0.8762541806018601, f1: 0.46289752646285237\n",
            "epoch: 792, step: 4, Train: label_loss: 0.08385214954614639, precision: 0.33784579164212253, recall: 0.9198717948716474, f1: 0.49418854925037653\n",
            "epoch: 792, step: 5, Train: label_loss: 0.08517478406429291, precision: 0.3067776456599104, recall: 0.9084507042251921, f1: 0.4586666666288826\n",
            "epoch: 792, step: 6, Train: label_loss: 0.08598826825618744, precision: 0.3140643623360957, recall: 0.8827470686765689, f1: 0.4632967032579517\n",
            "epoch: 792, step: 7, Train: label_loss: 0.08228279650211334, precision: 0.32757593805834856, recall: 0.8928571428569978, f1: 0.4793028322046938\n",
            "epoch: 792, step: 8, Train: label_loss: 0.08400876820087433, precision: 0.3291888691533257, recall: 0.9040650406502594, f1: 0.4826388888497116\n",
            "epoch: 792, step: 9, Train: label_loss: 0.07561659812927246, precision: 0.30627962085306243, recall: 0.8944636678199144, f1: 0.4563106795736079\n",
            "epoch: 792, step: 10, Train: label_loss: 0.07606630772352219, precision: 0.3231780167263845, recall: 0.8942148760329099, f1: 0.4747696357661371\n",
            "epoch: 792, step: 11, Train: label_loss: 0.08318188786506653, precision: 0.3301492537313236, recall: 0.8977272727271269, f1: 0.4827586206502965\n",
            "epoch: 792, step: 12, Train: label_loss: 0.09460625052452087, precision: 0.32155688622752565, recall: 0.896494156928064, f1: 0.47333627144633383\n",
            "epoch: 792, step: 13, Train: label_loss: 0.08767662942409515, precision: 0.318779904306201, recall: 0.9003378378376857, f1: 0.47084805649843875\n",
            "epoch: 792, step: 14, Train: label_loss: 0.09662006795406342, precision: 0.3082932692307507, recall: 0.8799313893652007, f1: 0.45660881171053025\n",
            "epoch: 792, step: 15, Train: label_loss: 0.09827204048633575, precision: 0.3100177830468103, recall: 0.9159369527143755, f1: 0.46324180687094163\n",
            "epoch: 792, step: 16, Train: label_loss: 0.08103854954242706, precision: 0.31394658753707333, recall: 0.9027303754264671, f1: 0.4658740642505278\n",
            "epoch: 792, step: 17, Train: label_loss: 0.07714672386646271, precision: 0.33294117647056864, recall: 0.9233278955952816, f1: 0.489407695594377\n",
            "epoch: 792, step: 18, Train: label_loss: 0.08696646243333817, precision: 0.32250443000588763, recall: 0.9285714285712706, f1: 0.47873739584069247\n",
            "epoch: 792, step: 19, Train: label_loss: 0.08877996355295181, precision: 0.3189093064611548, recall: 0.9196581196579624, f1: 0.4735915492574959\n",
            "epoch: 792, step: 20, Train: label_loss: 0.08997666090726852, precision: 0.3370786516853733, recall: 0.9268292682925322, f1: 0.4943625324846941\n",
            "epoch: 792, step: 21, Train: label_loss: 0.094617560505867, precision: 0.3329326923076723, recall: 0.884984025558964, f1: 0.48384279472005604\n",
            "epoch: 792, step: 22, Train: label_loss: 0.0917910784482956, precision: 0.3266272189348919, recall: 0.9108910891087605, f1: 0.48083623689490107\n",
            "epoch: 792, step: 23, Train: label_loss: 0.09762462973594666, precision: 0.3124999999999773, recall: 0.8775510204079842, f1: 0.4608788852774073\n",
            "epoch: 793, step: 0, Train: label_loss: 0.08860248327255249, precision: 0.3220439691027735, recall: 0.9124579124577588, f1: 0.47606499776552313\n",
            "epoch: 793, step: 1, Train: label_loss: 0.07489598542451859, precision: 0.33392434988177694, recall: 0.8968253968252544, f1: 0.48664944009822936\n",
            "epoch: 793, step: 2, Train: label_loss: 0.08182314783334732, precision: 0.32733812949638325, recall: 0.8778135048230099, f1: 0.4768558951568968\n",
            "epoch: 793, step: 3, Train: label_loss: 0.08223666250705719, precision: 0.3155688622754302, recall: 0.8682042833606477, f1: 0.46288976719844976\n",
            "epoch: 793, step: 4, Train: label_loss: 0.09406749904155731, precision: 0.31483715319660344, recall: 0.8729096989965095, f1: 0.4627659574078058\n",
            "epoch: 793, step: 5, Train: label_loss: 0.0855252742767334, precision: 0.33194527067219914, recall: 0.9087947882734676, f1: 0.4862745097646869\n",
            "epoch: 793, step: 6, Train: label_loss: 0.08211266994476318, precision: 0.3045023696682284, recall: 0.9081272084804048, f1: 0.45607808336962485\n",
            "epoch: 793, step: 7, Train: label_loss: 0.07205455750226974, precision: 0.3179396092362156, recall: 0.9070945945944413, f1: 0.4708461200842765\n",
            "epoch: 793, step: 8, Train: label_loss: 0.08969541639089584, precision: 0.32499999999998064, recall: 0.9024793388428259, f1: 0.47789934350588253\n",
            "epoch: 793, step: 9, Train: label_loss: 0.08464707434177399, precision: 0.3319402985074429, recall: 0.90553745928324, f1: 0.4858016600742869\n",
            "epoch: 793, step: 10, Train: label_loss: 0.08947958052158356, precision: 0.3049434187015899, recall: 0.9029982363314103, f1: 0.4559216384306039\n",
            "epoch: 793, step: 11, Train: label_loss: 0.07425414770841599, precision: 0.3347131874630198, recall: 0.9143780290790121, f1: 0.4900432900040156\n",
            "epoch: 793, step: 12, Train: label_loss: 0.08180828392505646, precision: 0.3218934911242413, recall: 0.9220338983049284, f1: 0.4771929824177367\n",
            "epoch: 793, step: 13, Train: label_loss: 0.08545811474323273, precision: 0.3211764705882164, recall: 0.9191919191917644, f1: 0.47602441146986324\n",
            "epoch: 793, step: 14, Train: label_loss: 0.08264431357383728, precision: 0.31127012522359504, recall: 0.9015544041449219, f1: 0.4627659574086115\n",
            "epoch: 793, step: 15, Train: label_loss: 0.08827053010463715, precision: 0.3245666467423596, recall: 0.9004975124376615, f1: 0.47715289978526193\n",
            "epoch: 793, step: 16, Train: label_loss: 0.07855809479951859, precision: 0.3225806451612714, recall: 0.9228187919461538, f1: 0.47805302038747466\n",
            "epoch: 793, step: 17, Train: label_loss: 0.0873507410287857, precision: 0.33927510398096616, recall: 0.890795631825134, f1: 0.49139414798066333\n",
            "epoch: 793, step: 18, Train: label_loss: 0.08463782072067261, precision: 0.3369369369369167, recall: 0.8876582278479608, f1: 0.4884632128464433\n",
            "epoch: 793, step: 19, Train: label_loss: 0.10595372319221497, precision: 0.30681133212776934, recall: 0.8760757314972674, f1: 0.45446428567582514\n",
            "epoch: 793, step: 20, Train: label_loss: 0.09463973343372345, precision: 0.2988643156006994, recall: 0.8818342151673929, f1: 0.44642857139072106\n",
            "epoch: 793, step: 21, Train: label_loss: 0.07770383358001709, precision: 0.3329425556857952, recall: 0.9235772357722075, f1: 0.489444205045021\n",
            "epoch: 793, step: 22, Train: label_loss: 0.08917644619941711, precision: 0.31796690307326725, recall: 0.9134125636670775, f1: 0.47172292850176417\n",
            "epoch: 793, step: 23, Train: label_loss: 0.09371358901262283, precision: 0.3294629898403244, recall: 0.9007936507934721, f1: 0.48246546223490844\n",
            "epoch: 794, step: 0, Train: label_loss: 0.08534334599971771, precision: 0.31858407079644135, recall: 0.8970099667772595, f1: 0.4701784936486985\n",
            "epoch: 794, step: 1, Train: label_loss: 0.08080601692199707, precision: 0.329404832056551, recall: 0.9104234527685813, f1: 0.48377325829066614\n",
            "epoch: 794, step: 2, Train: label_loss: 0.07761989533901215, precision: 0.32162001191183315, recall: 0.8766233766232342, f1: 0.4705882352548035\n",
            "epoch: 794, step: 3, Train: label_loss: 0.07838857173919678, precision: 0.3241500586166281, recall: 0.9201331114807121, f1: 0.47941048977504014\n",
            "epoch: 794, step: 4, Train: label_loss: 0.07938797771930695, precision: 0.32499999999998064, recall: 0.9039735099336251, f1: 0.478108581397132\n",
            "epoch: 794, step: 5, Train: label_loss: 0.08256582170724869, precision: 0.33214285714283737, recall: 0.9147540983605057, f1: 0.48733624450235824\n",
            "epoch: 794, step: 6, Train: label_loss: 0.08551639318466187, precision: 0.33254156769594223, recall: 0.9120521172636951, f1: 0.48738033068316505\n",
            "epoch: 794, step: 7, Train: label_loss: 0.10115702450275421, precision: 0.3282766990291063, recall: 0.8912685337725055, f1: 0.4798226163685952\n",
            "epoch: 794, step: 8, Train: label_loss: 0.08773023635149002, precision: 0.32531569452794196, recall: 0.8883415435138113, f1: 0.4762323943269158\n",
            "epoch: 794, step: 9, Train: label_loss: 0.09266625344753265, precision: 0.3225030084235666, recall: 0.9023569023567504, f1: 0.4751773049257024\n",
            "epoch: 794, step: 10, Train: label_loss: 0.08159578591585159, precision: 0.33553421368545405, recall: 0.8817034700314066, f1: 0.48608695648176325\n",
            "epoch: 794, step: 11, Train: label_loss: 0.07826261967420578, precision: 0.32021151586367097, recall: 0.9128978224454082, f1: 0.4741191822146632\n",
            "epoch: 794, step: 12, Train: label_loss: 0.0704183280467987, precision: 0.3507638072855258, recall: 0.9241486068110024, f1: 0.5085178875239543\n",
            "epoch: 794, step: 13, Train: label_loss: 0.08159676194190979, precision: 0.32915921288012345, recall: 0.8961038961037505, f1: 0.4814653292236374\n",
            "epoch: 794, step: 14, Train: label_loss: 0.06948402523994446, precision: 0.31117647058821696, recall: 0.9232111692843066, f1: 0.46546414426493454\n",
            "epoch: 794, step: 15, Train: label_loss: 0.08290211111307144, precision: 0.3133174791914201, recall: 0.9197207678881466, f1: 0.4674057649287922\n",
            "epoch: 794, step: 16, Train: label_loss: 0.08408482372760773, precision: 0.3095238095237911, recall: 0.890410958903957, f1: 0.4593639575588502\n",
            "epoch: 794, step: 17, Train: label_loss: 0.08711754530668259, precision: 0.3056537102473318, recall: 0.9041811846688319, f1: 0.4568661971452957\n",
            "epoch: 794, step: 18, Train: label_loss: 0.08312224596738815, precision: 0.3082394783639414, recall: 0.8919382504286634, f1: 0.4581497796974689\n",
            "epoch: 794, step: 19, Train: label_loss: 0.0785830169916153, precision: 0.30990041007613883, recall: 0.913644214162191, f1: 0.4628171478186514\n",
            "epoch: 794, step: 20, Train: label_loss: 0.09055079519748688, precision: 0.32121573301547546, recall: 0.8894389438942426, f1: 0.47197898419915185\n",
            "epoch: 794, step: 21, Train: label_loss: 0.0939730703830719, precision: 0.32170313424007557, recall: 0.8991735537188595, f1: 0.47386759577996024\n",
            "epoch: 794, step: 22, Train: label_loss: 0.0887821763753891, precision: 0.3371394230769028, recall: 0.9063004846525191, f1: 0.49145860705635924\n",
            "epoch: 794, step: 23, Train: label_loss: 0.08932559937238693, precision: 0.2960526315789257, recall: 0.8823529411762784, f1: 0.4433497536569099\n",
            "epoch: 795, step: 0, Train: label_loss: 0.06842320412397385, precision: 0.3309900410075963, recall: 0.9069020866772219, f1: 0.48497854073331276\n",
            "epoch: 795, step: 1, Train: label_loss: 0.08105999231338501, precision: 0.3183165382335318, recall: 0.9070945945944413, f1: 0.47125932422652983\n",
            "epoch: 795, step: 2, Train: label_loss: 0.09273072332143784, precision: 0.31528279181706886, recall: 0.8791946308723356, f1: 0.46412754646243143\n",
            "epoch: 795, step: 3, Train: label_loss: 0.0766754299402237, precision: 0.3372572101235823, recall: 0.9271844660192674, f1: 0.4946050927532448\n",
            "epoch: 795, step: 4, Train: label_loss: 0.07002060860395432, precision: 0.32456140350875295, recall: 0.9312080536911188, f1: 0.48135299215590277\n",
            "epoch: 795, step: 5, Train: label_loss: 0.08409865200519562, precision: 0.32660332541565756, recall: 0.9105960264899154, f1: 0.48076923073032923\n",
            "epoch: 795, step: 6, Train: label_loss: 0.07163641601800919, precision: 0.33038869257948583, recall: 0.9166666666665169, f1: 0.48571428567529473\n",
            "epoch: 795, step: 7, Train: label_loss: 0.0938427671790123, precision: 0.32168246445495724, recall: 0.9049999999998491, f1: 0.4746503496116143\n",
            "epoch: 795, step: 8, Train: label_loss: 0.08819878101348877, precision: 0.3082352941176289, recall: 0.9113043478259284, f1: 0.46065934062152686\n",
            "epoch: 795, step: 9, Train: label_loss: 0.0972195416688919, precision: 0.32628398791538815, recall: 0.8866995073890169, f1: 0.4770318020807721\n",
            "epoch: 795, step: 10, Train: label_loss: 0.08964681625366211, precision: 0.3195020746887777, recall: 0.8983333333331835, f1: 0.4713598600399597\n",
            "epoch: 795, step: 11, Train: label_loss: 0.07210534065961838, precision: 0.3038575667655606, recall: 0.893542757416947, f1: 0.4534986713526974\n",
            "epoch: 795, step: 12, Train: label_loss: 0.07768644392490387, precision: 0.3445825932504236, recall: 0.9150943396224975, f1: 0.5006451612505356\n",
            "epoch: 795, step: 13, Train: label_loss: 0.08480885624885559, precision: 0.337902264600695, recall: 0.8971518987340352, f1: 0.4909090908693004\n",
            "epoch: 795, step: 14, Train: label_loss: 0.09328596293926239, precision: 0.315444245676785, recall: 0.8905723905722406, f1: 0.46587406425018935\n",
            "epoch: 795, step: 15, Train: label_loss: 0.0991380587220192, precision: 0.3031755542240681, recall: 0.8877192982454583, f1: 0.45198749437915653\n",
            "epoch: 795, step: 16, Train: label_loss: 0.08953743427991867, precision: 0.3183165382335318, recall: 0.9210977701542159, f1: 0.47312775326574946\n",
            "epoch: 795, step: 17, Train: label_loss: 0.0763237401843071, precision: 0.33116113744073866, recall: 0.9104234527685813, f1: 0.4856646394048031\n",
            "epoch: 795, step: 18, Train: label_loss: 0.08688007295131683, precision: 0.3119047619047433, recall: 0.9003436426115291, f1: 0.4633068080961345\n",
            "epoch: 795, step: 19, Train: label_loss: 0.09223511815071106, precision: 0.3093955715140449, recall: 0.8944636678199144, f1: 0.4597598932476734\n",
            "epoch: 795, step: 20, Train: label_loss: 0.09849477559328079, precision: 0.31086824529445595, recall: 0.8648648648647187, f1: 0.4573470298851336\n",
            "epoch: 795, step: 21, Train: label_loss: 0.08565353602170944, precision: 0.32273545290939876, recall: 0.8892561983469603, f1: 0.4735915492566575\n",
            "epoch: 795, step: 22, Train: label_loss: 0.08774251490831375, precision: 0.3376546847377526, recall: 0.9124203821654597, f1: 0.49290322576697926\n",
            "epoch: 795, step: 23, Train: label_loss: 0.10860499739646912, precision: 0.3188622754490779, recall: 0.8402366863903669, f1: 0.46228974494107555\n",
            "epoch: 796, step: 0, Train: label_loss: 0.09282778203487396, precision: 0.3325227963525634, recall: 0.8751999999998599, f1: 0.4819383259512422\n",
            "epoch: 796, step: 1, Train: label_loss: 0.08234347403049469, precision: 0.3238265002970693, recall: 0.8963815789472209, f1: 0.47577477080339403\n",
            "epoch: 796, step: 2, Train: label_loss: 0.08611226826906204, precision: 0.30933967876262286, recall: 0.8888888888887369, f1: 0.4589585171726007\n",
            "epoch: 796, step: 3, Train: label_loss: 0.10258553177118301, precision: 0.3137847642079617, recall: 0.8708053691273706, f1: 0.4613333332943478\n",
            "epoch: 796, step: 4, Train: label_loss: 0.08092677593231201, precision: 0.3325344517675055, recall: 0.8795562599047734, f1: 0.48260869561231573\n",
            "epoch: 796, step: 5, Train: label_loss: 0.09068405628204346, precision: 0.3040581465778132, recall: 0.8655172413791611, f1: 0.4500224114361573\n",
            "epoch: 796, step: 6, Train: label_loss: 0.09967891871929169, precision: 0.3081570996978666, recall: 0.8793103448274345, f1: 0.45637583888770095\n",
            "epoch: 796, step: 7, Train: label_loss: 0.08925123512744904, precision: 0.3182912154031096, recall: 0.8831385642736421, f1: 0.46793454219895825\n",
            "epoch: 796, step: 8, Train: label_loss: 0.08968643844127655, precision: 0.31323877068556066, recall: 0.9028960817715668, f1: 0.4651162790314811\n",
            "epoch: 796, step: 9, Train: label_loss: 0.09060569107532501, precision: 0.31878787878785947, recall: 0.8708609271521737, f1: 0.46672582072381413\n",
            "epoch: 796, step: 10, Train: label_loss: 0.09450912475585938, precision: 0.3319302465423733, recall: 0.8888888888887457, f1: 0.4833625218517829\n",
            "epoch: 796, step: 11, Train: label_loss: 0.08416415750980377, precision: 0.32014388489206713, recall: 0.9005059021920909, f1: 0.4723573639594918\n",
            "epoch: 796, step: 12, Train: label_loss: 0.09226842224597931, precision: 0.3269230769230573, recall: 0.9021558872303644, f1: 0.4799294221047122\n",
            "epoch: 796, step: 13, Train: label_loss: 0.07896333187818527, precision: 0.3036363636363452, recall: 0.8652849740931148, f1: 0.44952893670443694\n",
            "epoch: 796, step: 14, Train: label_loss: 0.09897725284099579, precision: 0.31455961653682957, recall: 0.8764607679464312, f1: 0.46296296292405104\n",
            "epoch: 796, step: 15, Train: label_loss: 0.08840395510196686, precision: 0.3207434052757601, recall: 0.8813838550245664, f1: 0.47032967029050415\n",
            "epoch: 796, step: 16, Train: label_loss: 0.10127800703048706, precision: 0.3089480048367407, recall: 0.8545150501670811, f1: 0.4538188276696572\n",
            "epoch: 796, step: 17, Train: label_loss: 0.09175009280443192, precision: 0.33729216152017, recall: 0.9087999999998545, f1: 0.49198787349880324\n",
            "epoch: 796, step: 18, Train: label_loss: 0.07863330096006393, precision: 0.3246290801186751, recall: 0.8967213114752628, f1: 0.4766884531199702\n",
            "epoch: 796, step: 19, Train: label_loss: 0.10368432849645615, precision: 0.3294406883835077, recall: 0.8507936507935157, f1: 0.47496677000845167\n",
            "epoch: 796, step: 20, Train: label_loss: 0.10264429450035095, precision: 0.3181008902076963, recall: 0.9023569023567504, f1: 0.4703817463414085\n",
            "epoch: 796, step: 21, Train: label_loss: 0.09414607286453247, precision: 0.3009535160905661, recall: 0.893805309734355, f1: 0.4502897904214775\n",
            "epoch: 796, step: 22, Train: label_loss: 0.0886218249797821, precision: 0.31515877771118544, recall: 0.8915254237286624, f1: 0.46569278437925005\n",
            "epoch: 796, step: 23, Train: label_loss: 0.08498529344797134, precision: 0.34081041968159614, recall: 0.9235294117645249, f1: 0.4978858350557056\n",
            "epoch: 797, step: 0, Train: label_loss: 0.07878932356834412, precision: 0.33883323512078145, recall: 0.9199999999998527, f1: 0.49526270452564447\n",
            "epoch: 797, step: 1, Train: label_loss: 0.0878729373216629, precision: 0.3412322274881314, recall: 0.9128367670363053, f1: 0.4967658473083396\n",
            "epoch: 797, step: 2, Train: label_loss: 0.09261563420295715, precision: 0.30612244897957347, recall: 0.8854166666665129, f1: 0.4549509366254707\n",
            "epoch: 797, step: 3, Train: label_loss: 0.0846722424030304, precision: 0.33753753753751725, recall: 0.8963317384368585, f1: 0.49040139612077066\n",
            "epoch: 797, step: 4, Train: label_loss: 0.08891886472702026, precision: 0.3359611885991306, recall: 0.8779714738508909, f1: 0.4859649122406268\n",
            "epoch: 797, step: 5, Train: label_loss: 0.08724071085453033, precision: 0.3307416267942386, recall: 0.8933764135701302, f1: 0.4827586206501757\n",
            "epoch: 797, step: 6, Train: label_loss: 0.09178543090820312, precision: 0.3311298076922878, recall: 0.8930307941651713, f1: 0.4831214379262965\n",
            "epoch: 797, step: 7, Train: label_loss: 0.0928092896938324, precision: 0.29510155316605163, recall: 0.8821428571426996, f1: 0.4422560429346404\n",
            "epoch: 797, step: 8, Train: label_loss: 0.07762958109378815, precision: 0.3295724465557999, recall: 0.9083469721766106, f1: 0.4836601306798417\n",
            "epoch: 797, step: 9, Train: label_loss: 0.08605760335922241, precision: 0.30160618679355733, recall: 0.8973451327432039, f1: 0.4514692786800249\n",
            "epoch: 797, step: 10, Train: label_loss: 0.08838596940040588, precision: 0.32585596221957935, recall: 0.9078947368419559, f1: 0.47958297129036526\n",
            "epoch: 797, step: 11, Train: label_loss: 0.07688647508621216, precision: 0.31591448931114513, recall: 0.9016949152540844, f1: 0.4678979770943369\n",
            "epoch: 797, step: 12, Train: label_loss: 0.0864645317196846, precision: 0.33293556085916864, recall: 0.892799999999857, f1: 0.4850065188652131\n",
            "epoch: 797, step: 13, Train: label_loss: 0.08814384043216705, precision: 0.3182359952324006, recall: 0.9128205128203567, f1: 0.47193990274553727\n",
            "epoch: 797, step: 14, Train: label_loss: 0.08797261863946915, precision: 0.3193779904306029, recall: 0.878289473684066, f1: 0.46842105259242667\n",
            "epoch: 797, step: 15, Train: label_loss: 0.09855607151985168, precision: 0.3108433734939572, recall: 0.8911917098444055, f1: 0.46092005355696886\n",
            "epoch: 797, step: 16, Train: label_loss: 0.10158008337020874, precision: 0.31351351351349466, recall: 0.8877551020406653, f1: 0.46338215708521935\n",
            "epoch: 797, step: 17, Train: label_loss: 0.0936155617237091, precision: 0.3124999999999814, recall: 0.8868243243241745, f1: 0.462147887285369\n",
            "epoch: 797, step: 18, Train: label_loss: 0.10050807893276215, precision: 0.32416267942581795, recall: 0.8856209150325349, f1: 0.4746059544265772\n",
            "epoch: 797, step: 19, Train: label_loss: 0.09778180718421936, precision: 0.31582125603862826, recall: 0.8834459459457966, f1: 0.46530249106436256\n",
            "epoch: 797, step: 20, Train: label_loss: 0.09776566922664642, precision: 0.3050746268656534, recall: 0.8996478873237852, f1: 0.4556397681297708\n",
            "epoch: 797, step: 21, Train: label_loss: 0.09235836565494537, precision: 0.32174955062909993, recall: 0.8890728476819719, f1: 0.4725032995649825\n",
            "epoch: 797, step: 22, Train: label_loss: 0.09723660349845886, precision: 0.3270858524788194, recall: 0.861464968152729, f1: 0.47414548637549075\n",
            "epoch: 797, step: 23, Train: label_loss: 0.08550536632537842, precision: 0.3088774761555166, recall: 0.8807531380751296, f1: 0.45736013032543743\n",
            "epoch: 798, step: 0, Train: label_loss: 0.09877747297286987, precision: 0.3233353329333939, recall: 0.8953488372091535, f1: 0.4750991625876813\n",
            "epoch: 798, step: 1, Train: label_loss: 0.08354401588439941, precision: 0.3341331733653069, recall: 0.8841269841268438, f1: 0.4849804091895782\n",
            "epoch: 798, step: 2, Train: label_loss: 0.0788564532995224, precision: 0.33293768545992086, recall: 0.8975999999998563, f1: 0.4857142856747719\n",
            "epoch: 798, step: 3, Train: label_loss: 0.08540599793195724, precision: 0.3242280285035437, recall: 0.9069767441858958, f1: 0.4776902886750704\n",
            "epoch: 798, step: 4, Train: label_loss: 0.08881321549415588, precision: 0.3267267267267071, recall: 0.8788368336024428, f1: 0.47635726791140826\n",
            "epoch: 798, step: 5, Train: label_loss: 0.10821526497602463, precision: 0.31204819277106555, recall: 0.8764805414550124, f1: 0.46023989334195536\n",
            "epoch: 798, step: 6, Train: label_loss: 0.0792318806052208, precision: 0.31421744324968254, recall: 0.8945578231290995, f1: 0.46507515469181104\n",
            "epoch: 798, step: 7, Train: label_loss: 0.08930235356092453, precision: 0.3215780035863526, recall: 0.8966666666665172, f1: 0.4733831939778186\n",
            "epoch: 798, step: 8, Train: label_loss: 0.10061739385128021, precision: 0.33233532934129745, recall: 0.902439024390097, f1: 0.48577680521225725\n",
            "epoch: 798, step: 9, Train: label_loss: 0.09392011165618896, precision: 0.3036244800950503, recall: 0.8964912280700181, f1: 0.45361739898568615\n",
            "epoch: 798, step: 10, Train: label_loss: 0.08762051910161972, precision: 0.30938242280283196, recall: 0.8905982905981383, f1: 0.4592331423151491\n",
            "epoch: 798, step: 11, Train: label_loss: 0.09572179615497589, precision: 0.31627056672758586, recall: 0.8752107925799535, f1: 0.46463742162613636\n",
            "epoch: 798, step: 12, Train: label_loss: 0.08304374665021896, precision: 0.3192627824018835, recall: 0.9148211243610025, f1: 0.47333627144683876\n",
            "epoch: 798, step: 13, Train: label_loss: 0.07615002989768982, precision: 0.3412322274881314, recall: 0.9245585874797874, f1: 0.49848550407134995\n",
            "epoch: 798, step: 14, Train: label_loss: 0.08620452135801315, precision: 0.31351351351349466, recall: 0.8862478777587629, f1: 0.46317657493917036\n",
            "epoch: 798, step: 15, Train: label_loss: 0.0988568514585495, precision: 0.32168246445495724, recall: 0.9219015280134257, f1: 0.47694334647016967\n",
            "epoch: 798, step: 16, Train: label_loss: 0.08480218052864075, precision: 0.3532898636632867, recall: 0.8922155688621418, f1: 0.5061571124858576\n",
            "epoch: 798, step: 17, Train: label_loss: 0.10892945528030396, precision: 0.3096812988574678, recall: 0.867003367003221, f1: 0.45635799730278\n",
            "epoch: 798, step: 18, Train: label_loss: 0.0808725580573082, precision: 0.3333333333333137, recall: 0.9173419773094137, f1: 0.4889848811703634\n",
            "epoch: 798, step: 19, Train: label_loss: 0.092038094997406, precision: 0.3099940155595266, recall: 0.8885077186962455, f1: 0.4596273291541556\n",
            "epoch: 798, step: 20, Train: label_loss: 0.09738489985466003, precision: 0.30228365384613565, recall: 0.8918439716310474, f1: 0.4515260322781257\n",
            "epoch: 798, step: 21, Train: label_loss: 0.08443642407655716, precision: 0.30810488676994585, recall: 0.8822525597268118, f1: 0.4567137808803197\n",
            "epoch: 798, step: 22, Train: label_loss: 0.08515246212482452, precision: 0.32388419782868977, recall: 0.8703403565638783, f1: 0.4720879120483397\n",
            "epoch: 798, step: 23, Train: label_loss: 0.0720265582203865, precision: 0.31719653179188456, recall: 0.9107883817425496, f1: 0.4705251875286209\n",
            "epoch: 799, step: 0, Train: label_loss: 0.08545112609863281, precision: 0.3114061557030591, recall: 0.8790459965926951, f1: 0.4598930480896694\n",
            "epoch: 799, step: 1, Train: label_loss: 0.0901927649974823, precision: 0.3234403391883511, recall: 0.8811881188117358, f1: 0.47319450594206797\n",
            "epoch: 799, step: 2, Train: label_loss: 0.09374460577964783, precision: 0.30943847072877484, recall: 0.8824531516182482, f1: 0.45820433432684105\n",
            "epoch: 799, step: 3, Train: label_loss: 0.0781300738453865, precision: 0.32875074716076935, recall: 0.9016393442621472, f1: 0.48182216378033327\n",
            "epoch: 799, step: 4, Train: label_loss: 0.08582726120948792, precision: 0.3309481216457763, recall: 0.8865814696484207, f1: 0.4819800260133458\n",
            "epoch: 799, step: 5, Train: label_loss: 0.08559996634721756, precision: 0.3180737217597908, recall: 0.9114139693354494, f1: 0.4715733803053669\n",
            "epoch: 799, step: 6, Train: label_loss: 0.08140997588634491, precision: 0.32465996451801743, recall: 0.9089403973508429, f1: 0.4784313725101946\n",
            "epoch: 799, step: 7, Train: label_loss: 0.08646289259195328, precision: 0.3214069132807567, recall: 0.8818635607319664, f1: 0.47111111107191667\n",
            "epoch: 799, step: 8, Train: label_loss: 0.10342851281166077, precision: 0.30442692540932054, recall: 0.8494077834177919, f1: 0.44821428567540006\n",
            "epoch: 799, step: 9, Train: label_loss: 0.09255671501159668, precision: 0.3189706762417523, recall: 0.8957983193275805, f1: 0.47043248010245037\n",
            "epoch: 799, step: 10, Train: label_loss: 0.08927227556705475, precision: 0.29711884753899775, recall: 0.8684210526314265, f1: 0.4427549194610788\n",
            "epoch: 799, step: 11, Train: label_loss: 0.0937960147857666, precision: 0.33764705882350954, recall: 0.9111111111109664, f1: 0.49270386262144644\n",
            "epoch: 799, step: 12, Train: label_loss: 0.09215867519378662, precision: 0.32559523809521873, recall: 0.8937908496730566, f1: 0.47731239088577104\n",
            "epoch: 799, step: 13, Train: label_loss: 0.0939558893442154, precision: 0.35301132975549476, recall: 0.9121725731893817, f1: 0.5090283748522421\n",
            "epoch: 799, step: 14, Train: label_loss: 0.07936625182628632, precision: 0.30602409638552375, recall: 0.8804159445405753, f1: 0.45417970492368115\n",
            "epoch: 799, step: 15, Train: label_loss: 0.08836384117603302, precision: 0.32758620689653223, recall: 0.8944805194803742, f1: 0.47954743251076104\n",
            "epoch: 799, step: 16, Train: label_loss: 0.07761777937412262, precision: 0.3347083087801806, recall: 0.9190938511325373, f1: 0.4907127429413811\n",
            "epoch: 799, step: 17, Train: label_loss: 0.08893315494060516, precision: 0.3259833134683953, recall: 0.885113268608271, f1: 0.47648083619754933\n",
            "epoch: 799, step: 18, Train: label_loss: 0.08238063752651215, precision: 0.3261390887289972, recall: 0.8874388254484685, f1: 0.4769837790049331\n",
            "epoch: 799, step: 19, Train: label_loss: 0.08530666679143906, precision: 0.3428063943161431, recall: 0.9263999999998517, f1: 0.5004321520780733\n",
            "epoch: 799, step: 20, Train: label_loss: 0.08691631257534027, precision: 0.321764705882334, recall: 0.9334470989759499, f1: 0.47856517931441284\n",
            "epoch: 799, step: 21, Train: label_loss: 0.08670306950807571, precision: 0.31818181818179914, recall: 0.9001692047375803, f1: 0.47017233756631677\n",
            "epoch: 799, step: 22, Train: label_loss: 0.09376955032348633, precision: 0.31350386674596586, recall: 0.9213286713285102, f1: 0.4678206834951401\n",
            "epoch: 799, step: 23, Train: label_loss: 0.0884404182434082, precision: 0.2935982339955634, recall: 0.8906249999998013, f1: 0.4416159379814752\n",
            "epoch: 800, step: 0, Train: label_loss: 0.08527141809463501, precision: 0.31394658753707333, recall: 0.9168110918542605, f1: 0.46772767458618175\n",
            "epoch: 800, step: 1, Train: label_loss: 0.07191622257232666, precision: 0.33881385789780744, recall: 0.907232704402373, f1: 0.4933732363861857\n",
            "epoch: 800, step: 2, Train: label_loss: 0.1022382527589798, precision: 0.32345971563979126, recall: 0.9084858569050068, f1: 0.47706422014472005\n",
            "epoch: 800, step: 3, Train: label_loss: 0.08744333684444427, precision: 0.3048852266038667, recall: 0.9249999999998347, f1: 0.45861000438940797\n",
            "epoch: 800, step: 4, Train: label_loss: 0.07920998334884644, precision: 0.314117647058805, recall: 0.9066213921899988, f1: 0.4665792922291038\n",
            "epoch: 800, step: 5, Train: label_loss: 0.09107637405395508, precision: 0.30416415208205766, recall: 0.8600682593855187, f1: 0.44939812746916147\n",
            "epoch: 800, step: 6, Train: label_loss: 0.08675701916217804, precision: 0.328605200945607, recall: 0.9174917491747661, f1: 0.4838990426069036\n",
            "epoch: 800, step: 7, Train: label_loss: 0.08741335570812225, precision: 0.3187463039621337, recall: 0.886513157894591, f1: 0.46889952149215525\n",
            "epoch: 800, step: 8, Train: label_loss: 0.08553210645914078, precision: 0.32883147386962247, recall: 0.9150326797384125, f1: 0.4838012958573914\n",
            "epoch: 800, step: 9, Train: label_loss: 0.07446561008691788, precision: 0.31440281030443124, recall: 0.9258620689653575, f1: 0.4694055943677062\n",
            "epoch: 800, step: 10, Train: label_loss: 0.07337348163127899, precision: 0.331962397179769, recall: 0.9262295081965694, f1: 0.48875432522062745\n",
            "epoch: 800, step: 11, Train: label_loss: 0.08681677281856537, precision: 0.33116499112948955, recall: 0.9061488673137692, f1: 0.4850584668295297\n",
            "epoch: 800, step: 12, Train: label_loss: 0.07825692743062973, precision: 0.3242603550295666, recall: 0.9118136439266369, f1: 0.47839371449639306\n",
            "epoch: 800, step: 13, Train: label_loss: 0.08457078039646149, precision: 0.3200475907197906, recall: 0.9011725293130818, f1: 0.4723441615064956\n",
            "epoch: 800, step: 14, Train: label_loss: 0.08818413317203522, precision: 0.3119376124774858, recall: 0.8873720136517257, f1: 0.46160674652161165\n",
            "epoch: 800, step: 15, Train: label_loss: 0.069875568151474, precision: 0.3331357439241059, recall: 0.9153094462539225, f1: 0.4884832681051153\n",
            "epoch: 800, step: 16, Train: label_loss: 0.07896861433982849, precision: 0.33116113744073866, recall: 0.9059967585087672, f1: 0.4850325379217069\n",
            "epoch: 800, step: 17, Train: label_loss: 0.08009188622236252, precision: 0.3229959040374299, recall: 0.9340101522841059, f1: 0.47999999996177234\n",
            "epoch: 800, step: 18, Train: label_loss: 0.08801396191120148, precision: 0.32042882668253003, recall: 0.8981636060098667, f1: 0.4723441615064121\n",
            "epoch: 800, step: 19, Train: label_loss: 0.07654936611652374, precision: 0.33451746595616727, recall: 0.9083601286172173, f1: 0.4889658156248308\n",
            "epoch: 800, step: 20, Train: label_loss: 0.0913449376821518, precision: 0.3076002393775998, recall: 0.8786324786323284, f1: 0.45567375882679434\n",
            "epoch: 800, step: 21, Train: label_loss: 0.0867786556482315, precision: 0.3244047619047426, recall: 0.8949096880129893, f1: 0.47619047615138055\n",
            "epoch: 800, step: 22, Train: label_loss: 0.0794985219836235, precision: 0.3181008902076963, recall: 0.8963210702339638, f1: 0.4695575996108776\n",
            "epoch: 800, step: 23, Train: label_loss: 0.09842529892921448, precision: 0.33531157270027184, recall: 0.8742746615085348, f1: 0.4847184986193923\n",
            "epoch: 801, step: 0, Train: label_loss: 0.0750478133559227, precision: 0.30088495575219465, recall: 0.8994708994707408, f1: 0.4509283819252587\n",
            "epoch: 801, step: 1, Train: label_loss: 0.09614591300487518, precision: 0.32174955062909993, recall: 0.8920265780729415, f1: 0.4729194187192519\n",
            "epoch: 801, step: 2, Train: label_loss: 0.07834784686565399, precision: 0.331962397179769, recall: 0.9083601286172173, f1: 0.4862306367938027\n",
            "epoch: 801, step: 3, Train: label_loss: 0.08550600707530975, precision: 0.33154121863797303, recall: 0.8966074313407275, f1: 0.4840819886216847\n",
            "epoch: 801, step: 4, Train: label_loss: 0.08070773631334305, precision: 0.320307874481923, recall: 0.8956953642382622, f1: 0.47187091143084414\n",
            "epoch: 801, step: 5, Train: label_loss: 0.08125294744968414, precision: 0.32305868405451554, recall: 0.9159663865544678, f1: 0.47765118313406313\n",
            "epoch: 801, step: 6, Train: label_loss: 0.0853976309299469, precision: 0.3178340200117529, recall: 0.9230769230767653, f1: 0.4728546409425888\n",
            "epoch: 801, step: 7, Train: label_loss: 0.08559476584196091, precision: 0.33095662507425244, recall: 0.9161184210524809, f1: 0.4862505455742355\n",
            "epoch: 801, step: 8, Train: label_loss: 0.08691157400608063, precision: 0.3277511961722292, recall: 0.8838709677417929, f1: 0.4781849912344882\n",
            "epoch: 801, step: 9, Train: label_loss: 0.08227857947349548, precision: 0.3217910447761002, recall: 0.9013377926419897, f1: 0.47426308839057213\n",
            "epoch: 801, step: 10, Train: label_loss: 0.10049615800380707, precision: 0.3206751054852127, recall: 0.8837209302324113, f1: 0.47058823525500343\n",
            "epoch: 801, step: 11, Train: label_loss: 0.08899638801813126, precision: 0.3031400966183392, recall: 0.8581196581195114, f1: 0.4480142793009605\n",
            "epoch: 801, step: 12, Train: label_loss: 0.0701032280921936, precision: 0.3315758640890257, recall: 0.9293924466336733, f1: 0.4887737478023013\n",
            "epoch: 801, step: 13, Train: label_loss: 0.07563793659210205, precision: 0.32625368731561494, recall: 0.918604651162638, f1: 0.4814976055337649\n",
            "epoch: 801, step: 14, Train: label_loss: 0.08493637293577194, precision: 0.30618311533886405, recall: 0.8864027538724808, f1: 0.45514803354553335\n",
            "epoch: 801, step: 15, Train: label_loss: 0.07671168446540833, precision: 0.3091334894613402, recall: 0.9087779690187764, f1: 0.4613368282713858\n",
            "epoch: 801, step: 16, Train: label_loss: 0.07512146234512329, precision: 0.3283935981031222, recall: 0.9037520391515654, f1: 0.4817391303956431\n",
            "epoch: 801, step: 17, Train: label_loss: 0.0883672684431076, precision: 0.3305833824395798, recall: 0.9181669394433849, f1: 0.4861351819367647\n",
            "epoch: 801, step: 18, Train: label_loss: 0.09005223214626312, precision: 0.33531157270027684, recall: 0.9025559105429868, f1: 0.4889658156246717\n",
            "epoch: 801, step: 19, Train: label_loss: 0.08049480617046356, precision: 0.3164705882352755, recall: 0.9057239057237532, f1: 0.4690496948177279\n",
            "epoch: 801, step: 20, Train: label_loss: 0.08571000397205353, precision: 0.32222222222220337, recall: 0.916805324459082, f1: 0.47684984851188394\n",
            "epoch: 801, step: 21, Train: label_loss: 0.076870858669281, precision: 0.3311726576310942, recall: 0.9289256198345571, f1: 0.4882710685971776\n",
            "epoch: 801, step: 22, Train: label_loss: 0.08613394945859909, precision: 0.33471810089018783, recall: 0.9126213592231532, f1: 0.4897959183280372\n",
            "epoch: 801, step: 23, Train: label_loss: 0.07525663077831268, precision: 0.30225782957026204, recall: 0.881104033970089, f1: 0.450108459831763\n",
            "epoch: 802, step: 0, Train: label_loss: 0.0724000483751297, precision: 0.3357058125741201, recall: 0.9027113237638114, f1: 0.4894076955938155\n",
            "epoch: 802, step: 1, Train: label_loss: 0.09019071608781815, precision: 0.31198589894240236, recall: 0.9076923076921525, f1: 0.4643637953269939\n",
            "epoch: 802, step: 2, Train: label_loss: 0.08323636651039124, precision: 0.3210526315789286, recall: 0.935264054514321, f1: 0.4780148018774515\n",
            "epoch: 802, step: 3, Train: label_loss: 0.0970255583524704, precision: 0.3269689737469972, recall: 0.8925081433223302, f1: 0.4786026200480478\n",
            "epoch: 802, step: 4, Train: label_loss: 0.07377184182405472, precision: 0.3105076741440194, recall: 0.9163763066200493, f1: 0.4638447971402828\n",
            "epoch: 802, step: 5, Train: label_loss: 0.08554194867610931, precision: 0.31946955997586984, recall: 0.8789386401325242, f1: 0.4686118478830485\n",
            "epoch: 802, step: 6, Train: label_loss: 0.08706451952457428, precision: 0.3116028708133785, recall: 0.8967297762476941, f1: 0.46249445180367194\n",
            "epoch: 802, step: 7, Train: label_loss: 0.07758498936891556, precision: 0.3142350856467623, recall: 0.9220103986133583, f1: 0.46872246692239605\n",
            "epoch: 802, step: 8, Train: label_loss: 0.07597597688436508, precision: 0.3258293838862366, recall: 0.91362126245832, f1: 0.4803493449393689\n",
            "epoch: 802, step: 9, Train: label_loss: 0.07205156981945038, precision: 0.3313644418192362, recall: 0.9136807817588087, f1: 0.4863459037320267\n",
            "epoch: 802, step: 10, Train: label_loss: 0.0748278796672821, precision: 0.32475131655937245, recall: 0.920398009950096, f1: 0.4801038061897742\n",
            "epoch: 802, step: 11, Train: label_loss: 0.08255834877490997, precision: 0.3161676646706397, recall: 0.8949152542371364, f1: 0.4672566371295185\n",
            "epoch: 802, step: 12, Train: label_loss: 0.08345136046409607, precision: 0.3392645314353298, recall: 0.9108280254775619, f1: 0.4943820224323197\n",
            "epoch: 802, step: 13, Train: label_loss: 0.07827131450176239, precision: 0.33769322235432, recall: 0.9176090468496094, f1: 0.49369839196410475\n",
            "epoch: 802, step: 14, Train: label_loss: 0.08980531990528107, precision: 0.3365212193663875, recall: 0.8922345483358332, f1: 0.4887152777379621\n",
            "epoch: 802, step: 15, Train: label_loss: 0.09937580674886703, precision: 0.31303288672348883, recall: 0.8726655348046056, f1: 0.46077991927978834\n",
            "epoch: 802, step: 16, Train: label_loss: 0.07905206084251404, precision: 0.3376546847377526, recall: 0.9124203821654597, f1: 0.49290322576697926\n",
            "epoch: 802, step: 17, Train: label_loss: 0.07426134496927261, precision: 0.33771667662879035, recall: 0.9127625201937135, f1: 0.49301919716820936\n",
            "epoch: 802, step: 18, Train: label_loss: 0.0766260176897049, precision: 0.3191365227537737, recall: 0.9334470989759499, f1: 0.4756521738750284\n",
            "epoch: 802, step: 19, Train: label_loss: 0.07835748046636581, precision: 0.33195754716979176, recall: 0.9259868421051108, f1: 0.488715277738885\n",
            "epoch: 802, step: 20, Train: label_loss: 0.09875470399856567, precision: 0.3133612941881178, recall: 0.8849407783416438, f1: 0.46283185836841473\n",
            "epoch: 802, step: 21, Train: label_loss: 0.08255788683891296, precision: 0.3254577672770038, recall: 0.912251655628988, f1: 0.4797562037052106\n",
            "epoch: 802, step: 22, Train: label_loss: 0.08946867287158966, precision: 0.302615933412586, recall: 0.8730703259003647, f1: 0.4494481235820407\n",
            "epoch: 802, step: 23, Train: label_loss: 0.08556254208087921, precision: 0.3142016188373573, recall: 0.8970588235292233, f1: 0.4653950953293743\n",
            "epoch: 803, step: 0, Train: label_loss: 0.08556323498487473, precision: 0.3098758131283081, recall: 0.9128919860625586, f1: 0.4626931566950111\n",
            "epoch: 803, step: 1, Train: label_loss: 0.08461914211511612, precision: 0.3297935103244643, recall: 0.9133986928103082, f1: 0.4846120502427279\n",
            "epoch: 803, step: 2, Train: label_loss: 0.11681360751390457, precision: 0.32114564290065073, recall: 0.8696369636962261, f1: 0.46906987089959634\n",
            "epoch: 803, step: 3, Train: label_loss: 0.07247467339038849, precision: 0.33923303834806257, recall: 0.9185303514375529, f1: 0.49547608785371333\n",
            "epoch: 803, step: 4, Train: label_loss: 0.08872004598379135, precision: 0.31594724220621606, recall: 0.9039451114921262, f1: 0.46823633936628395\n",
            "epoch: 803, step: 5, Train: label_loss: 0.08955548703670502, precision: 0.3412462908011667, recall: 0.9055118110234793, f1: 0.4956896551326127\n",
            "epoch: 803, step: 6, Train: label_loss: 0.0833183228969574, precision: 0.3172331544424378, recall: 0.9094017094015538, f1: 0.4703801944797367\n",
            "epoch: 803, step: 7, Train: label_loss: 0.08086329698562622, precision: 0.33333333333331344, recall: 0.8958333333331897, f1: 0.48587570617511816\n",
            "epoch: 803, step: 8, Train: label_loss: 0.08889979124069214, precision: 0.30866425992777924, recall: 0.8724489795916883, f1: 0.4559999999613517\n",
            "epoch: 803, step: 9, Train: label_loss: 0.11858990788459778, precision: 0.34402515723268273, recall: 0.8200899550223657, f1: 0.48471422237745954\n",
            "epoch: 803, step: 10, Train: label_loss: 0.14003252983093262, precision: 0.29890955740857605, recall: 0.7898305084744424, f1: 0.43369008837334094\n",
            "epoch: 803, step: 11, Train: label_loss: 0.12166348844766617, precision: 0.3113735239278862, recall: 0.8505942275041, f1: 0.4558689717532647\n",
            "epoch: 803, step: 12, Train: label_loss: 0.09960930049419403, precision: 0.31200487507615404, recall: 0.8561872909697564, f1: 0.45734702988488246\n",
            "epoch: 803, step: 13, Train: label_loss: 0.10964686423540115, precision: 0.3188228080931748, recall: 0.8595041322312629, f1: 0.4651162790302533\n",
            "epoch: 803, step: 14, Train: label_loss: 0.12107924371957779, precision: 0.2954403497813682, recall: 0.8044217687073462, f1: 0.4321608039807688\n",
            "epoch: 803, step: 15, Train: label_loss: 0.12386459112167358, precision: 0.3006948831332722, recall: 0.8081494057723585, f1: 0.4383057089843725\n",
            "epoch: 803, step: 16, Train: label_loss: 0.14179715514183044, precision: 0.28700711053650374, recall: 0.7474747474746216, f1: 0.41475945815697196\n",
            "epoch: 803, step: 17, Train: label_loss: 0.10583306103944778, precision: 0.31720759338638593, recall: 0.836833602584679, f1: 0.4600355239387816\n",
            "epoch: 803, step: 18, Train: label_loss: 0.12208481132984161, precision: 0.30268918073794226, recall: 0.8053244592344749, f1: 0.4399999999602493\n",
            "epoch: 803, step: 19, Train: label_loss: 0.10597159713506699, precision: 0.3277982779827597, recall: 0.8624595469254267, f1: 0.475044563239904\n",
            "epoch: 803, step: 20, Train: label_loss: 0.1251843273639679, precision: 0.28721432983321266, recall: 0.836330935251648, f1: 0.4275862068584555\n",
            "epoch: 803, step: 21, Train: label_loss: 0.11222673952579498, precision: 0.31637032495399653, recall: 0.8628762541804577, f1: 0.46298788690551534\n",
            "epoch: 803, step: 22, Train: label_loss: 0.10244908928871155, precision: 0.3243243243243044, recall: 0.8627450980390746, f1: 0.47142857138881566\n",
            "epoch: 803, step: 23, Train: label_loss: 0.10722258687019348, precision: 0.302201974183728, recall: 0.861471861471675, f1: 0.4474423833229379\n",
            "epoch: 804, step: 0, Train: label_loss: 0.11022202670574188, precision: 0.31990080595162307, recall: 0.8376623376622017, f1: 0.46298788690478004\n",
            "epoch: 804, step: 1, Train: label_loss: 0.1102089062333107, precision: 0.3176829268292489, recall: 0.8513071895423445, f1: 0.4626998223404843\n",
            "epoch: 804, step: 2, Train: label_loss: 0.10382954776287079, precision: 0.31238447319776264, recall: 0.8637137989777063, f1: 0.4588235293727108\n",
            "epoch: 804, step: 3, Train: label_loss: 0.1087135598063469, precision: 0.29999999999998156, recall: 0.8460207612455283, f1: 0.4429347825700057\n",
            "epoch: 804, step: 4, Train: label_loss: 0.10029630362987518, precision: 0.3279802347127654, recall: 0.8592233009707347, f1: 0.47474295928048776\n",
            "epoch: 804, step: 5, Train: label_loss: 0.10504123568534851, precision: 0.3220651505838769, recall: 0.8646864686467219, f1: 0.4693237796290182\n",
            "epoch: 804, step: 6, Train: label_loss: 0.11753010749816895, precision: 0.30440173589582736, recall: 0.8279932546372971, f1: 0.445149591982408\n",
            "epoch: 804, step: 7, Train: label_loss: 0.11109162122011185, precision: 0.3091905051734444, recall: 0.8804159445405753, f1: 0.45765765761914506\n",
            "epoch: 804, step: 8, Train: label_loss: 0.11667589843273163, precision: 0.31634555624609595, recall: 0.8262987012985671, f1: 0.45752808984755816\n",
            "epoch: 804, step: 9, Train: label_loss: 0.11322201788425446, precision: 0.3058103975534981, recall: 0.8474576271185004, f1: 0.44943820220817976\n",
            "epoch: 804, step: 10, Train: label_loss: 0.08713929355144501, precision: 0.31272509003599563, recall: 0.866888519134631, f1: 0.45963828844798155\n",
            "epoch: 804, step: 11, Train: label_loss: 0.1031712144613266, precision: 0.3339393939393737, recall: 0.8636363636362282, f1: 0.4816433566030964\n",
            "epoch: 804, step: 12, Train: label_loss: 0.10869564116001129, precision: 0.3146135265700293, recall: 0.8527004909982238, f1: 0.4596382884475709\n",
            "epoch: 804, step: 13, Train: label_loss: 0.10506574809551239, precision: 0.31768953068590144, recall: 0.864157119476127, f1: 0.46458424985066227\n",
            "epoch: 804, step: 14, Train: label_loss: 0.10193978250026703, precision: 0.2995139732685116, recall: 0.8694885361550494, f1: 0.4455490284299889\n",
            "epoch: 804, step: 15, Train: label_loss: 0.09636449813842773, precision: 0.3117824773413709, recall: 0.8760611205431449, f1: 0.45989304808958464\n",
            "epoch: 804, step: 16, Train: label_loss: 0.09393255412578583, precision: 0.3113553113552923, recall: 0.8514190317193904, f1: 0.4559678139974017\n",
            "epoch: 804, step: 17, Train: label_loss: 0.10103115439414978, precision: 0.31476997578690585, recall: 0.8768971332207627, f1: 0.46325167033970366\n",
            "epoch: 804, step: 18, Train: label_loss: 0.08932702243328094, precision: 0.32424242424240457, recall: 0.8713355048858515, f1: 0.4726148409498272\n",
            "epoch: 804, step: 19, Train: label_loss: 0.10617774724960327, precision: 0.32521315468938333, recall: 0.8754098360654302, f1: 0.47424511541338865\n",
            "epoch: 804, step: 20, Train: label_loss: 0.09401004016399384, precision: 0.3463151587776904, recall: 0.9131121642968542, f1: 0.5021720242867558\n",
            "epoch: 804, step: 21, Train: label_loss: 0.09434644877910614, precision: 0.30550514216574076, recall: 0.8797909407663972, f1: 0.45352492138064593\n",
            "epoch: 804, step: 22, Train: label_loss: 0.09897622466087341, precision: 0.31028368794324407, recall: 0.898972602739572, f1: 0.4613356765874681\n",
            "epoch: 804, step: 23, Train: label_loss: 0.10867499560117722, precision: 0.3296130952380707, recall: 0.8824701195217366, f1: 0.47995666301560486\n",
            "epoch: 805, step: 0, Train: label_loss: 0.09433573484420776, precision: 0.3249400479616112, recall: 0.8988391376449587, f1: 0.4773227652625832\n",
            "epoch: 805, step: 1, Train: label_loss: 0.09618980437517166, precision: 0.295646916565883, recall: 0.8548951048949553, f1: 0.4393530996922321\n",
            "epoch: 805, step: 2, Train: label_loss: 0.10459470748901367, precision: 0.32822085889568536, recall: 0.8813838550245664, f1: 0.4783191774302395\n",
            "epoch: 805, step: 3, Train: label_loss: 0.09042403101921082, precision: 0.3166963755198861, recall: 0.8942953020132727, f1: 0.46774901268621294\n",
            "epoch: 805, step: 4, Train: label_loss: 0.08931485563516617, precision: 0.32788868723530984, recall: 0.8630573248406268, f1: 0.47523016216961195\n",
            "epoch: 805, step: 5, Train: label_loss: 0.09811361879110336, precision: 0.3042168674698612, recall: 0.8767361111109588, f1: 0.4516994632890812\n",
            "epoch: 805, step: 6, Train: label_loss: 0.10080014169216156, precision: 0.3218673218673021, recall: 0.8646864686467219, f1: 0.46911369736418224\n",
            "epoch: 805, step: 7, Train: label_loss: 0.10475394874811172, precision: 0.3025362318840397, recall: 0.8851590106005502, f1: 0.4509450944714423\n",
            "epoch: 805, step: 8, Train: label_loss: 0.0959722027182579, precision: 0.2933413317336357, recall: 0.8685612788630783, f1: 0.43856502238373984\n",
            "epoch: 805, step: 9, Train: label_loss: 0.08700601011514664, precision: 0.32640949554894205, recall: 0.91362126245832, f1: 0.48097944902107403\n",
            "epoch: 805, step: 10, Train: label_loss: 0.09440841525793076, precision: 0.3361344537814924, recall: 0.8903020667725134, f1: 0.48801742915406576\n",
            "epoch: 805, step: 11, Train: label_loss: 0.09322917461395264, precision: 0.32639714625443955, recall: 0.8840579710143504, f1: 0.476769431137297\n",
            "epoch: 805, step: 12, Train: label_loss: 0.0922982394695282, precision: 0.3260095011876291, recall: 0.8999999999998524, f1: 0.4786399302137513\n",
            "epoch: 805, step: 13, Train: label_loss: 0.09269043803215027, precision: 0.31299093655587235, recall: 0.885470085469934, f1: 0.46249999996136754\n",
            "epoch: 805, step: 14, Train: label_loss: 0.10593471676111221, precision: 0.31249999999998085, recall: 0.8443708609270124, f1: 0.4561717352020303\n",
            "epoch: 805, step: 15, Train: label_loss: 0.09923252463340759, precision: 0.32733812949638325, recall: 0.8849270664504237, f1: 0.477899343505394\n",
            "epoch: 805, step: 16, Train: label_loss: 0.1119496077299118, precision: 0.3240460327074304, recall: 0.882838283828237, f1: 0.4740806379757408\n",
            "epoch: 805, step: 17, Train: label_loss: 0.09273847937583923, precision: 0.33731343283580073, recall: 0.9025559105429868, f1: 0.49109083003423\n",
            "epoch: 805, step: 18, Train: label_loss: 0.09458658844232559, precision: 0.32055122828038823, recall: 0.8946488294312884, f1: 0.4719894132826883\n",
            "epoch: 805, step: 19, Train: label_loss: 0.10181964933872223, precision: 0.3178016726403633, recall: 0.8971332209104725, f1: 0.46934274367548706\n",
            "epoch: 805, step: 20, Train: label_loss: 0.08935350179672241, precision: 0.3149370125974616, recall: 0.8793969849244757, f1: 0.46378091868904237\n",
            "epoch: 805, step: 21, Train: label_loss: 0.10181911289691925, precision: 0.31208257437763737, recall: 0.8697123519457073, f1: 0.45933869522471926\n",
            "epoch: 805, step: 22, Train: label_loss: 0.10730135440826416, precision: 0.3349397590361244, recall: 0.8755905511809644, f1: 0.4845315903738747\n",
            "epoch: 805, step: 23, Train: label_loss: 0.10341174155473709, precision: 0.31342182890853143, recall: 0.8709016393440838, f1: 0.4609544468156924\n",
            "epoch: 806, step: 0, Train: label_loss: 0.09137055277824402, precision: 0.3086124401913691, recall: 0.8835616438354651, f1: 0.45744680847222685\n",
            "epoch: 806, step: 1, Train: label_loss: 0.08549308776855469, precision: 0.31591591591589696, recall: 0.8679867986797247, f1: 0.4632320563236675\n",
            "epoch: 806, step: 2, Train: label_loss: 0.08654136210680008, precision: 0.3154121863799095, recall: 0.887394957983044, f1: 0.4654032613098776\n",
            "epoch: 806, step: 3, Train: label_loss: 0.09973549097776413, precision: 0.3089820359281252, recall: 0.89739130434767, f1: 0.4596881959529453\n",
            "epoch: 806, step: 4, Train: label_loss: 0.07787599414587021, precision: 0.3339233038347886, recall: 0.9129032258063043, f1: 0.4889848811702427\n",
            "epoch: 806, step: 5, Train: label_loss: 0.10271960496902466, precision: 0.31829268292680984, recall: 0.8515497553016554, f1: 0.46338215708418307\n",
            "epoch: 806, step: 6, Train: label_loss: 0.0985015481710434, precision: 0.31223628691981237, recall: 0.886986301369711, f1: 0.46188140878890693\n",
            "epoch: 806, step: 7, Train: label_loss: 0.09509254992008209, precision: 0.31860036832410565, recall: 0.8425324675323307, f1: 0.4623608017418762\n",
            "epoch: 806, step: 8, Train: label_loss: 0.09112657606601715, precision: 0.32830416415206226, recall: 0.8962108731464751, f1: 0.4805653709854471\n",
            "epoch: 806, step: 9, Train: label_loss: 0.10526160895824432, precision: 0.31318681318679403, recall: 0.8709677419353359, f1: 0.46070947459059886\n",
            "epoch: 806, step: 10, Train: label_loss: 0.10646098852157593, precision: 0.2944377267230777, recall: 0.866548042704472, f1: 0.43953068588267946\n",
            "epoch: 806, step: 11, Train: label_loss: 0.08736535906791687, precision: 0.3142340168877977, recall: 0.8845500848894933, f1: 0.4637294169617204\n",
            "epoch: 806, step: 12, Train: label_loss: 0.10143216699361801, precision: 0.3138554216867281, recall: 0.8741610738253566, f1: 0.46187943258519426\n",
            "epoch: 806, step: 13, Train: label_loss: 0.08924055099487305, precision: 0.3204747774480522, recall: 0.912162162162008, f1: 0.474308300356736\n",
            "epoch: 806, step: 14, Train: label_loss: 0.09755092859268188, precision: 0.3162650602409448, recall: 0.8853288364248085, f1: 0.4660452729305472\n",
            "epoch: 806, step: 15, Train: label_loss: 0.08812378346920013, precision: 0.3198090692123914, recall: 0.9008403361343024, f1: 0.4720387494108689\n",
            "epoch: 806, step: 16, Train: label_loss: 0.08503526449203491, precision: 0.3139255702280724, recall: 0.8834459459457966, f1: 0.4632418068700395\n",
            "epoch: 806, step: 17, Train: label_loss: 0.09109444916248322, precision: 0.34177215189871357, recall: 0.8696319018403573, f1: 0.4906966680684947\n",
            "epoch: 806, step: 18, Train: label_loss: 0.08589910715818405, precision: 0.3365212193663875, recall: 0.8908227848099856, f1: 0.4885032537562514\n",
            "epoch: 806, step: 19, Train: label_loss: 0.09011045843362808, precision: 0.3223487118034558, recall: 0.8805237315874171, f1: 0.47192982452212845\n",
            "epoch: 806, step: 20, Train: label_loss: 0.09898122400045395, precision: 0.3276801938219063, recall: 0.9001663893509317, f1: 0.48046181168373986\n",
            "epoch: 806, step: 21, Train: label_loss: 0.0930575579404831, precision: 0.32349397590359497, recall: 0.8803278688523146, f1: 0.47312775326462087\n",
            "epoch: 806, step: 22, Train: label_loss: 0.09672049432992935, precision: 0.3255131964809193, recall: 0.9128289473682708, f1: 0.47989623861230785\n",
            "epoch: 806, step: 23, Train: label_loss: 0.08942493051290512, precision: 0.3289949385393833, recall: 0.9154929577462947, f1: 0.4840425531525429\n",
            "epoch: 807, step: 0, Train: label_loss: 0.09718051552772522, precision: 0.3281343731253552, recall: 0.8996710526314309, f1: 0.4808791208399128\n",
            "epoch: 807, step: 1, Train: label_loss: 0.08811160176992416, precision: 0.3429084380610208, recall: 0.9095238095236651, f1: 0.4980443285129937\n",
            "epoch: 807, step: 2, Train: label_loss: 0.08061692118644714, precision: 0.32106824925814115, recall: 0.9046822742473403, f1: 0.4739378011001458\n",
            "epoch: 807, step: 3, Train: label_loss: 0.0909600704908371, precision: 0.31081888822472736, recall: 0.9059233449475773, f1: 0.46283934130593385\n",
            "epoch: 807, step: 4, Train: label_loss: 0.08247829228639603, precision: 0.35125448028671735, recall: 0.9032258064514741, f1: 0.5058064515725397\n",
            "epoch: 807, step: 5, Train: label_loss: 0.08290588855743408, precision: 0.3082394783639414, recall: 0.9138840070297163, f1: 0.4609929077636569\n",
            "epoch: 807, step: 6, Train: label_loss: 0.08066847175359726, precision: 0.31585150265171974, recall: 0.911564625850185, f1: 0.46914660827683513\n",
            "epoch: 807, step: 7, Train: label_loss: 0.08318488299846649, precision: 0.33553421368545405, recall: 0.8929712460062471, f1: 0.48778359507369\n",
            "epoch: 807, step: 8, Train: label_loss: 0.07848607003688812, precision: 0.32562277580069243, recall: 0.9242424242422685, f1: 0.48157894732984824\n",
            "epoch: 807, step: 9, Train: label_loss: 0.08736443519592285, precision: 0.34066587395955167, recall: 0.9066455696201097, f1: 0.495246326667253\n",
            "epoch: 807, step: 10, Train: label_loss: 0.08276107907295227, precision: 0.3467933491686255, recall: 0.8888888888887535, f1: 0.49893208026714125\n",
            "epoch: 807, step: 11, Train: label_loss: 0.09120963513851166, precision: 0.3297746144721038, recall: 0.9099836333877397, f1: 0.4841097082761029\n",
            "epoch: 807, step: 12, Train: label_loss: 0.10264524072408676, precision: 0.3136778115501329, recall: 0.8628762541804577, f1: 0.4600980828855079\n",
            "epoch: 807, step: 13, Train: label_loss: 0.09755183756351471, precision: 0.3194029850746078, recall: 0.8931552587644586, f1: 0.47053649952139964\n",
            "epoch: 807, step: 14, Train: label_loss: 0.07893195748329163, precision: 0.3154796939375918, recall: 0.9069373942468854, f1: 0.46812227070402235\n",
            "epoch: 807, step: 15, Train: label_loss: 0.09440670907497406, precision: 0.2999999999999817, recall: 0.8395904436858634, f1: 0.4420485174813858\n",
            "epoch: 807, step: 16, Train: label_loss: 0.08707469701766968, precision: 0.2989064398541738, recall: 0.8601398601397097, f1: 0.4436429215126302\n",
            "epoch: 807, step: 17, Train: label_loss: 0.0880989208817482, precision: 0.32918149466190216, recall: 0.9039087947881264, f1: 0.4826086956129937\n",
            "epoch: 807, step: 18, Train: label_loss: 0.09330132603645325, precision: 0.3115338882282811, recall: 0.9034482758619131, f1: 0.4633068080962205\n",
            "epoch: 807, step: 19, Train: label_loss: 0.08108603209257126, precision: 0.31164991129507325, recall: 0.9165217391302753, f1: 0.46513680490471687\n",
            "epoch: 807, step: 20, Train: label_loss: 0.08219630271196365, precision: 0.33096506808760623, recall: 0.9089430894307464, f1: 0.48524305551637803\n",
            "epoch: 807, step: 21, Train: label_loss: 0.09787368774414062, precision: 0.29970149253729556, recall: 0.9028776978415641, f1: 0.4500224114372133\n",
            "epoch: 807, step: 22, Train: label_loss: 0.08985095471143723, precision: 0.3081986834230815, recall: 0.8818493150683421, f1: 0.4567627494072538\n",
            "epoch: 807, step: 23, Train: label_loss: 0.08703697472810745, precision: 0.33919413919411434, recall: 0.9060665362033452, f1: 0.4936034114741681\n",
            "epoch: 808, step: 0, Train: label_loss: 0.09387730062007904, precision: 0.31941923774952696, recall: 0.8785357737103363, f1: 0.4685004436165733\n",
            "epoch: 808, step: 1, Train: label_loss: 0.09162595868110657, precision: 0.3074183976260945, recall: 0.886986301369711, f1: 0.4565888056029841\n",
            "epoch: 808, step: 2, Train: label_loss: 0.09323787689208984, precision: 0.3377088305489059, recall: 0.9143780290790121, f1: 0.4932461873243975\n",
            "epoch: 808, step: 3, Train: label_loss: 0.09572502970695496, precision: 0.3199999999999812, recall: 0.9204737732654956, f1: 0.47490178957319806\n",
            "epoch: 808, step: 4, Train: label_loss: 0.08673912286758423, precision: 0.3056047197639938, recall: 0.9103690685411404, f1: 0.45759717310720377\n",
            "epoch: 808, step: 5, Train: label_loss: 0.0734860897064209, precision: 0.3236686390532353, recall: 0.9147157190633921, f1: 0.4781468531082008\n",
            "epoch: 808, step: 6, Train: label_loss: 0.08798597753047943, precision: 0.3366804489072453, recall: 0.9149277688602062, f1: 0.49222797923524125\n",
            "epoch: 808, step: 7, Train: label_loss: 0.08796627819538116, precision: 0.3460144927536023, recall: 0.8734756097559644, f1: 0.49567474044374016\n",
            "epoch: 808, step: 8, Train: label_loss: 0.07919604331254959, precision: 0.3285457809694597, recall: 0.8985270049098365, f1: 0.48115687989063205\n",
            "epoch: 808, step: 9, Train: label_loss: 0.08236672729253769, precision: 0.34007134363850533, recall: 0.9022082018926021, f1: 0.4939550949515598\n",
            "epoch: 808, step: 10, Train: label_loss: 0.08712669461965561, precision: 0.3174791914387445, recall: 0.9005059021920909, f1: 0.46945054941196496\n",
            "epoch: 808, step: 11, Train: label_loss: 0.08575163781642914, precision: 0.3177458033572951, recall: 0.886287625417912, f1: 0.46778464250303126\n",
            "epoch: 808, step: 12, Train: label_loss: 0.07719817757606506, precision: 0.3060982830076787, recall: 0.90701754385949, f1: 0.4577246568900723\n",
            "epoch: 808, step: 13, Train: label_loss: 0.07922644168138504, precision: 0.3299881936245378, recall: 0.9285714285712743, f1: 0.4869337978706755\n",
            "epoch: 808, step: 14, Train: label_loss: 0.08046755939722061, precision: 0.32499999999998064, recall: 0.8907014681890879, f1: 0.4762320104274226\n",
            "epoch: 808, step: 15, Train: label_loss: 0.0861595869064331, precision: 0.31744115872056017, recall: 0.8752079866887063, f1: 0.4658990256473426\n",
            "epoch: 808, step: 16, Train: label_loss: 0.08363163471221924, precision: 0.32384341637008757, recall: 0.9054726368157702, f1: 0.4770642201446373\n",
            "epoch: 808, step: 17, Train: label_loss: 0.09283456206321716, precision: 0.31585220500594063, recall: 0.8983050847456104, f1: 0.4673721340002659\n",
            "epoch: 808, step: 18, Train: label_loss: 0.09180048108100891, precision: 0.2945454545454367, recall: 0.8709677419353277, f1: 0.44021739126653764\n",
            "epoch: 808, step: 19, Train: label_loss: 0.08187727630138397, precision: 0.3189604252805482, recall: 0.9278350515462322, f1: 0.47472527468715736\n",
            "epoch: 808, step: 20, Train: label_loss: 0.10088015347719193, precision: 0.31604342581421496, recall: 0.8911564625848823, f1: 0.4666073018312975\n",
            "epoch: 808, step: 21, Train: label_loss: 0.09260079264640808, precision: 0.3315380011968682, recall: 0.8821656050954009, f1: 0.48194867329648233\n",
            "epoch: 808, step: 22, Train: label_loss: 0.0900995135307312, precision: 0.3321407274895449, recall: 0.9012944983817311, f1: 0.48540305006953643\n",
            "epoch: 808, step: 23, Train: label_loss: 0.09081284701824188, precision: 0.3182481751824585, recall: 0.8916155419221081, f1: 0.46906939210749427\n",
            "epoch: 809, step: 0, Train: label_loss: 0.08689920604228973, precision: 0.3158529234478411, recall: 0.859016393442482, f1: 0.46187747902631393\n",
            "epoch: 809, step: 1, Train: label_loss: 0.11454504728317261, precision: 0.2858903265557433, recall: 0.8241563055060702, f1: 0.4245196705930077\n",
            "epoch: 809, step: 2, Train: label_loss: 0.12002094089984894, precision: 0.3276942355889519, recall: 0.8408360128616011, f1: 0.47159603242127657\n",
            "epoch: 809, step: 3, Train: label_loss: 0.11169272661209106, precision: 0.3078335373316825, recall: 0.8613013698628661, f1: 0.4535617673191446\n",
            "epoch: 809, step: 4, Train: label_loss: 0.11799436807632446, precision: 0.3138461538461345, recall: 0.8279220779219435, f1: 0.4551539490899482\n",
            "epoch: 809, step: 5, Train: label_loss: 0.10790012776851654, precision: 0.32349397590359497, recall: 0.8935108153076715, f1: 0.4750110570153275\n",
            "epoch: 809, step: 6, Train: label_loss: 0.11392535269260406, precision: 0.32850241545891734, recall: 0.8788368336024428, f1: 0.47824175820210496\n",
            "epoch: 809, step: 7, Train: label_loss: 0.09963976591825485, precision: 0.3197815533980388, recall: 0.8555194805193416, f1: 0.46554770314055993\n",
            "epoch: 809, step: 8, Train: label_loss: 0.09678172320127487, precision: 0.3250303766706971, recall: 0.8727569331156814, f1: 0.47366091186833725\n",
            "epoch: 809, step: 9, Train: label_loss: 0.0980338603258133, precision: 0.327002967359031, recall: 0.9092409240922591, f1: 0.4810126581888968\n",
            "epoch: 809, step: 10, Train: label_loss: 0.1047331839799881, precision: 0.3188759926694979, recall: 0.8613861386137192, f1: 0.4654480605936031\n",
            "epoch: 809, step: 11, Train: label_loss: 0.10444573312997818, precision: 0.3200483091787246, recall: 0.8745874587457302, f1: 0.468611847882925\n",
            "epoch: 809, step: 12, Train: label_loss: 0.10352090001106262, precision: 0.3149370125974616, recall: 0.898972602739572, f1: 0.4664593513609104\n",
            "epoch: 809, step: 13, Train: label_loss: 0.10050556063652039, precision: 0.32038834951454365, recall: 0.8785357737103363, f1: 0.4695420186357613\n",
            "epoch: 809, step: 14, Train: label_loss: 0.10603967308998108, precision: 0.31391784181481824, recall: 0.8462809917353973, f1: 0.45796064396764197\n",
            "epoch: 809, step: 15, Train: label_loss: 0.08736163377761841, precision: 0.32757593805834856, recall: 0.9046052631577459, f1: 0.48097944902082695\n",
            "epoch: 809, step: 16, Train: label_loss: 0.10198970139026642, precision: 0.3035066505441171, recall: 0.8760907504361473, f1: 0.45083071392671575\n",
            "epoch: 809, step: 17, Train: label_loss: 0.11886204034090042, precision: 0.3185679611650292, recall: 0.8720930232556691, f1: 0.4666666666274312\n",
            "epoch: 809, step: 18, Train: label_loss: 0.0987955629825592, precision: 0.3195195195195003, recall: 0.8971332209104725, f1: 0.47121346320303487\n",
            "epoch: 809, step: 19, Train: label_loss: 0.09523136168718338, precision: 0.3130644190246651, recall: 0.8798646362096649, f1: 0.46181172287421285\n",
            "epoch: 809, step: 20, Train: label_loss: 0.10346980392932892, precision: 0.33333333333331333, recall: 0.8894230769229343, f1: 0.4849279160808757\n",
            "epoch: 809, step: 21, Train: label_loss: 0.11211542785167694, precision: 0.3201701093559951, recall: 0.8739635157544156, f1: 0.4686527345094003\n",
            "epoch: 809, step: 22, Train: label_loss: 0.09460081160068512, precision: 0.30257639304971223, recall: 0.8922261484097362, f1: 0.45190156595766295\n",
            "epoch: 809, step: 23, Train: label_loss: 0.11611907184123993, precision: 0.32466567607724184, recall: 0.8619329388558458, f1: 0.4716675660692119\n",
            "epoch: 810, step: 0, Train: label_loss: 0.09248537570238113, precision: 0.3123515439429743, recall: 0.903780068728367, f1: 0.46425419237131654\n",
            "epoch: 810, step: 1, Train: label_loss: 0.088360495865345, precision: 0.33492537313430837, recall: 0.9033816425119318, f1: 0.48867595814864745\n",
            "epoch: 810, step: 2, Train: label_loss: 0.11717021465301514, precision: 0.2965009208102949, recall: 0.8671454219028963, f1: 0.4419030191751587\n",
            "epoch: 810, step: 3, Train: label_loss: 0.10285810381174088, precision: 0.3212996389891503, recall: 0.8944723618088953, f1: 0.47277556437010176\n",
            "epoch: 810, step: 4, Train: label_loss: 0.08620250225067139, precision: 0.32055122828038823, recall: 0.8857615894038268, f1: 0.47074351073964177\n",
            "epoch: 810, step: 5, Train: label_loss: 0.09090821444988251, precision: 0.32938388625590465, recall: 0.9159802306423531, f1: 0.48453159037499427\n",
            "epoch: 810, step: 6, Train: label_loss: 0.09399619698524475, precision: 0.3231231231231037, recall: 0.8951747088184866, f1: 0.47484554276768975\n",
            "epoch: 810, step: 7, Train: label_loss: 0.10368385910987854, precision: 0.3064220183486051, recall: 0.8549488054606049, f1: 0.4511481314334229\n",
            "epoch: 810, step: 8, Train: label_loss: 0.10453160107135773, precision: 0.3283403235470145, recall: 0.9013157894735359, f1: 0.48133508999155605\n",
            "epoch: 810, step: 9, Train: label_loss: 0.09644496440887451, precision: 0.3216232586311132, recall: 0.8592233009707347, f1: 0.46804759802114193\n",
            "epoch: 810, step: 10, Train: label_loss: 0.08538928627967834, precision: 0.3261390887289972, recall: 0.8845528455283114, f1: 0.47656592199300857\n",
            "epoch: 810, step: 11, Train: label_loss: 0.08685219287872314, precision: 0.3327359617682, recall: 0.8954983922828141, f1: 0.4851916375911166\n",
            "epoch: 810, step: 12, Train: label_loss: 0.09553205966949463, precision: 0.33553025763928485, recall: 0.8874801901741858, f1: 0.48695652169927184\n",
            "epoch: 810, step: 13, Train: label_loss: 0.08833758533000946, precision: 0.31893491124258466, recall: 0.9043624161072308, f1: 0.47156605420462955\n",
            "epoch: 810, step: 14, Train: label_loss: 0.09034396708011627, precision: 0.3285198555956481, recall: 0.8921568627449522, f1: 0.48021108175481325\n",
            "epoch: 810, step: 15, Train: label_loss: 0.0971321165561676, precision: 0.3488649940262635, recall: 0.8943338437977191, f1: 0.501933820329157\n",
            "epoch: 810, step: 16, Train: label_loss: 0.11745487153530121, precision: 0.293103448275844, recall: 0.8607594936707303, f1: 0.43729903533183606\n",
            "epoch: 810, step: 17, Train: label_loss: 0.10714276134967804, precision: 0.32964329643294404, recall: 0.8758169934639091, f1: 0.4789991063051722\n",
            "epoch: 810, step: 18, Train: label_loss: 0.10390331596136093, precision: 0.29848942598185507, recall: 0.87744227353448, f1: 0.445446348023396\n",
            "epoch: 810, step: 19, Train: label_loss: 0.12174525856971741, precision: 0.3236744759555904, recall: 0.8620689655170998, f1: 0.4706409681359721\n",
            "epoch: 810, step: 20, Train: label_loss: 0.10248559713363647, precision: 0.32673860911269026, recall: 0.887622149836989, f1: 0.47765118313328014\n",
            "epoch: 810, step: 21, Train: label_loss: 0.09680210798978806, precision: 0.31607465382297917, recall: 0.8883248730962964, f1: 0.466252220209914\n",
            "epoch: 810, step: 22, Train: label_loss: 0.09129208326339722, precision: 0.312350119904058, recall: 0.8800675675674189, f1: 0.46106194686394786\n",
            "epoch: 810, step: 23, Train: label_loss: 0.10204548388719559, precision: 0.3081525804038662, recall: 0.867368421052449, f1: 0.4547461368266073\n",
            "epoch: 811, step: 0, Train: label_loss: 0.10147587209939957, precision: 0.3067150635208526, recall: 0.860780984719718, f1: 0.45227475464453926\n",
            "epoch: 811, step: 1, Train: label_loss: 0.09062133729457855, precision: 0.3131009615384427, recall: 0.8712374581938341, f1: 0.4606542882015589\n",
            "epoch: 811, step: 2, Train: label_loss: 0.08578909933567047, precision: 0.3254156769596006, recall: 0.8896103896102451, f1: 0.47652173909117423\n",
            "epoch: 811, step: 3, Train: label_loss: 0.08598662912845612, precision: 0.3202846975088778, recall: 0.8881578947366959, f1: 0.4707933739801807\n",
            "epoch: 811, step: 4, Train: label_loss: 0.08572766184806824, precision: 0.3167366526694471, recall: 0.8844221105526157, f1: 0.46643109536748745\n",
            "epoch: 811, step: 5, Train: label_loss: 0.10675634443759918, precision: 0.30773918342472223, recall: 0.8444816053510293, f1: 0.45109423846013974\n",
            "epoch: 811, step: 6, Train: label_loss: 0.10025307536125183, precision: 0.32653061224487834, recall: 0.8816855753645247, f1: 0.4765659219929279\n",
            "epoch: 811, step: 7, Train: label_loss: 0.07055331766605377, precision: 0.34513274336281147, recall: 0.9183673469386313, f1: 0.5017152658264578\n",
            "epoch: 811, step: 8, Train: label_loss: 0.10175548493862152, precision: 0.3182093163944151, recall: 0.8665568369026578, f1: 0.46548672562438614\n",
            "epoch: 811, step: 9, Train: label_loss: 0.08841811120510101, precision: 0.33038869257948583, recall: 0.9257425742572729, f1: 0.4869791666278561\n",
            "epoch: 811, step: 10, Train: label_loss: 0.09798894822597504, precision: 0.2921415716856453, recall: 0.8774774774773193, f1: 0.43834383434592133\n",
            "epoch: 811, step: 11, Train: label_loss: 0.09946614503860474, precision: 0.31625967837996927, recall: 0.8791390728475365, f1: 0.4651773981213606\n",
            "epoch: 811, step: 12, Train: label_loss: 0.08870872855186462, precision: 0.320597014925354, recall: 0.9010067114092447, f1: 0.4729194187195016\n",
            "epoch: 811, step: 13, Train: label_loss: 0.09626079350709915, precision: 0.30922242314645515, recall: 0.8860103626941475, f1: 0.4584450401760801\n",
            "epoch: 811, step: 14, Train: label_loss: 0.07845916599035263, precision: 0.3365041617122273, recall: 0.9173419773094137, f1: 0.4923879947410262\n",
            "epoch: 811, step: 15, Train: label_loss: 0.09890344738960266, precision: 0.3194278903456305, recall: 0.9008403361343024, f1: 0.47162340515268636\n",
            "epoch: 811, step: 16, Train: label_loss: 0.09277969598770142, precision: 0.31362007168456907, recall: 0.9005145797597083, f1: 0.4652193176399759\n",
            "epoch: 811, step: 17, Train: label_loss: 0.08721175789833069, precision: 0.3110447761193844, recall: 0.8815566835869912, f1: 0.45984112970544394\n",
            "epoch: 811, step: 18, Train: label_loss: 0.09159283339977264, precision: 0.3259036144578117, recall: 0.9001663893509317, f1: 0.4785493144235536\n",
            "epoch: 811, step: 19, Train: label_loss: 0.09931007027626038, precision: 0.32934847579197074, recall: 0.8830128205126789, f1: 0.4797562037044001\n",
            "epoch: 811, step: 20, Train: label_loss: 0.1000840812921524, precision: 0.32828588734098557, recall: 0.8929159802304953, f1: 0.480070859128051\n",
            "epoch: 811, step: 21, Train: label_loss: 0.08037040382623672, precision: 0.3357058125741201, recall: 0.9041533546324434, f1: 0.48961937712309744\n",
            "epoch: 811, step: 22, Train: label_loss: 0.09311742335557938, precision: 0.30440024110908354, recall: 0.8797909407663972, f1: 0.452306314337044\n",
            "epoch: 811, step: 23, Train: label_loss: 0.1188850998878479, precision: 0.31625183016103103, recall: 0.874493927125329, f1: 0.4645161289931976\n",
            "epoch: 812, step: 0, Train: label_loss: 0.11549625545740128, precision: 0.2950121654501037, recall: 0.8479020979019496, f1: 0.4377256317306145\n",
            "epoch: 812, step: 1, Train: label_loss: 0.0762244164943695, precision: 0.3303571428571232, recall: 0.8966074313407275, f1: 0.482818616750516\n",
            "epoch: 812, step: 2, Train: label_loss: 0.096003457903862, precision: 0.30699638118212863, recall: 0.8821490467936078, f1: 0.45548098430170064\n",
            "epoch: 812, step: 3, Train: label_loss: 0.08942017704248428, precision: 0.3357314148680854, recall: 0.8846761453395127, f1: 0.4867448934846284\n",
            "epoch: 812, step: 4, Train: label_loss: 0.0954594612121582, precision: 0.30476190476188664, recall: 0.9110320284695888, f1: 0.4567350579463354\n",
            "epoch: 812, step: 5, Train: label_loss: 0.08457828313112259, precision: 0.32900943396224475, recall: 0.9192751235583329, f1: 0.4845853234522363\n",
            "epoch: 812, step: 6, Train: label_loss: 0.09553500264883041, precision: 0.3377088305489059, recall: 0.9055999999998551, f1: 0.49196001734413486\n",
            "epoch: 812, step: 7, Train: label_loss: 0.0892498642206192, precision: 0.3164251207729277, recall: 0.8836424957839993, f1: 0.46598488213098194\n",
            "epoch: 812, step: 8, Train: label_loss: 0.088950015604496, precision: 0.30982519590112656, recall: 0.8801369863012191, f1: 0.4583147569832898\n",
            "epoch: 812, step: 9, Train: label_loss: 0.06553982198238373, precision: 0.3149560117301868, recall: 0.9132653061222936, f1: 0.46838203223395675\n",
            "epoch: 812, step: 10, Train: label_loss: 0.09048879891633987, precision: 0.3120143454871302, recall: 0.8787878787877308, f1: 0.46052051165074365\n",
            "epoch: 812, step: 11, Train: label_loss: 0.09174840152263641, precision: 0.3285799168151914, recall: 0.8933764135701302, f1: 0.4804517810205878\n",
            "epoch: 812, step: 12, Train: label_loss: 0.10531524568796158, precision: 0.3281249999999803, recall: 0.8708133971290477, f1: 0.47664775203353305\n",
            "epoch: 812, step: 13, Train: label_loss: 0.08573877811431885, precision: 0.32796660703635494, recall: 0.8814102564101151, f1: 0.47805302038633135\n",
            "epoch: 812, step: 14, Train: label_loss: 0.08866502344608307, precision: 0.31398104265400983, recall: 0.9028960817715668, f1: 0.46593406589573555\n",
            "epoch: 812, step: 15, Train: label_loss: 0.08600138127803802, precision: 0.3193779904306029, recall: 0.87684729064025, f1: 0.46821569483148856\n",
            "epoch: 812, step: 16, Train: label_loss: 0.09299454838037491, precision: 0.3287342531493504, recall: 0.9118136439266369, f1: 0.4832451498728198\n",
            "epoch: 812, step: 17, Train: label_loss: 0.09544505178928375, precision: 0.318452380952362, recall: 0.8901830282860415, f1: 0.4690925032491786\n",
            "epoch: 812, step: 18, Train: label_loss: 0.10525534301996231, precision: 0.34435096153844086, recall: 0.9124203821654597, f1: 0.49999999996017186\n",
            "epoch: 812, step: 19, Train: label_loss: 0.0790286436676979, precision: 0.3414344991108274, recall: 0.9215999999998524, f1: 0.4982698961542782\n",
            "epoch: 812, step: 20, Train: label_loss: 0.09276915341615677, precision: 0.33173939031677635, recall: 0.9039087947881264, f1: 0.4853519894665813\n",
            "epoch: 812, step: 21, Train: label_loss: 0.09357362985610962, precision: 0.3042693926638422, recall: 0.8846153846152299, f1: 0.45279642054352914\n",
            "epoch: 812, step: 22, Train: label_loss: 0.10052971541881561, precision: 0.31094978826374403, recall: 0.8726655348046056, f1: 0.4585191792654128\n",
            "epoch: 812, step: 23, Train: label_loss: 0.08735094964504242, precision: 0.3073561544063869, recall: 0.8997867803836035, f1: 0.45819761125406683\n",
            "epoch: 813, step: 0, Train: label_loss: 0.08685755729675293, precision: 0.30186410102223077, recall: 0.8807017543858103, f1: 0.44961934613300936\n",
            "epoch: 813, step: 1, Train: label_loss: 0.0826549232006073, precision: 0.327002967359031, recall: 0.9018003273320946, f1: 0.47996515675532364\n",
            "epoch: 813, step: 2, Train: label_loss: 0.10468055307865143, precision: 0.29524397776403366, recall: 0.8313043478259423, f1: 0.43573381946903006\n",
            "epoch: 813, step: 3, Train: label_loss: 0.08403287082910538, precision: 0.31691394658751826, recall: 0.8944723618088953, f1: 0.46801051705159635\n",
            "epoch: 813, step: 4, Train: label_loss: 0.08725790679454803, precision: 0.3218116805720905, recall: 0.8881578947366959, f1: 0.4724409448428027\n",
            "epoch: 813, step: 5, Train: label_loss: 0.08482014387845993, precision: 0.3201911589008172, recall: 0.8903654485048355, f1: 0.47100175743029504\n",
            "epoch: 813, step: 6, Train: label_loss: 0.08642786741256714, precision: 0.31622911694508854, recall: 0.8877721943047089, f1: 0.46634403867658036\n",
            "epoch: 813, step: 7, Train: label_loss: 0.08476097881793976, precision: 0.3189706762417523, recall: 0.8795379537952344, f1: 0.46815985942510424\n",
            "epoch: 813, step: 8, Train: label_loss: 0.0897398591041565, precision: 0.32342449464920786, recall: 0.9158249158247616, f1: 0.47803163440778085\n",
            "epoch: 813, step: 9, Train: label_loss: 0.08181005716323853, precision: 0.3032448377580942, recall: 0.901754385964754, f1: 0.45386313462013156\n",
            "epoch: 813, step: 10, Train: label_loss: 0.08587634563446045, precision: 0.31696969696967775, recall: 0.8731218697828258, f1: 0.4650955980044529\n",
            "epoch: 813, step: 11, Train: label_loss: 0.09763719141483307, precision: 0.3269230769230573, recall: 0.8703999999998607, f1: 0.47531673215772635\n",
            "epoch: 813, step: 12, Train: label_loss: 0.07988497614860535, precision: 0.33590963139118096, recall: 0.9083601286172173, f1: 0.49045138884942946\n",
            "epoch: 813, step: 13, Train: label_loss: 0.07739342749118805, precision: 0.35419126328215145, recall: 0.9160305343510051, f1: 0.510855683229215\n",
            "epoch: 813, step: 14, Train: label_loss: 0.0870044082403183, precision: 0.32838479809974297, recall: 0.9095394736840609, f1: 0.4825479929801746\n",
            "epoch: 813, step: 15, Train: label_loss: 0.099880650639534, precision: 0.32115038945474406, recall: 0.881578947368276, f1: 0.470794905538329\n",
            "epoch: 813, step: 16, Train: label_loss: 0.09494730830192566, precision: 0.3039568345323559, recall: 0.8863636363634814, f1: 0.45267857139050105\n",
            "epoch: 813, step: 17, Train: label_loss: 0.09838739037513733, precision: 0.31919905771493995, recall: 0.9078726968172683, f1: 0.47233115464556213\n",
            "epoch: 813, step: 18, Train: label_loss: 0.09181657433509827, precision: 0.34097767048881467, recall: 0.8773291925464476, f1: 0.49109083003352894\n",
            "epoch: 813, step: 19, Train: label_loss: 0.10790564864873886, precision: 0.31711711711709806, recall: 0.8859060402683077, f1: 0.4670499778470268\n",
            "epoch: 813, step: 20, Train: label_loss: 0.08345802128314972, precision: 0.3387193297426488, recall: 0.8955696202530228, f1: 0.4915327832862305\n",
            "epoch: 813, step: 21, Train: label_loss: 0.079299196600914, precision: 0.3060498220640388, recall: 0.8911917098444055, f1: 0.45562913903475083\n",
            "epoch: 813, step: 22, Train: label_loss: 0.09395581483840942, precision: 0.29843561973524074, recall: 0.8872987477637052, f1: 0.4466456550726021\n",
            "epoch: 813, step: 23, Train: label_loss: 0.10720418393611908, precision: 0.3235077376565716, recall: 0.8904665314399817, f1: 0.47459459455544895\n",
            "epoch: 814, step: 0, Train: label_loss: 0.08297082781791687, precision: 0.3244837758111903, recall: 0.9243697478990043, f1: 0.4803493449396608\n",
            "epoch: 814, step: 1, Train: label_loss: 0.096462681889534, precision: 0.31204819277106555, recall: 0.885470085469934, f1: 0.46146993314627854\n",
            "epoch: 814, step: 2, Train: label_loss: 0.09101296961307526, precision: 0.323232323232304, recall: 0.8962108731464751, f1: 0.47510917026667415\n",
            "epoch: 814, step: 3, Train: label_loss: 0.10426671802997589, precision: 0.32621951219510203, recall: 0.8713355048858515, f1: 0.4747116237402646\n",
            "epoch: 814, step: 4, Train: label_loss: 0.08090665936470032, precision: 0.31766805472930887, recall: 0.9050847457625584, f1: 0.47027741079373053\n",
            "epoch: 814, step: 5, Train: label_loss: 0.0809016078710556, precision: 0.331563421828889, recall: 0.9183006535946211, f1: 0.4872128304767978\n",
            "epoch: 814, step: 6, Train: label_loss: 0.07312028110027313, precision: 0.3250591016548271, recall: 0.906095551894414, f1: 0.478468899482626\n",
            "epoch: 814, step: 7, Train: label_loss: 0.07903830707073212, precision: 0.3032296650717522, recall: 0.8848167539265471, f1: 0.45167037858109554\n",
            "epoch: 814, step: 8, Train: label_loss: 0.0822155624628067, precision: 0.33195266272187385, recall: 0.8961661341851603, f1: 0.484455958509734\n",
            "epoch: 814, step: 9, Train: label_loss: 0.08276471495628357, precision: 0.3271531100478273, recall: 0.885113268608271, f1: 0.4777292576024717\n",
            "epoch: 814, step: 10, Train: label_loss: 0.0910375565290451, precision: 0.303933253873641, recall: 0.9026548672564774, f1: 0.45474810517849895\n",
            "epoch: 814, step: 11, Train: label_loss: 0.08378676325082779, precision: 0.32537313432833875, recall: 0.8934426229506731, f1: 0.4770240699827017\n",
            "epoch: 814, step: 12, Train: label_loss: 0.0882076770067215, precision: 0.33076923076921116, recall: 0.9089430894307464, f1: 0.48503253792178774\n",
            "epoch: 814, step: 13, Train: label_loss: 0.08773718774318695, precision: 0.31316725978645826, recall: 0.8949152542371364, f1: 0.46397188045364496\n",
            "epoch: 814, step: 14, Train: label_loss: 0.09452725946903229, precision: 0.3249249249249054, recall: 0.8839869281044307, f1: 0.47518664906034375\n",
            "epoch: 814, step: 15, Train: label_loss: 0.09401026368141174, precision: 0.3085169743894992, recall: 0.8993055555553994, f1: 0.45942350328786424\n",
            "epoch: 814, step: 16, Train: label_loss: 0.09275303781032562, precision: 0.32258064516127105, recall: 0.8940397350991897, f1: 0.47410008775730234\n",
            "epoch: 814, step: 17, Train: label_loss: 0.07491129636764526, precision: 0.34094903339189564, recall: 0.9179810725550602, f1: 0.49722340876011994\n",
            "epoch: 814, step: 18, Train: label_loss: 0.07034695148468018, precision: 0.32688927943759066, recall: 0.9331103678928205, f1: 0.48416485896370137\n",
            "epoch: 814, step: 19, Train: label_loss: 0.08823511749505997, precision: 0.33113772455087837, recall: 0.9006514657978989, f1: 0.48423817859462137\n",
            "epoch: 814, step: 20, Train: label_loss: 0.08174488693475723, precision: 0.3347131874630198, recall: 0.9233278955952816, f1: 0.4913194444053474\n",
            "epoch: 814, step: 21, Train: label_loss: 0.07482088357210159, precision: 0.3126826417299642, recall: 0.9272097053724562, f1: 0.46765734261958414\n",
            "epoch: 814, step: 22, Train: label_loss: 0.08443164825439453, precision: 0.32538736591178036, recall: 0.9191919191917644, f1: 0.4806338027782409\n",
            "epoch: 814, step: 23, Train: label_loss: 0.07209794223308563, precision: 0.3217893217892986, recall: 0.9102040816324674, f1: 0.47547974409781557\n",
            "epoch: 815, step: 0, Train: label_loss: 0.08475176990032196, precision: 0.3060982830076787, recall: 0.8944636678199144, f1: 0.45610939563907477\n",
            "epoch: 815, step: 1, Train: label_loss: 0.07710262387990952, precision: 0.32725132430839743, recall: 0.9235880398669561, f1: 0.48326814424641595\n",
            "epoch: 815, step: 2, Train: label_loss: 0.07667216658592224, precision: 0.31668625146884155, recall: 0.9135593220337433, f1: 0.4703315880943635\n",
            "epoch: 815, step: 3, Train: label_loss: 0.08132591843605042, precision: 0.34109916367978843, recall: 0.9034810126580848, f1: 0.49522983517265523\n",
            "epoch: 815, step: 4, Train: label_loss: 0.08066956698894501, precision: 0.3305736250739012, recall: 0.9224422442242701, f1: 0.48672181101901524\n",
            "epoch: 815, step: 5, Train: label_loss: 0.08365510404109955, precision: 0.3137951450562277, recall: 0.8967851099829277, f1: 0.4649122806633095\n",
            "epoch: 815, step: 6, Train: label_loss: 0.07413115352392197, precision: 0.31591591591589696, recall: 0.8752079866887063, f1: 0.4642541923705151\n",
            "epoch: 815, step: 7, Train: label_loss: 0.08655491471290588, precision: 0.32913669064746226, recall: 0.8912337662336215, f1: 0.48073555162431303\n",
            "epoch: 815, step: 8, Train: label_loss: 0.08315591514110565, precision: 0.33019423190109887, recall: 0.9092382495946661, f1: 0.48445595851009404\n",
            "epoch: 815, step: 9, Train: label_loss: 0.0752679854631424, precision: 0.3102639296187501, recall: 0.9232111692843066, f1: 0.4644424933775826\n",
            "epoch: 815, step: 10, Train: label_loss: 0.09365575015544891, precision: 0.3216867469879324, recall: 0.8870431893686234, f1: 0.472148541074955\n",
            "epoch: 815, step: 11, Train: label_loss: 0.08538654446601868, precision: 0.3365098272781217, recall: 0.9039999999998553, f1: 0.49045138884931\n",
            "epoch: 815, step: 12, Train: label_loss: 0.09251455217599869, precision: 0.3257756563245629, recall: 0.9130434782607169, f1: 0.48021108175538946\n",
            "epoch: 815, step: 13, Train: label_loss: 0.08575446903705597, precision: 0.32770066385031216, recall: 0.8901639344260835, f1: 0.47904719890195496\n",
            "epoch: 815, step: 14, Train: label_loss: 0.08246514201164246, precision: 0.3104066985645747, recall: 0.8994800693239342, f1: 0.4615384615002732\n",
            "epoch: 815, step: 15, Train: label_loss: 0.08439585566520691, precision: 0.33808674985143566, recall: 0.9177419354837228, f1: 0.49413808072483006\n",
            "epoch: 815, step: 16, Train: label_loss: 0.08926193416118622, precision: 0.3389121338911931, recall: 0.8873239436618329, f1: 0.4904844290257024\n",
            "epoch: 815, step: 17, Train: label_loss: 0.08890385925769806, precision: 0.3367655966080959, recall: 0.8938906752410137, f1: 0.4892212934049907\n",
            "epoch: 815, step: 18, Train: label_loss: 0.08663763105869293, precision: 0.3158834027364476, recall: 0.8924369747897659, f1: 0.4666080843198665\n",
            "epoch: 815, step: 19, Train: label_loss: 0.08753809332847595, precision: 0.310262529832917, recall: 0.8919382504286634, f1: 0.4603806993861885\n",
            "epoch: 815, step: 20, Train: label_loss: 0.0713602676987648, precision: 0.32098765432096876, recall: 0.9130434782607169, f1: 0.47498912566829693\n",
            "epoch: 815, step: 21, Train: label_loss: 0.08832815289497375, precision: 0.3036244800950503, recall: 0.9044247787609018, f1: 0.4546263344818994\n",
            "epoch: 815, step: 22, Train: label_loss: 0.07646853476762772, precision: 0.33451327433626343, recall: 0.9325657894735307, f1: 0.4924012157665672\n",
            "epoch: 815, step: 23, Train: label_loss: 0.08574047684669495, precision: 0.31067251461986034, recall: 0.9023354564753923, f1: 0.46220772154966494\n",
            "epoch: 816, step: 0, Train: label_loss: 0.07887907326221466, precision: 0.3236686390532353, recall: 0.9056291390726977, f1: 0.4768962510509637\n",
            "epoch: 816, step: 1, Train: label_loss: 0.09296709299087524, precision: 0.3239352129573891, recall: 0.8925619834709267, f1: 0.47535211263693905\n",
            "epoch: 816, step: 2, Train: label_loss: 0.08041250705718994, precision: 0.323512080141407, recall: 0.9226890756300969, f1: 0.47905759158455347\n",
            "epoch: 816, step: 3, Train: label_loss: 0.08372972905635834, precision: 0.3140298507462499, recall: 0.8870151770656176, f1: 0.4638447971394694\n",
            "epoch: 816, step: 4, Train: label_loss: 0.08666905015707016, precision: 0.3240190249702542, recall: 0.9008264462808427, f1: 0.4766069085749513\n",
            "epoch: 816, step: 5, Train: label_loss: 0.07717589288949966, precision: 0.3185011709601687, recall: 0.9235993208826954, f1: 0.4736612973061871\n",
            "epoch: 816, step: 6, Train: label_loss: 0.0866377204656601, precision: 0.32544378698222926, recall: 0.9090909090907587, f1: 0.47930283220514236\n",
            "epoch: 816, step: 7, Train: label_loss: 0.09046243131160736, precision: 0.31345926800470403, recall: 0.9045996592843433, f1: 0.4655852695803239\n",
            "epoch: 816, step: 8, Train: label_loss: 0.08203592896461487, precision: 0.3244523386619109, recall: 0.914858096827894, f1: 0.47902097898228496\n",
            "epoch: 816, step: 9, Train: label_loss: 0.08242787420749664, precision: 0.32352941176468686, recall: 0.9121061359865816, f1: 0.47763786361740396\n",
            "epoch: 816, step: 10, Train: label_loss: 0.08203631639480591, precision: 0.31519138755978976, recall: 0.8932203389828994, f1: 0.46595932798969264\n",
            "epoch: 816, step: 11, Train: label_loss: 0.0798288881778717, precision: 0.3478002378121077, recall: 0.8986175115205992, f1: 0.5015002142760526\n",
            "epoch: 816, step: 12, Train: label_loss: 0.07978744804859161, precision: 0.3453791469194108, recall: 0.9095163806550842, f1: 0.5006440532017963\n",
            "epoch: 816, step: 13, Train: label_loss: 0.06961048394441605, precision: 0.32430841671569605, recall: 0.9291736930858466, f1: 0.4808027922827176\n",
            "epoch: 816, step: 14, Train: label_loss: 0.06983000040054321, precision: 0.34084173088320446, recall: 0.9199999999998527, f1: 0.49740484425116416\n",
            "epoch: 816, step: 15, Train: label_loss: 0.0873425230383873, precision: 0.31610219845512083, recall: 0.9140893470788807, f1: 0.46975717435470876\n",
            "epoch: 816, step: 16, Train: label_loss: 0.08884795010089874, precision: 0.3187463039621337, recall: 0.9151103565363471, f1: 0.4728070175054987\n",
            "epoch: 816, step: 17, Train: label_loss: 0.10600589215755463, precision: 0.32185990338162307, recall: 0.8780889621085868, f1: 0.47105612015513426\n",
            "epoch: 816, step: 18, Train: label_loss: 0.11391767114400864, precision: 0.3191358024691161, recall: 0.829855537720573, f1: 0.46098974583589647\n",
            "epoch: 816, step: 19, Train: label_loss: 0.09437854588031769, precision: 0.3183165382335318, recall: 0.9086294416242117, f1: 0.4714661983811989\n",
            "epoch: 816, step: 20, Train: label_loss: 0.11955919861793518, precision: 0.2944823310601181, recall: 0.839222614840841, f1: 0.4359798072125364\n",
            "epoch: 816, step: 21, Train: label_loss: 0.11341363191604614, precision: 0.3074096754439493, recall: 0.8465430016861978, f1: 0.4510332434469471\n",
            "epoch: 816, step: 22, Train: label_loss: 0.12001362442970276, precision: 0.30607187112761425, recall: 0.8288590604025454, f1: 0.44705882348998044\n",
            "epoch: 816, step: 23, Train: label_loss: 0.10496362298727036, precision: 0.31379821958454646, recall: 0.8685831622174808, f1: 0.4610354223042819\n",
            "epoch: 817, step: 0, Train: label_loss: 0.10983192175626755, precision: 0.32210655235760427, recall: 0.8511326860840046, f1: 0.46734784536216806\n",
            "epoch: 817, step: 1, Train: label_loss: 0.11617165058851242, precision: 0.31674757281551474, recall: 0.871452420701023, f1: 0.4646194926177316\n",
            "epoch: 817, step: 2, Train: label_loss: 0.09470853209495544, precision: 0.31562881562879636, recall: 0.8573797678273868, f1: 0.46140116015696486\n",
            "epoch: 817, step: 3, Train: label_loss: 0.0964689701795578, precision: 0.32728372655775395, recall: 0.8796747967478243, f1: 0.4770723103660749\n",
            "epoch: 817, step: 4, Train: label_loss: 0.10725057125091553, precision: 0.32412523020255835, recall: 0.8627450980390746, f1: 0.4712182061182205\n",
            "epoch: 817, step: 5, Train: label_loss: 0.12236569821834564, precision: 0.3097454996896145, recall: 0.8544520547943741, f1: 0.4546697038333415\n",
            "epoch: 817, step: 6, Train: label_loss: 0.10327774286270142, precision: 0.3196319018404712, recall: 0.8555008210179219, f1: 0.4653863331448128\n",
            "epoch: 817, step: 7, Train: label_loss: 0.10393598675727844, precision: 0.2963194011228761, recall: 0.809199318568857, f1: 0.4337899542986213\n",
            "epoch: 817, step: 8, Train: label_loss: 0.1125866174697876, precision: 0.3136167590880891, recall: 0.8357963875203881, f1: 0.4560931899244363\n",
            "epoch: 817, step: 9, Train: label_loss: 0.10852561891078949, precision: 0.3284493284493084, recall: 0.8691437802906511, f1: 0.47673903407623286\n",
            "epoch: 817, step: 10, Train: label_loss: 0.11992776393890381, precision: 0.2861557478368179, recall: 0.8253119429588546, f1: 0.42496558050325917\n",
            "epoch: 817, step: 11, Train: label_loss: 0.1072593480348587, precision: 0.31985294117645097, recall: 0.8599670510706985, f1: 0.4662795890627148\n",
            "epoch: 817, step: 12, Train: label_loss: 0.12359227240085602, precision: 0.3025577043044103, recall: 0.8178752107924421, f1: 0.44171220396782235\n",
            "epoch: 817, step: 13, Train: label_loss: 0.1165892481803894, precision: 0.31997571341831693, recall: 0.8797996661100367, f1: 0.4692787176812361\n",
            "epoch: 817, step: 14, Train: label_loss: 0.10672546923160553, precision: 0.3274282223579519, recall: 0.8617363344050061, f1: 0.47454625936686934\n",
            "epoch: 817, step: 15, Train: label_loss: 0.11949580907821655, precision: 0.31660470879799774, recall: 0.846026490066085, f1: 0.46077547335978525\n",
            "epoch: 817, step: 16, Train: label_loss: 0.11129371076822281, precision: 0.3112462006078838, recall: 0.8648648648647187, f1: 0.4577559230723477\n",
            "epoch: 817, step: 17, Train: label_loss: 0.10944894701242447, precision: 0.32648125755741675, recall: 0.878048780487662, f1: 0.4759806081578859\n",
            "epoch: 817, step: 18, Train: label_loss: 0.0995202288031578, precision: 0.3237804878048583, recall: 0.8648208469053965, f1: 0.4711623779549942\n",
            "epoch: 817, step: 19, Train: label_loss: 0.09855975210666656, precision: 0.3174019607842943, recall: 0.8547854785477137, f1: 0.4629133154206996\n",
            "epoch: 817, step: 20, Train: label_loss: 0.10029275715351105, precision: 0.31276213301376193, recall: 0.8758389261743497, f1: 0.4609271522790611\n",
            "epoch: 817, step: 21, Train: label_loss: 0.10839049518108368, precision: 0.30006161429449785, recall: 0.8573943661970321, f1: 0.44454586942754953\n",
            "epoch: 817, step: 22, Train: label_loss: 0.09479345381259918, precision: 0.3263931414574203, recall: 0.8824503311256816, f1: 0.47653106835570913\n",
            "epoch: 817, step: 23, Train: label_loss: 0.100766122341156, precision: 0.3045112781954658, recall: 0.8385093167700127, f1: 0.4467733038770247\n",
            "epoch: 818, step: 0, Train: label_loss: 0.08784474432468414, precision: 0.3156007172743386, recall: 0.8814691151918395, f1: 0.464788732355498\n",
            "epoch: 818, step: 1, Train: label_loss: 0.10526827722787857, precision: 0.297198538367826, recall: 0.824324324324185, f1: 0.4368845120469508\n",
            "epoch: 818, step: 2, Train: label_loss: 0.1041654720902443, precision: 0.31563065781530986, recall: 0.8760469011723825, f1: 0.46406388638515156\n",
            "epoch: 818, step: 3, Train: label_loss: 0.11812329292297363, precision: 0.3083538083537894, recall: 0.8508474576269743, f1: 0.4526600540637052\n",
            "epoch: 818, step: 4, Train: label_loss: 0.08739419281482697, precision: 0.3420427553443977, recall: 0.9028213166142784, f1: 0.4961240309678555\n",
            "epoch: 818, step: 5, Train: label_loss: 0.106999970972538, precision: 0.31990231990230034, recall: 0.8576104746316108, f1: 0.4659848821302381\n",
            "epoch: 818, step: 6, Train: label_loss: 0.09811572730541229, precision: 0.3178528347406322, recall: 0.8768718801995212, f1: 0.4665781318776828\n",
            "epoch: 818, step: 7, Train: label_loss: 0.09274642169475555, precision: 0.3281155930162355, recall: 0.8790322580643742, f1: 0.47786058742201176\n",
            "epoch: 818, step: 8, Train: label_loss: 0.09620742499828339, precision: 0.3077844311377061, recall: 0.8986013986012414, f1: 0.45851917926614405\n",
            "epoch: 818, step: 9, Train: label_loss: 0.11094030737876892, precision: 0.3053527980535094, recall: 0.8853615520280624, f1: 0.4540931704729037\n",
            "epoch: 818, step: 10, Train: label_loss: 0.0918702557682991, precision: 0.326347305389202, recall: 0.9023178807945526, f1: 0.47933157427932715\n",
            "epoch: 818, step: 11, Train: label_loss: 0.08407825231552124, precision: 0.3201675643327157, recall: 0.9052453468695592, f1: 0.473032714373381\n",
            "epoch: 818, step: 12, Train: label_loss: 0.09775002300739288, precision: 0.3138424821002199, recall: 0.9053356282270386, f1: 0.4661054496737347\n",
            "epoch: 818, step: 13, Train: label_loss: 0.10650123655796051, precision: 0.317191283292959, recall: 0.8911564625848823, f1: 0.46785714281838225\n",
            "epoch: 818, step: 14, Train: label_loss: 0.08890898525714874, precision: 0.323758228605606, recall: 0.9216354344121087, f1: 0.47918511953632587\n",
            "epoch: 818, step: 15, Train: label_loss: 0.09196220338344574, precision: 0.31464737793849823, recall: 0.8729096989965095, f1: 0.4625609215383234\n",
            "epoch: 818, step: 16, Train: label_loss: 0.09931585192680359, precision: 0.3083941605839228, recall: 0.871134020618407, f1: 0.4555256064303424\n",
            "epoch: 818, step: 17, Train: label_loss: 0.08603570610284805, precision: 0.3267622461170653, recall: 0.8794212218648103, f1: 0.476480836197389\n",
            "epoch: 818, step: 18, Train: label_loss: 0.08837367594242096, precision: 0.32354703415216757, recall: 0.8925619834709267, f1: 0.47493403690021857\n",
            "epoch: 818, step: 19, Train: label_loss: 0.09555280953645706, precision: 0.3207660083781974, recall: 0.880131362889839, f1: 0.47017543855729793\n",
            "epoch: 818, step: 20, Train: label_loss: 0.09103937447071075, precision: 0.3275030156815243, recall: 0.8660287081338331, f1: 0.4752735229360676\n",
            "epoch: 818, step: 21, Train: label_loss: 0.09437347948551178, precision: 0.34232613908870846, recall: 0.890795631825134, f1: 0.49458640099925966\n",
            "epoch: 818, step: 22, Train: label_loss: 0.08676020801067352, precision: 0.3297997644287203, recall: 0.9195402298849064, f1: 0.4854789769875404\n",
            "epoch: 818, step: 23, Train: label_loss: 0.08326548337936401, precision: 0.3228173147468582, recall: 0.9016393442621103, f1: 0.4754186925597171\n",
            "epoch: 819, step: 0, Train: label_loss: 0.09301172941923141, precision: 0.32155688622752565, recall: 0.8788870703762882, f1: 0.47084612008348925\n",
            "epoch: 819, step: 1, Train: label_loss: 0.08490744233131409, precision: 0.3130590339892479, recall: 0.8898305084744254, f1: 0.46316718125832274\n",
            "epoch: 819, step: 2, Train: label_loss: 0.08719973266124725, precision: 0.3249551166965694, recall: 0.8858075040781589, f1: 0.4754816111690933\n",
            "epoch: 819, step: 3, Train: label_loss: 0.06840163469314575, precision: 0.31371394938197095, recall: 0.9080068143098964, f1: 0.4663167103729889\n",
            "epoch: 819, step: 4, Train: label_loss: 0.09648445248603821, precision: 0.31607795371496245, recall: 0.8606965174127925, f1: 0.46236080174240546\n",
            "epoch: 819, step: 5, Train: label_loss: 0.09084045886993408, precision: 0.31944444444442516, recall: 0.8714991762766273, f1: 0.4675209897972026\n",
            "epoch: 819, step: 6, Train: label_loss: 0.08702430129051208, precision: 0.32501485442659983, recall: 0.9086378737540018, f1: 0.4787746170289823\n",
            "epoch: 819, step: 7, Train: label_loss: 0.08049038052558899, precision: 0.338305489260123, recall: 0.9043062200955495, f1: 0.49240121576580204\n",
            "epoch: 819, step: 8, Train: label_loss: 0.09369280934333801, precision: 0.32900943396224475, recall: 0.9223140495866243, f1: 0.4850065188660223\n",
            "epoch: 819, step: 9, Train: label_loss: 0.07068084180355072, precision: 0.3231132075471507, recall: 0.9102990033221079, f1: 0.4769364664538926\n",
            "epoch: 819, step: 10, Train: label_loss: 0.0744590014219284, precision: 0.31753554502367787, recall: 0.9054054054052524, f1: 0.4701754385580037\n",
            "epoch: 819, step: 11, Train: label_loss: 0.09030089527368546, precision: 0.31175771971494587, recall: 0.898972602739572, f1: 0.46296296292468386\n",
            "epoch: 819, step: 12, Train: label_loss: 0.0879640057682991, precision: 0.311942959001764, recall: 0.8928571428569909, f1: 0.46235138701574463\n",
            "epoch: 819, step: 13, Train: label_loss: 0.09004408866167068, precision: 0.3472304943418495, recall: 0.8996913580245525, f1: 0.5010743446095357\n",
            "epoch: 819, step: 14, Train: label_loss: 0.10166767239570618, precision: 0.33373277411621727, recall: 0.9027552674228682, f1: 0.48731408569982876\n",
            "epoch: 819, step: 15, Train: label_loss: 0.10435256361961365, precision: 0.313549160671444, recall: 0.9032815198616747, f1: 0.4655095682750093\n",
            "epoch: 819, step: 16, Train: label_loss: 0.08287171274423599, precision: 0.3331360946745365, recall: 0.9110032362458073, f1: 0.48786828418951395\n",
            "epoch: 819, step: 17, Train: label_loss: 0.0913633406162262, precision: 0.3112305854241152, recall: 0.8800675675674189, f1: 0.45984112970540175\n",
            "epoch: 819, step: 18, Train: label_loss: 0.0960719957947731, precision: 0.29934013197358733, recall: 0.8879003558717281, f1: 0.44773441001159714\n",
            "epoch: 819, step: 19, Train: label_loss: 0.0908607691526413, precision: 0.33313503866744004, recall: 0.9017713365537999, f1: 0.4865334491351901\n",
            "epoch: 819, step: 20, Train: label_loss: 0.09871629625558853, precision: 0.30047789725207286, recall: 0.8982142857141252, f1: 0.45031333926409367\n",
            "epoch: 819, step: 21, Train: label_loss: 0.0842236876487732, precision: 0.3315380011968682, recall: 0.8807631160570936, f1: 0.4817391303950031\n",
            "epoch: 819, step: 22, Train: label_loss: 0.09519651532173157, precision: 0.311711711711693, recall: 0.869346733668196, f1: 0.4588859416056679\n",
            "epoch: 819, step: 23, Train: label_loss: 0.09417746961116791, precision: 0.317090909090886, recall: 0.8989690721647631, f1: 0.4688172042624726\n",
            "epoch: 820, step: 0, Train: label_loss: 0.0864579975605011, precision: 0.32553956834530423, recall: 0.8814935064933633, f1: 0.47548161116897203\n",
            "epoch: 820, step: 1, Train: label_loss: 0.09053467959165573, precision: 0.3285198555956481, recall: 0.9009900990097522, f1: 0.4814814814422786\n",
            "epoch: 820, step: 2, Train: label_loss: 0.0975106805562973, precision: 0.29873264936630667, recall: 0.8623693379789438, f1: 0.44374719852740807\n",
            "epoch: 820, step: 3, Train: label_loss: 0.08663296699523926, precision: 0.3232628398791345, recall: 0.8857615894038268, f1: 0.47366091186870474\n",
            "epoch: 820, step: 4, Train: label_loss: 0.09109969437122345, precision: 0.32209512341960733, recall: 0.8857615894038268, f1: 0.4724061809762997\n",
            "epoch: 820, step: 5, Train: label_loss: 0.08808295428752899, precision: 0.3374777975133015, recall: 0.9018987341770724, f1: 0.4911676001326669\n",
            "epoch: 820, step: 6, Train: label_loss: 0.09664004296064377, precision: 0.2925659472421887, recall: 0.8872727272725659, f1: 0.44003606849287147\n",
            "epoch: 820, step: 7, Train: label_loss: 0.09309335052967072, precision: 0.31518451300663547, recall: 0.8890784982933636, f1: 0.4653863331457708\n",
            "epoch: 820, step: 8, Train: label_loss: 0.09624718129634857, precision: 0.32409638554214915, recall: 0.883415435139428, f1: 0.47421771701665766\n",
            "epoch: 820, step: 9, Train: label_loss: 0.0865866094827652, precision: 0.33174224343673436, recall: 0.9040650406502594, f1: 0.48537756434304724\n",
            "epoch: 820, step: 10, Train: label_loss: 0.08449587225914001, precision: 0.3211284513805329, recall: 0.8685064935063525, f1: 0.46888694124012376\n",
            "epoch: 820, step: 11, Train: label_loss: 0.08841493725776672, precision: 0.3489059727971408, recall: 0.9021406727827366, f1: 0.5031982942028052\n",
            "epoch: 820, step: 12, Train: label_loss: 0.07647473365068436, precision: 0.34515366430258004, recall: 0.9314194577350986, f1: 0.5036653729661079\n",
            "epoch: 820, step: 13, Train: label_loss: 0.08403773605823517, precision: 0.3247607655502198, recall: 0.9065108514188803, f1: 0.47820343457142345\n",
            "epoch: 820, step: 14, Train: label_loss: 0.09900140762329102, precision: 0.30557219892149157, recall: 0.8808290155438893, f1: 0.4537366547659853\n",
            "epoch: 820, step: 15, Train: label_loss: 0.07804577052593231, precision: 0.3195020746887777, recall: 0.8953488372091535, f1: 0.4709480121936088\n",
            "epoch: 820, step: 16, Train: label_loss: 0.09472328424453735, precision: 0.32121573301547546, recall: 0.8983333333331835, f1: 0.47322212463191915\n",
            "epoch: 820, step: 17, Train: label_loss: 0.0872160866856575, precision: 0.2990373044524489, recall: 0.8843416370105187, f1: 0.446942446005357\n",
            "epoch: 820, step: 18, Train: label_loss: 0.0823216587305069, precision: 0.3080625752105711, recall: 0.8873483535527058, f1: 0.4573470298857739\n",
            "epoch: 820, step: 19, Train: label_loss: 0.09626041352748871, precision: 0.3230861965038985, recall: 0.881578947368276, f1: 0.47287163648474545\n",
            "epoch: 820, step: 20, Train: label_loss: 0.09124775975942612, precision: 0.3110447761193844, recall: 0.8982758620688106, f1: 0.46208425716795715\n",
            "epoch: 820, step: 21, Train: label_loss: 0.0977177619934082, precision: 0.31362007168456907, recall: 0.8808724832213286, f1: 0.4625550660405304\n",
            "epoch: 820, step: 22, Train: label_loss: 0.07392220944166183, precision: 0.33215547703178255, recall: 0.9291598023062719, f1: 0.48937093271603976\n",
            "epoch: 820, step: 23, Train: label_loss: 0.09352058172225952, precision: 0.32843497428359086, recall: 0.8662790697672739, f1: 0.47629195520781836\n",
            "epoch: 821, step: 0, Train: label_loss: 0.08965911716222763, precision: 0.32910628019321686, recall: 0.8804523424877414, f1: 0.4791208790812258\n",
            "epoch: 821, step: 1, Train: label_loss: 0.08828513324260712, precision: 0.32956573468171746, recall: 0.8921095008050093, f1: 0.4813205907511766\n",
            "epoch: 821, step: 2, Train: label_loss: 0.09025801718235016, precision: 0.313995215310986, recall: 0.8692052980131011, f1: 0.461335676586628\n",
            "epoch: 821, step: 3, Train: label_loss: 0.10071465373039246, precision: 0.32306763285022205, recall: 0.882838283828237, f1: 0.47303271437275657\n",
            "epoch: 821, step: 4, Train: label_loss: 0.11390773952007294, precision: 0.3234403391883511, recall: 0.8571428571427195, f1: 0.46965699204460964\n",
            "epoch: 821, step: 5, Train: label_loss: 0.11288198828697205, precision: 0.2902633190446852, recall: 0.8315789473682751, f1: 0.43032228775098047\n",
            "epoch: 821, step: 6, Train: label_loss: 0.12010021507740021, precision: 0.3410334346504352, recall: 0.8670788253476248, f1: 0.48952879577095537\n",
            "epoch: 821, step: 7, Train: label_loss: 0.10951196402311325, precision: 0.318042813455638, recall: 0.8666666666665221, f1: 0.46532438474815285\n",
            "epoch: 821, step: 8, Train: label_loss: 0.10733824968338013, precision: 0.33553421368545405, recall: 0.9074675324673851, f1: 0.489921121783505\n",
            "epoch: 821, step: 9, Train: label_loss: 0.12286484241485596, precision: 0.32496940024477816, recall: 0.8820598006643052, f1: 0.474955277241467\n",
            "epoch: 821, step: 10, Train: label_loss: 0.10442019253969193, precision: 0.30515587529974186, recall: 0.897707231040406, f1: 0.4554809843021375\n",
            "epoch: 821, step: 11, Train: label_loss: 0.11448988318443298, precision: 0.3310893512851694, recall: 0.8825448613375395, f1: 0.48153093008934134\n",
            "epoch: 821, step: 12, Train: label_loss: 0.10741917788982391, precision: 0.31696969696967775, recall: 0.8834459459457966, f1: 0.4665477252064095\n",
            "epoch: 821, step: 13, Train: label_loss: 0.10292619466781616, precision: 0.2932375822860387, recall: 0.8844765342958691, f1: 0.44044943816480886\n",
            "epoch: 821, step: 14, Train: label_loss: 0.1062360554933548, precision: 0.3302864107251475, recall: 0.8813008130079867, f1: 0.48049645386100814\n",
            "epoch: 821, step: 15, Train: label_loss: 0.09609990566968918, precision: 0.33313253012046184, recall: 0.9021207177812557, f1: 0.48658161016734114\n",
            "epoch: 821, step: 16, Train: label_loss: 0.08990460634231567, precision: 0.3383233532933929, recall: 0.9054487179485727, f1: 0.49258936351745813\n",
            "epoch: 821, step: 17, Train: label_loss: 0.09346763789653778, precision: 0.31480362537762446, recall: 0.8830508474574774, f1: 0.4641425389367119\n",
            "epoch: 821, step: 18, Train: label_loss: 0.08460111916065216, precision: 0.30285035629451884, recall: 0.8947368421051061, f1: 0.45252883758417844\n",
            "epoch: 821, step: 19, Train: label_loss: 0.0976736843585968, precision: 0.29683698296835176, recall: 0.8516579406630276, f1: 0.4402345511569378\n",
            "epoch: 821, step: 20, Train: label_loss: 0.1045399159193039, precision: 0.3042693926638422, recall: 0.8576271186439224, f1: 0.44917887257559297\n",
            "epoch: 821, step: 21, Train: label_loss: 0.1065097227692604, precision: 0.3017031630170133, recall: 0.8566493955093512, f1: 0.4462438146263031\n",
            "epoch: 821, step: 22, Train: label_loss: 0.08371265232563019, precision: 0.3457382953181065, recall: 0.8834355828219503, f1: 0.4969801552658236\n",
            "epoch: 821, step: 23, Train: label_loss: 0.09364896267652512, precision: 0.306784660766939, recall: 0.8684759916490881, f1: 0.4534059945117801\n",
            "epoch: 822, step: 0, Train: label_loss: 0.08530545234680176, precision: 0.3038049940546787, recall: 0.894921190893013, f1: 0.45361739898564224\n",
            "epoch: 822, step: 1, Train: label_loss: 0.09734289348125458, precision: 0.3380447585394383, recall: 0.9425287356320291, f1: 0.4976159514132003\n",
            "epoch: 822, step: 2, Train: label_loss: 0.09532090276479721, precision: 0.3161367726454519, recall: 0.8739635157544156, f1: 0.4643171805776841\n",
            "epoch: 822, step: 3, Train: label_loss: 0.09685887396335602, precision: 0.2924641148325184, recall: 0.8874773139744305, f1: 0.43994601885606227\n",
            "epoch: 822, step: 4, Train: label_loss: 0.10183122754096985, precision: 0.3397590361445578, recall: 0.8785046728970594, f1: 0.4900086880570422\n",
            "epoch: 822, step: 5, Train: label_loss: 0.08988884091377258, precision: 0.31610219845512083, recall: 0.8866666666665188, f1: 0.4660534384193798\n",
            "epoch: 822, step: 6, Train: label_loss: 0.08668245375156403, precision: 0.3485748218527109, recall: 0.9086687306500141, f1: 0.5038626609040859\n",
            "epoch: 822, step: 7, Train: label_loss: 0.08452081680297852, precision: 0.3242442205097614, recall: 0.9162479061975014, f1: 0.47898423813997953\n",
            "epoch: 822, step: 8, Train: label_loss: 0.09099288284778595, precision: 0.3347255369928201, recall: 0.9077669902911152, f1: 0.48910200519163016\n",
            "epoch: 822, step: 9, Train: label_loss: 0.08147342503070831, precision: 0.33412182140743146, recall: 0.9098228663444589, f1: 0.48875432522018264\n",
            "epoch: 822, step: 10, Train: label_loss: 0.09909705817699432, precision: 0.3247761194029657, recall: 0.8932676518881948, f1: 0.4763572679118131\n",
            "epoch: 822, step: 11, Train: label_loss: 0.09177097678184509, precision: 0.3217286914765713, recall: 0.8948247078462612, f1: 0.47328918318401214\n",
            "epoch: 822, step: 12, Train: label_loss: 0.09824248403310776, precision: 0.32850241545891734, recall: 0.8859934853418752, f1: 0.4792951541455152\n",
            "epoch: 822, step: 13, Train: label_loss: 0.09121013432741165, precision: 0.32429174201324146, recall: 0.8951747088184866, f1: 0.4761061946511812\n",
            "epoch: 822, step: 14, Train: label_loss: 0.10491572320461273, precision: 0.30736714975843554, recall: 0.8821490467936078, f1: 0.45588893860919294\n",
            "epoch: 822, step: 15, Train: label_loss: 0.09531241655349731, precision: 0.3144918821406906, recall: 0.8940170940169411, f1: 0.4653024910646592\n",
            "epoch: 822, step: 16, Train: label_loss: 0.0949535220861435, precision: 0.3148479427549007, recall: 0.9072164948452048, f1: 0.46746347937737726\n",
            "epoch: 822, step: 17, Train: label_loss: 0.0905536562204361, precision: 0.3079249848759644, recall: 0.8806228373700898, f1: 0.4562976243452524\n",
            "epoch: 822, step: 18, Train: label_loss: 0.09322499483823776, precision: 0.3108591885441342, recall: 0.8967297762476941, f1: 0.46167478950537\n",
            "epoch: 822, step: 19, Train: label_loss: 0.10739785432815552, precision: 0.33574879227051113, recall: 0.8755905511809644, f1: 0.48537756434225393\n",
            "epoch: 822, step: 20, Train: label_loss: 0.08770032227039337, precision: 0.3335325762103805, recall: 0.8815165876775858, f1: 0.4839549002203187\n",
            "epoch: 822, step: 21, Train: label_loss: 0.08084388077259064, precision: 0.3074183976260945, recall: 0.8915662650600874, f1: 0.45719329210657633\n",
            "epoch: 822, step: 22, Train: label_loss: 0.0741463229060173, precision: 0.321764705882334, recall: 0.9026402640262536, f1: 0.47441457064638143\n",
            "epoch: 822, step: 23, Train: label_loss: 0.08613145351409912, precision: 0.3115835777125871, recall: 0.8854166666664822, f1: 0.46095444681610465\n",
            "epoch: 823, step: 0, Train: label_loss: 0.08793972432613373, precision: 0.3258426966291942, recall: 0.9183333333331802, f1: 0.48101265818914496\n",
            "epoch: 823, step: 1, Train: label_loss: 0.094956174492836, precision: 0.31801692865778003, recall: 0.8580750407828942, f1: 0.4640494044598405\n",
            "epoch: 823, step: 2, Train: label_loss: 0.08829512447118759, precision: 0.32014388489206713, recall: 0.8944723618088953, f1: 0.4715231787690846\n",
            "epoch: 823, step: 3, Train: label_loss: 0.083457812666893, precision: 0.32724056603771656, recall: 0.9249999999998457, f1: 0.4834494773132675\n",
            "epoch: 823, step: 4, Train: label_loss: 0.08479849249124527, precision: 0.3415071770334724, recall: 0.890795631825134, f1: 0.49373108513066544\n",
            "epoch: 823, step: 5, Train: label_loss: 0.08524028956890106, precision: 0.34268656716415863, recall: 0.8968749999998598, f1: 0.49589632825368785\n",
            "epoch: 823, step: 6, Train: label_loss: 0.07733543962240219, precision: 0.3283935981031222, recall: 0.9187396351573932, f1: 0.4838427947209866\n",
            "epoch: 823, step: 7, Train: label_loss: 0.095285564661026, precision: 0.32370283018866014, recall: 0.9258010118042282, f1: 0.47968545212408437\n",
            "epoch: 823, step: 8, Train: label_loss: 0.08443884551525116, precision: 0.3359050445103658, recall: 0.9203252032518828, f1: 0.4921739130042568\n",
            "epoch: 823, step: 9, Train: label_loss: 0.08944375067949295, precision: 0.3152173913043288, recall: 0.8847457627117143, f1: 0.4648263579309458\n",
            "epoch: 823, step: 10, Train: label_loss: 0.09199055284261703, precision: 0.3068656716417727, recall: 0.9065255731920799, f1: 0.4585191792663635\n",
            "epoch: 823, step: 11, Train: label_loss: 0.08485573530197144, precision: 0.32461355529130054, recall: 0.8834951456309249, f1: 0.4747826086563112\n",
            "epoch: 823, step: 12, Train: label_loss: 0.08529502898454666, precision: 0.32778108268885614, recall: 0.9137645107792846, f1: 0.48248686510995753\n",
            "epoch: 823, step: 13, Train: label_loss: 0.08902943134307861, precision: 0.3042704626334339, recall: 0.899999999999842, f1: 0.45478723400474835\n",
            "epoch: 823, step: 14, Train: label_loss: 0.09466814994812012, precision: 0.3389524382901662, recall: 0.8880126182963899, f1: 0.49063180823883684\n",
            "epoch: 823, step: 15, Train: label_loss: 0.08628502488136292, precision: 0.3284023668638859, recall: 0.9234608985023421, f1: 0.4845045831127173\n",
            "epoch: 823, step: 16, Train: label_loss: 0.0789751410484314, precision: 0.3223140495867578, recall: 0.9069767441858958, f1: 0.4756097560588297\n",
            "epoch: 823, step: 17, Train: label_loss: 0.09002376347780228, precision: 0.34142011834317504, recall: 0.9336569579286514, f1: 0.49999999996074335\n",
            "epoch: 823, step: 18, Train: label_loss: 0.08286494016647339, precision: 0.3153846153845967, recall: 0.9111111111109553, f1: 0.4685714285331833\n",
            "epoch: 823, step: 19, Train: label_loss: 0.08421982824802399, precision: 0.3075539568345139, recall: 0.8860103626941475, f1: 0.45660881171070206\n",
            "epoch: 823, step: 20, Train: label_loss: 0.08282470703125, precision: 0.3220439691027735, recall: 0.8958677685948931, f1: 0.4737762237372817\n",
            "epoch: 823, step: 21, Train: label_loss: 0.08791600167751312, precision: 0.31077844311375385, recall: 0.8856655290100877, f1: 0.46010638294022643\n",
            "epoch: 823, step: 22, Train: label_loss: 0.09184011816978455, precision: 0.3002392344497428, recall: 0.8838028169012527, f1: 0.4482142856763911\n",
            "epoch: 823, step: 23, Train: label_loss: 0.09599863737821579, precision: 0.3155159613956707, recall: 0.8655804480649969, f1: 0.462459194737726\n",
            "epoch: 824, step: 0, Train: label_loss: 0.07957416027784348, precision: 0.32332155477029895, recall: 0.9059405940592564, f1: 0.47656249996119043\n",
            "epoch: 824, step: 1, Train: label_loss: 0.09070057421922684, precision: 0.32202380952379034, recall: 0.8956953642382622, f1: 0.4737302976843479\n",
            "epoch: 824, step: 2, Train: label_loss: 0.08408161997795105, precision: 0.3339275103980788, recall: 0.9079159935378177, f1: 0.488271068596608\n",
            "epoch: 824, step: 3, Train: label_loss: 0.08601605892181396, precision: 0.3319551092734594, recall: 0.9108589951376157, f1: 0.48658008654089296\n",
            "epoch: 824, step: 4, Train: label_loss: 0.0996999517083168, precision: 0.3029394121175583, recall: 0.8922261484097362, f1: 0.4523063143373947\n",
            "epoch: 824, step: 5, Train: label_loss: 0.09667246043682098, precision: 0.3091671659676268, recall: 0.8850771869638275, f1: 0.4582593250059919\n",
            "epoch: 824, step: 6, Train: label_loss: 0.08341631293296814, precision: 0.32361689470551314, recall: 0.9021558872303644, f1: 0.4763572679120597\n",
            "epoch: 824, step: 7, Train: label_loss: 0.08065123856067657, precision: 0.3189093064611548, recall: 0.9087837837836302, f1: 0.4721369021115672\n",
            "epoch: 824, step: 8, Train: label_loss: 0.09609589725732803, precision: 0.32660332541565756, recall: 0.9181969949914994, f1: 0.4818221637807867\n",
            "epoch: 824, step: 9, Train: label_loss: 0.0892450362443924, precision: 0.3140643623360957, recall: 0.8917089678509489, f1: 0.46452181573931\n",
            "epoch: 824, step: 10, Train: label_loss: 0.0807979479432106, precision: 0.3031755542240681, recall: 0.8724137931032978, f1: 0.4499777678585262\n",
            "epoch: 824, step: 11, Train: label_loss: 0.09083813428878784, precision: 0.30741190765490234, recall: 0.8724137931032978, f1: 0.4546271338338426\n",
            "epoch: 824, step: 12, Train: label_loss: 0.07028638571500778, precision: 0.31955109273477145, recall: 0.9016666666665163, f1: 0.4718709114310098\n",
            "epoch: 824, step: 13, Train: label_loss: 0.08326681703329086, precision: 0.3205430932703471, recall: 0.9110738255032028, f1: 0.47423580782171537\n",
            "epoch: 824, step: 14, Train: label_loss: 0.09328369796276093, precision: 0.32716417910445805, recall: 0.8896103896102451, f1: 0.47839371449577917\n",
            "epoch: 824, step: 15, Train: label_loss: 0.07937338948249817, precision: 0.34080188679243273, recall: 0.9145569620251717, f1: 0.49656357384356337\n",
            "epoch: 824, step: 16, Train: label_loss: 0.07771407812833786, precision: 0.3178340200117529, recall: 0.9230769230767653, f1: 0.4728546409425888\n",
            "epoch: 824, step: 17, Train: label_loss: 0.0661601796746254, precision: 0.33819241982505316, recall: 0.9523809523807959, f1: 0.4991394147633466\n",
            "epoch: 824, step: 18, Train: label_loss: 0.078823983669281, precision: 0.30928444707271974, recall: 0.9143356643355044, f1: 0.46221829426178673\n",
            "epoch: 824, step: 19, Train: label_loss: 0.07765069603919983, precision: 0.33888228299641265, recall: 0.9223300970872294, f1: 0.49565217387370075\n",
            "epoch: 824, step: 20, Train: label_loss: 0.08037497103214264, precision: 0.3487690504102961, recall: 0.9370078740156004, f1: 0.5083297735614469\n",
            "epoch: 824, step: 21, Train: label_loss: 0.08427193760871887, precision: 0.3292181069958654, recall: 0.9180327868850954, f1: 0.48463868451324343\n",
            "epoch: 824, step: 22, Train: label_loss: 0.08122603595256805, precision: 0.3268321513002171, recall: 0.8933764135701302, f1: 0.47858070095597743\n",
            "epoch: 824, step: 23, Train: label_loss: 0.08481273055076599, precision: 0.3148558758314623, recall: 0.8747433264885268, f1: 0.4630434782218949\n",
            "epoch: 825, step: 0, Train: label_loss: 0.07901355624198914, precision: 0.3261648745519518, recall: 0.8980263157893259, f1: 0.478527607322832\n",
            "epoch: 825, step: 1, Train: label_loss: 0.08138464391231537, precision: 0.32620320855613033, recall: 0.8854838709675991, f1: 0.476769431137337\n",
            "epoch: 825, step: 2, Train: label_loss: 0.0863189697265625, precision: 0.32081097197374353, recall: 0.8907284768210445, f1: 0.4717229285011367\n",
            "epoch: 825, step: 3, Train: label_loss: 0.09226511418819427, precision: 0.3106562311860138, recall: 0.8989547038325959, f1: 0.46174496640473867\n",
            "epoch: 825, step: 4, Train: label_loss: 0.09887992590665817, precision: 0.33532219570403726, recall: 0.8934817170109867, f1: 0.4876355747975841\n",
            "epoch: 825, step: 5, Train: label_loss: 0.08455873280763626, precision: 0.34774881516585615, recall: 0.924409448818752, f1: 0.505380972840127\n",
            "epoch: 825, step: 6, Train: label_loss: 0.07867431640625, precision: 0.3093270365997456, recall: 0.9128919860625586, f1: 0.46208112870994783\n",
            "epoch: 825, step: 7, Train: label_loss: 0.07508530467748642, precision: 0.3210023866348257, recall: 0.8892561983469603, f1: 0.47172292850109554\n",
            "epoch: 825, step: 8, Train: label_loss: 0.07716397196054459, precision: 0.3313713949381794, recall: 0.9199346405227254, f1: 0.4872349631804052\n",
            "epoch: 825, step: 9, Train: label_loss: 0.08374272286891937, precision: 0.3069129916567159, recall: 0.8925476603118037, f1: 0.4567627494075551\n",
            "epoch: 825, step: 10, Train: label_loss: 0.08878549933433533, precision: 0.2999999999999821, recall: 0.8967971530247514, f1: 0.4495985726653368\n",
            "epoch: 825, step: 11, Train: label_loss: 0.10650704801082611, precision: 0.3083886541943085, recall: 0.8631756756755298, f1: 0.4544241884894066\n",
            "epoch: 825, step: 12, Train: label_loss: 0.09054222702980042, precision: 0.31182795698922866, recall: 0.8877551020406653, f1: 0.4615384614999458\n",
            "epoch: 825, step: 13, Train: label_loss: 0.06801661849021912, precision: 0.32801418439714375, recall: 0.9113300492609341, f1: 0.48239895693626256\n",
            "epoch: 825, step: 14, Train: label_loss: 0.0797700434923172, precision: 0.33293556085916864, recall: 0.8985507246375364, f1: 0.48585111010417087\n",
            "epoch: 825, step: 15, Train: label_loss: 0.10646731406450272, precision: 0.3267933782955042, recall: 0.8367346938774196, f1: 0.4700176366438661\n",
            "epoch: 825, step: 16, Train: label_loss: 0.0865660160779953, precision: 0.31283905967448383, recall: 0.8781725888323386, f1: 0.46133333329455767\n",
            "epoch: 825, step: 17, Train: label_loss: 0.08578621596097946, precision: 0.30685920577615483, recall: 0.8688245315160359, f1: 0.4535349043633398\n",
            "epoch: 825, step: 18, Train: label_loss: 0.08418291807174683, precision: 0.3208999407933498, recall: 0.9093959731542097, f1: 0.4743982494143528\n",
            "epoch: 825, step: 19, Train: label_loss: 0.08590428531169891, precision: 0.3149370125974616, recall: 0.8764607679464312, f1: 0.46337157983750016\n",
            "epoch: 825, step: 20, Train: label_loss: 0.0978064090013504, precision: 0.3228915662650408, recall: 0.8758169934639091, f1: 0.47183098587608985\n",
            "epoch: 825, step: 21, Train: label_loss: 0.09329614043235779, precision: 0.31369047619045753, recall: 0.9023972602738181, f1: 0.4655477031418884\n",
            "epoch: 825, step: 22, Train: label_loss: 0.09659074991941452, precision: 0.3292978208232246, recall: 0.8760064412236914, f1: 0.47866256045298566\n",
            "epoch: 825, step: 23, Train: label_loss: 0.10780321061611176, precision: 0.31750741839760255, recall: 0.8879668049790689, f1: 0.46775956280267594\n",
            "epoch: 826, step: 0, Train: label_loss: 0.08436974138021469, precision: 0.3408820023837699, recall: 0.9122807017542404, f1: 0.49631236438551485\n",
            "epoch: 826, step: 1, Train: label_loss: 0.09194058924913406, precision: 0.32870090634439103, recall: 0.8845528455283114, f1: 0.47929515414547486\n",
            "epoch: 826, step: 2, Train: label_loss: 0.09428103268146515, precision: 0.32995830851695473, recall: 0.89354838709663, f1: 0.48194867329680047\n",
            "epoch: 826, step: 3, Train: label_loss: 0.08299456536769867, precision: 0.3252080856123469, recall: 0.9041322314048091, f1: 0.47835592475335087\n",
            "epoch: 826, step: 4, Train: label_loss: 0.08015120774507523, precision: 0.3301662707838284, recall: 0.8924558587478503, f1: 0.4820112700082148\n",
            "epoch: 826, step: 5, Train: label_loss: 0.08211123198270798, precision: 0.32068761114402367, recall: 0.9046822742473403, f1: 0.47352297589129344\n",
            "epoch: 826, step: 6, Train: label_loss: 0.08464215695858002, precision: 0.32576210400476235, recall: 0.8949096880129893, f1: 0.4776511831334835\n",
            "epoch: 826, step: 7, Train: label_loss: 0.07845617830753326, precision: 0.30773809523807694, recall: 0.8991304347824522, f1: 0.45853658532781905\n",
            "epoch: 826, step: 8, Train: label_loss: 0.0842970758676529, precision: 0.32360097323599, recall: 0.8735632183906611, f1: 0.472259209902809\n",
            "epoch: 826, step: 9, Train: label_loss: 0.10081030428409576, precision: 0.3163265306122259, recall: 0.8932203389828994, f1: 0.4671985815216163\n",
            "epoch: 826, step: 10, Train: label_loss: 0.09585674107074738, precision: 0.330930930930911, recall: 0.8944805194803742, f1: 0.4831214379263368\n",
            "epoch: 826, step: 11, Train: label_loss: 0.09604516625404358, precision: 0.3437312537492295, recall: 0.9066455696201097, f1: 0.4984775989161583\n",
            "epoch: 826, step: 12, Train: label_loss: 0.07890327274799347, precision: 0.33195754716979176, recall: 0.9184339314843526, f1: 0.48765699433081455\n",
            "epoch: 826, step: 13, Train: label_loss: 0.09051387012004852, precision: 0.2993440667859094, recall: 0.898032200357621, f1: 0.44901610014135074\n",
            "epoch: 826, step: 14, Train: label_loss: 0.09031827747821808, precision: 0.3271196632591505, recall: 0.8845528455283114, f1: 0.4776119402590479\n",
            "epoch: 826, step: 15, Train: label_loss: 0.08301398158073425, precision: 0.31594546532303996, recall: 0.889816360600853, f1: 0.46631671037248373\n",
            "epoch: 826, step: 16, Train: label_loss: 0.09182970970869064, precision: 0.3131009615384427, recall: 0.8785834738615719, f1: 0.46167478950485963\n",
            "epoch: 826, step: 17, Train: label_loss: 0.08840803802013397, precision: 0.3174791914387445, recall: 0.8870431893686234, f1: 0.46760070048653274\n",
            "epoch: 826, step: 18, Train: label_loss: 0.08561066538095474, precision: 0.29803688280783475, recall: 0.8882978723402679, f1: 0.4463251670001999\n",
            "epoch: 826, step: 19, Train: label_loss: 0.09686895459890366, precision: 0.32213557288540356, recall: 0.8774509803920134, f1: 0.471259324225702\n",
            "epoch: 826, step: 20, Train: label_loss: 0.09500502794981003, precision: 0.3080168776371122, recall: 0.8735042735041241, f1: 0.45543672010401526\n",
            "epoch: 826, step: 21, Train: label_loss: 0.08762338757514954, precision: 0.31425163983301646, recall: 0.9086206896550156, f1: 0.4669915817074506\n",
            "epoch: 826, step: 22, Train: label_loss: 0.08093417435884476, precision: 0.31676646706584927, recall: 0.8801996672211513, f1: 0.4658740642498972\n",
            "epoch: 826, step: 23, Train: label_loss: 0.09048561751842499, precision: 0.3190094683175296, recall: 0.9182389937104993, f1: 0.4735135134751909\n",
            "epoch: 827, step: 0, Train: label_loss: 0.07896368205547333, precision: 0.32921083627795467, recall: 0.9089430894307464, f1: 0.4833549502419401\n",
            "epoch: 827, step: 1, Train: label_loss: 0.09319837391376495, precision: 0.33213644524235, recall: 0.8995137763369693, f1: 0.4851398601004283\n",
            "epoch: 827, step: 2, Train: label_loss: 0.0773996114730835, precision: 0.3238602723504841, recall: 0.8967213114752628, f1: 0.47585906912147685\n",
            "epoch: 827, step: 3, Train: label_loss: 0.09215240925550461, precision: 0.29101796407183883, recall: 0.8836363636362029, f1: 0.43783783780052465\n",
            "epoch: 827, step: 4, Train: label_loss: 0.09449785947799683, precision: 0.3193277310924178, recall: 0.9016949152540844, f1: 0.47163120563509114\n",
            "epoch: 827, step: 5, Train: label_loss: 0.08082826435565948, precision: 0.3359374999999798, recall: 0.8929712460062471, f1: 0.4882096069471298\n",
            "epoch: 827, step: 6, Train: label_loss: 0.09981116652488708, precision: 0.33132166566081284, recall: 0.8769968051116809, f1: 0.48094612348183696\n",
            "epoch: 827, step: 7, Train: label_loss: 0.08568037301301956, precision: 0.32938388625590465, recall: 0.8924558587478503, f1: 0.48117697962306083\n",
            "epoch: 827, step: 8, Train: label_loss: 0.08139771223068237, precision: 0.3337271116361291, recall: 0.9069020866772219, f1: 0.487910189943359\n",
            "epoch: 827, step: 9, Train: label_loss: 0.08662091195583344, precision: 0.29126794258371463, recall: 0.8711985688728315, f1: 0.4365755266320597\n",
            "epoch: 827, step: 10, Train: label_loss: 0.08532126247882843, precision: 0.31283264340625, recall: 0.9168110918542605, f1: 0.466490299785655\n",
            "epoch: 827, step: 11, Train: label_loss: 0.09702224284410477, precision: 0.310262529832917, recall: 0.8965517241377764, f1: 0.4609929077631784\n",
            "epoch: 827, step: 12, Train: label_loss: 0.07440049201250076, precision: 0.3369304556354714, recall: 0.8934817170109867, f1: 0.489333913760797\n",
            "epoch: 827, step: 13, Train: label_loss: 0.08328820019960403, precision: 0.32934847579197074, recall: 0.890145395799533, f1: 0.4808027922816485\n",
            "epoch: 827, step: 14, Train: label_loss: 0.07554131746292114, precision: 0.32825322391557277, recall: 0.9225700164743125, f1: 0.4842196281497458\n",
            "epoch: 827, step: 15, Train: label_loss: 0.08412087708711624, precision: 0.29432835820893766, recall: 0.8996350364961861, f1: 0.4435447592970442\n",
            "epoch: 827, step: 16, Train: label_loss: 0.08891148865222931, precision: 0.30579010856451716, recall: 0.8894736842103702, f1: 0.4551166965507515\n",
            "epoch: 827, step: 17, Train: label_loss: 0.07855671644210815, precision: 0.33532576210398474, recall: 0.886255924170476, f1: 0.4865568082862335\n",
            "epoch: 827, step: 18, Train: label_loss: 0.08251968026161194, precision: 0.32951807228913677, recall: 0.8822580645159867, f1: 0.4798245613638698\n",
            "epoch: 827, step: 19, Train: label_loss: 0.0886436179280281, precision: 0.3146936347412067, recall: 0.8831385642736421, f1: 0.4640350876805179\n",
            "epoch: 827, step: 20, Train: label_loss: 0.08912070095539093, precision: 0.33192516596256294, recall: 0.8856682769724821, f1: 0.48287971901209886\n",
            "epoch: 827, step: 21, Train: label_loss: 0.08785326033830643, precision: 0.3151658767772325, recall: 0.9236111111109507, f1: 0.4699646642729747\n",
            "epoch: 827, step: 22, Train: label_loss: 0.09461617469787598, precision: 0.32552552552550595, recall: 0.8885245901637887, f1: 0.4764835164442271\n",
            "epoch: 827, step: 23, Train: label_loss: 0.08868692815303802, precision: 0.3279411764705641, recall: 0.9083503054987967, f1: 0.4819016747313626\n",
            "epoch: 828, step: 0, Train: label_loss: 0.0887114405632019, precision: 0.32106824925814115, recall: 0.9138513513511969, f1: 0.47518664906117164\n",
            "epoch: 828, step: 1, Train: label_loss: 0.07634584605693817, precision: 0.31663685152055354, recall: 0.9061433447097429, f1: 0.46928855497704586\n",
            "epoch: 828, step: 2, Train: label_loss: 0.081459179520607, precision: 0.30900529723364867, recall: 0.8898305084744254, f1: 0.45871559629197173\n",
            "epoch: 828, step: 3, Train: label_loss: 0.07908567041158676, precision: 0.32720806164787625, recall: 0.9199999999998466, f1: 0.48272846519955653\n",
            "epoch: 828, step: 4, Train: label_loss: 0.09152241051197052, precision: 0.3174508636092723, recall: 0.8973063973062462, f1: 0.46898372191471704\n",
            "epoch: 828, step: 5, Train: label_loss: 0.09083188325166702, precision: 0.3176400476757856, recall: 0.8809917355370444, f1: 0.46692947871702656\n",
            "epoch: 828, step: 6, Train: label_loss: 0.09713505208492279, precision: 0.31136638452235116, recall: 0.8684654300167169, f1: 0.45838896302296733\n",
            "epoch: 828, step: 7, Train: label_loss: 0.0970655083656311, precision: 0.32534451767523515, recall: 0.8772213247171442, f1: 0.47465034961083835\n",
            "epoch: 828, step: 8, Train: label_loss: 0.07395204156637192, precision: 0.32958579881654854, recall: 0.9042207792206324, f1: 0.4830875975323563\n",
            "epoch: 828, step: 9, Train: label_loss: 0.07604000717401505, precision: 0.3417796110783535, recall: 0.9250398724081459, f1: 0.4991394147626214\n",
            "epoch: 828, step: 10, Train: label_loss: 0.08148998022079468, precision: 0.3219540906415349, recall: 0.9177852348991749, f1: 0.47668845312054925\n",
            "epoch: 828, step: 11, Train: label_loss: 0.08831137418746948, precision: 0.3183183183182992, recall: 0.8745874587457302, f1: 0.46675473355836544\n",
            "epoch: 828, step: 12, Train: label_loss: 0.0734969824552536, precision: 0.32216343327452546, recall: 0.9256756756755192, f1: 0.4779764500270705\n",
            "epoch: 828, step: 13, Train: label_loss: 0.094027079641819, precision: 0.32818073721757857, recall: 0.900489396410946, f1: 0.48104575159479324\n",
            "epoch: 828, step: 14, Train: label_loss: 0.07268048077821732, precision: 0.3443983402489422, recall: 0.9106583072098885, f1: 0.4997849461966944\n",
            "epoch: 828, step: 15, Train: label_loss: 0.08795347064733505, precision: 0.3315347721822343, recall: 0.8977272727271269, f1: 0.4842381785945405\n",
            "epoch: 828, step: 16, Train: label_loss: 0.08374524116516113, precision: 0.33412182140743146, recall: 0.9142394822004992, f1: 0.48938934599800066\n",
            "epoch: 828, step: 17, Train: label_loss: 0.09698936343193054, precision: 0.3143028846153657, recall: 0.8924914675766394, f1: 0.4648888888503248\n",
            "epoch: 828, step: 18, Train: label_loss: 0.09335864335298538, precision: 0.31205250596656847, recall: 0.8924914675766394, f1: 0.4624226347979971\n",
            "epoch: 828, step: 19, Train: label_loss: 0.07446645200252533, precision: 0.3238039673278691, recall: 0.9296482412058744, f1: 0.4803115534017086\n",
            "epoch: 828, step: 20, Train: label_loss: 0.08168840408325195, precision: 0.3113095238095053, recall: 0.9032815198616747, f1: 0.46303674188304017\n",
            "epoch: 828, step: 21, Train: label_loss: 0.10259927809238434, precision: 0.319606637984, recall: 0.8441558441557071, f1: 0.46366473469038877\n",
            "epoch: 828, step: 22, Train: label_loss: 0.10530921816825867, precision: 0.31170406306850745, recall: 0.8624161073824056, f1: 0.45790645875828667\n",
            "epoch: 828, step: 23, Train: label_loss: 0.10883133113384247, precision: 0.29157345264725637, recall: 0.8537117903928267, f1: 0.4346859365934592\n",
            "epoch: 829, step: 0, Train: label_loss: 0.09827244281768799, precision: 0.3049001814881848, recall: 0.8630136986299891, f1: 0.4506034867740734\n",
            "epoch: 829, step: 1, Train: label_loss: 0.08376224339008331, precision: 0.3032979976442695, recall: 0.9019264448334672, f1: 0.45394446889133877\n",
            "epoch: 829, step: 2, Train: label_loss: 0.10265085101127625, precision: 0.32721712538224296, recall: 0.8615136876005053, f1: 0.4742907801019029\n",
            "epoch: 829, step: 3, Train: label_loss: 0.07829825580120087, precision: 0.33294117647056864, recall: 0.9070512820511366, f1: 0.48709122199165733\n",
            "epoch: 829, step: 4, Train: label_loss: 0.11508208513259888, precision: 0.2996368038740739, recall: 0.857885615251151, f1: 0.44414535662377014\n",
            "epoch: 829, step: 5, Train: label_loss: 0.08121815323829651, precision: 0.2949640287769607, recall: 0.8571428571427078, f1: 0.438893844743311\n",
            "epoch: 829, step: 6, Train: label_loss: 0.08629793673753738, precision: 0.3223487118034558, recall: 0.8677419354837309, f1: 0.47007426819986575\n",
            "epoch: 829, step: 7, Train: label_loss: 0.09806828200817108, precision: 0.3134418324291553, recall: 0.8828522920202235, f1: 0.46263345191858196\n",
            "epoch: 829, step: 8, Train: label_loss: 0.11824231594800949, precision: 0.3199999999999803, recall: 0.8400646203552762, f1: 0.46345811047694163\n",
            "epoch: 829, step: 9, Train: label_loss: 0.07304932922124863, precision: 0.33748517200472494, recall: 0.9147909967844188, f1: 0.4930675909484518\n",
            "epoch: 829, step: 10, Train: label_loss: 0.09827026724815369, precision: 0.32451923076921124, recall: 0.9015025041734721, f1: 0.47724259828184473\n",
            "epoch: 829, step: 11, Train: label_loss: 0.09174735844135284, precision: 0.33373134328356213, recall: 0.9104234527685813, f1: 0.4884228920533168\n",
            "epoch: 829, step: 12, Train: label_loss: 0.08887523412704468, precision: 0.3229665071770142, recall: 0.9168081494056167, f1: 0.47766475007199993\n",
            "epoch: 829, step: 13, Train: label_loss: 0.0916750431060791, precision: 0.3104715248009608, recall: 0.8380165289254813, f1: 0.45308310988008016\n",
            "epoch: 829, step: 14, Train: label_loss: 0.08319510519504547, precision: 0.31904761904760004, recall: 0.913117546848226, f1: 0.4728716364856215\n",
            "epoch: 829, step: 15, Train: label_loss: 0.11468426883220673, precision: 0.32908318154217797, recall: 0.891447368420906, f1: 0.48070953432864294\n",
            "epoch: 829, step: 16, Train: label_loss: 0.09824658930301666, precision: 0.3202614379084777, recall: 0.8998330550916694, f1: 0.4723926379980507\n",
            "epoch: 829, step: 17, Train: label_loss: 0.0969223827123642, precision: 0.32570740517758423, recall: 0.9031719532552749, f1: 0.4787610619079012\n",
            "epoch: 829, step: 18, Train: label_loss: 0.09073029458522797, precision: 0.31591591591589696, recall: 0.8665568369026578, f1: 0.46302816897488613\n",
            "epoch: 829, step: 19, Train: label_loss: 0.08748282492160797, precision: 0.3351095322675941, recall: 0.9114331723025907, f1: 0.49004329000393543\n",
            "epoch: 829, step: 20, Train: label_loss: 0.09571592509746552, precision: 0.3183165382335318, recall: 0.8935108153076715, f1: 0.46940559436681795\n",
            "epoch: 829, step: 21, Train: label_loss: 0.08074384927749634, precision: 0.328783382789298, recall: 0.8921095008050093, f1: 0.48048568946624054\n",
            "epoch: 829, step: 22, Train: label_loss: 0.09071538597345352, precision: 0.30976632714198266, recall: 0.8852739726025881, f1: 0.458943630676158\n",
            "epoch: 829, step: 23, Train: label_loss: 0.09573730826377869, precision: 0.31042128603101915, recall: 0.867768595041143, f1: 0.45726728357572827\n",
            "epoch: 830, step: 0, Train: label_loss: 0.08594825863838196, precision: 0.3171753441053072, recall: 0.8907563025208586, f1: 0.4677846425031567\n",
            "epoch: 830, step: 1, Train: label_loss: 0.09175063669681549, precision: 0.3425149700598597, recall: 0.9137380191691831, f1: 0.4982578396815487\n",
            "epoch: 830, step: 2, Train: label_loss: 0.09307903051376343, precision: 0.31733653269344225, recall: 0.8772802653398213, f1: 0.4660792951151289\n",
            "epoch: 830, step: 3, Train: label_loss: 0.08521959185600281, precision: 0.31585220500594063, recall: 0.8937605396288543, f1: 0.46675473355890584\n",
            "epoch: 830, step: 4, Train: label_loss: 0.0961826741695404, precision: 0.3299340131973407, recall: 0.8914100486222217, f1: 0.4816112083668296\n",
            "epoch: 830, step: 5, Train: label_loss: 0.08930470049381256, precision: 0.3013205282112664, recall: 0.8655172413791611, f1: 0.4470169189287026\n",
            "epoch: 830, step: 6, Train: label_loss: 0.09436486661434174, precision: 0.31582125603862826, recall: 0.8819561551431901, f1: 0.4650955980047036\n",
            "epoch: 830, step: 7, Train: label_loss: 0.0910857617855072, precision: 0.3218731475992696, recall: 0.9080267558526909, f1: 0.4752735229372452\n",
            "epoch: 830, step: 8, Train: label_loss: 0.0906962975859642, precision: 0.332934131736507, recall: 0.8982229402260261, f1: 0.4858016600740853\n",
            "epoch: 830, step: 9, Train: label_loss: 0.09518137574195862, precision: 0.3225030084235666, recall: 0.8786885245900198, f1: 0.47183098587617117\n",
            "epoch: 830, step: 10, Train: label_loss: 0.08962602913379669, precision: 0.32512019230767275, recall: 0.8883415435138113, f1: 0.476022877215459\n",
            "epoch: 830, step: 11, Train: label_loss: 0.10030139237642288, precision: 0.31476997578690585, recall: 0.890410958903957, f1: 0.46511627903113273\n",
            "epoch: 830, step: 12, Train: label_loss: 0.10102416574954987, precision: 0.31303288672348883, recall: 0.8638655462183421, f1: 0.4595440321468753\n",
            "epoch: 830, step: 13, Train: label_loss: 0.09449872374534607, precision: 0.305974652987308, recall: 0.8726333907055296, f1: 0.4530831098810883\n",
            "epoch: 830, step: 14, Train: label_loss: 0.09163270890712738, precision: 0.3261390887289972, recall: 0.8903436988541914, f1: 0.4774023694210032\n",
            "epoch: 830, step: 15, Train: label_loss: 0.08601102977991104, precision: 0.3212778782398842, recall: 0.8780889621085868, f1: 0.4704324801019531\n",
            "epoch: 830, step: 16, Train: label_loss: 0.10832835733890533, precision: 0.3121212121211932, recall: 0.8583333333331902, f1: 0.45777777773862594\n",
            "epoch: 830, step: 17, Train: label_loss: 0.0918121188879013, precision: 0.3017607771705949, recall: 0.9003623188404165, f1: 0.45202364707468057\n",
            "epoch: 830, step: 18, Train: label_loss: 0.07269296050071716, precision: 0.330378250590997, recall: 0.9163934426228005, f1: 0.4856646394049658\n",
            "epoch: 830, step: 19, Train: label_loss: 0.09879590570926666, precision: 0.31793641271743744, recall: 0.8892617449662937, f1: 0.46840477238714084\n",
            "epoch: 830, step: 20, Train: label_loss: 0.08979988098144531, precision: 0.33253731343281595, recall: 0.9086460032624945, f1: 0.4868881118488416\n",
            "epoch: 830, step: 21, Train: label_loss: 0.08426360785961151, precision: 0.3335325762103805, recall: 0.8942307692306258, f1: 0.4858511101040512\n",
            "epoch: 830, step: 22, Train: label_loss: 0.09267160296440125, precision: 0.33313432835818907, recall: 0.8971061093246145, f1: 0.485851110104131\n",
            "epoch: 830, step: 23, Train: label_loss: 0.09169072657823563, precision: 0.3156732891831997, recall: 0.8918918918917065, f1: 0.46630434778742097\n",
            "epoch: 831, step: 0, Train: label_loss: 0.09202396869659424, precision: 0.29390681003582475, recall: 0.8770053475934265, f1: 0.440268456338199\n",
            "epoch: 831, step: 1, Train: label_loss: 0.08871626853942871, precision: 0.304136253041344, recall: 0.8605851979344473, f1: 0.44943820220856295\n",
            "epoch: 831, step: 2, Train: label_loss: 0.08757244050502777, precision: 0.3283935981031222, recall: 0.9126853377263735, f1: 0.48299912812145873\n",
            "epoch: 831, step: 3, Train: label_loss: 0.09366876631975174, precision: 0.3095238095237911, recall: 0.8888888888887369, f1: 0.4591611478645151\n",
            "epoch: 831, step: 4, Train: label_loss: 0.09756442904472351, precision: 0.31759149940966247, recall: 0.9011725293130818, f1: 0.46966390218752496\n",
            "epoch: 831, step: 5, Train: label_loss: 0.08679932355880737, precision: 0.3432657926102298, recall: 0.8958009331258326, f1: 0.49633778539721124\n",
            "epoch: 831, step: 6, Train: label_loss: 0.08847786486148834, precision: 0.3226571767496843, recall: 0.8962108731464751, f1: 0.47448757082888876\n",
            "epoch: 831, step: 7, Train: label_loss: 0.08231070637702942, precision: 0.3085612366230494, recall: 0.9073426573424986, f1: 0.4605146406009491\n",
            "epoch: 831, step: 8, Train: label_loss: 0.0775204449892044, precision: 0.313995215310986, recall: 0.8928571428569909, f1: 0.4646017698729663\n",
            "epoch: 831, step: 9, Train: label_loss: 0.08644528687000275, precision: 0.3240796620398115, recall: 0.9010067114092447, f1: 0.4766977363125776\n",
            "epoch: 831, step: 10, Train: label_loss: 0.09563592076301575, precision: 0.32048192771082407, recall: 0.8896321070232626, f1: 0.4712134632028256\n",
            "epoch: 831, step: 11, Train: label_loss: 0.09421905875205994, precision: 0.290361445783115, recall: 0.8763636363634769, f1: 0.43619909498519827\n",
            "epoch: 831, step: 12, Train: label_loss: 0.09242174029350281, precision: 0.3114852675886764, recall: 0.8779661016947664, f1: 0.4598313359577493\n",
            "epoch: 831, step: 13, Train: label_loss: 0.08858713507652283, precision: 0.34792899408281963, recall: 0.9074074074072673, f1: 0.5029940119359364\n",
            "epoch: 831, step: 14, Train: label_loss: 0.08700570464134216, precision: 0.34880952380950303, recall: 0.9071207430339152, f1: 0.5038693034852029\n",
            "epoch: 831, step: 15, Train: label_loss: 0.07607904821634293, precision: 0.3130177514792714, recall: 0.905821917808064, f1: 0.4652594546671518\n",
            "epoch: 831, step: 16, Train: label_loss: 0.08937900513410568, precision: 0.3017292784734465, recall: 0.8908450704223783, f1: 0.4507795099844327\n",
            "epoch: 831, step: 17, Train: label_loss: 0.08459815382957458, precision: 0.32002383790224553, recall: 0.8861386138612398, f1: 0.4702276707140382\n",
            "epoch: 831, step: 18, Train: label_loss: 0.09950663149356842, precision: 0.3260073260073061, recall: 0.8557692307690936, f1: 0.4721485410740641\n",
            "epoch: 831, step: 19, Train: label_loss: 0.1271435022354126, precision: 0.33312302839114616, recall: 0.817337461300183, f1: 0.47333034509552485\n",
            "epoch: 831, step: 20, Train: label_loss: 0.14783290028572083, precision: 0.30114358322742685, recall: 0.780889621087186, f1: 0.4346629985842734\n",
            "epoch: 831, step: 21, Train: label_loss: 0.12751156091690063, precision: 0.3366153846153639, recall: 0.8560250391234967, f1: 0.48321554766262104\n",
            "epoch: 831, step: 22, Train: label_loss: 0.10241398215293884, precision: 0.31151515151513265, recall: 0.8682432432430965, f1: 0.4585191792652862\n",
            "epoch: 831, step: 23, Train: label_loss: 0.10992968827486038, precision: 0.3152818991097689, recall: 0.8780991735535376, f1: 0.4639737990877079\n",
            "epoch: 832, step: 0, Train: label_loss: 0.09256839007139206, precision: 0.32261904761902843, recall: 0.9186440677964544, f1: 0.4775330396090635\n",
            "epoch: 832, step: 1, Train: label_loss: 0.10780266672372818, precision: 0.3199999999999806, recall: 0.8844221105526157, f1: 0.4699599465563992\n",
            "epoch: 832, step: 2, Train: label_loss: 0.10674510896205902, precision: 0.3002450980391973, recall: 0.8448275862067508, f1: 0.44303797464481337\n",
            "epoch: 832, step: 3, Train: label_loss: 0.11400338262319565, precision: 0.31292517006800785, recall: 0.8405315614616543, f1: 0.45606128882928\n",
            "epoch: 832, step: 4, Train: label_loss: 0.09694673866033554, precision: 0.31978481769274836, recall: 0.8901830282860415, f1: 0.4705364995213165\n",
            "epoch: 832, step: 5, Train: label_loss: 0.09231027960777283, precision: 0.3107947805456518, recall: 0.9003436426115291, f1: 0.46208112870960205\n",
            "epoch: 832, step: 6, Train: label_loss: 0.10872286558151245, precision: 0.3245560318432134, recall: 0.877483443708464, f1: 0.4738489047437289\n",
            "epoch: 832, step: 7, Train: label_loss: 0.11398162692785263, precision: 0.3520531400965971, recall: 0.895545314900016, f1: 0.5054182921137579\n",
            "epoch: 832, step: 8, Train: label_loss: 0.09629961848258972, precision: 0.34100545124165105, recall: 0.8838304552588879, f1: 0.4921328670926446\n",
            "epoch: 832, step: 9, Train: label_loss: 0.09850823879241943, precision: 0.3155048076922887, recall: 0.883838383838235, f1: 0.4650132860550749\n",
            "epoch: 832, step: 10, Train: label_loss: 0.10877010226249695, precision: 0.326567164179085, recall: 0.8865478119933733, f1: 0.47731239088556876\n",
            "epoch: 832, step: 11, Train: label_loss: 0.10664728283882141, precision: 0.31765424557114735, recall: 0.8538587848931274, f1: 0.4630454140298902\n",
            "epoch: 832, step: 12, Train: label_loss: 0.10197106003761292, precision: 0.30632289748309965, recall: 0.8457627118642633, f1: 0.4497521405647969\n",
            "epoch: 832, step: 13, Train: label_loss: 0.11896046996116638, precision: 0.31498470948010304, recall: 0.8512396694213469, f1: 0.4598214285319593\n",
            "epoch: 832, step: 14, Train: label_loss: 0.12207134068012238, precision: 0.31926605504585204, recall: 0.8571428571427163, f1: 0.4652406416716409\n",
            "epoch: 832, step: 15, Train: label_loss: 0.11775259673595428, precision: 0.3110018438844308, recall: 0.856175972927097, f1: 0.4562669070844021\n",
            "epoch: 832, step: 16, Train: label_loss: 0.12611648440361023, precision: 0.2999377722464032, recall: 0.8324697754748129, f1: 0.4409881060909348\n",
            "epoch: 832, step: 17, Train: label_loss: 0.11140701174736023, precision: 0.3197781885397215, recall: 0.8722689075628786, f1: 0.46798917940163626\n",
            "epoch: 832, step: 18, Train: label_loss: 0.09646320343017578, precision: 0.3185140073081414, recall: 0.8573770491801872, f1: 0.46447602127484605\n",
            "epoch: 832, step: 19, Train: label_loss: 0.1087944284081459, precision: 0.3303303303303105, recall: 0.8928571428569978, f1: 0.4822446295089761\n",
            "epoch: 832, step: 20, Train: label_loss: 0.12162254750728607, precision: 0.31508515815083243, recall: 0.8720538720537252, f1: 0.46291331542119696\n",
            "epoch: 832, step: 21, Train: label_loss: 0.11955238878726959, precision: 0.3037267080745153, recall: 0.8358974358972929, f1: 0.44555808652122686\n",
            "epoch: 832, step: 22, Train: label_loss: 0.11201116442680359, precision: 0.3183475091129819, recall: 0.8762541806018601, f1: 0.4670231728663898\n",
            "epoch: 832, step: 23, Train: label_loss: 0.09886039793491364, precision: 0.3190546528803309, recall: 0.8944099378880136, f1: 0.4703320631076237\n",
            "epoch: 833, step: 0, Train: label_loss: 0.09699118137359619, precision: 0.30997624703086046, recall: 0.9062499999998426, f1: 0.4619469026168444\n",
            "epoch: 833, step: 1, Train: label_loss: 0.09653124958276749, precision: 0.33074626865669665, recall: 0.9096880131361396, f1: 0.4851138353373815\n",
            "epoch: 833, step: 2, Train: label_loss: 0.10074487328529358, precision: 0.31212484993995726, recall: 0.8873720136517257, f1: 0.4618117228744248\n",
            "epoch: 833, step: 3, Train: label_loss: 0.09682103991508484, precision: 0.3201201201201009, recall: 0.8853820598005173, f1: 0.4702249668775818\n",
            "epoch: 833, step: 4, Train: label_loss: 0.10467857122421265, precision: 0.31559633027521006, recall: 0.8500823723227594, f1: 0.4603033005849135\n",
            "epoch: 833, step: 5, Train: label_loss: 0.10174665600061417, precision: 0.32267792521107824, recall: 0.8713355048858515, f1: 0.470950704185868\n",
            "epoch: 833, step: 6, Train: label_loss: 0.10082490742206573, precision: 0.31055155875297896, recall: 0.8676716917921494, f1: 0.4573951434489975\n",
            "epoch: 833, step: 7, Train: label_loss: 0.10854236781597137, precision: 0.32304900181486246, recall: 0.8739770867429011, f1: 0.4717314487238006\n",
            "epoch: 833, step: 8, Train: label_loss: 0.09245283901691437, precision: 0.30946601941745694, recall: 0.8499999999998583, f1: 0.45373665476509684\n",
            "epoch: 833, step: 9, Train: label_loss: 0.0828881561756134, precision: 0.34798099762468243, recall: 0.9057187017000146, f1: 0.5027885027483553\n",
            "epoch: 833, step: 10, Train: label_loss: 0.09794607758522034, precision: 0.3327348892878317, recall: 0.8953301127212728, f1: 0.4851657940267688\n",
            "epoch: 833, step: 11, Train: label_loss: 0.10179749131202698, precision: 0.30277442702048835, recall: 0.8745644599301612, f1: 0.449820788492219\n",
            "epoch: 833, step: 12, Train: label_loss: 0.08899356424808502, precision: 0.32384341637008757, recall: 0.8980263157893259, f1: 0.47602441146928237\n",
            "epoch: 833, step: 13, Train: label_loss: 0.09756513684988022, precision: 0.31920048455479594, recall: 0.8653530377666887, f1: 0.4663716813765168\n",
            "epoch: 833, step: 14, Train: label_loss: 0.09157577157020569, precision: 0.3299401197604593, recall: 0.9003267973854737, f1: 0.48290972826920653\n",
            "epoch: 833, step: 15, Train: label_loss: 0.10030554234981537, precision: 0.3069486404833651, recall: 0.8743545611013985, f1: 0.45438282643734446\n",
            "epoch: 833, step: 16, Train: label_loss: 0.10903693735599518, precision: 0.3053527980535094, recall: 0.8640275387261851, f1: 0.45123595501755165\n",
            "epoch: 833, step: 17, Train: label_loss: 0.10022828727960587, precision: 0.32267792521107824, recall: 0.8887043189367294, f1: 0.47345132739450285\n",
            "epoch: 833, step: 18, Train: label_loss: 0.08993823826313019, precision: 0.3273809523809329, recall: 0.9090909090907587, f1: 0.48140043759778595\n",
            "epoch: 833, step: 19, Train: label_loss: 0.10155454277992249, precision: 0.3128048780487614, recall: 0.8549999999998574, f1: 0.45803571424645145\n",
            "epoch: 833, step: 20, Train: label_loss: 0.08533982932567596, precision: 0.3303624480094872, recall: 0.8953301127212728, f1: 0.48263888884947015\n",
            "epoch: 833, step: 21, Train: label_loss: 0.10778312385082245, precision: 0.32430806257519107, recall: 0.8749999999998579, f1: 0.47322212463126434\n",
            "epoch: 833, step: 22, Train: label_loss: 0.09368549287319183, precision: 0.29970149253729556, recall: 0.898032200357621, f1: 0.44941808411642137\n",
            "epoch: 833, step: 23, Train: label_loss: 0.09005988389253616, precision: 0.3160204828090478, recall: 0.8981288981287114, f1: 0.46753246749391\n",
            "epoch: 834, step: 0, Train: label_loss: 0.07981623709201813, precision: 0.3179122182680713, recall: 0.8963210702339638, f1: 0.46935201397181264\n",
            "epoch: 834, step: 1, Train: label_loss: 0.08504266291856766, precision: 0.31428571428569557, recall: 0.8918918918917411, f1: 0.4647887323557912\n",
            "epoch: 834, step: 2, Train: label_loss: 0.09482903778553009, precision: 0.3265913146936153, recall: 0.8912337662336215, f1: 0.47801480187624884\n",
            "epoch: 834, step: 3, Train: label_loss: 0.08917617797851562, precision: 0.30805970149251893, recall: 0.8989547038325959, f1: 0.4588706091215687\n",
            "epoch: 834, step: 4, Train: label_loss: 0.09509946405887604, precision: 0.34266984505361486, recall: 0.8928571428570041, f1: 0.49526270452490234\n",
            "epoch: 834, step: 5, Train: label_loss: 0.09524287283420563, precision: 0.29873264936630667, recall: 0.8490566037734392, f1: 0.44196428567574053\n",
            "epoch: 834, step: 6, Train: label_loss: 0.09160615503787994, precision: 0.31512605042014913, recall: 0.8928571428569909, f1: 0.46583850927816545\n",
            "epoch: 834, step: 7, Train: label_loss: 0.10133467614650726, precision: 0.32992788461536476, recall: 0.8826366559484111, f1: 0.4803149605902677\n",
            "epoch: 834, step: 8, Train: label_loss: 0.08212468773126602, precision: 0.32735961768217875, recall: 0.9013157894735359, f1: 0.480280455701447\n",
            "epoch: 834, step: 9, Train: label_loss: 0.08471553027629852, precision: 0.3184290030211288, recall: 0.9008547008545468, f1: 0.47053571424708107\n",
            "epoch: 834, step: 10, Train: label_loss: 0.09307294338941574, precision: 0.30801944106924006, recall: 0.8578680203044233, f1: 0.45328565038575636\n",
            "epoch: 834, step: 11, Train: label_loss: 0.08886627107858658, precision: 0.3287259615384418, recall: 0.8981937602625782, f1: 0.48130224369148156\n",
            "epoch: 834, step: 12, Train: label_loss: 0.08264695107936859, precision: 0.31733653269344225, recall: 0.9073756432245441, f1: 0.47022222218378584\n",
            "epoch: 834, step: 13, Train: label_loss: 0.08973933756351471, precision: 0.3238095238095045, recall: 0.9036544850496837, f1: 0.47677475894446386\n",
            "epoch: 834, step: 14, Train: label_loss: 0.07757193595170975, precision: 0.29797377830749117, recall: 0.8928571428569834, f1: 0.44682752453795155\n",
            "epoch: 834, step: 15, Train: label_loss: 0.07855811715126038, precision: 0.3512080141425839, recall: 0.9169230769229358, f1: 0.5078824030276531\n",
            "epoch: 834, step: 16, Train: label_loss: 0.11717323958873749, precision: 0.3216019417475533, recall: 0.8789386401325242, f1: 0.4709018213734394\n",
            "epoch: 834, step: 17, Train: label_loss: 0.09597499668598175, precision: 0.34335538184002745, recall: 0.8963893249606127, f1: 0.49652173909034125\n",
            "epoch: 834, step: 18, Train: label_loss: 0.08485472202301025, precision: 0.3283671036948553, recall: 0.8959349593494478, f1: 0.4805931094242884\n",
            "epoch: 834, step: 19, Train: label_loss: 0.06943919509649277, precision: 0.3213655091229946, recall: 0.9222972972971414, f1: 0.4766477520349626\n",
            "epoch: 834, step: 20, Train: label_loss: 0.09366653859615326, precision: 0.2960760998810763, recall: 0.8908765652950105, f1: 0.44444444440696057\n",
            "epoch: 834, step: 21, Train: label_loss: 0.07045334577560425, precision: 0.33412182140743146, recall: 0.9011164274320731, f1: 0.4874892148008724\n",
            "epoch: 834, step: 22, Train: label_loss: 0.11411743611097336, precision: 0.2967702620353262, recall: 0.855887521968215, f1: 0.4407239818621771\n",
            "epoch: 834, step: 23, Train: label_loss: 0.09076282382011414, precision: 0.34283625730991646, recall: 0.916015624999821, f1: 0.4989361701730787\n",
            "epoch: 835, step: 0, Train: label_loss: 0.09501641988754272, precision: 0.3089921544960586, recall: 0.8737201365186221, f1: 0.4565314310803959\n",
            "epoch: 835, step: 1, Train: label_loss: 0.0868682861328125, precision: 0.3286670724284645, recall: 0.8695652173911642, f1: 0.4770318020802879\n",
            "epoch: 835, step: 2, Train: label_loss: 0.08498958498239517, precision: 0.30542168674696957, recall: 0.8564189189187742, f1: 0.4502664298013475\n",
            "epoch: 835, step: 3, Train: label_loss: 0.08997566998004913, precision: 0.3132892363198849, recall: 0.8654485049832449, f1: 0.46004415007130606\n",
            "epoch: 835, step: 4, Train: label_loss: 0.10767409950494766, precision: 0.3206751054852127, recall: 0.8636363636362234, f1: 0.4676923076527759\n",
            "epoch: 835, step: 5, Train: label_loss: 0.08777052164077759, precision: 0.29739336492889235, recall: 0.9045045045043415, f1: 0.44761480156771105\n",
            "epoch: 835, step: 6, Train: label_loss: 0.08002963662147522, precision: 0.3178066037735662, recall: 0.9213675213673638, f1: 0.4725997369192951\n",
            "epoch: 835, step: 7, Train: label_loss: 0.08555518090724945, precision: 0.32021466905185925, recall: 0.896494156928064, f1: 0.4718804920525636\n",
            "epoch: 835, step: 8, Train: label_loss: 0.09365671128034592, precision: 0.3240356083085861, recall: 0.9191919191917644, f1: 0.47915752519178073\n",
            "epoch: 835, step: 9, Train: label_loss: 0.08723663538694382, precision: 0.3279279279279082, recall: 0.8921568627449522, f1: 0.4795783925825217\n",
            "epoch: 835, step: 10, Train: label_loss: 0.06471744179725647, precision: 0.3341246290800989, recall: 0.9290429042902757, f1: 0.4914884329597384\n",
            "epoch: 835, step: 11, Train: label_loss: 0.08454783260822296, precision: 0.33473305338930204, recall: 0.8815165876775858, f1: 0.485217391264411\n",
            "epoch: 835, step: 12, Train: label_loss: 0.09429435431957245, precision: 0.32045866022931074, recall: 0.8719211822658666, f1: 0.46866725503567547\n",
            "epoch: 835, step: 13, Train: label_loss: 0.09401871263980865, precision: 0.31891891891889973, recall: 0.8835274542427813, f1: 0.4686672550360045\n",
            "epoch: 835, step: 14, Train: label_loss: 0.08849148452281952, precision: 0.3258293838862366, recall: 0.9121061359865816, f1: 0.4801396769581171\n",
            "epoch: 835, step: 15, Train: label_loss: 0.0906582921743393, precision: 0.33511586452760933, recall: 0.9111470113084149, f1: 0.49000868805794584\n",
            "epoch: 835, step: 16, Train: label_loss: 0.0935896709561348, precision: 0.32269717037927015, recall: 0.880131362889839, f1: 0.4722466959959393\n",
            "epoch: 835, step: 17, Train: label_loss: 0.07477045059204102, precision: 0.3313609467455425, recall: 0.9225700164743125, f1: 0.48759251193320996\n",
            "epoch: 835, step: 18, Train: label_loss: 0.08615395426750183, precision: 0.3384706579727126, recall: 0.9224555735055052, f1: 0.49522983517317104\n",
            "epoch: 835, step: 19, Train: label_loss: 0.08532442897558212, precision: 0.3049219687874967, recall: 0.8834782608694115, f1: 0.4533690316440947\n",
            "epoch: 835, step: 20, Train: label_loss: 0.11073610931634903, precision: 0.31466030989271065, recall: 0.8979591836733166, f1: 0.46601941743725617\n",
            "epoch: 835, step: 21, Train: label_loss: 0.08727887272834778, precision: 0.32644628099171624, recall: 0.9140495867767083, f1: 0.4810787298437346\n",
            "epoch: 835, step: 22, Train: label_loss: 0.09276365488767624, precision: 0.31848284166163043, recall: 0.8700657894735411, f1: 0.4662847068800752\n",
            "epoch: 835, step: 23, Train: label_loss: 0.0833621472120285, precision: 0.3157514450866824, recall: 0.9199999999998063, f1: 0.4701452393379128\n",
            "epoch: 836, step: 0, Train: label_loss: 0.0907563716173172, precision: 0.3103448275861884, recall: 0.9062499999998426, f1: 0.4623560672781639\n",
            "epoch: 836, step: 1, Train: label_loss: 0.07499098032712936, precision: 0.30896226415092515, recall: 0.906574394463511, f1: 0.4608619172883424\n",
            "epoch: 836, step: 2, Train: label_loss: 0.08886492252349854, precision: 0.3523409363745287, recall: 0.9044684129428497, f1: 0.5071274297652214\n",
            "epoch: 836, step: 3, Train: label_loss: 0.07459105551242828, precision: 0.30304806565062703, recall: 0.919928825622612, f1: 0.4559082892043038\n",
            "epoch: 836, step: 4, Train: label_loss: 0.0822121873497963, precision: 0.32252358490564137, recall: 0.9162479061975014, f1: 0.47710423022747106\n",
            "epoch: 836, step: 5, Train: label_loss: 0.08858105540275574, precision: 0.3001797483522888, recall: 0.8713043478259354, f1: 0.4465240641329671\n",
            "epoch: 836, step: 6, Train: label_loss: 0.08854134380817413, precision: 0.32858837485170056, recall: 0.9081967213113264, f1: 0.48257839717348266\n",
            "epoch: 836, step: 7, Train: label_loss: 0.08998820185661316, precision: 0.3389121338911931, recall: 0.8985736925513631, f1: 0.4921874999601841\n",
            "epoch: 836, step: 8, Train: label_loss: 0.08428366482257843, precision: 0.3105700712588889, recall: 0.9001721170394319, f1: 0.46181015448720286\n",
            "epoch: 836, step: 9, Train: label_loss: 0.09044834971427917, precision: 0.3176400476757856, recall: 0.8988195615512817, f1: 0.4693967414849293\n",
            "epoch: 836, step: 10, Train: label_loss: 0.08567237108945847, precision: 0.3174224343675228, recall: 0.8971332209104725, f1: 0.4689290435929054\n",
            "epoch: 836, step: 11, Train: label_loss: 0.07695231586694717, precision: 0.3240190249702542, recall: 0.9113712374580415, f1: 0.47807017539985663\n",
            "epoch: 836, step: 12, Train: label_loss: 0.08083134889602661, precision: 0.33609467455619313, recall: 0.9205834683953127, f1: 0.4924143909447354\n",
            "epoch: 836, step: 13, Train: label_loss: 0.0895468220114708, precision: 0.35131964809382105, recall: 0.9229583975345265, f1: 0.5089209855165183\n",
            "epoch: 836, step: 14, Train: label_loss: 0.08023662865161896, precision: 0.32758620689653223, recall: 0.9198664440733021, f1: 0.4831214379270335\n",
            "epoch: 836, step: 15, Train: label_loss: 0.08171746879816055, precision: 0.3347230494341671, recall: 0.9093851132684612, f1: 0.4893339137612348\n",
            "epoch: 836, step: 16, Train: label_loss: 0.08158961683511734, precision: 0.34443783462222816, recall: 0.9132492113563228, f1: 0.5002159826815663\n",
            "epoch: 836, step: 17, Train: label_loss: 0.09305866062641144, precision: 0.32422586520945207, recall: 0.8855721393033357, f1: 0.4746666666273893\n",
            "epoch: 836, step: 18, Train: label_loss: 0.08322352170944214, precision: 0.3214497920380082, recall: 0.9016666666665163, f1: 0.4739378011000625\n",
            "epoch: 836, step: 19, Train: label_loss: 0.08860056102275848, precision: 0.29432835820893766, recall: 0.883512544802709, f1: 0.4415584415209133\n",
            "epoch: 836, step: 20, Train: label_loss: 0.08733652532100677, precision: 0.32622853759619147, recall: 0.9244966442951468, f1: 0.4822757111211355\n",
            "epoch: 836, step: 21, Train: label_loss: 0.08201278746128082, precision: 0.3364872856297849, recall: 0.9252032520323699, f1: 0.4934952297960558\n",
            "epoch: 836, step: 22, Train: label_loss: 0.08953089267015457, precision: 0.31600955794502295, recall: 0.8890756302519514, f1: 0.46628470688061346\n",
            "epoch: 836, step: 23, Train: label_loss: 0.09984107315540314, precision: 0.3216374269005613, recall: 0.8943089430892491, f1: 0.47311827953093205\n",
            "epoch: 837, step: 0, Train: label_loss: 0.07630187273025513, precision: 0.3355145746579217, recall: 0.9096774193546919, f1: 0.4902216427246039\n",
            "epoch: 837, step: 1, Train: label_loss: 0.08535134792327881, precision: 0.33811230585422114, recall: 0.8913385826770249, f1: 0.4902555218310214\n",
            "epoch: 837, step: 2, Train: label_loss: 0.08659341931343079, precision: 0.3293341331733456, recall: 0.8970588235292651, f1: 0.4817902588461487\n",
            "epoch: 837, step: 3, Train: label_loss: 0.0751817524433136, precision: 0.32507374631266517, recall: 0.9047619047617561, f1: 0.4782986110721783\n",
            "epoch: 837, step: 4, Train: label_loss: 0.0865492969751358, precision: 0.33728512151746665, recall: 0.8988941548181834, f1: 0.49051724133958785\n",
            "epoch: 837, step: 5, Train: label_loss: 0.09137149155139923, precision: 0.3139604553624737, recall: 0.8926746166949074, f1: 0.46453900705365864\n",
            "epoch: 837, step: 6, Train: label_loss: 0.08290326595306396, precision: 0.3217442545668638, recall: 0.9285714285712706, f1: 0.4778993435065937\n",
            "epoch: 837, step: 7, Train: label_loss: 0.08622784912586212, precision: 0.3099940155595266, recall: 0.9024390243900866, f1: 0.46146993314675255\n",
            "epoch: 837, step: 8, Train: label_loss: 0.10324978828430176, precision: 0.31272509003599563, recall: 0.8785834738615719, f1: 0.4612660468846573\n",
            "epoch: 837, step: 9, Train: label_loss: 0.08862555027008057, precision: 0.316676700782642, recall: 0.8723051409617126, f1: 0.46466431091494165\n",
            "epoch: 837, step: 10, Train: label_loss: 0.08061937242746353, precision: 0.3274544385655304, recall: 0.9191419141912675, f1: 0.48287819675359345\n",
            "epoch: 837, step: 11, Train: label_loss: 0.08735425025224686, precision: 0.31863609641385543, recall: 0.9328743545609409, f1: 0.47502191056673515\n",
            "epoch: 837, step: 12, Train: label_loss: 0.09246401488780975, precision: 0.30661809350332075, recall: 0.8444816053510293, f1: 0.44988864138626633\n",
            "epoch: 837, step: 13, Train: label_loss: 0.09144449979066849, precision: 0.3509815585960529, recall: 0.9035222052065998, f1: 0.5055698371490307\n",
            "epoch: 837, step: 14, Train: label_loss: 0.08312643319368362, precision: 0.32056570418383495, recall: 0.9096989966553662, f1: 0.47407407403549845\n",
            "epoch: 837, step: 15, Train: label_loss: 0.07326863706111908, precision: 0.30846063454757294, recall: 0.9259259259257625, f1: 0.46275892459887386\n",
            "epoch: 837, step: 16, Train: label_loss: 0.08931389451026917, precision: 0.31985731272292983, recall: 0.9165247018737791, f1: 0.47421771701757465\n",
            "epoch: 837, step: 17, Train: label_loss: 0.06964121013879776, precision: 0.32726204465332975, recall: 0.914614121510523, f1: 0.48204240584604086\n",
            "epoch: 837, step: 18, Train: label_loss: 0.0863487496972084, precision: 0.31506849315066615, recall: 0.8966101694913734, f1: 0.46628470688082413\n",
            "epoch: 837, step: 19, Train: label_loss: 0.09290509670972824, precision: 0.33655006031361057, recall: 0.8787401574801765, f1: 0.4866986480192206\n",
            "epoch: 837, step: 20, Train: label_loss: 0.07864886522293091, precision: 0.3187463039621337, recall: 0.9028475711891284, f1: 0.4711538461152362\n",
            "epoch: 837, step: 21, Train: label_loss: 0.09158572554588318, precision: 0.31594546532303996, recall: 0.9064625850338593, f1: 0.46857142853305556\n",
            "epoch: 837, step: 22, Train: label_loss: 0.07726922631263733, precision: 0.31907308377894716, recall: 0.897993311036639, f1: 0.47084612008402493\n",
            "epoch: 837, step: 23, Train: label_loss: 0.08088061958551407, precision: 0.2983988355167177, recall: 0.8951965065500229, f1: 0.44759825323756025\n",
            "epoch: 838, step: 0, Train: label_loss: 0.07668058574199677, precision: 0.32702542874037094, recall: 0.9095394736840609, f1: 0.4810787298436112\n",
            "epoch: 838, step: 1, Train: label_loss: 0.08495291322469711, precision: 0.31204819277106555, recall: 0.8691275167783776, f1: 0.4592198581171094\n",
            "epoch: 838, step: 2, Train: label_loss: 0.094170480966568, precision: 0.3109243697478805, recall: 0.885470085469934, f1: 0.4602398933422099\n",
            "epoch: 838, step: 3, Train: label_loss: 0.0802420899271965, precision: 0.3252225519287641, recall: 0.8983606557375576, f1: 0.4775599128149593\n",
            "epoch: 838, step: 4, Train: label_loss: 0.09469455480575562, precision: 0.3194278903456305, recall: 0.9008403361343024, f1: 0.47162340515268636\n",
            "epoch: 838, step: 5, Train: label_loss: 0.08867156505584717, precision: 0.32048192771082407, recall: 0.8721311475408405, f1: 0.46872246692100894\n",
            "epoch: 838, step: 6, Train: label_loss: 0.08135035634040833, precision: 0.30657815328905813, recall: 0.8654173764904828, f1: 0.4527629233124864\n",
            "epoch: 838, step: 7, Train: label_loss: 0.09462051093578339, precision: 0.32895522388057735, recall: 0.9077429983524039, f1: 0.4829097282694107\n",
            "epoch: 838, step: 8, Train: label_loss: 0.08082634210586548, precision: 0.3337285121517289, recall: 0.9154471544713958, f1: 0.48913987832743827\n",
            "epoch: 838, step: 9, Train: label_loss: 0.08652784675359726, precision: 0.30525686977298055, recall: 0.9044247787609018, f1: 0.4564537739684786\n",
            "epoch: 838, step: 10, Train: label_loss: 0.09633930027484894, precision: 0.33113377324533105, recall: 0.8860353130014629, f1: 0.4820960698293456\n",
            "epoch: 838, step: 11, Train: label_loss: 0.08114353567361832, precision: 0.3351001177856104, recall: 0.9222042139382621, f1: 0.4915766738269505\n",
            "epoch: 838, step: 12, Train: label_loss: 0.09423896670341492, precision: 0.33831440525999174, recall: 0.8885400313970347, f1: 0.49004329000330454\n",
            "epoch: 838, step: 13, Train: label_loss: 0.08338802307844162, precision: 0.3347255369928201, recall: 0.9092382495946661, f1: 0.4893153074181014\n",
            "epoch: 838, step: 14, Train: label_loss: 0.08963654935359955, precision: 0.3223880597014733, recall: 0.8955223880595529, f1: 0.4741000877573436\n",
            "epoch: 838, step: 15, Train: label_loss: 0.09163038432598114, precision: 0.3289156626505826, recall: 0.8863636363634924, f1: 0.47978910365116345\n",
            "epoch: 838, step: 16, Train: label_loss: 0.0971018522977829, precision: 0.30047505938240493, recall: 0.9068100358421314, f1: 0.451382693985765\n",
            "epoch: 838, step: 17, Train: label_loss: 0.08928462862968445, precision: 0.32896305125147024, recall: 0.9019607843135781, f1: 0.48209606982978814\n",
            "epoch: 838, step: 18, Train: label_loss: 0.11300444602966309, precision: 0.3052378085490484, recall: 0.874137931034332, f1: 0.4524765729200945\n",
            "epoch: 838, step: 19, Train: label_loss: 0.09172758460044861, precision: 0.30960854092524853, recall: 0.8969072164946912, f1: 0.4603174602792671\n",
            "epoch: 838, step: 20, Train: label_loss: 0.10319346189498901, precision: 0.2999999999999817, recall: 0.8601398601397097, f1: 0.44484629290917427\n",
            "epoch: 838, step: 21, Train: label_loss: 0.08463484048843384, precision: 0.3319402985074429, recall: 0.9114754098359161, f1: 0.48665207873543614\n",
            "epoch: 838, step: 22, Train: label_loss: 0.08600294589996338, precision: 0.3279279279279082, recall: 0.9009900990097522, f1: 0.4808454424971577\n",
            "epoch: 838, step: 23, Train: label_loss: 0.08644173294305801, precision: 0.3345428156748669, recall: 0.9074803149604513, f1: 0.48886532339643085\n",
            "epoch: 839, step: 0, Train: label_loss: 0.07347209751605988, precision: 0.3241013553329214, recall: 0.9090909090907587, f1: 0.4778453518291508\n",
            "epoch: 839, step: 1, Train: label_loss: 0.08478711545467377, precision: 0.32248342374922706, recall: 0.8813838550245664, f1: 0.4721977051681488\n",
            "epoch: 839, step: 2, Train: label_loss: 0.09203983843326569, precision: 0.3086196503917837, recall: 0.8663282571910547, f1: 0.4551111110723361\n",
            "epoch: 839, step: 3, Train: label_loss: 0.08651125431060791, precision: 0.3266152934202533, recall: 0.9198664440733021, f1: 0.4820647418685454\n",
            "epoch: 839, step: 4, Train: label_loss: 0.0862388089299202, precision: 0.32123735871503145, recall: 0.8970099667772595, f1: 0.47306176080212586\n",
            "epoch: 839, step: 5, Train: label_loss: 0.08634155988693237, precision: 0.3063549160671279, recall: 0.8780068728520828, f1: 0.4542222221838302\n",
            "epoch: 839, step: 6, Train: label_loss: 0.09638763219118118, precision: 0.3077844311377061, recall: 0.8954703832751052, f1: 0.45811051689593285\n",
            "epoch: 839, step: 7, Train: label_loss: 0.0918724536895752, precision: 0.30886670581325254, recall: 0.914782608695493, f1: 0.46180860400084955\n",
            "epoch: 839, step: 8, Train: label_loss: 0.08337840437889099, precision: 0.3281155930162355, recall: 0.8762057877812095, f1: 0.47744196229058133\n",
            "epoch: 839, step: 9, Train: label_loss: 0.08395044505596161, precision: 0.3279279279279082, recall: 0.8980263157893259, f1: 0.48042234927885186\n",
            "epoch: 839, step: 10, Train: label_loss: 0.08046368509531021, precision: 0.3291888691533257, recall: 0.9084967320259952, f1: 0.48326814424600534\n",
            "epoch: 839, step: 11, Train: label_loss: 0.07624470442533493, precision: 0.3255535607420511, recall: 0.8874388254484685, f1: 0.47635726791165023\n",
            "epoch: 839, step: 12, Train: label_loss: 0.09288514405488968, precision: 0.32728372655775395, recall: 0.8655999999998615, f1: 0.4749780508820019\n",
            "epoch: 839, step: 13, Train: label_loss: 0.09460106492042542, precision: 0.3214501510573824, recall: 0.8896321070232626, f1: 0.47225920990326237\n",
            "epoch: 839, step: 14, Train: label_loss: 0.07526800781488419, precision: 0.31081081081079254, recall: 0.913644214162191, f1: 0.4638316527459454\n",
            "epoch: 839, step: 15, Train: label_loss: 0.09333237260580063, precision: 0.32352941176468647, recall: 0.8909090909089435, f1: 0.47468075733647724\n",
            "epoch: 839, step: 16, Train: label_loss: 0.09310846030712128, precision: 0.3365269461077643, recall: 0.9093851132684612, f1: 0.4912587412192687\n",
            "epoch: 839, step: 17, Train: label_loss: 0.0772387683391571, precision: 0.3299522673030829, recall: 0.908045977011345, f1: 0.4840262581665494\n",
            "epoch: 839, step: 18, Train: label_loss: 0.09236849844455719, precision: 0.30875299760189995, recall: 0.8987783595111869, f1: 0.45961624271066936\n",
            "epoch: 839, step: 19, Train: label_loss: 0.09445469081401825, precision: 0.33056379821956494, recall: 0.9056910569104217, f1: 0.48434782604773574\n",
            "epoch: 839, step: 20, Train: label_loss: 0.08454794436693192, precision: 0.33588685916320943, recall: 0.9313725490194555, f1: 0.4937202251667143\n",
            "epoch: 839, step: 21, Train: label_loss: 0.08910086750984192, precision: 0.31279904306218226, recall: 0.8819561551431901, f1: 0.4618101544866924\n",
            "epoch: 839, step: 22, Train: label_loss: 0.08755964785814285, precision: 0.3273488928784963, recall: 0.8981937602625782, f1: 0.47982456136431473\n",
            "epoch: 839, step: 23, Train: label_loss: 0.07418288290500641, precision: 0.32846715328464754, recall: 0.9127789046651292, f1: 0.48309178740064174\n",
            "epoch: 840, step: 0, Train: label_loss: 0.09687022119760513, precision: 0.3037667071688758, recall: 0.863557858376362, f1: 0.449438202208649\n",
            "epoch: 840, step: 1, Train: label_loss: 0.08720359951257706, precision: 0.3229850746268464, recall: 0.9107744107742574, f1: 0.47686205372948665\n",
            "epoch: 840, step: 2, Train: label_loss: 0.09022179245948792, precision: 0.3216867469879324, recall: 0.878289473684066, f1: 0.47089947086018696\n",
            "epoch: 840, step: 3, Train: label_loss: 0.08839462697505951, precision: 0.33293697978594927, recall: 0.9017713365537999, f1: 0.4863221884104181\n",
            "epoch: 840, step: 4, Train: label_loss: 0.077257439494133, precision: 0.3179396092362156, recall: 0.9025210084032096, f1: 0.4702276707144949\n",
            "epoch: 840, step: 5, Train: label_loss: 0.07423318922519684, precision: 0.3301662707838284, recall: 0.9040650406502594, f1: 0.4836885602043526\n",
            "epoch: 840, step: 6, Train: label_loss: 0.08977861702442169, precision: 0.311750599520365, recall: 0.8919382504286634, f1: 0.4620168813476262\n",
            "epoch: 840, step: 7, Train: label_loss: 0.089033342897892, precision: 0.3337334933973389, recall: 0.8938906752410137, f1: 0.4860139859743537\n",
            "epoch: 840, step: 8, Train: label_loss: 0.07892017066478729, precision: 0.3238770685579005, recall: 0.9194630872481678, f1: 0.4790209789824102\n",
            "epoch: 840, step: 9, Train: label_loss: 0.08214029669761658, precision: 0.3254716981131883, recall: 0.918469217969897, f1: 0.4806269046195706\n",
            "epoch: 840, step: 10, Train: label_loss: 0.09159614890813828, precision: 0.3129862357869352, recall: 0.8775167785233426, f1: 0.4614027348531299\n",
            "epoch: 840, step: 11, Train: label_loss: 0.07173412293195724, precision: 0.3252941176470397, recall: 0.9140495867767083, f1: 0.4798264641694851\n",
            "epoch: 840, step: 12, Train: label_loss: 0.07952114194631577, precision: 0.34697508896795093, recall: 0.9055727554178165, f1: 0.5017152658261106\n",
            "epoch: 840, step: 13, Train: label_loss: 0.09074579179286957, precision: 0.32574850299399244, recall: 0.8816855753645247, f1: 0.47573240048526294\n",
            "epoch: 840, step: 14, Train: label_loss: 0.07782549411058426, precision: 0.3158205430932517, recall: 0.917667238421798, f1: 0.46991655683494066\n",
            "epoch: 840, step: 15, Train: label_loss: 0.08211563527584076, precision: 0.3365041617122273, recall: 0.8955696202530228, f1: 0.4891961970216182\n",
            "epoch: 840, step: 16, Train: label_loss: 0.07584213465452194, precision: 0.3202614379084777, recall: 0.9151103565363471, f1: 0.47447183094746653\n",
            "epoch: 840, step: 17, Train: label_loss: 0.07018642872571945, precision: 0.31802120141340884, recall: 0.9230769230767653, f1: 0.4730617608028408\n",
            "epoch: 840, step: 18, Train: label_loss: 0.08747544884681702, precision: 0.3124627310673636, recall: 0.897260273972449, f1: 0.46351172043930816\n",
            "epoch: 840, step: 19, Train: label_loss: 0.08747550845146179, precision: 0.308656716417892, recall: 0.8913793103446739, f1: 0.4585365853276028\n",
            "epoch: 840, step: 20, Train: label_loss: 0.0713503509759903, precision: 0.3260741612713169, recall: 0.9111842105261658, f1: 0.4802774165194413\n",
            "epoch: 840, step: 21, Train: label_loss: 0.08617423474788666, precision: 0.3185053380782729, recall: 0.9132653061222936, f1: 0.472295514473489\n",
            "epoch: 840, step: 22, Train: label_loss: 0.08378257602453232, precision: 0.32240762812870544, recall: 0.9001663893509317, f1: 0.47476963576630243\n",
            "epoch: 840, step: 23, Train: label_loss: 0.08300922811031342, precision: 0.32440260680663835, recall: 0.9124236252543967, f1: 0.47863247859372904\n",
            "epoch: 841, step: 0, Train: label_loss: 0.06923191994428635, precision: 0.33664523670366236, recall: 0.9245585874797874, f1: 0.49357326474231356\n",
            "epoch: 841, step: 1, Train: label_loss: 0.08854986727237701, precision: 0.31127012522359504, recall: 0.8923076923075397, f1: 0.46153846150007355\n",
            "epoch: 841, step: 2, Train: label_loss: 0.07731715589761734, precision: 0.3248520710058979, recall: 0.9149999999998474, f1: 0.4794759824940371\n",
            "epoch: 841, step: 3, Train: label_loss: 0.0904722586274147, precision: 0.3144391408114371, recall: 0.9054982817867859, f1: 0.4667847652407036\n",
            "epoch: 841, step: 4, Train: label_loss: 0.08491747826337814, precision: 0.3210023866348257, recall: 0.8996655518393144, f1: 0.47317502194888167\n",
            "epoch: 841, step: 5, Train: label_loss: 0.08899843692779541, precision: 0.31204819277106555, recall: 0.8779661016947664, f1: 0.46044444440571125\n",
            "epoch: 841, step: 6, Train: label_loss: 0.08415661752223969, precision: 0.32437171244884133, recall: 0.9128289473682708, f1: 0.478654592458036\n",
            "epoch: 841, step: 7, Train: label_loss: 0.07098536938428879, precision: 0.34365867913498865, recall: 0.9303797468352958, f1: 0.501920614557232\n",
            "epoch: 841, step: 8, Train: label_loss: 0.080973319709301, precision: 0.3144208037824873, recall: 0.9063032367971198, f1: 0.4668714348015555\n",
            "epoch: 841, step: 9, Train: label_loss: 0.09033562242984772, precision: 0.32352941176468647, recall: 0.9074074074072546, f1: 0.4769911504036854\n",
            "epoch: 841, step: 10, Train: label_loss: 0.07234411686658859, precision: 0.31775700934577583, recall: 0.9251700680270535, f1: 0.4730434782227696\n",
            "epoch: 841, step: 11, Train: label_loss: 0.07135281711816788, precision: 0.323512080141407, recall: 0.9119601328902139, f1: 0.4775989560291568\n",
            "epoch: 841, step: 12, Train: label_loss: 0.06967692077159882, precision: 0.31618936294562733, recall: 0.9295532646046513, f1: 0.4718709114317705\n",
            "epoch: 841, step: 13, Train: label_loss: 0.06562571227550507, precision: 0.3288155568650366, recall: 0.9147540983605057, f1: 0.4837451234981195\n",
            "epoch: 841, step: 14, Train: label_loss: 0.08075356483459473, precision: 0.30225653206649034, recall: 0.8806228373700898, f1: 0.45004420862681194\n",
            "epoch: 841, step: 15, Train: label_loss: 0.09458784759044647, precision: 0.3259964306959949, recall: 0.913333333333181, f1: 0.4804910126749097\n",
            "epoch: 841, step: 16, Train: label_loss: 0.09468692541122437, precision: 0.31411411411409523, recall: 0.8789915966385077, f1: 0.4628318583682465\n",
            "epoch: 841, step: 17, Train: label_loss: 0.08571486920118332, precision: 0.33588685916320943, recall: 0.9313725490194555, f1: 0.4937202251667143\n",
            "epoch: 841, step: 18, Train: label_loss: 0.07305990904569626, precision: 0.343195266272169, recall: 0.9133858267715096, f1: 0.4989247311430477\n",
            "epoch: 841, step: 19, Train: label_loss: 0.08413256704807281, precision: 0.3249400479616112, recall: 0.8727858293074279, f1: 0.4735692441718656\n",
            "epoch: 841, step: 20, Train: label_loss: 0.07407225668430328, precision: 0.3299941072480654, recall: 0.9240924092407715, f1: 0.48632218841102676\n",
            "epoch: 841, step: 21, Train: label_loss: 0.08241534233093262, precision: 0.3174791914387445, recall: 0.9097103918226729, f1: 0.4706919347346309\n",
            "epoch: 841, step: 22, Train: label_loss: 0.08934350311756134, precision: 0.33750745378650343, recall: 0.9055999999998551, f1: 0.49174630751904413\n",
            "epoch: 841, step: 23, Train: label_loss: 0.08966571092605591, precision: 0.323593864134381, recall: 0.9248434237993894, f1: 0.4794372293987746\n",
            "epoch: 842, step: 0, Train: label_loss: 0.07539938390254974, precision: 0.3085106382978541, recall: 0.9046793760830321, f1: 0.460114587886229\n",
            "epoch: 842, step: 1, Train: label_loss: 0.0676598846912384, precision: 0.34035087719296253, recall: 0.9223454833596002, f1: 0.49722340876023785\n",
            "epoch: 842, step: 2, Train: label_loss: 0.06891541182994843, precision: 0.34845840605000883, recall: 0.9330218068534372, f1: 0.5074121134715853\n",
            "epoch: 842, step: 3, Train: label_loss: 0.09261210262775421, precision: 0.3414344991108274, recall: 0.8916408668729269, f1: 0.4937848263636846\n",
            "epoch: 842, step: 4, Train: label_loss: 0.08423974364995956, precision: 0.322294500295664, recall: 0.8949096880129893, f1: 0.47391304343928514\n",
            "epoch: 842, step: 5, Train: label_loss: 0.07882335036993027, precision: 0.32305868405451554, recall: 0.8978583196044648, f1: 0.4751525718878064\n",
            "epoch: 842, step: 6, Train: label_loss: 0.06665438413619995, precision: 0.307236061684442, recall: 0.8993055555553994, f1: 0.4580017683085955\n",
            "epoch: 842, step: 7, Train: label_loss: 0.09142914414405823, precision: 0.31513353115725135, recall: 0.9061433447097429, f1: 0.4676354028678768\n",
            "epoch: 842, step: 8, Train: label_loss: 0.08196510374546051, precision: 0.30220107079117775, recall: 0.8804159445405753, f1: 0.4499557129822847\n",
            "epoch: 842, step: 9, Train: label_loss: 0.09372276067733765, precision: 0.3402122641509233, recall: 0.9115323854658907, f1: 0.49549162726823076\n",
            "epoch: 842, step: 10, Train: label_loss: 0.07372233271598816, precision: 0.3075550267697616, recall: 0.8960138648178689, f1: 0.4579273693153221\n",
            "epoch: 842, step: 11, Train: label_loss: 0.08561643958091736, precision: 0.3085680047932709, recall: 0.8910034602074582, f1: 0.45838896302360665\n",
            "epoch: 842, step: 12, Train: label_loss: 0.07962621748447418, precision: 0.3362936648904478, recall: 0.9044585987259706, f1: 0.49028916698676933\n",
            "epoch: 842, step: 13, Train: label_loss: 0.06738188862800598, precision: 0.32193396226413196, recall: 0.9191919191917644, f1: 0.47685589515804366\n",
            "epoch: 842, step: 14, Train: label_loss: 0.07383698225021362, precision: 0.3178066037735662, recall: 0.9135593220337433, f1: 0.4715660542048821\n",
            "epoch: 842, step: 15, Train: label_loss: 0.06859901547431946, precision: 0.3366627497062082, recall: 0.9362745098037685, f1: 0.4952463266680523\n",
            "epoch: 842, step: 16, Train: label_loss: 0.07052498310804367, precision: 0.3327423167848503, recall: 0.9154471544713958, f1: 0.48807975722136615\n",
            "epoch: 842, step: 17, Train: label_loss: 0.07106134295463562, precision: 0.3179696616102498, recall: 0.9316239316237723, f1: 0.47411918221517046\n",
            "epoch: 842, step: 18, Train: label_loss: 0.08600033074617386, precision: 0.3325358851674442, recall: 0.9159802306423531, f1: 0.4879333040416132\n",
            "epoch: 842, step: 19, Train: label_loss: 0.08840921521186829, precision: 0.3187274909963794, recall: 0.8999999999998474, f1: 0.47074468081239623\n",
            "epoch: 842, step: 20, Train: label_loss: 0.08379867672920227, precision: 0.32508833922259567, recall: 0.9123966942147251, f1: 0.47937472857607066\n",
            "epoch: 842, step: 21, Train: label_loss: 0.08500127494335175, precision: 0.29689366786139204, recall: 0.8890876565293578, f1: 0.44514106579314755\n",
            "epoch: 842, step: 22, Train: label_loss: 0.09288378059864044, precision: 0.33432304038002764, recall: 0.9066022544281953, f1: 0.488503253756687\n",
            "epoch: 842, step: 23, Train: label_loss: 0.0968654602766037, precision: 0.3055964653902573, recall: 0.8755274261601529, f1: 0.4530567685205444\n",
            "epoch: 843, step: 0, Train: label_loss: 0.07514283061027527, precision: 0.3173758865248039, recall: 0.9163822525595705, f1: 0.4714661983814112\n",
            "epoch: 843, step: 1, Train: label_loss: 0.06960457563400269, precision: 0.29840142095912975, recall: 0.8842105263156342, f1: 0.4462151394044602\n",
            "epoch: 843, step: 2, Train: label_loss: 0.09129093587398529, precision: 0.3157894736841914, recall: 0.8599670510706985, f1: 0.461946902615537\n",
            "epoch: 843, step: 3, Train: label_loss: 0.07539530098438263, precision: 0.3105924596050083, recall: 0.8841567291310248, f1: 0.4596988485000123\n",
            "epoch: 843, step: 4, Train: label_loss: 0.08307395875453949, precision: 0.32816229116943146, recall: 0.9046052631577459, f1: 0.48161120836719495\n",
            "epoch: 843, step: 5, Train: label_loss: 0.08022855222225189, precision: 0.3441943127961881, recall: 0.9135220125784727, f1: 0.49999999996020233\n",
            "epoch: 843, step: 6, Train: label_loss: 0.08016413450241089, precision: 0.3290017720023432, recall: 0.9101307189540996, f1: 0.4832971800043391\n",
            "epoch: 843, step: 7, Train: label_loss: 0.06489598751068115, precision: 0.35643564356433566, recall: 0.9415384615383167, f1: 0.5171102661198123\n",
            "epoch: 843, step: 8, Train: label_loss: 0.0877997875213623, precision: 0.30875299760189995, recall: 0.8743633276738753, f1: 0.45635799730299087\n",
            "epoch: 843, step: 9, Train: label_loss: 0.09526367485523224, precision: 0.30322580645159514, recall: 0.9265232974908733, f1: 0.45691559872550885\n",
            "epoch: 843, step: 10, Train: label_loss: 0.07184460759162903, precision: 0.32446808510636377, recall: 0.9180602006687427, f1: 0.47947598249412043\n",
            "epoch: 843, step: 11, Train: label_loss: 0.08824693411588669, precision: 0.3081986834230815, recall: 0.8894645941276529, f1: 0.4577777777395145\n",
            "epoch: 843, step: 12, Train: label_loss: 0.09389515966176987, precision: 0.3046080191501912, recall: 0.8806228373700898, f1: 0.4526456202374472\n",
            "epoch: 843, step: 13, Train: label_loss: 0.09843908995389938, precision: 0.31212484993995726, recall: 0.8888888888887369, f1: 0.4620168813475407\n",
            "epoch: 843, step: 14, Train: label_loss: 0.08833092451095581, precision: 0.3217286914765713, recall: 0.8687196110209289, f1: 0.46955759961009896\n",
            "epoch: 843, step: 15, Train: label_loss: 0.08786633610725403, precision: 0.3172331544424378, recall: 0.8926174496642797, f1: 0.46810382750196294\n",
            "epoch: 843, step: 16, Train: label_loss: 0.08567513525485992, precision: 0.34139150943394214, recall: 0.9308681672024226, f1: 0.49956859357587613\n",
            "epoch: 843, step: 17, Train: label_loss: 0.08730562031269073, precision: 0.338690476190456, recall: 0.8988941548181834, f1: 0.4920017293160174\n",
            "epoch: 843, step: 18, Train: label_loss: 0.08965496718883514, precision: 0.3417115499700573, recall: 0.9006309148263563, f1: 0.4954446854264545\n",
            "epoch: 843, step: 19, Train: label_loss: 0.08752082288265228, precision: 0.3150029886431372, recall: 0.896258503401208, f1: 0.46616541349530743\n",
            "epoch: 843, step: 20, Train: label_loss: 0.07484778016805649, precision: 0.3272189349112232, recall: 0.9125412541252619, f1: 0.48170731703427383\n",
            "epoch: 843, step: 21, Train: label_loss: 0.08801022917032242, precision: 0.31474820143883003, recall: 0.8823529411763222, f1: 0.4639858594397681\n",
            "epoch: 843, step: 22, Train: label_loss: 0.10554111003875732, precision: 0.31391784181481824, recall: 0.8434925864908001, f1: 0.4575513851257529\n",
            "epoch: 843, step: 23, Train: label_loss: 0.07211042940616608, precision: 0.31548480463094675, recall: 0.9121338912131983, f1: 0.46881720426283563\n",
            "epoch: 844, step: 0, Train: label_loss: 0.07515466958284378, precision: 0.33786178381569176, recall: 0.9196141479098199, f1: 0.4941684664833369\n",
            "epoch: 844, step: 1, Train: label_loss: 0.09182113409042358, precision: 0.31563245823387137, recall: 0.9011925042587902, f1: 0.4675209897980376\n",
            "epoch: 844, step: 2, Train: label_loss: 0.08747580647468567, precision: 0.30077890952664466, recall: 0.8900709219856577, f1: 0.44961934613327387\n",
            "epoch: 844, step: 3, Train: label_loss: 0.09032906591892242, precision: 0.325943678849591, recall: 0.8874388254484685, f1: 0.47677475894401317\n",
            "epoch: 844, step: 4, Train: label_loss: 0.07031789422035217, precision: 0.32051282051280183, recall: 0.9385665529008637, f1: 0.47784535182994736\n",
            "epoch: 844, step: 5, Train: label_loss: 0.09283008426427841, precision: 0.32915921288012345, recall: 0.8917609046848316, f1: 0.4808362368943728\n",
            "epoch: 844, step: 6, Train: label_loss: 0.09146932512521744, precision: 0.3301775147928799, recall: 0.9058441558440087, f1: 0.4839549002209946\n",
            "epoch: 844, step: 7, Train: label_loss: 0.08629763126373291, precision: 0.3035502958579702, recall: 0.89685314685299, f1: 0.4535809018189381\n",
            "epoch: 844, step: 8, Train: label_loss: 0.07755361497402191, precision: 0.33722969023960625, recall: 0.9321486268172968, f1: 0.49527896991802156\n",
            "epoch: 844, step: 9, Train: label_loss: 0.08210955560207367, precision: 0.3538553496712281, recall: 0.8942598187309827, f1: 0.507066381115647\n",
            "epoch: 844, step: 10, Train: label_loss: 0.09191712737083435, precision: 0.324275362318821, recall: 0.8731707317071751, f1: 0.47291941871872056\n",
            "epoch: 844, step: 11, Train: label_loss: 0.09275519102811813, precision: 0.3031379514505445, recall: 0.8998242530754129, f1: 0.4534986713528725\n",
            "epoch: 844, step: 12, Train: label_loss: 0.08501391857862473, precision: 0.30912364945976534, recall: 0.8894645941276529, f1: 0.45879732735589024\n",
            "epoch: 844, step: 13, Train: label_loss: 0.09895111620426178, precision: 0.33293627159021244, recall: 0.891547049441644, f1: 0.484822202909193\n",
            "epoch: 844, step: 14, Train: label_loss: 0.08378381282091141, precision: 0.3063276167947779, recall: 0.9233511586451116, f1: 0.46003552394123376\n",
            "epoch: 844, step: 15, Train: label_loss: 0.07790684700012207, precision: 0.33175355450235, recall: 0.9165302782322559, f1: 0.4871683340192167\n",
            "epoch: 844, step: 16, Train: label_loss: 0.09170138835906982, precision: 0.32793764988007623, recall: 0.8937908496730566, f1: 0.4798245613641924\n",
            "epoch: 844, step: 17, Train: label_loss: 0.07136450707912445, precision: 0.3094117647058641, recall: 0.903780068728367, f1: 0.4609991235377714\n",
            "epoch: 844, step: 18, Train: label_loss: 0.08660730719566345, precision: 0.34142011834317504, recall: 0.9129746835441592, f1: 0.49698535741081135\n",
            "epoch: 844, step: 19, Train: label_loss: 0.07570230960845947, precision: 0.32068761114402367, recall: 0.9001663893509317, f1: 0.4729020978633212\n",
            "epoch: 844, step: 20, Train: label_loss: 0.0733603984117508, precision: 0.3207769276044543, recall: 0.9038142620230672, f1: 0.4735013031758888\n",
            "epoch: 844, step: 21, Train: label_loss: 0.09669394791126251, precision: 0.3145454545454355, recall: 0.8841567291310248, f1: 0.46401430483384604\n",
            "epoch: 844, step: 22, Train: label_loss: 0.07638479024171829, precision: 0.3087802003535469, recall: 0.9160839160837558, f1: 0.46187747902791854\n",
            "epoch: 844, step: 23, Train: label_loss: 0.06382317841053009, precision: 0.33812949640285334, recall: 0.9251968503935187, f1: 0.49525816645178833\n",
            "epoch: 845, step: 0, Train: label_loss: 0.08823587745428085, precision: 0.29239065308566253, recall: 0.902033271718872, f1: 0.44162895923900386\n",
            "epoch: 845, step: 1, Train: label_loss: 0.08636216819286346, precision: 0.32890766445381237, recall: 0.8804523424877414, f1: 0.4789103690288989\n",
            "epoch: 845, step: 2, Train: label_loss: 0.0757145881652832, precision: 0.32882352941174536, recall: 0.917898193760112, f1: 0.4841922909962009\n",
            "epoch: 845, step: 3, Train: label_loss: 0.09486626833677292, precision: 0.31038575667653945, recall: 0.8879456706280325, f1: 0.459982409812058\n",
            "epoch: 845, step: 4, Train: label_loss: 0.0819149911403656, precision: 0.3244390539720846, recall: 0.8685064935063525, f1: 0.4724061809758107\n",
            "epoch: 845, step: 5, Train: label_loss: 0.09527245163917542, precision: 0.299999999999982, recall: 0.8728222996514158, f1: 0.4465240641330106\n",
            "epoch: 845, step: 6, Train: label_loss: 0.0739462673664093, precision: 0.3189604252805482, recall: 0.9015025041734721, f1: 0.4712041884430256\n",
            "epoch: 845, step: 7, Train: label_loss: 0.08503596484661102, precision: 0.30509478672983975, recall: 0.9019264448334672, f1: 0.4559539618922421\n",
            "epoch: 845, step: 8, Train: label_loss: 0.08654648065567017, precision: 0.33635813672109277, recall: 0.8742138364778499, f1: 0.48580166007341435\n",
            "epoch: 845, step: 9, Train: label_loss: 0.08853315562009811, precision: 0.30453172205436224, recall: 0.8780487804876519, f1: 0.4522207267450301\n",
            "epoch: 845, step: 10, Train: label_loss: 0.0866289734840393, precision: 0.3224271267102723, recall: 0.8988391376449587, f1: 0.474605954426946\n",
            "epoch: 845, step: 11, Train: label_loss: 0.07682542502880096, precision: 0.3147058823529227, recall: 0.9256055363320197, f1: 0.4697102721306573\n",
            "epoch: 845, step: 12, Train: label_loss: 0.08828701078891754, precision: 0.3321470937129103, recall: 0.9032258064514671, f1: 0.48568950559811014\n",
            "epoch: 845, step: 13, Train: label_loss: 0.08226370811462402, precision: 0.300832342449447, recall: 0.8846153846152299, f1: 0.4489795917988206\n",
            "epoch: 845, step: 14, Train: label_loss: 0.09252731502056122, precision: 0.3395098625223945, recall: 0.8874999999998613, f1: 0.49113705140826586\n",
            "epoch: 845, step: 15, Train: label_loss: 0.07415753602981567, precision: 0.32585596221957935, recall: 0.9064039408865506, f1: 0.4793747285759065\n",
            "epoch: 845, step: 16, Train: label_loss: 0.09298263490200043, precision: 0.3301662707838284, recall: 0.8924558587478503, f1: 0.4820112700082148\n",
            "epoch: 845, step: 17, Train: label_loss: 0.0836474746465683, precision: 0.31644815256255565, recall: 0.8939393939392434, f1: 0.4674295774261294\n",
            "epoch: 845, step: 18, Train: label_loss: 0.08764997124671936, precision: 0.3639639639639421, recall: 0.9004457652301782, f1: 0.5183917878118226\n",
            "epoch: 845, step: 19, Train: label_loss: 0.08056817948818207, precision: 0.3291888691533257, recall: 0.9070146818921848, f1: 0.48305821021283696\n",
            "epoch: 845, step: 20, Train: label_loss: 0.08263487368822098, precision: 0.3201911589008172, recall: 0.8993288590602517, f1: 0.4722466959964767\n",
            "epoch: 845, step: 21, Train: label_loss: 0.08372926712036133, precision: 0.3196622436670495, recall: 0.9013605442175338, f1: 0.47195013353209847\n",
            "epoch: 845, step: 22, Train: label_loss: 0.08111415058374405, precision: 0.3238770685579005, recall: 0.9241146711634192, f1: 0.4796498905523339\n",
            "epoch: 845, step: 23, Train: label_loss: 0.07096228003501892, precision: 0.3240343347639253, recall: 0.9263803680979701, f1: 0.48012718597109055\n",
            "epoch: 846, step: 0, Train: label_loss: 0.07768938690423965, precision: 0.29782224838138327, recall: 0.9133574007218567, f1: 0.449178872577166\n",
            "epoch: 846, step: 1, Train: label_loss: 0.07774968445301056, precision: 0.3386714116251282, recall: 0.9224555735055052, f1: 0.4954446854270486\n",
            "epoch: 846, step: 2, Train: label_loss: 0.08184176683425903, precision: 0.3140987507435863, recall: 0.8934010152282752, f1: 0.4647887323558335\n",
            "epoch: 846, step: 3, Train: label_loss: 0.07889914512634277, precision: 0.33530805687201803, recall: 0.9099678456590177, f1: 0.4900432900038955\n",
            "epoch: 846, step: 4, Train: label_loss: 0.09036704897880554, precision: 0.3267504488330146, recall: 0.8834951456309249, f1: 0.47706422014402583\n",
            "epoch: 846, step: 5, Train: label_loss: 0.0851837620139122, precision: 0.3170149253731154, recall: 0.9045996592843433, f1: 0.4694960211816852\n",
            "epoch: 846, step: 6, Train: label_loss: 0.08034375309944153, precision: 0.31426886792450975, recall: 0.9111111111109553, f1: 0.4673388864151306\n",
            "epoch: 846, step: 7, Train: label_loss: 0.08401590585708618, precision: 0.3017751479289762, recall: 0.8931698774078995, f1: 0.45112781951107916\n",
            "epoch: 846, step: 8, Train: label_loss: 0.08135692775249481, precision: 0.3253082795067337, recall: 0.9248747913187103, f1: 0.481320590752075\n",
            "epoch: 846, step: 9, Train: label_loss: 0.09105201065540314, precision: 0.31419939577037376, recall: 0.8813559322032404, f1: 0.46325167033983006\n",
            "epoch: 846, step: 10, Train: label_loss: 0.09119375050067902, precision: 0.3121661721068064, recall: 0.9068965517239815, f1: 0.46445916110976215\n",
            "epoch: 846, step: 11, Train: label_loss: 0.07833349704742432, precision: 0.31535269709541697, recall: 0.910958904109433, f1: 0.46851607217663666\n",
            "epoch: 846, step: 12, Train: label_loss: 0.08912615478038788, precision: 0.30989272943979085, recall: 0.8873720136517257, f1: 0.45936395755876486\n",
            "epoch: 846, step: 13, Train: label_loss: 0.08600661158561707, precision: 0.3375224416516854, recall: 0.8966613672494599, f1: 0.49043478256891543\n",
            "epoch: 846, step: 14, Train: label_loss: 0.09150028973817825, precision: 0.33073696824443793, recall: 0.8874598070738122, f1: 0.48188563941915225\n",
            "epoch: 846, step: 15, Train: label_loss: 0.10260210931301117, precision: 0.32894736842103295, recall: 0.9001636661209655, f1: 0.48182216378029263\n",
            "epoch: 846, step: 16, Train: label_loss: 0.07550226151943207, precision: 0.33470346447443716, recall: 0.9223300970872294, f1: 0.49116760013322364\n",
            "epoch: 846, step: 17, Train: label_loss: 0.08874142169952393, precision: 0.3430962343096029, recall: 0.8982785602502505, f1: 0.49653979234750106\n",
            "epoch: 846, step: 18, Train: label_loss: 0.07381802797317505, precision: 0.32028053769723436, recall: 0.9241146711634192, f1: 0.47569444440617614\n",
            "epoch: 846, step: 19, Train: label_loss: 0.07752256095409393, precision: 0.3286549707602147, recall: 0.9213114754096849, f1: 0.4844827585818882\n",
            "epoch: 846, step: 20, Train: label_loss: 0.08101056516170502, precision: 0.3358823529411567, recall: 0.9254457050241611, f1: 0.4928787224468545\n",
            "epoch: 846, step: 21, Train: label_loss: 0.07254201918840408, precision: 0.3337278106508678, recall: 0.903846153846009, f1: 0.48746758855175293\n",
            "epoch: 846, step: 22, Train: label_loss: 0.0874582901597023, precision: 0.3248969982342363, recall: 0.9154228855719875, f1: 0.4795829712905711\n",
            "epoch: 846, step: 23, Train: label_loss: 0.09091243147850037, precision: 0.3071271124173176, recall: 0.8950749464666178, f1: 0.4573304157168323\n",
            "epoch: 847, step: 0, Train: label_loss: 0.0761316567659378, precision: 0.3168141592920167, recall: 0.9179487179485609, f1: 0.4710526315407567\n",
            "epoch: 847, step: 1, Train: label_loss: 0.07369127869606018, precision: 0.3374413145539708, recall: 0.9083728278039639, f1: 0.49208386816756206\n",
            "epoch: 847, step: 2, Train: label_loss: 0.09546853601932526, precision: 0.3107378524294955, recall: 0.880952380952231, f1: 0.4594235032873494\n",
            "epoch: 847, step: 3, Train: label_loss: 0.08494199812412262, precision: 0.3117960877296792, recall: 0.9022298456259172, f1: 0.46343612330980327\n",
            "epoch: 847, step: 4, Train: label_loss: 0.06697238981723785, precision: 0.31220657276993474, recall: 0.9220103986133583, f1: 0.466462077998114\n",
            "epoch: 847, step: 5, Train: label_loss: 0.08764013648033142, precision: 0.32684365781708985, recall: 0.9233333333331794, f1: 0.4827886709853054\n",
            "epoch: 847, step: 6, Train: label_loss: 0.08140886574983597, precision: 0.3160682754561321, recall: 0.9101694915252694, f1: 0.4692005242080914\n",
            "epoch: 847, step: 7, Train: label_loss: 0.08114369213581085, precision: 0.3168141592920167, recall: 0.9055649241145184, f1: 0.4694055943671523\n",
            "epoch: 847, step: 8, Train: label_loss: 0.09378571808338165, precision: 0.3363309352517784, recall: 0.8904761904760491, f1: 0.48825065270167334\n",
            "epoch: 847, step: 9, Train: label_loss: 0.08889677375555038, precision: 0.34813925570226, recall: 0.8978328173373222, f1: 0.5017301037659169\n",
            "epoch: 847, step: 10, Train: label_loss: 0.08656530827283859, precision: 0.32997032640947593, recall: 0.9129720853857285, f1: 0.4847428072844106\n",
            "epoch: 847, step: 11, Train: label_loss: 0.08549800515174866, precision: 0.3341303048415819, recall: 0.9074675324673851, f1: 0.48842289205323586\n",
            "epoch: 847, step: 12, Train: label_loss: 0.07422415167093277, precision: 0.3202846975088778, recall: 0.912162162162008, f1: 0.47410008775780266\n",
            "epoch: 847, step: 13, Train: label_loss: 0.07644452899694443, precision: 0.3388527498521384, recall: 0.905213270142037, f1: 0.4931153183768434\n",
            "epoch: 847, step: 14, Train: label_loss: 0.06858497858047485, precision: 0.29953106682296016, recall: 0.8996478873237852, f1: 0.4494283201032036\n",
            "epoch: 847, step: 15, Train: label_loss: 0.09439314901828766, precision: 0.29555149299205996, recall: 0.8523725834796393, f1: 0.43891402711104605\n",
            "epoch: 847, step: 16, Train: label_loss: 0.087061807513237, precision: 0.32757593805834856, recall: 0.9090909090907587, f1: 0.4816112083673182\n",
            "epoch: 847, step: 17, Train: label_loss: 0.08567842096090317, precision: 0.31290898274834544, recall: 0.8900169204736226, f1: 0.46302816897555193\n",
            "epoch: 847, step: 18, Train: label_loss: 0.08763445913791656, precision: 0.34043812907043575, recall: 0.9259259259257767, f1: 0.4978354977961425\n",
            "epoch: 847, step: 19, Train: label_loss: 0.0758872777223587, precision: 0.34041297935101233, recall: 0.9173290937995361, f1: 0.4965576591687388\n",
            "epoch: 847, step: 20, Train: label_loss: 0.08215197175741196, precision: 0.3124627310673636, recall: 0.897260273972449, f1: 0.46351172043930816\n",
            "epoch: 847, step: 21, Train: label_loss: 0.07600145787000656, precision: 0.34772324068596405, recall: 0.9173166926675635, f1: 0.5042881646256164\n",
            "epoch: 847, step: 22, Train: label_loss: 0.09268544614315033, precision: 0.30220107079117775, recall: 0.8991150442476284, f1: 0.4523597506301583\n",
            "epoch: 847, step: 23, Train: label_loss: 0.08431485295295715, precision: 0.302037845705946, recall: 0.881104033970089, f1: 0.4498644986069149\n",
            "epoch: 848, step: 0, Train: label_loss: 0.0745740532875061, precision: 0.3430962343096029, recall: 0.8803680981593741, f1: 0.49376344081981466\n",
            "epoch: 848, step: 1, Train: label_loss: 0.08097244054079056, precision: 0.31575829383884385, recall: 0.9003378378376857, f1: 0.46754385961063555\n",
            "epoch: 848, step: 2, Train: label_loss: 0.08403177559375763, precision: 0.3323406789755609, recall: 0.8985507246375364, f1: 0.48521739126488556\n",
            "epoch: 848, step: 3, Train: label_loss: 0.07750184834003448, precision: 0.32746478873237517, recall: 0.9192751235583329, f1: 0.4829078320685374\n",
            "epoch: 848, step: 4, Train: label_loss: 0.07998712360858917, precision: 0.3110720562389976, recall: 0.9348591549294128, f1: 0.4668131867756787\n",
            "epoch: 848, step: 5, Train: label_loss: 0.07565213739871979, precision: 0.30112625963246586, recall: 0.8943661971829411, f1: 0.4505543236873276\n",
            "epoch: 848, step: 6, Train: label_loss: 0.0876360535621643, precision: 0.3120096560048092, recall: 0.8674496644293845, f1: 0.45894363067565064\n",
            "epoch: 848, step: 7, Train: label_loss: 0.08782894909381866, precision: 0.32170313424007557, recall: 0.9096989966553662, f1: 0.47531673215882503\n",
            "epoch: 848, step: 8, Train: label_loss: 0.08618589490652084, precision: 0.3179122182680713, recall: 0.8978224455609886, f1: 0.4695575996109194\n",
            "epoch: 848, step: 9, Train: label_loss: 0.08310717344284058, precision: 0.3081909251620325, recall: 0.909565217391146, f1: 0.4603873239058152\n",
            "epoch: 848, step: 10, Train: label_loss: 0.07743298262357712, precision: 0.29686575990536385, recall: 0.8700173310223794, f1: 0.44268077597613326\n",
            "epoch: 848, step: 11, Train: label_loss: 0.08423743396997452, precision: 0.3242442205097614, recall: 0.9056291390726977, f1: 0.4775207332653654\n",
            "epoch: 848, step: 12, Train: label_loss: 0.07449328154325485, precision: 0.32214369846876784, recall: 0.9086378737540018, f1: 0.4756521738743557\n",
            "epoch: 848, step: 13, Train: label_loss: 0.08008036017417908, precision: 0.31866825208083716, recall: 0.8903654485048355, f1: 0.46935201397164633\n",
            "epoch: 848, step: 14, Train: label_loss: 0.0769563540816307, precision: 0.34243323442134466, recall: 0.9100946372238311, f1: 0.49762828801542336\n",
            "epoch: 848, step: 15, Train: label_loss: 0.08831226825714111, precision: 0.3305439330543735, recall: 0.9065573770490316, f1: 0.48445028467389417\n",
            "epoch: 848, step: 16, Train: label_loss: 0.06778451055288315, precision: 0.3452520515826292, recall: 0.9378980891718252, f1: 0.5047129391208628\n",
            "epoch: 848, step: 17, Train: label_loss: 0.07369650155305862, precision: 0.3339233038347886, recall: 0.9218241042343774, f1: 0.49025552183185644\n",
            "epoch: 848, step: 18, Train: label_loss: 0.08049918711185455, precision: 0.31866825208083716, recall: 0.8874172185428993, f1: 0.46894138228828675\n",
            "epoch: 848, step: 19, Train: label_loss: 0.09679899364709854, precision: 0.3169722057953686, recall: 0.9084745762710323, f1: 0.4699693116670003\n",
            "epoch: 848, step: 20, Train: label_loss: 0.08817742764949799, precision: 0.31454005934716234, recall: 0.9106529209620428, f1: 0.46757829727101424\n",
            "epoch: 848, step: 21, Train: label_loss: 0.08309075981378555, precision: 0.3313289236319705, recall: 0.890145395799533, f1: 0.48290972826892403\n",
            "epoch: 848, step: 22, Train: label_loss: 0.0942653939127922, precision: 0.31100478468897663, recall: 0.8981001727114165, f1: 0.4620168813477981\n",
            "epoch: 848, step: 23, Train: label_loss: 0.07948857545852661, precision: 0.3253623188405561, recall: 0.8979999999998204, f1: 0.47765957442898943\n",
            "epoch: 849, step: 0, Train: label_loss: 0.06983716785907745, precision: 0.32473622508790595, recall: 0.9187396351573932, f1: 0.4798614118279771\n",
            "epoch: 849, step: 1, Train: label_loss: 0.08874612301588058, precision: 0.3195937873357037, recall: 0.9129692832762947, f1: 0.4734513273951745\n",
            "epoch: 849, step: 2, Train: label_loss: 0.0818687304854393, precision: 0.32028053769723436, recall: 0.9335604770015444, f1: 0.4769364664545227\n",
            "epoch: 849, step: 3, Train: label_loss: 0.09026789665222168, precision: 0.3174508636092723, recall: 0.9080068143098964, f1: 0.4704324801027881\n",
            "epoch: 849, step: 4, Train: label_loss: 0.0866299420595169, precision: 0.3036773428232323, recall: 0.9110320284695888, f1: 0.4555160141973349\n",
            "epoch: 849, step: 5, Train: label_loss: 0.0728912353515625, precision: 0.31216931216929383, recall: 0.9139414802063831, f1: 0.46538124448435214\n",
            "epoch: 849, step: 6, Train: label_loss: 0.07004878669977188, precision: 0.3042704626334339, recall: 0.8952879581150269, f1: 0.4541832668943681\n",
            "epoch: 849, step: 7, Train: label_loss: 0.0840633362531662, precision: 0.3277164439279298, recall: 0.9384359400996773, f1: 0.4857881136566813\n",
            "epoch: 849, step: 8, Train: label_loss: 0.09797286987304688, precision: 0.307236061684442, recall: 0.8993055555553994, f1: 0.4580017683085955\n",
            "epoch: 849, step: 9, Train: label_loss: 0.08646193146705627, precision: 0.31024274718766665, recall: 0.8821548821547336, f1: 0.4590451160368016\n",
            "epoch: 849, step: 10, Train: label_loss: 0.07903662323951721, precision: 0.3184789067141819, recall: 0.9100169779285381, f1: 0.47183098587704414\n",
            "epoch: 849, step: 11, Train: label_loss: 0.08513787388801575, precision: 0.33194527067219914, recall: 0.9102773246328041, f1: 0.48648648644728143\n",
            "epoch: 849, step: 12, Train: label_loss: 0.06640876084566116, precision: 0.32259953161590615, recall: 0.9214046822740933, f1: 0.4778837814012661\n",
            "epoch: 849, step: 13, Train: label_loss: 0.07749658823013306, precision: 0.3260095011876291, recall: 0.8926829268291231, f1: 0.4775989560286246\n",
            "epoch: 849, step: 14, Train: label_loss: 0.08914268761873245, precision: 0.32235294117645164, recall: 0.9057851239667923, f1: 0.47548806937555926\n",
            "epoch: 849, step: 15, Train: label_loss: 0.07862897217273712, precision: 0.3283935981031222, recall: 0.9187396351573932, f1: 0.4838427947209866\n",
            "epoch: 849, step: 16, Train: label_loss: 0.08583877980709076, precision: 0.32655502392342545, recall: 0.8806451612901804, f1: 0.47643979053640817\n",
            "epoch: 849, step: 17, Train: label_loss: 0.0669979453086853, precision: 0.3211978860833634, recall: 0.9071310116084731, f1: 0.4744145706465052\n",
            "epoch: 849, step: 18, Train: label_loss: 0.07516911625862122, precision: 0.3248520710058979, recall: 0.9165275459096967, f1: 0.47968545212383307\n",
            "epoch: 849, step: 19, Train: label_loss: 0.0816134661436081, precision: 0.35411764705880266, recall: 0.9204892966359448, f1: 0.5114698385324712\n",
            "epoch: 849, step: 20, Train: label_loss: 0.09447401762008667, precision: 0.33154121863797303, recall: 0.8922829581992134, f1: 0.4834494773123711\n",
            "epoch: 849, step: 21, Train: label_loss: 0.08299972862005234, precision: 0.32895522388057735, recall: 0.8930307941651713, f1: 0.48080279228172895\n",
            "epoch: 849, step: 22, Train: label_loss: 0.08371179550886154, precision: 0.31377245508980156, recall: 0.8941979522182774, f1: 0.4645390070537012\n",
            "epoch: 849, step: 23, Train: label_loss: 0.08901441842317581, precision: 0.36343930635835525, recall: 0.9229357798163443, f1: 0.5215137376473258\n",
            "epoch: 850, step: 0, Train: label_loss: 0.08812209963798523, precision: 0.3113095238095053, recall: 0.9001721170394319, f1: 0.4626271560873803\n",
            "epoch: 850, step: 1, Train: label_loss: 0.07869160175323486, precision: 0.3085480093676634, recall: 0.9229422066548295, f1: 0.46248354537706016\n",
            "epoch: 850, step: 2, Train: label_loss: 0.07945610582828522, precision: 0.3222354340071152, recall: 0.9249146757677602, f1: 0.4779541445824454\n",
            "epoch: 850, step: 3, Train: label_loss: 0.07829757034778595, precision: 0.3246753246753055, recall: 0.9212730318256412, f1: 0.48013967695836657\n",
            "epoch: 850, step: 4, Train: label_loss: 0.08660280704498291, precision: 0.31061055127443327, recall: 0.9034482758619131, f1: 0.46228495805627945\n",
            "epoch: 850, step: 5, Train: label_loss: 0.07915015518665314, precision: 0.3236686390532353, recall: 0.9193277310922824, f1: 0.478774617029274\n",
            "epoch: 850, step: 6, Train: label_loss: 0.0985187217593193, precision: 0.3100120627261574, recall: 0.8846815834766119, f1: 0.459133541721242\n",
            "epoch: 850, step: 7, Train: label_loss: 0.09501468390226364, precision: 0.32785888077856884, recall: 0.8665594855304073, f1: 0.47572815529993445\n",
            "epoch: 850, step: 8, Train: label_loss: 0.07664433866739273, precision: 0.3296187683284264, recall: 0.9243421052630058, f1: 0.48594898396466346\n",
            "epoch: 850, step: 9, Train: label_loss: 0.09346745163202286, precision: 0.3185096153845962, recall: 0.9028960817715668, f1: 0.4709018213741095\n",
            "epoch: 850, step: 10, Train: label_loss: 0.09322646260261536, precision: 0.32406287787180627, recall: 0.8786885245900198, f1: 0.473498233176138\n",
            "epoch: 850, step: 11, Train: label_loss: 0.08469220995903015, precision: 0.3321470937129103, recall: 0.9076175040517167, f1: 0.48632218841057884\n",
            "epoch: 850, step: 12, Train: label_loss: 0.07851068675518036, precision: 0.3169014084506856, recall: 0.9215017064844843, f1: 0.4716157204858937\n",
            "epoch: 850, step: 13, Train: label_loss: 0.07740786671638489, precision: 0.32782043709389674, recall: 0.9143327841843633, f1: 0.48260869561327935\n",
            "epoch: 850, step: 14, Train: label_loss: 0.08555592596530914, precision: 0.34196267308848033, recall: 0.8751926040060284, f1: 0.49177489173444555\n",
            "epoch: 850, step: 15, Train: label_loss: 0.0790199488401413, precision: 0.3329383886255727, recall: 0.9079159935378177, f1: 0.48721283047651487\n",
            "epoch: 850, step: 16, Train: label_loss: 0.09548668563365936, precision: 0.3285111512959416, recall: 0.8719999999998604, f1: 0.47723292465372585\n",
            "epoch: 850, step: 17, Train: label_loss: 0.09697142243385315, precision: 0.33313253012046184, recall: 0.8763866877970085, f1: 0.4827586206496997\n",
            "epoch: 850, step: 18, Train: label_loss: 0.08237825334072113, precision: 0.31688466111769814, recall: 0.8942953020132727, f1: 0.46795434587879414\n",
            "epoch: 850, step: 19, Train: label_loss: 0.08456685394048691, precision: 0.3112305854241152, recall: 0.9092495636996667, f1: 0.46372941696240805\n",
            "epoch: 850, step: 20, Train: label_loss: 0.08299139887094498, precision: 0.31127012522359504, recall: 0.9015544041449219, f1: 0.4627659574086115\n",
            "epoch: 850, step: 21, Train: label_loss: 0.08599008619785309, precision: 0.3185053380782729, recall: 0.9242685025815964, f1: 0.47375385968834827\n",
            "epoch: 850, step: 22, Train: label_loss: 0.10000786185264587, precision: 0.3202416918428809, recall: 0.8702791461410722, f1: 0.4681978798192887\n",
            "epoch: 850, step: 23, Train: label_loss: 0.08336848765611649, precision: 0.3486842105262903, recall: 0.9017013232512472, f1: 0.5028993146671602\n",
            "epoch: 851, step: 0, Train: label_loss: 0.08130146563053131, precision: 0.32540154669837446, recall: 0.92242833052261, f1: 0.48109058923141235\n",
            "epoch: 851, step: 1, Train: label_loss: 0.0843842625617981, precision: 0.3402366863905124, recall: 0.9185303514375529, f1: 0.4965457685270041\n",
            "epoch: 851, step: 2, Train: label_loss: 0.08313208818435669, precision: 0.33593281343729237, recall: 0.9017713365537999, f1: 0.4895104894708968\n",
            "epoch: 851, step: 3, Train: label_loss: 0.08245749771595001, precision: 0.3186943620177852, recall: 0.9163822525595705, f1: 0.47291941871992393\n",
            "epoch: 851, step: 4, Train: label_loss: 0.07959944009780884, precision: 0.3489059727971408, recall: 0.907692307692168, f1: 0.5040580947911127\n",
            "epoch: 851, step: 5, Train: label_loss: 0.0832977294921875, precision: 0.34084173088320446, recall: 0.9026687598114752, f1: 0.4948364887725563\n",
            "epoch: 851, step: 6, Train: label_loss: 0.07953596115112305, precision: 0.32956573468171746, recall: 0.9008130081299348, f1: 0.4825783971732796\n",
            "epoch: 851, step: 7, Train: label_loss: 0.07716836780309677, precision: 0.32168246445495724, recall: 0.8990066225164074, f1: 0.4738219894899385\n",
            "epoch: 851, step: 8, Train: label_loss: 0.07213054597377777, precision: 0.3245767659077452, recall: 0.9235880398669561, f1: 0.48034557231568603\n",
            "epoch: 851, step: 9, Train: label_loss: 0.0833999365568161, precision: 0.32640949554894205, recall: 0.9090909090907587, f1: 0.48034934493924497\n",
            "epoch: 851, step: 10, Train: label_loss: 0.09271621704101562, precision: 0.32875074716076935, recall: 0.8986928104573695, f1: 0.4814004375974996\n",
            "epoch: 851, step: 11, Train: label_loss: 0.07858994603157043, precision: 0.3143872113676546, recall: 0.8969594594593079, f1: 0.4655852695801122\n",
            "epoch: 851, step: 12, Train: label_loss: 0.08329556882381439, precision: 0.3186101295641744, recall: 0.9185059422748865, f1: 0.47310887621882114\n",
            "epoch: 851, step: 13, Train: label_loss: 0.08487695455551147, precision: 0.3263847528290455, recall: 0.9028006589784344, f1: 0.4794400699522045\n",
            "epoch: 851, step: 14, Train: label_loss: 0.08047786355018616, precision: 0.313173652694592, recall: 0.868770764119457, f1: 0.46038732390466974\n",
            "epoch: 851, step: 15, Train: label_loss: 0.08860458433628082, precision: 0.3222026947861557, recall: 0.9401709401707794, f1: 0.4799301919340168\n",
            "epoch: 851, step: 16, Train: label_loss: 0.08303987979888916, precision: 0.31656804733725935, recall: 0.900673400673249, f1: 0.4684763572294232\n",
            "epoch: 851, step: 17, Train: label_loss: 0.0949137732386589, precision: 0.30619469026546864, recall: 0.9041811846688319, f1: 0.4574702511741516\n",
            "epoch: 851, step: 18, Train: label_loss: 0.07649955153465271, precision: 0.32619047619045677, recall: 0.8954248366011608, f1: 0.4781849912348111\n",
            "epoch: 851, step: 19, Train: label_loss: 0.09002894163131714, precision: 0.3020895522387879, recall: 0.8971631205672167, f1: 0.451987494379421\n",
            "epoch: 851, step: 20, Train: label_loss: 0.07844341546297073, precision: 0.3242117787031336, recall: 0.9038142620230672, f1: 0.4772329246546166\n",
            "epoch: 851, step: 21, Train: label_loss: 0.07841283828020096, precision: 0.3066347878063176, recall: 0.882960413080743, f1: 0.45519077192265356\n",
            "epoch: 851, step: 22, Train: label_loss: 0.10918140411376953, precision: 0.30389768574906795, recall: 0.8693379790939252, f1: 0.450361010791898\n",
            "epoch: 851, step: 23, Train: label_loss: 0.0765920877456665, precision: 0.31775018261502425, recall: 0.8859470468429967, f1: 0.4677419354449619\n",
            "epoch: 852, step: 0, Train: label_loss: 0.08832283318042755, precision: 0.3315602836879237, recall: 0.9181669394433849, f1: 0.48719062089019666\n",
            "epoch: 852, step: 1, Train: label_loss: 0.07036436349153519, precision: 0.33919156414760754, recall: 0.9293739967895779, f1: 0.49699570811528604\n",
            "epoch: 852, step: 2, Train: label_loss: 0.08434376120567322, precision: 0.3122786304604302, recall: 0.8981324278436505, f1: 0.4634253175262807\n",
            "epoch: 852, step: 3, Train: label_loss: 0.08908408880233765, precision: 0.32733812949638325, recall: 0.895081967212968, f1: 0.47936786651034813\n",
            "epoch: 852, step: 4, Train: label_loss: 0.07668383419513702, precision: 0.32275132275130375, recall: 0.9400684931505239, f1: 0.4805251640756917\n",
            "epoch: 852, step: 5, Train: label_loss: 0.08549214899539948, precision: 0.31775147928992203, recall: 0.9132653061222936, f1: 0.47146619838132614\n",
            "epoch: 852, step: 6, Train: label_loss: 0.08609703183174133, precision: 0.30820265379974016, recall: 0.8690476190474712, f1: 0.4550311664795621\n",
            "epoch: 852, step: 7, Train: label_loss: 0.09338858723640442, precision: 0.3182640144665269, recall: 0.8785357737103363, f1: 0.467256637129058\n",
            "epoch: 852, step: 8, Train: label_loss: 0.0974443107843399, precision: 0.32951116475556247, recall: 0.8834951456309249, f1: 0.4799999999603866\n",
            "epoch: 852, step: 9, Train: label_loss: 0.10424317419528961, precision: 0.3196374622356302, recall: 0.8714991762766273, f1: 0.46772767458491765\n",
            "epoch: 852, step: 10, Train: label_loss: 0.09195122122764587, precision: 0.30819477434677506, recall: 0.9057591623035067, f1: 0.45990252543837046\n",
            "epoch: 852, step: 11, Train: label_loss: 0.08582091331481934, precision: 0.31730769230767325, recall: 0.8712871287127274, f1: 0.465198237846283\n",
            "epoch: 852, step: 12, Train: label_loss: 0.08539702743291855, precision: 0.31739390316794275, recall: 0.8879598662205872, f1: 0.46763540286737104\n",
            "epoch: 852, step: 13, Train: label_loss: 0.09135889261960983, precision: 0.3353293413173452, recall: 0.9017713365537999, f1: 0.4888694892664199\n",
            "epoch: 852, step: 14, Train: label_loss: 0.08979309350252151, precision: 0.3239520958083638, recall: 0.8942148760329099, f1: 0.47560439556531114\n",
            "epoch: 852, step: 15, Train: label_loss: 0.09233184158802032, precision: 0.32155688622752565, recall: 0.8935108153076715, f1: 0.4729194187192933\n",
            "epoch: 852, step: 16, Train: label_loss: 0.0986974686384201, precision: 0.3351383874849377, recall: 0.8855325914148036, f1: 0.48625054557339215\n",
            "epoch: 852, step: 17, Train: label_loss: 0.09010358154773712, precision: 0.3273273273273077, recall: 0.8776167471818231, f1: 0.4768153980356272\n",
            "epoch: 852, step: 18, Train: label_loss: 0.0906078964471817, precision: 0.3018072289156445, recall: 0.8882978723402679, f1: 0.4505395683074261\n",
            "epoch: 852, step: 19, Train: label_loss: 0.10988850891590118, precision: 0.3144918821406906, recall: 0.8834459459457966, f1: 0.46385809308762327\n",
            "epoch: 852, step: 20, Train: label_loss: 0.10959909856319427, precision: 0.32360097323599, recall: 0.8692810457514919, f1: 0.47163120563418\n",
            "epoch: 852, step: 21, Train: label_loss: 0.08659175038337708, precision: 0.32384341637008757, recall: 0.9130434782607169, f1: 0.47810858139738105\n",
            "epoch: 852, step: 22, Train: label_loss: 0.07837256789207458, precision: 0.32901706886401827, recall: 0.9254966887415685, f1: 0.4854537559317345\n",
            "epoch: 852, step: 23, Train: label_loss: 0.08278965950012207, precision: 0.30351906158355546, recall: 0.8697478991594811, f1: 0.4499999999615967\n",
            "epoch: 853, step: 0, Train: label_loss: 0.09307443350553513, precision: 0.3139604553624737, recall: 0.8896434634973022, f1: 0.464127546462726\n",
            "epoch: 853, step: 1, Train: label_loss: 0.08660745620727539, precision: 0.32194244604314615, recall: 0.9040404040402518, f1: 0.47480106096918734\n",
            "epoch: 853, step: 2, Train: label_loss: 0.10041474550962448, precision: 0.31766124171185545, recall: 0.8932203389828994, f1: 0.4686527345099432\n",
            "epoch: 853, step: 3, Train: label_loss: 0.07542376220226288, precision: 0.34191616766465016, recall: 0.9020537124801102, f1: 0.4958749456830646\n",
            "epoch: 853, step: 4, Train: label_loss: 0.08100885152816772, precision: 0.3085169743894992, recall: 0.8915662650600874, f1: 0.45840707960777916\n",
            "epoch: 853, step: 5, Train: label_loss: 0.0815323144197464, precision: 0.32437275985661146, recall: 0.8945634266884852, f1: 0.47610697058781704\n",
            "epoch: 853, step: 6, Train: label_loss: 0.08451729267835617, precision: 0.34880952380950303, recall: 0.9113530326592673, f1: 0.5045200171790336\n",
            "epoch: 853, step: 7, Train: label_loss: 0.07477200031280518, precision: 0.32068761114402367, recall: 0.9092436974788387, f1: 0.4741454863768329\n",
            "epoch: 853, step: 8, Train: label_loss: 0.10265599191188812, precision: 0.3069908814589479, recall: 0.8530405405403964, f1: 0.4514975413110608\n",
            "epoch: 853, step: 9, Train: label_loss: 0.08449123799800873, precision: 0.3086053412462725, recall: 0.8950086058518252, f1: 0.4589585171727722\n",
            "epoch: 853, step: 10, Train: label_loss: 0.09068058431148529, precision: 0.3252225519287641, recall: 0.9102990033221079, f1: 0.4792304328426745\n",
            "epoch: 853, step: 11, Train: label_loss: 0.07706736028194427, precision: 0.31691394658751826, recall: 0.8944723618088953, f1: 0.46801051705159635\n",
            "epoch: 853, step: 12, Train: label_loss: 0.07152564823627472, precision: 0.3274956217162681, recall: 0.9272727272725739, f1: 0.484037963723246\n",
            "epoch: 853, step: 13, Train: label_loss: 0.09291969239711761, precision: 0.3211940298507271, recall: 0.8966666666665172, f1: 0.4729670329281555\n",
            "epoch: 853, step: 14, Train: label_loss: 0.0813540369272232, precision: 0.2900943396226244, recall: 0.9196261682241271, f1: 0.44105782156816253\n",
            "epoch: 853, step: 15, Train: label_loss: 0.08748115599155426, precision: 0.31141661685592875, recall: 0.9029462738299994, f1: 0.4631111110729338\n",
            "epoch: 853, step: 16, Train: label_loss: 0.07818335294723511, precision: 0.3165382335506629, recall: 0.914383561643679, f1: 0.4702774107939858\n",
            "epoch: 853, step: 17, Train: label_loss: 0.08134342730045319, precision: 0.3235995232419354, recall: 0.8916256157634003, f1: 0.47485789239638776\n",
            "epoch: 853, step: 18, Train: label_loss: 0.09452298283576965, precision: 0.34451767525462285, recall: 0.8956386292833495, f1: 0.49762007784819123\n",
            "epoch: 853, step: 19, Train: label_loss: 0.08545313775539398, precision: 0.33927510398096616, recall: 0.9150641025639559, f1: 0.49501517117852495\n",
            "epoch: 853, step: 20, Train: label_loss: 0.09825463593006134, precision: 0.3275030156815243, recall: 0.8843648208467615, f1: 0.4779929577069941\n",
            "epoch: 853, step: 21, Train: label_loss: 0.07832854241132736, precision: 0.3236686390532353, recall: 0.8952536824875784, f1: 0.4754454584572593\n",
            "epoch: 853, step: 22, Train: label_loss: 0.08075547218322754, precision: 0.32300357568532045, recall: 0.9093959731542097, f1: 0.47669305185221905\n",
            "epoch: 853, step: 23, Train: label_loss: 0.07817795872688293, precision: 0.3343108504398582, recall: 0.8803088803087102, f1: 0.48459086074644947\n",
            "epoch: 854, step: 0, Train: label_loss: 0.08659054338932037, precision: 0.3109792284866284, recall: 0.9128919860625586, f1: 0.4639220893821502\n",
            "epoch: 854, step: 1, Train: label_loss: 0.09114553034305573, precision: 0.31893491124258466, recall: 0.9089376053961367, f1: 0.472185720504648\n",
            "epoch: 854, step: 2, Train: label_loss: 0.09448684006929398, precision: 0.31174334140433946, recall: 0.8728813559320554, f1: 0.45941123992549543\n",
            "epoch: 854, step: 3, Train: label_loss: 0.08614020049571991, precision: 0.3364928909952407, recall: 0.8987341772150476, f1: 0.48965517237411\n",
            "epoch: 854, step: 4, Train: label_loss: 0.09549681842327118, precision: 0.3169856459329954, recall: 0.9013605442175338, f1: 0.46902654863402793\n",
            "epoch: 854, step: 5, Train: label_loss: 0.09370213001966476, precision: 0.3343337334933773, recall: 0.8855325914148036, f1: 0.4854030500690986\n",
            "epoch: 854, step: 6, Train: label_loss: 0.06852001696825027, precision: 0.32998225901831285, recall: 0.9223140495866243, f1: 0.4860627177311787\n",
            "epoch: 854, step: 7, Train: label_loss: 0.08914852142333984, precision: 0.3249097472923992, recall: 0.878048780487662, f1: 0.4743083003557867\n",
            "epoch: 854, step: 8, Train: label_loss: 0.08638664335012436, precision: 0.3301662707838284, recall: 0.899676375404385, f1: 0.4830582102126348\n",
            "epoch: 854, step: 9, Train: label_loss: 0.07865438610315323, precision: 0.3293627159023032, recall: 0.8991869918697725, f1: 0.48212728853961584\n",
            "epoch: 854, step: 10, Train: label_loss: 0.09099806100130081, precision: 0.3226571767496843, recall: 0.9189189189187636, f1: 0.47761194025999726\n",
            "epoch: 854, step: 11, Train: label_loss: 0.08802126348018646, precision: 0.3368669022379071, recall: 0.9225806451611415, f1: 0.4935289041885539\n",
            "epoch: 854, step: 12, Train: label_loss: 0.08539333939552307, precision: 0.308928571428553, recall: 0.888698630136834, f1: 0.45848056533270176\n",
            "epoch: 854, step: 13, Train: label_loss: 0.09583574533462524, precision: 0.3103030303030115, recall: 0.8576214405358696, f1: 0.45571873605350777\n",
            "epoch: 854, step: 14, Train: label_loss: 0.07790881395339966, precision: 0.32106824925814115, recall: 0.9153976311335168, f1: 0.4753954305414751\n",
            "epoch: 854, step: 15, Train: label_loss: 0.07151448726654053, precision: 0.31058823529409935, recall: 0.9134948096884232, f1: 0.4635645302518167\n",
            "epoch: 854, step: 16, Train: label_loss: 0.0856776237487793, precision: 0.3122743682310281, recall: 0.8856655290100877, f1: 0.46174377220340695\n",
            "epoch: 854, step: 17, Train: label_loss: 0.09116245806217194, precision: 0.3190984578884745, recall: 0.9011725293130818, f1: 0.4713096802066266\n",
            "epoch: 854, step: 18, Train: label_loss: 0.08067679405212402, precision: 0.33333333333331344, recall: 0.9001610305956682, f1: 0.4865100086637362\n",
            "epoch: 854, step: 19, Train: label_loss: 0.0837533250451088, precision: 0.33074626865669665, recall: 0.8807631160570936, f1: 0.4809027777380415\n",
            "epoch: 854, step: 20, Train: label_loss: 0.08348707109689713, precision: 0.3305833824395798, recall: 0.9211822660097009, f1: 0.48655680828719394\n",
            "epoch: 854, step: 21, Train: label_loss: 0.07168087363243103, precision: 0.31971580817049616, recall: 0.9060402684562238, f1: 0.4726477023684011\n",
            "epoch: 854, step: 22, Train: label_loss: 0.09003481268882751, precision: 0.31893491124258466, recall: 0.9229452054792939, f1: 0.4740545294252865\n",
            "epoch: 854, step: 23, Train: label_loss: 0.12422032654285431, precision: 0.3025718608169211, recall: 0.840336134453605, f1: 0.4449388208731446\n",
            "epoch: 855, step: 0, Train: label_loss: 0.08258770406246185, precision: 0.3057851239669241, recall: 0.9184397163118938, f1: 0.4588131089084514\n",
            "epoch: 855, step: 1, Train: label_loss: 0.0825565904378891, precision: 0.3055222088835351, recall: 0.8760757314972674, f1: 0.4530485090848931\n",
            "epoch: 855, step: 2, Train: label_loss: 0.08165733516216278, precision: 0.32202380952379034, recall: 0.8971807628522558, f1: 0.4739378010999381\n",
            "epoch: 855, step: 3, Train: label_loss: 0.09219612181186676, precision: 0.32155688622752565, recall: 0.8876033057849771, f1: 0.4720879120488279\n",
            "epoch: 855, step: 4, Train: label_loss: 0.0778275802731514, precision: 0.3593380614656998, recall: 0.9268292682925415, f1: 0.5178875638438466\n",
            "epoch: 855, step: 5, Train: label_loss: 0.06524226814508438, precision: 0.3378698224851871, recall: 0.9209677419353353, f1: 0.49437229433297947\n",
            "epoch: 855, step: 6, Train: label_loss: 0.06999580562114716, precision: 0.3077377436503067, recall: 0.9013840830448266, f1: 0.4588287097814751\n",
            "epoch: 855, step: 7, Train: label_loss: 0.07787713408470154, precision: 0.3179396092362156, recall: 0.9040404040402518, f1: 0.4704336399088987\n",
            "epoch: 855, step: 8, Train: label_loss: 0.07115260511636734, precision: 0.3384889946460239, recall: 0.901743264659128, f1: 0.49221453283224254\n",
            "epoch: 855, step: 9, Train: label_loss: 0.09306374192237854, precision: 0.3237237237237043, recall: 0.8968386023293016, f1: 0.47572815530078766\n",
            "epoch: 855, step: 10, Train: label_loss: 0.07944118976593018, precision: 0.32597014925371187, recall: 0.8834951456309249, f1: 0.4762320104272207\n",
            "epoch: 855, step: 11, Train: label_loss: 0.08526456356048584, precision: 0.32559523809521873, recall: 0.9162479061975014, f1: 0.4804567412875753\n",
            "epoch: 855, step: 12, Train: label_loss: 0.0962475836277008, precision: 0.3117824773413709, recall: 0.8881239242683496, f1: 0.46153846149995564\n",
            "epoch: 855, step: 13, Train: label_loss: 0.08544247597455978, precision: 0.32581602373885304, recall: 0.9149999999998474, f1: 0.4805251640750169\n",
            "epoch: 855, step: 14, Train: label_loss: 0.085325226187706, precision: 0.3119047619047433, recall: 0.9034482758619131, f1: 0.46371681412109605\n",
            "epoch: 855, step: 15, Train: label_loss: 0.08502345532178879, precision: 0.33611940298505455, recall: 0.9007999999998558, f1: 0.4895652173516823\n",
            "epoch: 855, step: 16, Train: label_loss: 0.08117758482694626, precision: 0.31519810762860345, recall: 0.9064625850338593, f1: 0.4677490126865503\n",
            "epoch: 855, step: 17, Train: label_loss: 0.08469211310148239, precision: 0.32451923076921124, recall: 0.8837970540096752, f1: 0.4747252746859448\n",
            "epoch: 855, step: 18, Train: label_loss: 0.0802985355257988, precision: 0.31175771971494587, recall: 0.9178321678320073, f1: 0.46542553187700025\n",
            "epoch: 855, step: 19, Train: label_loss: 0.08742233365774155, precision: 0.32202380952379034, recall: 0.9031719532552749, f1: 0.47476963576638553\n",
            "epoch: 855, step: 20, Train: label_loss: 0.08860020339488983, precision: 0.32728372655775395, recall: 0.8868852459014939, f1: 0.47812638087087495\n",
            "epoch: 855, step: 21, Train: label_loss: 0.08893047273159027, precision: 0.3245823389021286, recall: 0.90066225165548, f1: 0.4771929824171518\n",
            "epoch: 855, step: 22, Train: label_loss: 0.07867132127285004, precision: 0.30760095011874655, recall: 0.8977469670709015, f1: 0.45820433432727026\n",
            "epoch: 855, step: 23, Train: label_loss: 0.0887540802359581, precision: 0.3422382671479897, recall: 0.904580152671583, f1: 0.4965950759161169\n",
            "epoch: 856, step: 0, Train: label_loss: 0.07787980139255524, precision: 0.31933767001772206, recall: 0.8955223880595529, f1: 0.47079337398038645\n",
            "epoch: 856, step: 1, Train: label_loss: 0.07523901760578156, precision: 0.31408367707717655, recall: 0.9064625850338593, f1: 0.46652078770790756\n",
            "epoch: 856, step: 2, Train: label_loss: 0.0758381336927414, precision: 0.31879787860929176, recall: 0.9138513513511969, f1: 0.47269550018004675\n",
            "epoch: 856, step: 3, Train: label_loss: 0.0785735547542572, precision: 0.3161328588374664, recall: 0.9018612521149065, f1: 0.4681598594257292\n",
            "epoch: 856, step: 4, Train: label_loss: 0.0830584466457367, precision: 0.29868578255673245, recall: 0.8771929824559864, f1: 0.4456327985360374\n",
            "epoch: 856, step: 5, Train: label_loss: 0.1021336242556572, precision: 0.31269160024522913, recall: 0.8360655737703547, f1: 0.45515394909019063\n",
            "epoch: 856, step: 6, Train: label_loss: 0.10453953593969345, precision: 0.31176833025259937, recall: 0.824104234527553, f1: 0.45239159584748095\n",
            "epoch: 856, step: 7, Train: label_loss: 0.12461038678884506, precision: 0.2866161616161435, recall: 0.774744027303622, f1: 0.41843317968403954\n",
            "epoch: 856, step: 8, Train: label_loss: 0.09332127869129181, precision: 0.30326876513315354, recall: 0.8898756660744422, f1: 0.45237020312231585\n",
            "epoch: 856, step: 9, Train: label_loss: 0.1146971806883812, precision: 0.31038721573446154, recall: 0.8416666666665263, f1: 0.4535249213795418\n",
            "epoch: 856, step: 10, Train: label_loss: 0.08786172419786453, precision: 0.3456716417910241, recall: 0.8962848297212235, f1: 0.4989228780295822\n",
            "epoch: 856, step: 11, Train: label_loss: 0.104482501745224, precision: 0.32602071907371566, recall: 0.8629032258063124, f1: 0.47324192831044143\n",
            "epoch: 856, step: 12, Train: label_loss: 0.09878013283014297, precision: 0.34382566585954333, recall: 0.8902821316613024, f1: 0.49606986895539323\n",
            "epoch: 856, step: 13, Train: label_loss: 0.09088447690010071, precision: 0.30484160191271337, recall: 0.8947368421051061, f1: 0.4547481051782787\n",
            "epoch: 856, step: 14, Train: label_loss: 0.10215935111045837, precision: 0.32927571515518383, recall: 0.8768233387356763, f1: 0.47876106190716516\n",
            "epoch: 856, step: 15, Train: label_loss: 0.09195725619792938, precision: 0.34853029394119084, recall: 0.90077519379831, f1: 0.5025951556690691\n",
            "epoch: 856, step: 16, Train: label_loss: 0.08719853311777115, precision: 0.32370283018866014, recall: 0.9305084745761134, f1: 0.480314960591583\n",
            "epoch: 856, step: 17, Train: label_loss: 0.08978268504142761, precision: 0.31585220500594063, recall: 0.895270270270119, f1: 0.4669603523843103\n",
            "epoch: 856, step: 18, Train: label_loss: 0.07831424474716187, precision: 0.3188490898414375, recall: 0.9250425894376617, f1: 0.47423580782209535\n",
            "epoch: 856, step: 19, Train: label_loss: 0.10363811254501343, precision: 0.3155015197568197, recall: 0.8494271685759657, f1: 0.4601063829391861\n",
            "epoch: 856, step: 20, Train: label_loss: 0.0887218713760376, precision: 0.317383403997558, recall: 0.8675496688740285, f1: 0.46474501104721205\n",
            "epoch: 856, step: 21, Train: label_loss: 0.08212310820817947, precision: 0.3292978208232246, recall: 0.8788368336024428, f1: 0.4790841038792813\n",
            "epoch: 856, step: 22, Train: label_loss: 0.11753323674201965, precision: 0.30018645121191423, recall: 0.8104026845636223, f1: 0.4380952380557512\n",
            "epoch: 856, step: 23, Train: label_loss: 0.08986972272396088, precision: 0.3064046579330199, recall: 0.9014989293359954, f1: 0.45736013032601897\n",
            "epoch: 857, step: 0, Train: label_loss: 0.08710792660713196, precision: 0.3074626865671458, recall: 0.8743633276738753, f1: 0.4549469964278956\n",
            "epoch: 857, step: 1, Train: label_loss: 0.10408276319503784, precision: 0.3164251207729277, recall: 0.8762541806018601, f1: 0.4649511978314275\n",
            "epoch: 857, step: 2, Train: label_loss: 0.10080762207508087, precision: 0.29436705027254423, recall: 0.8556338028167507, f1: 0.4380351509307754\n",
            "epoch: 857, step: 3, Train: label_loss: 0.08581720292568207, precision: 0.3158208955223692, recall: 0.8816666666665196, f1: 0.4650549450160683\n",
            "epoch: 857, step: 4, Train: label_loss: 0.09011149406433105, precision: 0.3199279711884562, recall: 0.9049235993207292, f1: 0.4727272726886361\n",
            "epoch: 857, step: 5, Train: label_loss: 0.09412229806184769, precision: 0.3188836104512875, recall: 0.9101694915252694, f1: 0.4722955144734042\n",
            "epoch: 857, step: 6, Train: label_loss: 0.0788176953792572, precision: 0.3258691809074646, recall: 0.9140495867767083, f1: 0.4804517810211575\n",
            "epoch: 857, step: 7, Train: label_loss: 0.09141634404659271, precision: 0.3317249698431645, recall: 0.8828250401282691, f1: 0.4822446295086957\n",
            "epoch: 857, step: 8, Train: label_loss: 0.10461374372243881, precision: 0.2992744860942987, recall: 0.8669001751311967, f1: 0.4449438201865249\n",
            "epoch: 857, step: 9, Train: label_loss: 0.08696606755256653, precision: 0.34082840236684375, recall: 0.9215999999998524, f1: 0.4976241900253337\n",
            "epoch: 857, step: 10, Train: label_loss: 0.0822690948843956, precision: 0.33074626865669665, recall: 0.8978930307940197, f1: 0.483420593328849\n",
            "epoch: 857, step: 11, Train: label_loss: 0.1014370545744896, precision: 0.33553025763928485, recall: 0.9032258064514671, f1: 0.4892966360460851\n",
            "epoch: 857, step: 12, Train: label_loss: 0.08263146877288818, precision: 0.32619047619045677, recall: 0.8939641109297073, f1: 0.4779764500262013\n",
            "epoch: 857, step: 13, Train: label_loss: 0.08635953068733215, precision: 0.32304038004748675, recall: 0.8932676518881948, f1: 0.47448757082880677\n",
            "epoch: 857, step: 14, Train: label_loss: 0.08865761756896973, precision: 0.3228111971411362, recall: 0.9018302828617467, f1: 0.4754385964523637\n",
            "epoch: 857, step: 15, Train: label_loss: 0.0877850353717804, precision: 0.3146936347412067, recall: 0.8890756302519514, f1: 0.4648506150755784\n",
            "epoch: 857, step: 16, Train: label_loss: 0.08520057797431946, precision: 0.3082886106141736, recall: 0.8852739726025881, f1: 0.45731976997491247\n",
            "epoch: 857, step: 17, Train: label_loss: 0.08995102345943451, precision: 0.3251497005987829, recall: 0.9034941763725618, f1: 0.4782034345713404\n",
            "epoch: 857, step: 18, Train: label_loss: 0.08974608778953552, precision: 0.3241954707985504, recall: 0.9051580698833768, f1: 0.47740236942141406\n",
            "epoch: 857, step: 19, Train: label_loss: 0.1009015366435051, precision: 0.29907692307690464, recall: 0.8265306122447573, f1: 0.4392227744751734\n",
            "epoch: 857, step: 20, Train: label_loss: 0.08920353651046753, precision: 0.32673860911269026, recall: 0.8949096880129893, f1: 0.47870004387820836\n",
            "epoch: 857, step: 21, Train: label_loss: 0.08154100179672241, precision: 0.3235995232419354, recall: 0.8945634266884852, f1: 0.4752735229368728\n",
            "epoch: 857, step: 22, Train: label_loss: 0.07738874107599258, precision: 0.32461355529130054, recall: 0.8907014681890879, f1: 0.47581699342485906\n",
            "epoch: 857, step: 23, Train: label_loss: 0.07888282835483551, precision: 0.3304029304029062, recall: 0.8966202783298417, f1: 0.4828693789755847\n",
            "epoch: 858, step: 0, Train: label_loss: 0.08935036510229111, precision: 0.3224271267102723, recall: 0.8958677685948931, f1: 0.47419072612026614\n",
            "epoch: 858, step: 1, Train: label_loss: 0.08209080994129181, precision: 0.32488207547167897, recall: 0.930743243243086, f1: 0.48164335660495566\n",
            "epoch: 858, step: 2, Train: label_loss: 0.08901692181825638, precision: 0.32147093712928104, recall: 0.9063545150500156, f1: 0.47460595442715364\n",
            "epoch: 858, step: 3, Train: label_loss: 0.096108078956604, precision: 0.3110709987966118, recall: 0.8777589134124145, f1: 0.4593513993393744\n",
            "epoch: 858, step: 4, Train: label_loss: 0.09309186041355133, precision: 0.3168552709946208, recall: 0.8692810457514919, f1: 0.4644260148014858\n",
            "epoch: 858, step: 5, Train: label_loss: 0.08450894802808762, precision: 0.3038575667655606, recall: 0.8842832469773947, f1: 0.4522968197498783\n",
            "epoch: 858, step: 6, Train: label_loss: 0.08843491971492767, precision: 0.3038507821901141, recall: 0.8844133099823319, f1: 0.45230631433717494\n",
            "epoch: 858, step: 7, Train: label_loss: 0.08577780425548553, precision: 0.3281715306730001, recall: 0.9198664440733021, f1: 0.4837576821385446\n",
            "epoch: 858, step: 8, Train: label_loss: 0.09692317247390747, precision: 0.31051051051049183, recall: 0.8777589134124145, f1: 0.45874001770758244\n",
            "epoch: 858, step: 9, Train: label_loss: 0.09404061734676361, precision: 0.32753449310136007, recall: 0.8749999999998597, f1: 0.4766477520336518\n",
            "epoch: 858, step: 10, Train: label_loss: 0.08210719376802444, precision: 0.3403880070546537, recall: 0.9263999999998517, f1: 0.49785038689100947\n",
            "epoch: 858, step: 11, Train: label_loss: 0.08554324507713318, precision: 0.32219570405726, recall: 0.8970099667772595, f1: 0.47410008775738494\n",
            "epoch: 858, step: 12, Train: label_loss: 0.10227004438638687, precision: 0.30629539951571993, recall: 0.8634812286687945, f1: 0.45218945483172357\n",
            "epoch: 858, step: 13, Train: label_loss: 0.08019386231899261, precision: 0.3319377990430423, recall: 0.880952380952241, f1: 0.48218940048148845\n",
            "epoch: 858, step: 14, Train: label_loss: 0.0852525383234024, precision: 0.32915173237751916, recall: 0.9077429983524039, f1: 0.48312143792670276\n",
            "epoch: 858, step: 15, Train: label_loss: 0.08488716185092926, precision: 0.3374999999999799, recall: 0.9014308426071698, f1: 0.49112169766495073\n",
            "epoch: 858, step: 16, Train: label_loss: 0.08789373934268951, precision: 0.32455089820357336, recall: 0.8885245901637887, f1: 0.4754385964519935\n",
            "epoch: 858, step: 17, Train: label_loss: 0.09258825331926346, precision: 0.3291442250149414, recall: 0.8914100486222217, f1: 0.4807692307297993\n",
            "epoch: 858, step: 18, Train: label_loss: 0.09580564498901367, precision: 0.30366806975343935, recall: 0.8813263525303872, f1: 0.4516994632892116\n",
            "epoch: 858, step: 19, Train: label_loss: 0.07903571426868439, precision: 0.3206106870228819, recall: 0.9269949066212347, f1: 0.47643979053768637\n",
            "epoch: 858, step: 20, Train: label_loss: 0.08276848495006561, precision: 0.3271861986912357, recall: 0.8972267536703267, f1: 0.4795117697951461\n",
            "epoch: 858, step: 21, Train: label_loss: 0.08937519788742065, precision: 0.3217286914765713, recall: 0.9008403361343024, f1: 0.474126492663521\n",
            "epoch: 858, step: 22, Train: label_loss: 0.0946134477853775, precision: 0.3112462006078838, recall: 0.8519134775372957, f1: 0.45592163842915084\n",
            "epoch: 858, step: 23, Train: label_loss: 0.08282504975795746, precision: 0.3155588020452655, recall: 0.89256198347089, f1: 0.4662709119958935\n",
            "epoch: 859, step: 0, Train: label_loss: 0.06963122636079788, precision: 0.329376854599387, recall: 0.9098360655736213, f1: 0.48366013067988245\n",
            "epoch: 859, step: 1, Train: label_loss: 0.08320898562669754, precision: 0.30773809523807694, recall: 0.9038461538459958, f1: 0.459147424473608\n",
            "epoch: 859, step: 2, Train: label_loss: 0.08200840651988983, precision: 0.32765707574865954, recall: 0.9207920792077687, f1: 0.48332611516262985\n",
            "epoch: 859, step: 3, Train: label_loss: 0.07849236577749252, precision: 0.3390838786436443, recall: 0.9223300970872294, f1: 0.49586776855568776\n",
            "epoch: 859, step: 4, Train: label_loss: 0.07988761365413666, precision: 0.34219858156026345, recall: 0.9175911251979528, f1: 0.49849332755401643\n",
            "epoch: 859, step: 5, Train: label_loss: 0.0875437930226326, precision: 0.3144876325088154, recall: 0.9112627986346568, f1: 0.4676007004872049\n",
            "epoch: 859, step: 6, Train: label_loss: 0.08105944842100143, precision: 0.30299401197602976, recall: 0.8739205526768784, f1: 0.4499777678585693\n",
            "epoch: 859, step: 7, Train: label_loss: 0.08938583731651306, precision: 0.3303411131059048, recall: 0.8903225806450177, f1: 0.4818856394192322\n",
            "epoch: 859, step: 8, Train: label_loss: 0.07856288552284241, precision: 0.31414868105513705, recall: 0.8806722689074149, f1: 0.4631020768502852\n",
            "epoch: 859, step: 9, Train: label_loss: 0.0883576050400734, precision: 0.3331367924528105, recall: 0.9098228663444589, f1: 0.487699611527402\n",
            "epoch: 859, step: 10, Train: label_loss: 0.08702778816223145, precision: 0.34753901560622164, recall: 0.8948995363213454, f1: 0.5006485083902706\n",
            "epoch: 859, step: 11, Train: label_loss: 0.07893155515193939, precision: 0.3165298944900166, recall: 0.912162162162008, f1: 0.4699738903011348\n",
            "epoch: 859, step: 12, Train: label_loss: 0.08192438632249832, precision: 0.32976827094472194, recall: 0.8995137763369693, f1: 0.48260869561287256\n",
            "epoch: 859, step: 13, Train: label_loss: 0.09229029715061188, precision: 0.3371121718376887, recall: 0.8968253968252544, f1: 0.4900260190409043\n",
            "epoch: 859, step: 14, Train: label_loss: 0.09150582551956177, precision: 0.31435493640216144, recall: 0.8664440734556149, f1: 0.4613333332942227\n",
            "epoch: 859, step: 15, Train: label_loss: 0.09016147255897522, precision: 0.3115547489413, recall: 0.8640939597313986, f1: 0.45798132499435185\n",
            "epoch: 859, step: 16, Train: label_loss: 0.07286649197340012, precision: 0.3137603795966599, recall: 0.8966101694913734, f1: 0.46485061507578895\n",
            "epoch: 859, step: 17, Train: label_loss: 0.08348017185926437, precision: 0.31961836612997496, recall: 0.9054054054052524, f1: 0.47245482587589105\n",
            "epoch: 859, step: 18, Train: label_loss: 0.08517815172672272, precision: 0.33195754716979176, recall: 0.9154471544713958, f1: 0.48723496318028353\n",
            "epoch: 859, step: 19, Train: label_loss: 0.0931217148900032, precision: 0.3084725536992656, recall: 0.9038461538459958, f1: 0.45996441277340605\n",
            "epoch: 859, step: 20, Train: label_loss: 0.09372426569461823, precision: 0.316956261234253, recall: 0.8890756302519514, f1: 0.4673144875937195\n",
            "epoch: 859, step: 21, Train: label_loss: 0.09805160015821457, precision: 0.3018983466013287, recall: 0.8529411764704407, f1: 0.4459520578537\n",
            "epoch: 859, step: 22, Train: label_loss: 0.08795624226331711, precision: 0.313173652694592, recall: 0.8745819397991847, f1: 0.4611992944937577\n",
            "epoch: 859, step: 23, Train: label_loss: 0.0790744200348854, precision: 0.3049132947976658, recall: 0.9173913043476267, f1: 0.4577006507217238\n",
            "epoch: 860, step: 0, Train: label_loss: 0.08563534915447235, precision: 0.2964497041419943, recall: 0.9010791366904853, f1: 0.4461264469796254\n",
            "epoch: 860, step: 1, Train: label_loss: 0.08828946202993393, precision: 0.32635983263596374, recall: 0.8980263157893259, f1: 0.4787373958398583\n",
            "epoch: 860, step: 2, Train: label_loss: 0.07727093994617462, precision: 0.3327412670218867, recall: 0.9168026101140428, f1: 0.4882710685968503\n",
            "epoch: 860, step: 3, Train: label_loss: 0.08607921004295349, precision: 0.3217703349282104, recall: 0.8776508972266104, f1: 0.4708971553217487\n",
            "epoch: 860, step: 4, Train: label_loss: 0.09405547380447388, precision: 0.32499999999998064, recall: 0.8863636363634924, f1: 0.4756097560582571\n",
            "epoch: 860, step: 5, Train: label_loss: 0.07938506454229355, precision: 0.31610219845512083, recall: 0.9094017094015538, f1: 0.4691358024308133\n",
            "epoch: 860, step: 6, Train: label_loss: 0.09754707664251328, precision: 0.31411411411409523, recall: 0.8804713804712322, f1: 0.46303674188240174\n",
            "epoch: 860, step: 7, Train: label_loss: 0.07552748173475266, precision: 0.3364928909952407, recall: 0.9117174959870125, f1: 0.49156209429203435\n",
            "epoch: 860, step: 8, Train: label_loss: 0.08692844212055206, precision: 0.313209802749533, recall: 0.8926746166949074, f1: 0.46371681412079646\n",
            "epoch: 860, step: 9, Train: label_loss: 0.08124464750289917, precision: 0.33055390113160626, recall: 0.9128289473682708, f1: 0.4853519894668257\n",
            "epoch: 860, step: 10, Train: label_loss: 0.07815419882535934, precision: 0.31283264340625, recall: 0.9104991394146453, f1: 0.4656690140464004\n",
            "epoch: 860, step: 11, Train: label_loss: 0.08544845134019852, precision: 0.3183722321962706, recall: 0.8837209302324113, f1: 0.4681038275017132\n",
            "epoch: 860, step: 12, Train: label_loss: 0.07848773896694183, precision: 0.3345091122868704, recall: 0.9177419354837228, f1: 0.4903059025889813\n",
            "epoch: 860, step: 13, Train: label_loss: 0.08301346004009247, precision: 0.33849821215730996, recall: 0.9030206677264064, f1: 0.4924143909442568\n",
            "epoch: 860, step: 14, Train: label_loss: 0.08707542717456818, precision: 0.3228299643281615, recall: 0.8990066225164074, f1: 0.47506561675897746\n",
            "epoch: 860, step: 15, Train: label_loss: 0.08463020622730255, precision: 0.3132817153067115, recall: 0.9053356282270386, f1: 0.46548672562547766\n",
            "epoch: 860, step: 16, Train: label_loss: 0.07620219141244888, precision: 0.32569077013519543, recall: 0.9248747913187103, f1: 0.481739130396219\n",
            "epoch: 860, step: 17, Train: label_loss: 0.08311121165752411, precision: 0.30489260143196273, recall: 0.891797556718867, f1: 0.45442418849022104\n",
            "epoch: 860, step: 18, Train: label_loss: 0.08062613755464554, precision: 0.3109792284866284, recall: 0.8926746166949074, f1: 0.46126760559543983\n",
            "epoch: 860, step: 19, Train: label_loss: 0.07851731777191162, precision: 0.3192239858906338, recall: 0.9049999999998491, f1: 0.47196870921825135\n",
            "epoch: 860, step: 20, Train: label_loss: 0.06754603981971741, precision: 0.34347571679342637, recall: 0.9287974683542833, f1: 0.5014950875299546\n",
            "epoch: 860, step: 21, Train: label_loss: 0.07716876268386841, precision: 0.3281715306730001, recall: 0.9107438016527419, f1: 0.48248686510987504\n",
            "epoch: 860, step: 22, Train: label_loss: 0.07540461421012878, precision: 0.322294500295664, recall: 0.9098497495824858, f1: 0.47598253271241975\n",
            "epoch: 860, step: 23, Train: label_loss: 0.08199767023324966, precision: 0.3262773722627499, recall: 0.886904761904586, f1: 0.47705442898944184\n",
            "epoch: 861, step: 0, Train: label_loss: 0.08944772183895111, precision: 0.33293768545992086, recall: 0.9151712887437332, f1: 0.4882506527023526\n",
            "epoch: 861, step: 1, Train: label_loss: 0.07322172820568085, precision: 0.32538736591178036, recall: 0.8995057660624547, f1: 0.4778993435058003\n",
            "epoch: 861, step: 2, Train: label_loss: 0.09013070166110992, precision: 0.323758228605606, recall: 0.8825448613375395, f1: 0.4737302976839797\n",
            "epoch: 861, step: 3, Train: label_loss: 0.08494521677494049, precision: 0.32741267021904513, recall: 0.9035947712416823, f1: 0.4806605823164097\n",
            "epoch: 861, step: 4, Train: label_loss: 0.07319958508014679, precision: 0.33313748531137877, recall: 0.9189627228523631, f1: 0.4890038809440856\n",
            "epoch: 861, step: 5, Train: label_loss: 0.08030812442302704, precision: 0.33628841607563026, recall: 0.9118589743588281, f1: 0.49136442137682496\n",
            "epoch: 861, step: 6, Train: label_loss: 0.07695034891366959, precision: 0.32064247471741103, recall: 0.8968386023293016, f1: 0.4723926379979676\n",
            "epoch: 861, step: 7, Train: label_loss: 0.07886749505996704, precision: 0.3396337861783615, recall: 0.9259259259257767, f1: 0.4969749351378702\n",
            "epoch: 861, step: 8, Train: label_loss: 0.07416880130767822, precision: 0.32178508514384485, recall: 0.9351535836175878, f1: 0.4788117081313709\n",
            "epoch: 861, step: 9, Train: label_loss: 0.07881958782672882, precision: 0.33274336283183875, recall: 0.9141004862235147, f1: 0.4878892733172292\n",
            "epoch: 861, step: 10, Train: label_loss: 0.07535117864608765, precision: 0.3249266862169897, recall: 0.9233333333331794, f1: 0.48069414312847725\n",
            "epoch: 861, step: 11, Train: label_loss: 0.07551126182079315, precision: 0.32665094339620715, recall: 0.9264214046821193, f1: 0.4829991281218311\n",
            "epoch: 861, step: 12, Train: label_loss: 0.07351436465978622, precision: 0.31360946745560275, recall: 0.9028960817715668, f1: 0.46552481331259205\n",
            "epoch: 861, step: 13, Train: label_loss: 0.08237826824188232, precision: 0.3267973856208956, recall: 0.9001636661209655, f1: 0.4795117697952274\n",
            "epoch: 861, step: 14, Train: label_loss: 0.09162784367799759, precision: 0.33194278903454516, recall: 0.914614121510523, f1: 0.48710100564518427\n",
            "epoch: 861, step: 15, Train: label_loss: 0.08861254900693893, precision: 0.3309395571513865, recall: 0.9095394736840609, f1: 0.48530057038646063\n",
            "epoch: 861, step: 16, Train: label_loss: 0.08682242035865784, precision: 0.302491103202829, recall: 0.9058614564829651, f1: 0.4535349043643827\n",
            "epoch: 861, step: 17, Train: label_loss: 0.08690273016691208, precision: 0.3028673835125267, recall: 0.8910369068539734, f1: 0.4520731163241097\n",
            "epoch: 861, step: 18, Train: label_loss: 0.07025420665740967, precision: 0.32590855803046154, recall: 0.9328859060401119, f1: 0.4830582102135381\n",
            "epoch: 861, step: 19, Train: label_loss: 0.08199068158864975, precision: 0.32379248658316495, recall: 0.909547738693315, f1: 0.47757255932799075\n",
            "epoch: 861, step: 20, Train: label_loss: 0.0716998428106308, precision: 0.30918727915192523, recall: 0.908304498269739, f1: 0.4613356765877262\n",
            "epoch: 861, step: 21, Train: label_loss: 0.08191779255867004, precision: 0.31600955794502295, recall: 0.8996598639454252, f1: 0.4677276745857102\n",
            "epoch: 861, step: 22, Train: label_loss: 0.08329524099826813, precision: 0.33411903358866624, recall: 0.9071999999998548, f1: 0.4883720929838707\n",
            "epoch: 861, step: 23, Train: label_loss: 0.07236935198307037, precision: 0.30902527075810043, recall: 0.8935281837158886, f1: 0.4592274677729218\n",
            "epoch: 862, step: 0, Train: label_loss: 0.08342383801937103, precision: 0.312314098750725, recall: 0.883838383838235, f1: 0.4615384614998357\n",
            "epoch: 862, step: 1, Train: label_loss: 0.08278252184391022, precision: 0.3398345153664102, recall: 0.9380097879280688, f1: 0.49891540126243167\n",
            "epoch: 862, step: 2, Train: label_loss: 0.08187191933393478, precision: 0.3218527315914298, recall: 0.8973509933773348, f1: 0.4737762237373228\n",
            "epoch: 862, step: 3, Train: label_loss: 0.09011706709861755, precision: 0.3118214716525747, recall: 0.8822525597268118, f1: 0.4607843136868599\n",
            "epoch: 862, step: 4, Train: label_loss: 0.08445136249065399, precision: 0.32480666270075403, recall: 0.8995057660624547, f1: 0.47727272723370257\n",
            "epoch: 862, step: 5, Train: label_loss: 0.08597870171070099, precision: 0.3178807947019676, recall: 0.8799999999998532, f1: 0.4670499778468602\n",
            "epoch: 862, step: 6, Train: label_loss: 0.07926234602928162, precision: 0.33988095238093213, recall: 0.9165329052968031, f1: 0.4958749456834594\n",
            "epoch: 862, step: 7, Train: label_loss: 0.07732896506786346, precision: 0.3153846153845967, recall: 0.9080068143098964, f1: 0.4681598594258987\n",
            "epoch: 862, step: 8, Train: label_loss: 0.08144088834524155, precision: 0.3147268408550882, recall: 0.9090909090907531, f1: 0.4675782972709714\n",
            "epoch: 862, step: 9, Train: label_loss: 0.08039090037345886, precision: 0.3301606186793379, recall: 0.9053833605218751, f1: 0.4838709677027308\n",
            "epoch: 862, step: 10, Train: label_loss: 0.077297143638134, precision: 0.3205882352940988, recall: 0.917508417508263, f1: 0.47515257188834636\n",
            "epoch: 862, step: 11, Train: label_loss: 0.07840248942375183, precision: 0.29446757882211216, recall: 0.895117540686999, f1: 0.44315129808267195\n",
            "epoch: 862, step: 12, Train: label_loss: 0.08270804584026337, precision: 0.3297746144721038, recall: 0.9099836333877397, f1: 0.4841097082761029\n",
            "epoch: 862, step: 13, Train: label_loss: 0.06392910331487656, precision: 0.33840749414517923, recall: 0.9189189189187728, f1: 0.4946512622627129\n",
            "epoch: 862, step: 14, Train: label_loss: 0.07830563187599182, precision: 0.32269503546097383, recall: 0.9069767441858958, f1: 0.47602441146952945\n",
            "epoch: 862, step: 15, Train: label_loss: 0.06990484893321991, precision: 0.31121550205517845, recall: 0.9169550173008794, f1: 0.4647084611633494\n",
            "epoch: 862, step: 16, Train: label_loss: 0.07199590653181076, precision: 0.32594752186587017, recall: 0.9394957983191697, f1: 0.4839826839443959\n",
            "epoch: 862, step: 17, Train: label_loss: 0.07516594231128693, precision: 0.32981220657275057, recall: 0.9198036006545138, f1: 0.48552915762849025\n",
            "epoch: 862, step: 18, Train: label_loss: 0.08383206278085709, precision: 0.3347156398104067, recall: 0.9142394822004992, f1: 0.49002601904138177\n",
            "epoch: 862, step: 19, Train: label_loss: 0.0736963152885437, precision: 0.32540154669837446, recall: 0.8865478119933733, f1: 0.47606614443413264\n",
            "epoch: 862, step: 20, Train: label_loss: 0.09298278391361237, precision: 0.3193277310924178, recall: 0.8866666666665188, f1: 0.46954986756914385\n",
            "epoch: 862, step: 21, Train: label_loss: 0.08064736425876617, precision: 0.30442583732055595, recall: 0.888307155322707, f1: 0.4534521157748593\n",
            "epoch: 862, step: 22, Train: label_loss: 0.08389387279748917, precision: 0.31600955794502295, recall: 0.8920741989880451, f1: 0.4666960740680767\n",
            "epoch: 862, step: 23, Train: label_loss: 0.0827471911907196, precision: 0.34683357879231613, recall: 0.8803738317755363, f1: 0.49762282087857407\n",
            "epoch: 863, step: 0, Train: label_loss: 0.07703829556703568, precision: 0.3186157517899571, recall: 0.8899999999998516, f1: 0.4692442881860899\n",
            "epoch: 863, step: 1, Train: label_loss: 0.07348407804965973, precision: 0.3313609467455425, recall: 0.9256198347105907, f1: 0.4880174291550327\n",
            "epoch: 863, step: 2, Train: label_loss: 0.07821261137723923, precision: 0.3341246290800989, recall: 0.9199346405227254, f1: 0.49020461467571336\n",
            "epoch: 863, step: 3, Train: label_loss: 0.0749068409204483, precision: 0.3376394597768445, recall: 0.9185303514375529, f1: 0.4937741519572147\n",
            "epoch: 863, step: 4, Train: label_loss: 0.07866854220628738, precision: 0.3409893992932661, recall: 0.9190476190474731, f1: 0.49742268037285153\n",
            "epoch: 863, step: 5, Train: label_loss: 0.07893291115760803, precision: 0.34872705743041155, recall: 0.9103554868623013, f1: 0.5042808218777135\n",
            "epoch: 863, step: 6, Train: label_loss: 0.07320912927389145, precision: 0.3258293838862366, recall: 0.906095551894414, f1: 0.4793028322050601\n",
            "epoch: 863, step: 7, Train: label_loss: 0.08242910355329514, precision: 0.33510324483773835, recall: 0.926590538335901, f1: 0.49220103982229796\n",
            "epoch: 863, step: 8, Train: label_loss: 0.0687117651104927, precision: 0.2901891252954911, recall: 0.8815080789944557, f1: 0.4366385059653636\n",
            "epoch: 863, step: 9, Train: label_loss: 0.0828588604927063, precision: 0.323775388291498, recall: 0.9139966273185642, f1: 0.4781649757001887\n",
            "epoch: 863, step: 10, Train: label_loss: 0.07094525545835495, precision: 0.3365098272781217, recall: 0.9025559105429868, f1: 0.49023861167405813\n",
            "epoch: 863, step: 11, Train: label_loss: 0.08243300020694733, precision: 0.32527990571595017, recall: 0.9277310924368188, f1: 0.4816753926316736\n",
            "epoch: 863, step: 12, Train: label_loss: 0.07952859997749329, precision: 0.34109916367978843, recall: 0.9135999999998538, f1: 0.49673771200908334\n",
            "epoch: 863, step: 13, Train: label_loss: 0.08430951833724976, precision: 0.31801909307874, recall: 0.9049235993207292, f1: 0.47064017656191576\n",
            "epoch: 863, step: 14, Train: label_loss: 0.09215198457241058, precision: 0.3154121863799095, recall: 0.9072164948452048, f1: 0.468085106344652\n",
            "epoch: 863, step: 15, Train: label_loss: 0.09453611075878143, precision: 0.2974111980734318, recall: 0.8681898066782304, f1: 0.4430493273162099\n",
            "epoch: 863, step: 16, Train: label_loss: 0.08395422995090485, precision: 0.3045023696682284, recall: 0.8954703832751052, f1: 0.45446507511681716\n",
            "epoch: 863, step: 17, Train: label_loss: 0.0817389041185379, precision: 0.33233890214795153, recall: 0.9221854304634234, f1: 0.4885964911890806\n",
            "epoch: 863, step: 18, Train: label_loss: 0.08906018733978271, precision: 0.32576210400476235, recall: 0.8905228758168479, f1: 0.4770240699826203\n",
            "epoch: 863, step: 19, Train: label_loss: 0.08376645296812057, precision: 0.3214920071047767, recall: 0.8945634266884852, f1: 0.4729965156405054\n",
            "epoch: 863, step: 20, Train: label_loss: 0.07654454559087753, precision: 0.3264340626847826, recall: 0.9078947368419559, f1: 0.48020878638993586\n",
            "epoch: 863, step: 21, Train: label_loss: 0.09775004535913467, precision: 0.32391826923074973, recall: 0.886513157894591, f1: 0.4744718309466751\n",
            "epoch: 863, step: 22, Train: label_loss: 0.08525735139846802, precision: 0.30030030030028226, recall: 0.8726003490399873, f1: 0.44682752453737795\n",
            "epoch: 863, step: 23, Train: label_loss: 0.09711920469999313, precision: 0.29446494464942474, recall: 0.8730853391682991, f1: 0.44039735095560906\n",
            "epoch: 864, step: 0, Train: label_loss: 0.095990851521492, precision: 0.2894580107206498, recall: 0.8788426763108718, f1: 0.43548387093042795\n",
            "epoch: 864, step: 1, Train: label_loss: 0.08248743414878845, precision: 0.33313503866744004, recall: 0.8945686900957037, f1: 0.4854789769868555\n",
            "epoch: 864, step: 2, Train: label_loss: 0.07788677513599396, precision: 0.33154761904759933, recall: 0.8969404186794047, f1: 0.4841373315555075\n",
            "epoch: 864, step: 3, Train: label_loss: 0.09386174380779266, precision: 0.30736968244455914, recall: 0.884482758620537, f1: 0.45620275674247407\n",
            "epoch: 864, step: 4, Train: label_loss: 0.07430647313594818, precision: 0.3364705882352743, recall: 0.9240710823908038, f1: 0.49331608448001146\n",
            "epoch: 864, step: 5, Train: label_loss: 0.08673202246427536, precision: 0.3155368926214568, recall: 0.8885135135133634, f1: 0.46569278437916567\n",
            "epoch: 864, step: 6, Train: label_loss: 0.09425248205661774, precision: 0.3315282791816888, recall: 0.8887096774192115, f1: 0.4829097282688839\n",
            "epoch: 864, step: 7, Train: label_loss: 0.08435727655887604, precision: 0.32556750298683834, recall: 0.8993399339932509, f1: 0.4780701753995254\n",
            "epoch: 864, step: 8, Train: label_loss: 0.08308742940425873, precision: 0.32273545290939876, recall: 0.8966666666665172, f1: 0.47463608289001546\n",
            "epoch: 864, step: 9, Train: label_loss: 0.08208534866571426, precision: 0.31011904761902914, recall: 0.8982758620688106, f1: 0.46106194686445917\n",
            "epoch: 864, step: 10, Train: label_loss: 0.08424180001020432, precision: 0.3060982830076787, recall: 0.8929188255611583, f1: 0.4559082892035588\n",
            "epoch: 864, step: 11, Train: label_loss: 0.07289761304855347, precision: 0.33000587199058545, recall: 0.9273927392737743, f1: 0.4867908184974065\n",
            "epoch: 864, step: 12, Train: label_loss: 0.07724042236804962, precision: 0.3317507418397429, recall: 0.9194078947366908, f1: 0.4875708678196882\n",
            "epoch: 864, step: 13, Train: label_loss: 0.07959579676389694, precision: 0.32123735871503145, recall: 0.9106239460369459, f1: 0.474934036900718\n",
            "epoch: 864, step: 14, Train: label_loss: 0.09589887410402298, precision: 0.3116028708133785, recall: 0.8998272884281692, f1: 0.4629053753504635\n",
            "epoch: 864, step: 15, Train: label_loss: 0.08107572793960571, precision: 0.32625368731561494, recall: 0.918604651162638, f1: 0.4814976055337649\n",
            "epoch: 864, step: 16, Train: label_loss: 0.08976615965366364, precision: 0.3325344517675055, recall: 0.8753943217664234, f1: 0.4819800260130312\n",
            "epoch: 864, step: 17, Train: label_loss: 0.06840841472148895, precision: 0.3124999999999814, recall: 0.8928571428569909, f1: 0.46296296292451333\n",
            "epoch: 864, step: 18, Train: label_loss: 0.07711858302354813, precision: 0.31175771971494587, recall: 0.8928571428569909, f1: 0.4621478872855382\n",
            "epoch: 864, step: 19, Train: label_loss: 0.09321358799934387, precision: 0.32559523809521873, recall: 0.8996710526314309, f1: 0.47814685310778743\n",
            "epoch: 864, step: 20, Train: label_loss: 0.07426411658525467, precision: 0.32565011820329043, recall: 0.930743243243086, f1: 0.48248686511041683\n",
            "epoch: 864, step: 21, Train: label_loss: 0.07934194803237915, precision: 0.32451499118163873, recall: 0.9019607843135781, f1: 0.4773022048897062\n",
            "epoch: 864, step: 22, Train: label_loss: 0.09215855598449707, precision: 0.32093581283741324, recall: 0.8784893267650445, f1: 0.4701230228078631\n",
            "epoch: 864, step: 23, Train: label_loss: 0.08947481215000153, precision: 0.34520348837206793, recall: 0.9064885496181475, f1: 0.4999999999600014\n",
            "epoch: 865, step: 0, Train: label_loss: 0.08681000769138336, precision: 0.3373277411623525, recall: 0.8742236024843363, f1: 0.48681366187071506\n",
            "epoch: 865, step: 1, Train: label_loss: 0.07887588441371918, precision: 0.3256637168141401, recall: 0.9078947368419559, f1: 0.47937472857594743\n",
            "epoch: 865, step: 2, Train: label_loss: 0.07385355234146118, precision: 0.3111373011196045, recall: 0.9103448275860498, f1: 0.4637681159040206\n",
            "epoch: 865, step: 3, Train: label_loss: 0.06813624501228333, precision: 0.3153258954785487, recall: 0.9290657439444758, f1: 0.4708461200848745\n",
            "epoch: 865, step: 4, Train: label_loss: 0.09927822649478912, precision: 0.29963898916965703, recall: 0.8908765652950105, f1: 0.44844664561740166\n",
            "epoch: 865, step: 5, Train: label_loss: 0.09442087262868881, precision: 0.3150029886431372, recall: 0.9070567986229074, f1: 0.4676131321710997\n",
            "epoch: 865, step: 6, Train: label_loss: 0.07321496307849884, precision: 0.34456264775411677, recall: 0.9283439490444381, f1: 0.502586206857025\n",
            "epoch: 865, step: 7, Train: label_loss: 0.07758744806051254, precision: 0.33116113744073866, recall: 0.9270315091209076, f1: 0.4879965080362483\n",
            "epoch: 865, step: 8, Train: label_loss: 0.07931549847126007, precision: 0.32162001191183315, recall: 0.8940397350991897, f1: 0.4730617608020432\n",
            "epoch: 865, step: 9, Train: label_loss: 0.09302613139152527, precision: 0.3247761194029657, recall: 0.9036544850496837, f1: 0.4778216951740607\n",
            "epoch: 865, step: 10, Train: label_loss: 0.08809088170528412, precision: 0.3335336538461338, recall: 0.906862745097891, f1: 0.4876977152506217\n",
            "epoch: 865, step: 11, Train: label_loss: 0.07518167048692703, precision: 0.3249414519906133, recall: 0.920398009950096, f1: 0.480311553401459\n",
            "epoch: 865, step: 12, Train: label_loss: 0.07497454434633255, precision: 0.3088322465915644, recall: 0.9013840830448266, f1: 0.46004415007232125\n",
            "epoch: 865, step: 13, Train: label_loss: 0.0886177271604538, precision: 0.3264340626847826, recall: 0.9199999999998466, f1: 0.48188563942004836\n",
            "epoch: 865, step: 14, Train: label_loss: 0.08806589990854263, precision: 0.32340678975578774, recall: 0.8901639344260835, f1: 0.4744429881653198\n",
            "epoch: 865, step: 15, Train: label_loss: 0.08242027461528778, precision: 0.32319618366128067, recall: 0.8870703764319333, f1: 0.473776223737036\n",
            "epoch: 865, step: 16, Train: label_loss: 0.08096694201231003, precision: 0.32537313432833875, recall: 0.8934426229506731, f1: 0.4770240699827017\n",
            "epoch: 865, step: 17, Train: label_loss: 0.07132740318775177, precision: 0.30416911332940083, recall: 0.9071803852888077, f1: 0.4555848724337663\n",
            "epoch: 865, step: 18, Train: label_loss: 0.08490359783172607, precision: 0.33999999999998, recall: 0.9131121642968542, f1: 0.4954993570114233\n",
            "epoch: 865, step: 19, Train: label_loss: 0.08663579821586609, precision: 0.3311494937462578, recall: 0.899676375404385, f1: 0.48410970827581945\n",
            "epoch: 865, step: 20, Train: label_loss: 0.07705571502447128, precision: 0.3378299120234406, recall: 0.9335494327389086, f1: 0.4961240309686867\n",
            "epoch: 865, step: 21, Train: label_loss: 0.07291501760482788, precision: 0.3062426383980974, recall: 0.9171075837740886, f1: 0.4591611478652962\n",
            "epoch: 865, step: 22, Train: label_loss: 0.082505002617836, precision: 0.32918149466190216, recall: 0.906862745097891, f1: 0.4830287205875112\n",
            "epoch: 865, step: 23, Train: label_loss: 0.08605087548494339, precision: 0.3218978102189546, recall: 0.8999999999998164, f1: 0.4741935483482378\n",
            "epoch: 866, step: 0, Train: label_loss: 0.08054617792367935, precision: 0.33806986382472837, recall: 0.9049128367668929, f1: 0.49224137927070083\n",
            "epoch: 866, step: 1, Train: label_loss: 0.08245588093996048, precision: 0.3305389221556688, recall: 0.8888888888887457, f1: 0.4818856394191922\n",
            "epoch: 866, step: 2, Train: label_loss: 0.08024170249700546, precision: 0.3196915776986762, recall: 0.9089376053961367, f1: 0.47301447999656226\n",
            "epoch: 866, step: 3, Train: label_loss: 0.07678081095218658, precision: 0.308333333333315, recall: 0.8915662650600874, f1: 0.4582043343270976\n",
            "epoch: 866, step: 4, Train: label_loss: 0.08226591348648071, precision: 0.3211117681844872, recall: 0.9141414141412602, f1: 0.4752735229374126\n",
            "epoch: 866, step: 5, Train: label_loss: 0.0858822613954544, precision: 0.32859680284189885, recall: 0.8980582524270391, f1: 0.48114434326372507\n",
            "epoch: 866, step: 6, Train: label_loss: 0.10635286569595337, precision: 0.31283905967448383, recall: 0.8826530612243396, f1: 0.4619492656489013\n",
            "epoch: 866, step: 7, Train: label_loss: 0.08023542910814285, precision: 0.30955188679243456, recall: 0.9036144578311697, f1: 0.4611330697906707\n",
            "epoch: 866, step: 8, Train: label_loss: 0.07317821681499481, precision: 0.30979228486645044, recall: 0.9046793760830321, f1: 0.46153846150041744\n",
            "epoch: 866, step: 9, Train: label_loss: 0.08852005004882812, precision: 0.30326409495547163, recall: 0.909252669038984, f1: 0.45482866039858544\n",
            "epoch: 866, step: 10, Train: label_loss: 0.07088559865951538, precision: 0.3119482048263501, recall: 0.9137931034481183, f1: 0.4651162790317809\n",
            "epoch: 866, step: 11, Train: label_loss: 0.07478248327970505, precision: 0.3163204747774293, recall: 0.9033898305083214, f1: 0.4685714285329708\n",
            "epoch: 866, step: 12, Train: label_loss: 0.058468546718358994, precision: 0.33254577672768265, recall: 0.9184339314843526, f1: 0.4882914136643074\n",
            "epoch: 866, step: 13, Train: label_loss: 0.07113239169120789, precision: 0.3305736250739012, recall: 0.9254966887415685, f1: 0.48714596946008476\n",
            "epoch: 866, step: 14, Train: label_loss: 0.09108798205852509, precision: 0.32174955062909993, recall: 0.8846787479405461, f1: 0.47188049205223304\n",
            "epoch: 866, step: 15, Train: label_loss: 0.061728786677122116, precision: 0.33821805392729554, recall: 0.9217252396164661, f1: 0.4948542023620539\n",
            "epoch: 866, step: 16, Train: label_loss: 0.07766561955213547, precision: 0.31753554502367787, recall: 0.8874172185428993, f1: 0.46771378704665806\n",
            "epoch: 866, step: 17, Train: label_loss: 0.08276514708995819, precision: 0.3347131874630198, recall: 0.9099678456590177, f1: 0.4894076955940143\n",
            "epoch: 866, step: 18, Train: label_loss: 0.08025546371936798, precision: 0.33392539964474044, recall: 0.9126213592231532, f1: 0.488946683965935\n",
            "epoch: 866, step: 19, Train: label_loss: 0.06958412379026413, precision: 0.3149466192170632, recall: 0.8999999999998474, f1: 0.4666080843200771\n",
            "epoch: 866, step: 20, Train: label_loss: 0.07850395143032074, precision: 0.30935672514618073, recall: 0.913644214162191, f1: 0.46221057226448187\n",
            "epoch: 866, step: 21, Train: label_loss: 0.07354503870010376, precision: 0.34292425132117776, recall: 0.9240506329112461, f1: 0.5002141327227888\n",
            "epoch: 866, step: 22, Train: label_loss: 0.07324681431055069, precision: 0.3362831858406881, recall: 0.9298531810765204, f1: 0.49393414207533076\n",
            "epoch: 866, step: 23, Train: label_loss: 0.08346326649188995, precision: 0.32597498160409666, recall: 0.8949494949493142, f1: 0.4778856526037413\n",
            "epoch: 867, step: 0, Train: label_loss: 0.07693769037723541, precision: 0.3170011806375255, recall: 0.9242685025815964, f1: 0.47208791204983785\n",
            "epoch: 867, step: 1, Train: label_loss: 0.07543550431728363, precision: 0.32722976963967354, recall: 0.9126853377263735, f1: 0.48173913039588817\n",
            "epoch: 867, step: 2, Train: label_loss: 0.08111617714166641, precision: 0.3374925727866704, recall: 0.9030206677264064, f1: 0.49134948092920705\n",
            "epoch: 867, step: 3, Train: label_loss: 0.08295533061027527, precision: 0.3060982830076787, recall: 0.8975694444442885, f1: 0.4565121412423861\n",
            "epoch: 867, step: 4, Train: label_loss: 0.08367374539375305, precision: 0.30896226415092515, recall: 0.9113043478259284, f1: 0.4614707177076287\n",
            "epoch: 867, step: 5, Train: label_loss: 0.06946415454149246, precision: 0.33118782913982847, recall: 0.9324546952222516, f1: 0.4887737478023834\n",
            "epoch: 867, step: 6, Train: label_loss: 0.07739134132862091, precision: 0.31109799291615636, recall: 0.9008547008545468, f1: 0.4624835453764547\n",
            "epoch: 867, step: 7, Train: label_loss: 0.07902821898460388, precision: 0.330597889800684, recall: 0.9431438127088723, f1: 0.4895833332948541\n",
            "epoch: 867, step: 8, Train: label_loss: 0.06667494773864746, precision: 0.3231132075471507, recall: 0.9118136439266369, f1: 0.477144100962627\n",
            "epoch: 867, step: 9, Train: label_loss: 0.08504727482795715, precision: 0.32499999999998064, recall: 0.895081967212968, f1: 0.47685589515738097\n",
            "epoch: 867, step: 10, Train: label_loss: 0.07097691297531128, precision: 0.3185011709601687, recall: 0.9251700680270535, f1: 0.4738675957806717\n",
            "epoch: 867, step: 11, Train: label_loss: 0.08129429072141647, precision: 0.2992957746478698, recall: 0.9205776173283536, f1: 0.4517271921684209\n",
            "epoch: 867, step: 12, Train: label_loss: 0.0792844295501709, precision: 0.3242442205097614, recall: 0.9101497504158219, f1: 0.4781468531080759\n",
            "epoch: 867, step: 13, Train: label_loss: 0.0776832178235054, precision: 0.3410165484633368, recall: 0.9202551834129313, f1: 0.4976282880156988\n",
            "epoch: 867, step: 14, Train: label_loss: 0.08847112953662872, precision: 0.31421744324968254, recall: 0.8976109215015532, f1: 0.46548672562526366\n",
            "epoch: 867, step: 15, Train: label_loss: 0.07281309366226196, precision: 0.3392018779342524, recall: 0.9459901800325783, f1: 0.49935205179695563\n",
            "epoch: 867, step: 16, Train: label_loss: 0.08764888346195221, precision: 0.3186943620177852, recall: 0.8846787479405461, f1: 0.4685863873955746\n",
            "epoch: 867, step: 17, Train: label_loss: 0.09402301907539368, precision: 0.3411131059245756, recall: 0.9076433121017662, f1: 0.4958677685552892\n",
            "epoch: 867, step: 18, Train: label_loss: 0.10248178243637085, precision: 0.3225609756097364, recall: 0.8587662337660943, f1: 0.4689716311659334\n",
            "epoch: 867, step: 19, Train: label_loss: 0.10175508260726929, precision: 0.3311138014527645, recall: 0.8894308943087984, f1: 0.48257609171163274\n",
            "epoch: 867, step: 20, Train: label_loss: 0.08281105756759644, precision: 0.33710541989277326, recall: 0.9085072231138188, f1: 0.4917463075191237\n",
            "epoch: 867, step: 21, Train: label_loss: 0.10157507658004761, precision: 0.3190591073582437, recall: 0.8981324278436505, f1: 0.4708500222131662\n",
            "epoch: 867, step: 22, Train: label_loss: 0.08719085156917572, precision: 0.3266908212560189, recall: 0.8839869281044307, f1: 0.4770723103661962\n",
            "epoch: 867, step: 23, Train: label_loss: 0.08614420890808105, precision: 0.32753623188403425, recall: 0.9168356997969743, f1: 0.48264815799639965\n",
            "epoch: 868, step: 0, Train: label_loss: 0.08867070078849792, precision: 0.3323442136498319, recall: 0.9076175040517167, f1: 0.48653344913535074\n",
            "epoch: 868, step: 1, Train: label_loss: 0.08146315068006516, precision: 0.32758620689653223, recall: 0.9003267973854737, f1: 0.4803836093767036\n",
            "epoch: 868, step: 2, Train: label_loss: 0.10024185478687286, precision: 0.33412745681951556, recall: 0.9019292604500158, f1: 0.4876140807949283\n",
            "epoch: 868, step: 3, Train: label_loss: 0.08373810350894928, precision: 0.3267857142856948, recall: 0.8955954323000169, f1: 0.4788486698255907\n",
            "epoch: 868, step: 4, Train: label_loss: 0.07263346016407013, precision: 0.32130177514791, recall: 0.9049999999998491, f1: 0.4742358078215485\n",
            "epoch: 868, step: 5, Train: label_loss: 0.07924449443817139, precision: 0.3201911589008172, recall: 0.8993288590602517, f1: 0.4722466959964767\n",
            "epoch: 868, step: 6, Train: label_loss: 0.0737413763999939, precision: 0.30439952437572504, recall: 0.8982456140349301, f1: 0.4547069271379944\n",
            "epoch: 868, step: 7, Train: label_loss: 0.09277121722698212, precision: 0.29239065308566253, recall: 0.8683274021350768, f1: 0.4374719856189272\n",
            "epoch: 868, step: 8, Train: label_loss: 0.0880797952413559, precision: 0.31454005934716234, recall: 0.8818635607319664, f1: 0.46369203845639045\n",
            "epoch: 868, step: 9, Train: label_loss: 0.07106337696313858, precision: 0.32482185273157216, recall: 0.8967213114752628, f1: 0.4768962510507175\n",
            "epoch: 868, step: 10, Train: label_loss: 0.09794767946004868, precision: 0.31480362537762446, recall: 0.8800675675674189, f1: 0.4637294169615938\n",
            "epoch: 868, step: 11, Train: label_loss: 0.07122122496366501, precision: 0.33293978748522235, recall: 0.9082125603863271, f1: 0.48725701939914434\n",
            "epoch: 868, step: 12, Train: label_loss: 0.06527359783649445, precision: 0.3366568914955814, recall: 0.9111111111109664, f1: 0.49164882223036294\n",
            "epoch: 868, step: 13, Train: label_loss: 0.07753230631351471, precision: 0.33235294117645103, recall: 0.9277504105088787, f1: 0.4893893459983659\n",
            "epoch: 868, step: 14, Train: label_loss: 0.08110058307647705, precision: 0.3180737217597908, recall: 0.900673400673249, f1: 0.47012302280848456\n",
            "epoch: 868, step: 15, Train: label_loss: 0.0819961279630661, precision: 0.3255813953488178, recall: 0.9054726368157702, f1: 0.47894736838210517\n",
            "epoch: 868, step: 16, Train: label_loss: 0.09294896572828293, precision: 0.3234761617380613, recall: 0.8758169934639091, f1: 0.4724548258750637\n",
            "epoch: 868, step: 17, Train: label_loss: 0.08940889686346054, precision: 0.30843373493974047, recall: 0.8707482993195798, f1: 0.4555160141962051\n",
            "epoch: 868, step: 18, Train: label_loss: 0.08986645936965942, precision: 0.3241013553329214, recall: 0.906095551894414, f1: 0.4774305555167049\n",
            "epoch: 868, step: 19, Train: label_loss: 0.0865163505077362, precision: 0.31619844590553997, recall: 0.89358108108093, f1: 0.4671081677317672\n",
            "epoch: 868, step: 20, Train: label_loss: 0.08469866216182709, precision: 0.3443786982248317, recall: 0.9194312796207078, f1: 0.5010761945362882\n",
            "epoch: 868, step: 21, Train: label_loss: 0.08778785169124603, precision: 0.3028335301062395, recall: 0.899999999999842, f1: 0.4531802119764181\n",
            "epoch: 868, step: 22, Train: label_loss: 0.07642510533332825, precision: 0.31625967837996927, recall: 0.898477157360254, f1: 0.4678414096530749\n",
            "epoch: 868, step: 23, Train: label_loss: 0.09328235685825348, precision: 0.314705882352918, recall: 0.9029535864976999, f1: 0.4667393674643445\n",
            "epoch: 869, step: 0, Train: label_loss: 0.07932422310113907, precision: 0.3274021352312973, recall: 0.9199999999998466, f1: 0.4829396325071738\n",
            "epoch: 869, step: 1, Train: label_loss: 0.07449410855770111, precision: 0.3145208700764071, recall: 0.9067796610167954, f1: 0.4670449584951091\n",
            "epoch: 869, step: 2, Train: label_loss: 0.06692969799041748, precision: 0.3233038348082405, recall: 0.917922948073548, f1: 0.47818499123542957\n",
            "epoch: 869, step: 3, Train: label_loss: 0.07483057677745819, precision: 0.3181818181817994, recall: 0.9166666666665108, f1: 0.47239263799851333\n",
            "epoch: 869, step: 4, Train: label_loss: 0.07572779804468155, precision: 0.3351254480286538, recall: 0.886255924170476, f1: 0.4863459037312698\n",
            "epoch: 869, step: 5, Train: label_loss: 0.09110012650489807, precision: 0.3070388349514377, recall: 0.8605442176869285, f1: 0.452593917671393\n",
            "epoch: 869, step: 6, Train: label_loss: 0.07120497524738312, precision: 0.31733021077281515, recall: 0.9202037351441561, f1: 0.4719198954777153\n",
            "epoch: 869, step: 7, Train: label_loss: 0.08651483058929443, precision: 0.32691149909690986, recall: 0.8701923076921682, f1: 0.4752735229361864\n",
            "epoch: 869, step: 8, Train: label_loss: 0.07596960663795471, precision: 0.33510324483773835, recall: 0.9176090468496094, f1: 0.4909248054923157\n",
            "epoch: 869, step: 9, Train: label_loss: 0.09908872842788696, precision: 0.32951116475556247, recall: 0.879227053139955, f1: 0.47936786650990426\n",
            "epoch: 869, step: 10, Train: label_loss: 0.08838048577308655, precision: 0.28512396694213193, recall: 0.879781420764867, f1: 0.43067320549130117\n",
            "epoch: 869, step: 11, Train: label_loss: 0.07796894013881683, precision: 0.340524781341088, recall: 0.9358974358972858, f1: 0.4993587002601087\n",
            "epoch: 869, step: 12, Train: label_loss: 0.07971058785915375, precision: 0.3163808397397802, recall: 0.8946488294312884, f1: 0.46745303622173523\n",
            "epoch: 869, step: 13, Train: label_loss: 0.08926266431808472, precision: 0.318452380952362, recall: 0.8901830282860415, f1: 0.4690925032491786\n",
            "epoch: 869, step: 14, Train: label_loss: 0.0827648863196373, precision: 0.31899641577059024, recall: 0.8855721393033357, f1: 0.46903820812966335\n",
            "epoch: 869, step: 15, Train: label_loss: 0.09646251797676086, precision: 0.33655006031361057, recall: 0.8801261829651608, f1: 0.48691099472433563\n",
            "epoch: 869, step: 16, Train: label_loss: 0.08317000418901443, precision: 0.31623415811705996, recall: 0.8675496688740285, f1: 0.46351172043846856\n",
            "epoch: 869, step: 17, Train: label_loss: 0.09093611687421799, precision: 0.3273915626856609, recall: 0.903278688524442, f1: 0.48059310942449157\n",
            "epoch: 869, step: 18, Train: label_loss: 0.09946909546852112, precision: 0.3179611650485244, recall: 0.8851351351349855, f1: 0.4678571428182133\n",
            "epoch: 869, step: 19, Train: label_loss: 0.091626837849617, precision: 0.31119090365049007, recall: 0.902777777777621, f1: 0.46283934130584686\n",
            "epoch: 869, step: 20, Train: label_loss: 0.09975310415029526, precision: 0.3069129916567159, recall: 0.8987783595111869, f1: 0.45757441133473137\n",
            "epoch: 869, step: 21, Train: label_loss: 0.09192933142185211, precision: 0.3335336538461338, recall: 0.9009740259738797, f1: 0.4868421052236791\n",
            "epoch: 869, step: 22, Train: label_loss: 0.10551682114601135, precision: 0.3197278911564428, recall: 0.8352180936993804, f1: 0.4624329158812072\n",
            "epoch: 869, step: 23, Train: label_loss: 0.08990247547626495, precision: 0.30746705710100236, recall: 0.8917197452227407, f1: 0.4572672835764077\n",
            "epoch: 870, step: 0, Train: label_loss: 0.08839954435825348, precision: 0.28987265009094665, recall: 0.8643761301987586, f1: 0.43415077198777874\n",
            "epoch: 870, step: 1, Train: label_loss: 0.07811155915260315, precision: 0.3038575667655606, recall: 0.9045936395758118, f1: 0.45490892932704236\n",
            "epoch: 870, step: 2, Train: label_loss: 0.08782883733510971, precision: 0.3183183183182992, recall: 0.8983050847456104, f1: 0.470066518808328\n",
            "epoch: 870, step: 3, Train: label_loss: 0.07690252363681793, precision: 0.33353186420486397, recall: 0.9195402298849064, f1: 0.48951048947138187\n",
            "epoch: 870, step: 4, Train: label_loss: 0.08710940182209015, precision: 0.3179122182680713, recall: 0.885950413222994, f1: 0.4679179397253862\n",
            "epoch: 870, step: 5, Train: label_loss: 0.08393432199954987, precision: 0.31799163179914414, recall: 0.8881469115190503, f1: 0.4683098591160611\n",
            "epoch: 870, step: 6, Train: label_loss: 0.08056904375553131, precision: 0.32217573221755397, recall: 0.9089376053961367, f1: 0.4757281553011217\n",
            "epoch: 870, step: 7, Train: label_loss: 0.0696573406457901, precision: 0.33039906103284444, recall: 0.9229508196719798, f1: 0.4866032843172271\n",
            "epoch: 870, step: 8, Train: label_loss: 0.09840767085552216, precision: 0.3089921544960586, recall: 0.8663282571910547, f1: 0.4555160141960781\n",
            "epoch: 870, step: 9, Train: label_loss: 0.08537442982196808, precision: 0.31688466111769814, recall: 0.8853820598005173, f1: 0.46672504374397583\n",
            "epoch: 870, step: 10, Train: label_loss: 0.10682427138090134, precision: 0.3288996372430273, recall: 0.8774193548385681, f1: 0.47845206680286384\n",
            "epoch: 870, step: 11, Train: label_loss: 0.09790726006031036, precision: 0.3377245508981834, recall: 0.892405063290998, f1: 0.4900086880574302\n",
            "epoch: 870, step: 12, Train: label_loss: 0.0924970805644989, precision: 0.3088057901085459, recall: 0.8634064080942894, f1: 0.4549089293258786\n",
            "epoch: 870, step: 13, Train: label_loss: 0.09912508726119995, precision: 0.3347483323225995, recall: 0.8831999999998587, f1: 0.4854881266091726\n",
            "epoch: 870, step: 14, Train: label_loss: 0.08764895796775818, precision: 0.3399399399399195, recall: 0.8775193798448251, f1: 0.49004329000299623\n",
            "epoch: 870, step: 15, Train: label_loss: 0.08415037393569946, precision: 0.3049940546967714, recall: 0.884482758620537, f1: 0.45358090181859095\n",
            "epoch: 870, step: 16, Train: label_loss: 0.07976755499839783, precision: 0.3268206039076183, recall: 0.9246231155777345, f1: 0.4829396325072989\n",
            "epoch: 870, step: 17, Train: label_loss: 0.08624230325222015, precision: 0.3309395571513865, recall: 0.8991869918697725, f1: 0.48381452314522905\n",
            "epoch: 870, step: 18, Train: label_loss: 0.09467695653438568, precision: 0.33473305338930204, recall: 0.9058441558440087, f1: 0.488830486162919\n",
            "epoch: 870, step: 19, Train: label_loss: 0.0919584408402443, precision: 0.30400485436891356, recall: 0.8713043478259354, f1: 0.45074224017753295\n",
            "epoch: 870, step: 20, Train: label_loss: 0.08721558004617691, precision: 0.3228672985781799, recall: 0.930034129692674, f1: 0.4793315742800818\n",
            "epoch: 870, step: 21, Train: label_loss: 0.09038973599672318, precision: 0.31839904420547677, recall: 0.8942953020132727, f1: 0.4696035241903095\n",
            "epoch: 870, step: 22, Train: label_loss: 0.07796742022037506, precision: 0.3432128037936963, recall: 0.9118110236219036, f1: 0.49870801029613737\n",
            "epoch: 870, step: 23, Train: label_loss: 0.09899520874023438, precision: 0.3142016188373573, recall: 0.8786008230450867, f1: 0.4628726286874316\n",
            "epoch: 871, step: 0, Train: label_loss: 0.08706119656562805, precision: 0.32361689470551314, recall: 0.8991735537188595, f1: 0.4759405073976063\n",
            "epoch: 871, step: 1, Train: label_loss: 0.09729544073343277, precision: 0.30579010856451716, recall: 0.8681506849313582, f1: 0.4522747546447519\n",
            "epoch: 871, step: 2, Train: label_loss: 0.0809812992811203, precision: 0.31675547661336195, recall: 0.9098639455780765, f1: 0.4699165568347275\n",
            "epoch: 871, step: 3, Train: label_loss: 0.08633708953857422, precision: 0.3187537447573206, recall: 0.8735632183906611, f1: 0.4670763827527078\n",
            "epoch: 871, step: 4, Train: label_loss: 0.08175502717494965, precision: 0.33274336283183875, recall: 0.9126213592231532, f1: 0.48767833977921593\n",
            "epoch: 871, step: 5, Train: label_loss: 0.08887852728366852, precision: 0.3179640718562684, recall: 0.8835274542427813, f1: 0.46763540286724625\n",
            "epoch: 871, step: 6, Train: label_loss: 0.08916733413934708, precision: 0.3263847528290455, recall: 0.8998357963873727, f1: 0.4790209789818723\n",
            "epoch: 871, step: 7, Train: label_loss: 0.09437213838100433, precision: 0.3108591885441342, recall: 0.8845500848894933, f1: 0.46004415007185034\n",
            "epoch: 871, step: 8, Train: label_loss: 0.07901905477046967, precision: 0.32096584216723667, recall: 0.9190556492409917, f1: 0.47577477080401703\n",
            "epoch: 871, step: 9, Train: label_loss: 0.08233479410409927, precision: 0.32491186839011016, recall: 0.9262981574537811, f1: 0.4810787298440667\n",
            "epoch: 871, step: 10, Train: label_loss: 0.07779023051261902, precision: 0.3233890214796943, recall: 0.8813008130079867, f1: 0.47315582711039883\n",
            "epoch: 871, step: 11, Train: label_loss: 0.08971895277500153, precision: 0.3178571428571239, recall: 0.8885191347752265, f1: 0.4682156948318179\n",
            "epoch: 871, step: 12, Train: label_loss: 0.08131207525730133, precision: 0.3347230494341671, recall: 0.9079159935378177, f1: 0.48912097472125743\n",
            "epoch: 871, step: 13, Train: label_loss: 0.09144370257854462, precision: 0.31585220500594063, recall: 0.886287625417912, f1: 0.4657293496975969\n",
            "epoch: 871, step: 14, Train: label_loss: 0.07713313400745392, precision: 0.3146067415730151, recall: 0.910958904109433, f1: 0.46769230765410524\n",
            "epoch: 871, step: 15, Train: label_loss: 0.09483425319194794, precision: 0.32897085068409704, recall: 0.894822006472347, f1: 0.48107872984320527\n",
            "epoch: 871, step: 16, Train: label_loss: 0.08111522346735, precision: 0.3185579196217306, recall: 0.9058823529410241, f1: 0.4713598600401685\n",
            "epoch: 871, step: 17, Train: label_loss: 0.09410779178142548, precision: 0.33728512151746665, recall: 0.9031746031744597, f1: 0.4911523521399057\n",
            "epoch: 871, step: 18, Train: label_loss: 0.07076271623373032, precision: 0.30897207367793766, recall: 0.9059233449475773, f1: 0.4607886574719998\n",
            "epoch: 871, step: 19, Train: label_loss: 0.11472925543785095, precision: 0.29574861367835514, recall: 0.8362369337977636, f1: 0.43695949017528707\n",
            "epoch: 871, step: 20, Train: label_loss: 0.07402157038450241, precision: 0.3238770685579005, recall: 0.9028006589784344, f1: 0.4767290125752751\n",
            "epoch: 871, step: 21, Train: label_loss: 0.08732348680496216, precision: 0.34474474474472405, recall: 0.9025157232702983, f1: 0.49891351582262433\n",
            "epoch: 871, step: 22, Train: label_loss: 0.09154166281223297, precision: 0.3189448441246811, recall: 0.9001692047375803, f1: 0.4710048693725672\n",
            "epoch: 871, step: 23, Train: label_loss: 0.09954667091369629, precision: 0.32258064516126667, recall: 0.9090909090907213, f1: 0.47619047615176247\n",
            "epoch: 872, step: 0, Train: label_loss: 0.07448440045118332, precision: 0.338226658837326, recall: 0.9290322580643662, f1: 0.4959104605721033\n",
            "epoch: 872, step: 1, Train: label_loss: 0.09151660650968552, precision: 0.2835550181378305, recall: 0.8542805100180593, f1: 0.42578302311279054\n",
            "epoch: 872, step: 2, Train: label_loss: 0.08498324453830719, precision: 0.32608695652171943, recall: 0.878048780487662, f1: 0.47556142664474416\n",
            "epoch: 872, step: 3, Train: label_loss: 0.1054529920220375, precision: 0.3045871559632841, recall: 0.8327759197323021, f1: 0.4460367218595341\n",
            "epoch: 872, step: 4, Train: label_loss: 0.08867684751749039, precision: 0.32134292565945316, recall: 0.8874172185428993, f1: 0.4718309858764171\n",
            "epoch: 872, step: 5, Train: label_loss: 0.08661569654941559, precision: 0.3166963755198861, recall: 0.8973063973062462, f1: 0.4681598594256029\n",
            "epoch: 872, step: 6, Train: label_loss: 0.08905890583992004, precision: 0.32632211538459577, recall: 0.8887070376430624, f1: 0.4773626373233073\n",
            "epoch: 872, step: 7, Train: label_loss: 0.08747649937868118, precision: 0.3311298076922878, recall: 0.8732171156892435, f1: 0.48017429189908584\n",
            "epoch: 872, step: 8, Train: label_loss: 0.09166577458381653, precision: 0.31077844311375385, recall: 0.8856655290100877, f1: 0.46010638294022643\n",
            "epoch: 872, step: 9, Train: label_loss: 0.07889480888843536, precision: 0.31978481769274836, recall: 0.900673400673249, f1: 0.47198941328285554\n",
            "epoch: 872, step: 10, Train: label_loss: 0.08315630257129669, precision: 0.3136553369111322, recall: 0.8900169204736226, f1: 0.46384479713955384\n",
            "epoch: 872, step: 11, Train: label_loss: 0.09061598777770996, precision: 0.3146067415730151, recall: 0.9047619047617508, f1: 0.4668714348015131\n",
            "epoch: 872, step: 12, Train: label_loss: 0.08795435726642609, precision: 0.34005934718098874, recall: 0.9138755980859786, f1: 0.49567474044485665\n",
            "epoch: 872, step: 13, Train: label_loss: 0.08769278228282928, precision: 0.3377403846153643, recall: 0.8892405063289731, f1: 0.48954703828758506\n",
            "epoch: 872, step: 14, Train: label_loss: 0.08679978549480438, precision: 0.3104066985645747, recall: 0.888698630136834, f1: 0.4601063829403118\n",
            "epoch: 872, step: 15, Train: label_loss: 0.10717670619487762, precision: 0.3295724465557999, recall: 0.9173553719006747, f1: 0.48492791608164443\n",
            "epoch: 872, step: 16, Train: label_loss: 0.09138494729995728, precision: 0.3123515439429743, recall: 0.8960817717204606, f1: 0.4632320563244617\n",
            "epoch: 872, step: 17, Train: label_loss: 0.08534218370914459, precision: 0.30764635603343443, recall: 0.9098939929327013, f1: 0.45982142853362107\n",
            "epoch: 872, step: 18, Train: label_loss: 0.0839916467666626, precision: 0.32671480144402365, recall: 0.8843648208467615, f1: 0.4771528997848122\n",
            "epoch: 872, step: 19, Train: label_loss: 0.07318723201751709, precision: 0.34041297935101233, recall: 0.9115323854658907, f1: 0.4957044673143145\n",
            "epoch: 872, step: 20, Train: label_loss: 0.09228096902370453, precision: 0.310240963855403, recall: 0.8758503401359053, f1: 0.45818505334211235\n",
            "epoch: 872, step: 21, Train: label_loss: 0.09687875211238861, precision: 0.33313432835818907, recall: 0.8913738019167905, f1: 0.48500651886517354\n",
            "epoch: 872, step: 22, Train: label_loss: 0.09267157316207886, precision: 0.2992220227408558, recall: 0.8833922261482537, f1: 0.4470272686255485\n",
            "epoch: 872, step: 23, Train: label_loss: 0.07656265795230865, precision: 0.33956834532371655, recall: 0.9254901960782499, f1: 0.4968421052238314\n",
            "epoch: 873, step: 0, Train: label_loss: 0.08357185125350952, precision: 0.3131009615384427, recall: 0.8845500848894933, f1: 0.4624944518033306\n",
            "epoch: 873, step: 1, Train: label_loss: 0.0809493139386177, precision: 0.3150029886431372, recall: 0.896258503401208, f1: 0.46616541349530743\n",
            "epoch: 873, step: 2, Train: label_loss: 0.06895934045314789, precision: 0.33589138134590696, recall: 0.9177419354837228, f1: 0.49178910972736617\n",
            "epoch: 873, step: 3, Train: label_loss: 0.07547642290592194, precision: 0.31320307874480086, recall: 0.9027303754264671, f1: 0.46505494501665745\n",
            "epoch: 873, step: 4, Train: label_loss: 0.07424427568912506, precision: 0.29526627218933166, recall: 0.8816254416959572, f1: 0.4423758864871949\n",
            "epoch: 873, step: 5, Train: label_loss: 0.08842414617538452, precision: 0.30366806975343935, recall: 0.8617747440271566, f1: 0.44908848373199106\n",
            "epoch: 873, step: 6, Train: label_loss: 0.08492156118154526, precision: 0.3301662707838284, recall: 0.8967741935482424, f1: 0.48263888884951023\n",
            "epoch: 873, step: 7, Train: label_loss: 0.0664711520075798, precision: 0.3062904174015105, recall: 0.9156414762740042, f1: 0.45903083696679886\n",
            "epoch: 873, step: 8, Train: label_loss: 0.07654274255037308, precision: 0.3323406789755609, recall: 0.8999999999998548, f1: 0.4854284471115022\n",
            "epoch: 873, step: 9, Train: label_loss: 0.08178619295358658, precision: 0.3247761194029657, recall: 0.9096989966553662, f1: 0.47866256045392414\n",
            "epoch: 873, step: 10, Train: label_loss: 0.07559794932603836, precision: 0.3311494937462578, recall: 0.8953301127212728, f1: 0.4834782608301031\n",
            "epoch: 873, step: 11, Train: label_loss: 0.07802522927522659, precision: 0.3303411131059048, recall: 0.8917609046848316, f1: 0.4820960698295053\n",
            "epoch: 873, step: 12, Train: label_loss: 0.08485902845859528, precision: 0.3052445492044605, recall: 0.9055944055942472, f1: 0.45658880560350285\n",
            "epoch: 873, step: 13, Train: label_loss: 0.07430242747068405, precision: 0.3331360946745365, recall: 0.9036918138040282, f1: 0.48681366187153613\n",
            "epoch: 873, step: 14, Train: label_loss: 0.07941600680351257, precision: 0.3108591885441342, recall: 0.8905982905981383, f1: 0.46085802738309584\n",
            "epoch: 873, step: 15, Train: label_loss: 0.08013609796762466, precision: 0.3384798099762269, recall: 0.9149277688602062, f1: 0.49414824443387473\n",
            "epoch: 873, step: 16, Train: label_loss: 0.08281806111335754, precision: 0.33490288404942115, recall: 0.9297385620913513, f1: 0.4924275205148921\n",
            "epoch: 873, step: 17, Train: label_loss: 0.07251767814159393, precision: 0.31550802139035555, recall: 0.8879598662205872, f1: 0.4655852695798605\n",
            "epoch: 873, step: 18, Train: label_loss: 0.08819214254617691, precision: 0.33971291866026676, recall: 0.9059011164272877, f1: 0.4941278816479779\n",
            "epoch: 873, step: 19, Train: label_loss: 0.07984881103038788, precision: 0.3372502937720131, recall: 0.924315619967645, f1: 0.4941885492504964\n",
            "epoch: 873, step: 20, Train: label_loss: 0.09518729150295258, precision: 0.3117192147531046, recall: 0.8836424957839993, f1: 0.46086191728770254\n",
            "epoch: 873, step: 21, Train: label_loss: 0.08004473149776459, precision: 0.32556750298683834, recall: 0.8890701468187783, f1: 0.47660690857462434\n",
            "epoch: 873, step: 22, Train: label_loss: 0.09854941070079803, precision: 0.3290017720023432, recall: 0.9131147540982109, f1: 0.4837168909727389\n",
            "epoch: 873, step: 23, Train: label_loss: 0.09635981917381287, precision: 0.30241051862671275, recall: 0.8999999999998044, f1: 0.45270639690051817\n",
            "epoch: 874, step: 0, Train: label_loss: 0.09560154378414154, precision: 0.32246376811592253, recall: 0.878289473684066, f1: 0.47173144872392286\n",
            "epoch: 874, step: 1, Train: label_loss: 0.07489163428544998, precision: 0.3329383886255727, recall: 0.9123376623375141, f1: 0.4878472221830041\n",
            "epoch: 874, step: 2, Train: label_loss: 0.08158501982688904, precision: 0.3185053380782729, recall: 0.9040404040402518, f1: 0.4710526315403755\n",
            "epoch: 874, step: 3, Train: label_loss: 0.08583991229534149, precision: 0.3327380952380754, recall: 0.9104234527685813, f1: 0.48735832602875784\n",
            "epoch: 874, step: 4, Train: label_loss: 0.08699622750282288, precision: 0.31790865384613476, recall: 0.8875838926173006, f1: 0.4681415928814785\n",
            "epoch: 874, step: 5, Train: label_loss: 0.07530798017978668, precision: 0.3112033195020562, recall: 0.8913412563665719, f1: 0.46133567658725516\n",
            "epoch: 874, step: 6, Train: label_loss: 0.07365051656961441, precision: 0.3269916765754859, recall: 0.9212730318256412, f1: 0.48266783673180386\n",
            "epoch: 874, step: 7, Train: label_loss: 0.09210823476314545, precision: 0.333530805687184, recall: 0.9184339314843526, f1: 0.48935245541502104\n",
            "epoch: 874, step: 8, Train: label_loss: 0.0752234011888504, precision: 0.30429594272074556, recall: 0.8994708994707408, f1: 0.45474810517841063\n",
            "epoch: 874, step: 9, Train: label_loss: 0.08063486218452454, precision: 0.34119033588683906, recall: 0.9263999999998517, f1: 0.4987080102965314\n",
            "epoch: 874, step: 10, Train: label_loss: 0.06856754422187805, precision: 0.3141514973575858, recall: 0.9272097053724562, f1: 0.46929824557618877\n",
            "epoch: 874, step: 11, Train: label_loss: 0.07585780322551727, precision: 0.3411764705882152, recall: 0.9235668789807446, f1: 0.4982817869021401\n",
            "epoch: 874, step: 12, Train: label_loss: 0.08488361537456512, precision: 0.32305868405451554, recall: 0.9159663865544678, f1: 0.47765118313406313\n",
            "epoch: 874, step: 13, Train: label_loss: 0.07425381243228912, precision: 0.3467217956290404, recall: 0.8961832061067333, f1: 0.49999999995972905\n",
            "epoch: 874, step: 14, Train: label_loss: 0.08410915732383728, precision: 0.3141852286049054, recall: 0.9193825042880069, f1: 0.46832678021537955\n",
            "epoch: 874, step: 15, Train: label_loss: 0.08028963208198547, precision: 0.31501182033095065, recall: 0.91423670668938, f1: 0.46857142853326883\n",
            "epoch: 874, step: 16, Train: label_loss: 0.08244775980710983, precision: 0.3164179104477423, recall: 0.8731466227346172, f1: 0.46450482029395224\n",
            "epoch: 874, step: 17, Train: label_loss: 0.082027867436409, precision: 0.31275964391689537, recall: 0.9086206896550156, f1: 0.46534216331726763\n",
            "epoch: 874, step: 18, Train: label_loss: 0.11566755175590515, precision: 0.3147147147146958, recall: 0.8689883913763069, f1: 0.4620811287087178\n",
            "epoch: 874, step: 19, Train: label_loss: 0.07904499024152756, precision: 0.31550802139035555, recall: 0.898477157360254, f1: 0.4670184696184811\n",
            "epoch: 874, step: 20, Train: label_loss: 0.09036360681056976, precision: 0.3218322427126519, recall: 0.9061976549412216, f1: 0.4749780508831415\n",
            "epoch: 874, step: 21, Train: label_loss: 0.08003948628902435, precision: 0.31758373205739726, recall: 0.8864774624372476, f1: 0.4676354028673293\n",
            "epoch: 874, step: 22, Train: label_loss: 0.07209890335798264, precision: 0.3370457209847399, recall: 0.9304207119739594, f1: 0.49483648877330844\n",
            "epoch: 874, step: 23, Train: label_loss: 0.08198314905166626, precision: 0.32440260680663835, recall: 0.9256198347105525, f1: 0.4804289543851074\n",
            "epoch: 875, step: 0, Train: label_loss: 0.08799969404935837, precision: 0.29640718562872476, recall: 0.8839285714284135, f1: 0.4439461883031555\n",
            "epoch: 875, step: 1, Train: label_loss: 0.0744442567229271, precision: 0.331357439241237, recall: 0.9285714285712743, f1: 0.4884228920538083\n",
            "epoch: 875, step: 2, Train: label_loss: 0.09784112870693207, precision: 0.3092537313432651, recall: 0.9055944055942472, f1: 0.46105918999315953\n",
            "epoch: 875, step: 3, Train: label_loss: 0.08512131869792938, precision: 0.3085169743894992, recall: 0.886986301369711, f1: 0.45779938131385345\n",
            "epoch: 875, step: 4, Train: label_loss: 0.08821126818656921, precision: 0.3238938053097154, recall: 0.9226890756300969, f1: 0.479475982494246\n",
            "epoch: 875, step: 5, Train: label_loss: 0.0810142308473587, precision: 0.31883194278901555, recall: 0.9037162162160635, f1: 0.47136563872792225\n",
            "epoch: 875, step: 6, Train: label_loss: 0.08637483417987823, precision: 0.3163875598085935, recall: 0.8700657894735411, f1: 0.46403508768014645\n",
            "epoch: 875, step: 7, Train: label_loss: 0.08245943486690521, precision: 0.32934847579197074, recall: 0.8930307941651713, f1: 0.48122270738417094\n",
            "epoch: 875, step: 8, Train: label_loss: 0.08208636939525604, precision: 0.3309859154929383, recall: 0.9141004862235147, f1: 0.48599741486829234\n",
            "epoch: 875, step: 9, Train: label_loss: 0.08965909481048584, precision: 0.3181008902076963, recall: 0.8903654485048355, f1: 0.4687363357722775\n",
            "epoch: 875, step: 10, Train: label_loss: 0.07464766502380371, precision: 0.31458699472757384, recall: 0.9163822525595705, f1: 0.46838203223404185\n",
            "epoch: 875, step: 11, Train: label_loss: 0.08273893594741821, precision: 0.35408103347032566, recall: 0.9262672811058484, f1: 0.5123194562046324\n",
            "epoch: 875, step: 12, Train: label_loss: 0.08605613559484482, precision: 0.3239012642985958, recall: 0.8936877076410475, f1: 0.4754750331027545\n",
            "epoch: 875, step: 13, Train: label_loss: 0.09830068796873093, precision: 0.32633473305336974, recall: 0.8903436988541914, f1: 0.4776119402592101\n",
            "epoch: 875, step: 14, Train: label_loss: 0.06788285076618195, precision: 0.32725132430839743, recall: 0.9174917491747661, f1: 0.4824295010457994\n",
            "epoch: 875, step: 15, Train: label_loss: 0.07221175730228424, precision: 0.32824427480914103, recall: 0.9285714285712743, f1: 0.4850325379223202\n",
            "epoch: 875, step: 16, Train: label_loss: 0.08444996923208237, precision: 0.33513189448439235, recall: 0.8858954041203033, f1: 0.4862983905647414\n",
            "epoch: 875, step: 17, Train: label_loss: 0.07991994172334671, precision: 0.3240685984624291, recall: 0.913333333333181, f1: 0.47839371449643453\n",
            "epoch: 875, step: 18, Train: label_loss: 0.08007222414016724, precision: 0.32096584216723667, recall: 0.9113712374580415, f1: 0.47473867591962327\n",
            "epoch: 875, step: 19, Train: label_loss: 0.08079573512077332, precision: 0.31973995271865724, recall: 0.9153976311335168, f1: 0.4739378011004396\n",
            "epoch: 875, step: 20, Train: label_loss: 0.08411404490470886, precision: 0.32256169212689056, recall: 0.9165275459096967, f1: 0.4771838330774842\n",
            "epoch: 875, step: 21, Train: label_loss: 0.07395845651626587, precision: 0.33372641509431994, recall: 0.9278688524588642, f1: 0.4908933217303444\n",
            "epoch: 875, step: 22, Train: label_loss: 0.08795478194952011, precision: 0.3209580838323161, recall: 0.8844884488447384, f1: 0.47100175743013006\n",
            "epoch: 875, step: 23, Train: label_loss: 0.08941130340099335, precision: 0.30752212389378264, recall: 0.8742138364778042, f1: 0.4549918166553927\n",
            "epoch: 876, step: 0, Train: label_loss: 0.07799162715673447, precision: 0.32776119402983117, recall: 0.8941368078174439, f1: 0.479685452123217\n",
            "epoch: 876, step: 1, Train: label_loss: 0.08512397110462189, precision: 0.30257639304971223, recall: 0.8969804618115635, f1: 0.4525089605357131\n",
            "epoch: 876, step: 2, Train: label_loss: 0.08423545956611633, precision: 0.31482575310098554, recall: 0.9080068143098964, f1: 0.4675438596108473\n",
            "epoch: 876, step: 3, Train: label_loss: 0.08119483292102814, precision: 0.33254577672768265, recall: 0.9066022544281953, f1: 0.486603284316782\n",
            "epoch: 876, step: 4, Train: label_loss: 0.07783447206020355, precision: 0.32250443000588763, recall: 0.9285714285712706, f1: 0.47873739584069247\n",
            "epoch: 876, step: 5, Train: label_loss: 0.08664624392986298, precision: 0.3194278903456305, recall: 0.8963210702339638, f1: 0.4710017574304612\n",
            "epoch: 876, step: 6, Train: label_loss: 0.0860569030046463, precision: 0.3191616766466875, recall: 0.8809917355370444, f1: 0.46857142853234474\n",
            "epoch: 876, step: 7, Train: label_loss: 0.07628892362117767, precision: 0.32602252519263036, recall: 0.9001636661209655, f1: 0.47867711049181694\n",
            "epoch: 876, step: 8, Train: label_loss: 0.0738527849316597, precision: 0.3337292161519992, recall: 0.9020866773674314, f1: 0.48721283047635483\n",
            "epoch: 876, step: 9, Train: label_loss: 0.08107228577136993, precision: 0.32437275985661146, recall: 0.909547738693315, f1: 0.47820343457150694\n",
            "epoch: 876, step: 10, Train: label_loss: 0.07579582184553146, precision: 0.3215547703180023, recall: 0.9269949066212347, f1: 0.47748141666481986\n",
            "epoch: 876, step: 11, Train: label_loss: 0.08361376076936722, precision: 0.33076923076921116, recall: 0.9194078947366908, f1: 0.4865100086642625\n",
            "epoch: 876, step: 12, Train: label_loss: 0.06883169710636139, precision: 0.3206330597889613, recall: 0.9101497504158219, f1: 0.4742089293069002\n",
            "epoch: 876, step: 13, Train: label_loss: 0.08183744549751282, precision: 0.31688466111769814, recall: 0.889816360600853, f1: 0.4673388864145403\n",
            "epoch: 876, step: 14, Train: label_loss: 0.07193059474229813, precision: 0.3174882629107795, recall: 0.9153976311335168, f1: 0.4714596949508253\n",
            "epoch: 876, step: 15, Train: label_loss: 0.06884849816560745, precision: 0.3278301886792259, recall: 0.9174917491747661, f1: 0.48305821021312306\n",
            "epoch: 876, step: 16, Train: label_loss: 0.08341723680496216, precision: 0.3388724035608107, recall: 0.9135999999998538, f1: 0.49437229433277985\n",
            "epoch: 876, step: 17, Train: label_loss: 0.15578028559684753, precision: 0.285359801488816, recall: 0.8170515097689489, f1: 0.4229885057087181\n",
            "epoch: 876, step: 18, Train: label_loss: 0.18304449319839478, precision: 0.3135866065679128, recall: 0.803630363036171, f1: 0.4511347845820884\n",
            "epoch: 876, step: 19, Train: label_loss: 0.19688469171524048, precision: 0.33376455368691244, recall: 0.7999999999998759, f1: 0.4710178000496949\n",
            "epoch: 876, step: 20, Train: label_loss: 0.17780673503875732, precision: 0.2871093749999813, recall: 0.7723292469350661, f1: 0.418604651123239\n",
            "epoch: 876, step: 21, Train: label_loss: 0.20921719074249268, precision: 0.30065359477122217, recall: 0.7603305785122709, f1: 0.430913348905481\n",
            "epoch: 876, step: 22, Train: label_loss: 0.1895703673362732, precision: 0.29127516778521534, recall: 0.7185430463574969, f1: 0.4145176694909079\n",
            "epoch: 876, step: 23, Train: label_loss: 0.16185542941093445, precision: 0.3127925117004436, recall: 0.8036072144286966, f1: 0.4503088152319325\n",
            "epoch: 877, step: 0, Train: label_loss: 0.18064340949058533, precision: 0.3172768143866206, recall: 0.8165289256196997, f1: 0.45698427378018885\n",
            "epoch: 877, step: 1, Train: label_loss: 0.15578116476535797, precision: 0.3188131313131112, recall: 0.8171521035597382, f1: 0.4586739327479551\n",
            "epoch: 877, step: 2, Train: label_loss: 0.160861074924469, precision: 0.3036175710594119, recall: 0.8006814310049742, f1: 0.44028103040505384\n",
            "epoch: 877, step: 3, Train: label_loss: 0.17010162770748138, precision: 0.31568754034859164, recall: 0.7749603803485301, f1: 0.4486238531698343\n",
            "epoch: 877, step: 4, Train: label_loss: 0.17757797241210938, precision: 0.28626444159176595, recall: 0.7824561403507398, f1: 0.41917293229156566\n",
            "epoch: 877, step: 5, Train: label_loss: 0.18872341513633728, precision: 0.2872270019854211, recall: 0.7331081081079842, f1: 0.4127436994364467\n",
            "epoch: 877, step: 6, Train: label_loss: 0.19063100218772888, precision: 0.2950166112956615, recall: 0.716129032257949, f1: 0.41788235289980963\n",
            "epoch: 877, step: 7, Train: label_loss: 0.19777296483516693, precision: 0.26031102096009057, recall: 0.6684027777776617, f1: 0.3746958637065765\n",
            "epoch: 877, step: 8, Train: label_loss: 0.193936288356781, precision: 0.28320971004718254, recall: 0.6885245901638215, f1: 0.40133779260080094\n",
            "epoch: 877, step: 9, Train: label_loss: 0.1954665184020996, precision: 0.27579231287928013, recall: 0.689713322090946, f1: 0.394026974910982\n",
            "epoch: 877, step: 10, Train: label_loss: 0.19764797389507294, precision: 0.2938451356717211, recall: 0.7538200339557294, f1: 0.42285714281674064\n",
            "epoch: 877, step: 11, Train: label_loss: 0.20471392571926117, precision: 0.2838753387533683, recall: 0.7030201342280699, f1: 0.40444015439913433\n",
            "epoch: 877, step: 12, Train: label_loss: 0.18492689728736877, precision: 0.2839095744680662, recall: 0.7478108581434767, f1: 0.41156626502030996\n",
            "epoch: 877, step: 13, Train: label_loss: 0.168584406375885, precision: 0.28911783644557054, recall: 0.7649063032366669, f1: 0.41962616818444803\n",
            "epoch: 877, step: 14, Train: label_loss: 0.20111793279647827, precision: 0.2954838709677229, recall: 0.782905982905849, f1: 0.4290398126065446\n",
            "epoch: 877, step: 15, Train: label_loss: 0.19052523374557495, precision: 0.29324324324322343, recall: 0.7138157894735667, f1: 0.41570881221921707\n",
            "epoch: 877, step: 16, Train: label_loss: 0.16266056895256042, precision: 0.32120051085566276, recall: 0.8099838969402882, f1: 0.45999085501187675\n",
            "epoch: 877, step: 17, Train: label_loss: 0.18472561240196228, precision: 0.2924773022049097, recall: 0.7709401709400391, f1: 0.4240714621133494\n",
            "epoch: 877, step: 18, Train: label_loss: 0.175512433052063, precision: 0.31661237785014223, recall: 0.7941176470586937, f1: 0.452724732143642\n",
            "epoch: 877, step: 19, Train: label_loss: 0.16931451857089996, precision: 0.3196614583333125, recall: 0.7957860615882016, f1: 0.4561077565777391\n",
            "epoch: 877, step: 20, Train: label_loss: 0.16699612140655518, precision: 0.3016393442622753, recall: 0.7491856677523209, f1: 0.4301075268407497\n",
            "epoch: 877, step: 21, Train: label_loss: 0.17322364449501038, precision: 0.30479896238649123, recall: 0.7704918032785621, f1: 0.43680297393703266\n",
            "epoch: 877, step: 22, Train: label_loss: 0.17873021960258484, precision: 0.31745009658723006, recall: 0.7739403453687952, f1: 0.45022831046098927\n",
            "epoch: 877, step: 23, Train: label_loss: 0.1794053167104721, precision: 0.28629359286291267, recall: 0.7278350515462417, f1: 0.4109429568860893\n",
            "epoch: 878, step: 0, Train: label_loss: 0.18532568216323853, precision: 0.3097112860892185, recall: 0.7699836867861712, f1: 0.4417407580311088\n",
            "epoch: 878, step: 1, Train: label_loss: 0.17037782073020935, precision: 0.2961741424801915, recall: 0.7675213675212362, f1: 0.4274155163805291\n",
            "epoch: 878, step: 2, Train: label_loss: 0.1808317005634308, precision: 0.29905913978492615, recall: 0.7466442953018881, f1: 0.4270633396904052\n",
            "epoch: 878, step: 3, Train: label_loss: 0.18859970569610596, precision: 0.31681178834559165, recall: 0.7592295345103115, f1: 0.44706994324763505\n",
            "epoch: 878, step: 4, Train: label_loss: 0.1893525868654251, precision: 0.29581151832458796, recall: 0.7687074829930665, f1: 0.4272211719825111\n",
            "epoch: 878, step: 5, Train: label_loss: 0.20215317606925964, precision: 0.2992843201040794, recall: 0.7823129251699349, f1: 0.4329411764305195\n",
            "epoch: 878, step: 6, Train: label_loss: 0.18288618326187134, precision: 0.2909328114807377, recall: 0.7585034013604152, f1: 0.42055634130830644\n",
            "epoch: 878, step: 7, Train: label_loss: 0.1582568883895874, precision: 0.27498408656904677, recall: 0.7686832740212155, f1: 0.40506329110039097\n",
            "epoch: 878, step: 8, Train: label_loss: 0.166683167219162, precision: 0.31697869593283945, recall: 0.79193548387084, f1: 0.452743199590297\n",
            "epoch: 878, step: 9, Train: label_loss: 0.15235567092895508, precision: 0.29877656149386356, recall: 0.7824620573354498, f1: 0.43243243239239787\n",
            "epoch: 878, step: 10, Train: label_loss: 0.17143559455871582, precision: 0.3005893909626522, recall: 0.7727272727271426, f1: 0.43281471000206695\n",
            "epoch: 878, step: 11, Train: label_loss: 0.15370875597000122, precision: 0.3108280254776872, recall: 0.8052805280526724, f1: 0.4485294117244778\n",
            "epoch: 878, step: 12, Train: label_loss: 0.16603274643421173, precision: 0.30045425048667745, recall: 0.7691029900330948, f1: 0.4321045263244684\n",
            "epoch: 878, step: 13, Train: label_loss: 0.17847010493278503, precision: 0.28028814669284347, recall: 0.7254237288134363, f1: 0.40434577227907664\n",
            "epoch: 878, step: 14, Train: label_loss: 0.17874501645565033, precision: 0.28928800513147596, recall: 0.7605396290049307, f1: 0.41914498137267525\n",
            "epoch: 878, step: 15, Train: label_loss: 0.1708829402923584, precision: 0.31835937499997924, recall: 0.776190476190353, f1: 0.4515235456650775\n",
            "epoch: 878, step: 16, Train: label_loss: 0.18184682726860046, precision: 0.31290743155147893, recall: 0.7643312101909611, f1: 0.44403330245642664\n",
            "epoch: 878, step: 17, Train: label_loss: 0.18207545578479767, precision: 0.29131286740690454, recall: 0.7716262975777212, f1: 0.42294926501469754\n",
            "epoch: 878, step: 18, Train: label_loss: 0.1578565537929535, precision: 0.3118622448979393, recall: 0.8003273322420948, f1: 0.44882973837171897\n",
            "epoch: 878, step: 19, Train: label_loss: 0.1621846854686737, precision: 0.3143227478936932, recall: 0.7847896440128179, f1: 0.448866265576889\n",
            "epoch: 878, step: 20, Train: label_loss: 0.1638924777507782, precision: 0.31262011531067824, recall: 0.8299319727889745, f1: 0.45416472774057065\n",
            "epoch: 878, step: 21, Train: label_loss: 0.17251038551330566, precision: 0.3185613359023559, recall: 0.8091353996736037, f1: 0.4571428571022773\n",
            "epoch: 878, step: 22, Train: label_loss: 0.15447553992271423, precision: 0.3074003795066219, recall: 0.7928221859705068, f1: 0.44302643569351213\n",
            "epoch: 878, step: 23, Train: label_loss: 0.17747095227241516, precision: 0.305511811023598, recall: 0.7775551102202851, f1: 0.438665912904615\n",
            "epoch: 879, step: 0, Train: label_loss: 0.17687706649303436, precision: 0.2992376111816836, recall: 0.7996604414260102, f1: 0.43550624129181253\n",
            "epoch: 879, step: 1, Train: label_loss: 0.16436389088630676, precision: 0.30183893468609374, recall: 0.7933333333332011, f1: 0.4372990353298051\n",
            "epoch: 879, step: 2, Train: label_loss: 0.16095250844955444, precision: 0.30739549839226316, recall: 0.7551342812005125, f1: 0.4369287019698074\n",
            "epoch: 879, step: 3, Train: label_loss: 0.1600218415260315, precision: 0.32190476190474143, recall: 0.8009478672984516, f1: 0.4592391303938416\n",
            "epoch: 879, step: 4, Train: label_loss: 0.1691056340932846, precision: 0.32262210796913093, recall: 0.8044871794870505, f1: 0.46055045867469285\n",
            "epoch: 879, step: 5, Train: label_loss: 0.16393479704856873, precision: 0.2949130714745464, recall: 0.7595356550579171, f1: 0.4248608533919504\n",
            "epoch: 879, step: 6, Train: label_loss: 0.15866541862487793, precision: 0.33543108873503236, recall: 0.8406940063090156, f1: 0.47953216370187457\n",
            "epoch: 879, step: 7, Train: label_loss: 0.16346779465675354, precision: 0.32626846499676776, recall: 0.8063492063490783, f1: 0.46456332871980033\n",
            "epoch: 879, step: 8, Train: label_loss: 0.14648135006427765, precision: 0.3105196451203859, recall: 0.8180300500833358, f1: 0.4501607716642503\n",
            "epoch: 879, step: 9, Train: label_loss: 0.14266356825828552, precision: 0.31673926571248806, recall: 0.8441127694857637, f1: 0.4606334841231735\n",
            "epoch: 879, step: 10, Train: label_loss: 0.14076945185661316, precision: 0.32881773399012754, recall: 0.8449367088606258, f1: 0.4734042552787745\n",
            "epoch: 879, step: 11, Train: label_loss: 0.15805883705615997, precision: 0.2902408111533403, recall: 0.7896551724136569, f1: 0.4244670991265487\n",
            "epoch: 879, step: 12, Train: label_loss: 0.139769047498703, precision: 0.28819875776395726, recall: 0.8212389380529519, f1: 0.42666666662816943\n",
            "epoch: 879, step: 13, Train: label_loss: 0.16635406017303467, precision: 0.3075015499069865, recall: 0.8435374149658429, f1: 0.45070422531291543\n",
            "epoch: 879, step: 14, Train: label_loss: 0.13096562027931213, precision: 0.3228200371057314, recall: 0.8543371522093528, f1: 0.46858168757235996\n",
            "epoch: 879, step: 15, Train: label_loss: 0.1370326578617096, precision: 0.30735386549338106, recall: 0.8260135135133739, f1: 0.4480073293236916\n",
            "epoch: 879, step: 16, Train: label_loss: 0.15910780429840088, precision: 0.2917951881554416, recall: 0.8491921005384471, f1: 0.43434343430532707\n",
            "epoch: 879, step: 17, Train: label_loss: 0.15347522497177124, precision: 0.29663608562689314, recall: 0.8584070796458657, f1: 0.44090909087087826\n",
            "epoch: 879, step: 18, Train: label_loss: 0.12637639045715332, precision: 0.32820197044332955, recall: 0.8652597402595997, f1: 0.47589285710293966\n",
            "epoch: 879, step: 19, Train: label_loss: 0.136187344789505, precision: 0.2969808995686816, recall: 0.860714285714132, f1: 0.441594136471206\n",
            "epoch: 879, step: 20, Train: label_loss: 0.13999280333518982, precision: 0.3259259259259058, recall: 0.831496062991995, f1: 0.4682926828863278\n",
            "epoch: 879, step: 21, Train: label_loss: 0.13486042618751526, precision: 0.2991930477963812, recall: 0.8441330998247207, f1: 0.4417965169182384\n",
            "epoch: 879, step: 22, Train: label_loss: 0.13220924139022827, precision: 0.3075030750307314, recall: 0.8561643835614972, f1: 0.4524886877438798\n",
            "epoch: 879, step: 23, Train: label_loss: 0.14717335999011993, precision: 0.3266717909300287, recall: 0.8252427184464416, f1: 0.46806167396812565\n",
            "epoch: 880, step: 0, Train: label_loss: 0.13522905111312866, precision: 0.31149567367117975, recall: 0.8330578512395317, f1: 0.45344129550690054\n",
            "epoch: 880, step: 1, Train: label_loss: 0.12815600633621216, precision: 0.30192188468690007, recall: 0.8198653198651817, f1: 0.44132306294204166\n",
            "epoch: 880, step: 2, Train: label_loss: 0.13071782886981964, precision: 0.3039755351681771, recall: 0.8688811188809669, f1: 0.4503851381582054\n",
            "epoch: 880, step: 3, Train: label_loss: 0.16058135032653809, precision: 0.2973141786383324, recall: 0.8484848484846972, f1: 0.44033302493840226\n",
            "epoch: 880, step: 4, Train: label_loss: 0.134985089302063, precision: 0.3018867924528118, recall: 0.8581314878891249, f1: 0.446645655071767\n",
            "epoch: 880, step: 5, Train: label_loss: 0.11949184536933899, precision: 0.3115547489413, recall: 0.8626465661640096, f1: 0.4577777777387508\n",
            "epoch: 880, step: 6, Train: label_loss: 0.14095327258110046, precision: 0.318042813455638, recall: 0.8580858085807164, f1: 0.4640785363281934\n",
            "epoch: 880, step: 7, Train: label_loss: 0.12637107074260712, precision: 0.30030769230767385, recall: 0.8327645051193118, f1: 0.44142921750962194\n",
            "epoch: 880, step: 8, Train: label_loss: 0.12163421511650085, precision: 0.32285368802900105, recall: 0.8725490196077005, f1: 0.47131509263484705\n",
            "epoch: 880, step: 9, Train: label_loss: 0.11022412776947021, precision: 0.31147540983604666, recall: 0.8564273789647985, f1: 0.45681211037936725\n",
            "epoch: 880, step: 10, Train: label_loss: 0.13248179852962494, precision: 0.3283950617283748, recall: 0.835164835164704, f1: 0.4714222418734879\n",
            "epoch: 880, step: 11, Train: label_loss: 0.10758648067712784, precision: 0.3183475091129819, recall: 0.8747913188646285, f1: 0.46681514472698044\n",
            "epoch: 880, step: 12, Train: label_loss: 0.13375556468963623, precision: 0.31036585365851765, recall: 0.8511705685617305, f1: 0.45487041997867134\n",
            "epoch: 880, step: 13, Train: label_loss: 0.12132177501916885, precision: 0.3222087378640581, recall: 0.8606158833061813, f1: 0.46887417214574895\n",
            "epoch: 880, step: 14, Train: label_loss: 0.13396969437599182, precision: 0.29889298892987093, recall: 0.8422876949738575, f1: 0.44121652288458324\n",
            "epoch: 880, step: 15, Train: label_loss: 0.10647454857826233, precision: 0.333537331701326, recall: 0.8706070287538544, f1: 0.48230088491565615\n",
            "epoch: 880, step: 16, Train: label_loss: 0.11534705758094788, precision: 0.3206153846153649, recall: 0.8485342019542591, f1: 0.4653863331446102\n",
            "epoch: 880, step: 17, Train: label_loss: 0.1077776849269867, precision: 0.34594594594592515, recall: 0.9070866141730854, f1: 0.5008695651773751\n",
            "epoch: 880, step: 18, Train: label_loss: 0.10022540390491486, precision: 0.3305489260143001, recall: 0.9022801302930126, f1: 0.4838427947205365\n",
            "epoch: 880, step: 19, Train: label_loss: 0.10974450409412384, precision: 0.32890766445381237, recall: 0.9023178807945526, f1: 0.48208757183165585\n",
            "epoch: 880, step: 20, Train: label_loss: 0.1206727921962738, precision: 0.30674087816943063, recall: 0.8449744463371643, f1: 0.45009074406251254\n",
            "epoch: 880, step: 21, Train: label_loss: 0.10880991816520691, precision: 0.31997571341831693, recall: 0.875415282391881, f1: 0.46865273450944156\n",
            "epoch: 880, step: 22, Train: label_loss: 0.12330042570829391, precision: 0.32208588957053236, recall: 0.864909390444668, f1: 0.46937863205697244\n",
            "epoch: 880, step: 23, Train: label_loss: 0.15503104031085968, precision: 0.31060606060603707, recall: 0.833333333333164, f1: 0.4525386313069687\n",
            "epoch: 881, step: 0, Train: label_loss: 0.1444704234600067, precision: 0.3215636822193996, recall: 0.8121019108278961, f1: 0.4607046070053903\n",
            "epoch: 881, step: 1, Train: label_loss: 0.1564023792743683, precision: 0.2962499999999815, recall: 0.8214904679374658, f1: 0.4354616444258607\n",
            "epoch: 881, step: 2, Train: label_loss: 0.1631227433681488, precision: 0.2980588603631623, recall: 0.8150684931505453, f1: 0.43649701967647314\n",
            "epoch: 881, step: 3, Train: label_loss: 0.16233401000499725, precision: 0.30808080808078864, recall: 0.811980033277735, f1: 0.44668192215687524\n",
            "epoch: 881, step: 4, Train: label_loss: 0.14551997184753418, precision: 0.3020257826887476, recall: 0.8381601362860581, f1: 0.444043321260654\n",
            "epoch: 881, step: 5, Train: label_loss: 0.12938839197158813, precision: 0.3203943314848848, recall: 0.8387096774192195, f1: 0.4636647346902287\n",
            "epoch: 881, step: 6, Train: label_loss: 0.1271730661392212, precision: 0.3064615384615196, recall: 0.8586206896550244, f1: 0.45170068023329807\n",
            "epoch: 881, step: 7, Train: label_loss: 0.1455783098936081, precision: 0.3088418430883992, recall: 0.8322147651005315, f1: 0.4504995458278715\n",
            "epoch: 881, step: 8, Train: label_loss: 0.1404493898153305, precision: 0.3258983890953949, recall: 0.8511326860840046, f1: 0.4713261648344661\n",
            "epoch: 881, step: 9, Train: label_loss: 0.12902209162712097, precision: 0.3382807668521745, recall: 0.8573667711597401, f1: 0.4851441241278955\n",
            "epoch: 881, step: 10, Train: label_loss: 0.12998679280281067, precision: 0.3054522924411211, recall: 0.8441780821916363, f1: 0.44858962689451476\n",
            "epoch: 881, step: 11, Train: label_loss: 0.13698217272758484, precision: 0.3006249999999812, recall: 0.8166383701187068, f1: 0.43947007762165774\n",
            "epoch: 881, step: 12, Train: label_loss: 0.1431942731142044, precision: 0.3561988672120606, recall: 0.8360413589363609, f1: 0.499558693691506\n",
            "epoch: 881, step: 13, Train: label_loss: 0.1305503398180008, precision: 0.30080296479306357, recall: 0.84402079722689, f1: 0.4435336975932754\n",
            "epoch: 881, step: 14, Train: label_loss: 0.14322718977928162, precision: 0.3162445954292578, recall: 0.8448844884487055, f1: 0.4602247190614463\n",
            "epoch: 881, step: 15, Train: label_loss: 0.122623011469841, precision: 0.3064118372379589, recall: 0.8438030560270213, f1: 0.44957033012821856\n",
            "epoch: 881, step: 16, Train: label_loss: 0.12292039394378662, precision: 0.29556650246303595, recall: 0.8347826086955069, f1: 0.4365620736311883\n",
            "epoch: 881, step: 17, Train: label_loss: 0.12218044698238373, precision: 0.29613733905577583, recall: 0.8429319371726277, f1: 0.43829401085077413\n",
            "epoch: 881, step: 18, Train: label_loss: 0.12856438755989075, precision: 0.3098159509202264, recall: 0.8487394957981766, f1: 0.4539325842304413\n",
            "epoch: 881, step: 19, Train: label_loss: 0.12784670293331146, precision: 0.30731102850060055, recall: 0.8198347107436661, f1: 0.44704821987918003\n",
            "epoch: 881, step: 20, Train: label_loss: 0.12999065220355988, precision: 0.31675874769795476, recall: 0.843137254901823, f1: 0.4605087014328132\n",
            "epoch: 881, step: 21, Train: label_loss: 0.12572000920772552, precision: 0.33022388059699437, recall: 0.841521394611594, f1: 0.4743188923221398\n",
            "epoch: 881, step: 22, Train: label_loss: 0.14777253568172455, precision: 0.3021943573667522, recall: 0.8183361629879764, f1: 0.4413919413525096\n",
            "epoch: 881, step: 23, Train: label_loss: 0.11011996865272522, precision: 0.31259259259256944, recall: 0.8647540983604786, f1: 0.45919477689239474\n",
            "epoch: 882, step: 0, Train: label_loss: 0.11403422057628632, precision: 0.3017135862912912, recall: 0.8398637137988347, f1: 0.44394416925418256\n",
            "epoch: 882, step: 1, Train: label_loss: 0.11570823937654495, precision: 0.3021276595744497, recall: 0.8827708703373209, f1: 0.4501811593822558\n",
            "epoch: 882, step: 2, Train: label_loss: 0.11933962255716324, precision: 0.304639804639786, recall: 0.8603448275860585, f1: 0.44995491429857687\n",
            "epoch: 882, step: 3, Train: label_loss: 0.13903431594371796, precision: 0.3083176985615817, recall: 0.8162251655627787, f1: 0.44757149337822527\n",
            "epoch: 882, step: 4, Train: label_loss: 0.14727145433425903, precision: 0.29688493324855075, recall: 0.823633156966345, f1: 0.43644859809184977\n",
            "epoch: 882, step: 5, Train: label_loss: 0.16789507865905762, precision: 0.3049414824447136, recall: 0.7552334943638075, f1: 0.434460398291541\n",
            "epoch: 882, step: 6, Train: label_loss: 0.1677514612674713, precision: 0.298132646490644, recall: 0.7615131578946115, f1: 0.42850532156988735\n",
            "epoch: 882, step: 7, Train: label_loss: 0.17056766152381897, precision: 0.30739549839226316, recall: 0.7647999999998776, f1: 0.4385321100508025\n",
            "epoch: 882, step: 8, Train: label_loss: 0.15609581768512726, precision: 0.283311772315635, recall: 0.7711267605632445, f1: 0.414380321625752\n",
            "epoch: 882, step: 9, Train: label_loss: 0.1559118777513504, precision: 0.30114358322742685, recall: 0.7860696517411632, f1: 0.4354616444247668\n",
            "epoch: 882, step: 10, Train: label_loss: 0.15720978379249573, precision: 0.2892405063290956, recall: 0.8003502626968826, f1: 0.4249186424528267\n",
            "epoch: 882, step: 11, Train: label_loss: 0.1271517276763916, precision: 0.30160692212606294, recall: 0.8201680672267528, f1: 0.44103027560456703\n",
            "epoch: 882, step: 12, Train: label_loss: 0.15674196183681488, precision: 0.31183469004381265, recall: 0.8097560975608439, f1: 0.4502712476994157\n",
            "epoch: 882, step: 13, Train: label_loss: 0.1432519108057022, precision: 0.32043147208119793, recall: 0.8145161290321267, f1: 0.45992714021444314\n",
            "epoch: 882, step: 14, Train: label_loss: 0.14130127429962158, precision: 0.31158961367952426, recall: 0.7935483870966461, f1: 0.4474761254710649\n",
            "epoch: 882, step: 15, Train: label_loss: 0.13020190596580505, precision: 0.29943855271364317, recall: 0.8135593220337604, f1: 0.4377564979086452\n",
            "epoch: 882, step: 16, Train: label_loss: 0.1496254801750183, precision: 0.32681388012616236, recall: 0.8068535825543914, f1: 0.46519982034509294\n",
            "epoch: 882, step: 17, Train: label_loss: 0.1286620944738388, precision: 0.3172413793103249, recall: 0.8019017432645321, f1: 0.4546271338317531\n",
            "epoch: 882, step: 18, Train: label_loss: 0.14424844086170197, precision: 0.32194813409232625, recall: 0.8157051282049974, f1: 0.4616780044945239\n",
            "epoch: 882, step: 19, Train: label_loss: 0.12929311394691467, precision: 0.3343672456575475, recall: 0.8693548387095371, f1: 0.4829749103540985\n",
            "epoch: 882, step: 20, Train: label_loss: 0.14568018913269043, precision: 0.3249999999999797, recall: 0.8360128617361999, f1: 0.4680468046401122\n",
            "epoch: 882, step: 21, Train: label_loss: 0.1523718237876892, precision: 0.3153210425937498, recall: 0.81444991789806, f1: 0.45462878089463965\n",
            "epoch: 882, step: 22, Train: label_loss: 0.1539023518562317, precision: 0.2783699059560954, recall: 0.8131868131866642, f1: 0.41475945815906834\n",
            "epoch: 882, step: 23, Train: label_loss: 0.1435733139514923, precision: 0.3066361556063839, recall: 0.8237704918031099, f1: 0.44691495271194315\n",
            "epoch: 883, step: 0, Train: label_loss: 0.13119575381278992, precision: 0.3036944270507011, recall: 0.8164983164981789, f1: 0.44272021903848435\n",
            "epoch: 883, step: 1, Train: label_loss: 0.12921570241451263, precision: 0.3064014916096764, recall: 0.8285714285712893, f1: 0.44736842101317426\n",
            "epoch: 883, step: 2, Train: label_loss: 0.1374150812625885, precision: 0.32061068702288037, recall: 0.7789799072641763, f1: 0.45425867503751177\n",
            "epoch: 883, step: 3, Train: label_loss: 0.13809508085250854, precision: 0.30706179066832867, recall: 0.8268251273343248, f1: 0.4478160919144879\n",
            "epoch: 883, step: 4, Train: label_loss: 0.1308341920375824, precision: 0.3197492163009204, recall: 0.8429752066114309, f1: 0.4636363635964465\n",
            "epoch: 883, step: 5, Train: label_loss: 0.11082182079553604, precision: 0.29840686274507977, recall: 0.8543859649121307, f1: 0.4423251589080023\n",
            "epoch: 883, step: 6, Train: label_loss: 0.1259065568447113, precision: 0.32188841201714763, recall: 0.8440514469452018, f1: 0.4660452729293611\n",
            "epoch: 883, step: 7, Train: label_loss: 0.1385432928800583, precision: 0.30532392559330945, recall: 0.7986577181206713, f1: 0.44176334102722886\n",
            "epoch: 883, step: 8, Train: label_loss: 0.12074555456638336, precision: 0.3055555555555367, recall: 0.8305369127515384, f1: 0.44675090248771204\n",
            "epoch: 883, step: 9, Train: label_loss: 0.12774431705474854, precision: 0.30854333128455386, recall: 0.8479729729728297, f1: 0.4524560612497058\n",
            "epoch: 883, step: 10, Train: label_loss: 0.13849641382694244, precision: 0.30055316533495385, recall: 0.8431034482757166, f1: 0.44313547798568015\n",
            "epoch: 883, step: 11, Train: label_loss: 0.12065118551254272, precision: 0.3096259963212563, recall: 0.8632478632477156, f1: 0.4557761732462976\n",
            "epoch: 883, step: 12, Train: label_loss: 0.10793748497962952, precision: 0.3186746987951615, recall: 0.8772802653398213, f1: 0.46752098979736695\n",
            "epoch: 883, step: 13, Train: label_loss: 0.11146645247936249, precision: 0.3142509135200783, recall: 0.8557213930346839, f1: 0.45968819595175986\n",
            "epoch: 883, step: 14, Train: label_loss: 0.11714984476566315, precision: 0.3145654834761129, recall: 0.859531772575107, f1: 0.46057347666323983\n",
            "epoch: 883, step: 15, Train: label_loss: 0.12070606648921967, precision: 0.3073619631901652, recall: 0.8520408163263856, f1: 0.45175834080860494\n",
            "epoch: 883, step: 16, Train: label_loss: 0.1156250536441803, precision: 0.3182093163944151, recall: 0.865131578947226, f1: 0.46528084914241746\n",
            "epoch: 883, step: 17, Train: label_loss: 0.12772980332374573, precision: 0.3124616329036027, recall: 0.8316993464050928, f1: 0.45426149036632557\n",
            "epoch: 883, step: 18, Train: label_loss: 0.11294738203287125, precision: 0.3225015328019422, recall: 0.8470209339773193, f1: 0.4671403196758238\n",
            "epoch: 883, step: 19, Train: label_loss: 0.11733859032392502, precision: 0.3155368926214568, recall: 0.8795986622072107, f1: 0.4644591611089994\n",
            "epoch: 883, step: 20, Train: label_loss: 0.16393673419952393, precision: 0.31327543424315674, recall: 0.8430717863103767, f1: 0.4568068746777768\n",
            "epoch: 883, step: 21, Train: label_loss: 0.13841040432453156, precision: 0.3070669168229952, recall: 0.8293918918917518, f1: 0.4481971702024198\n",
            "epoch: 883, step: 22, Train: label_loss: 0.11215092241764069, precision: 0.32575291948369234, recall: 0.8452950558212368, f1: 0.47027506650815837\n",
            "epoch: 883, step: 23, Train: label_loss: 0.12276681512594223, precision: 0.33283132530117976, recall: 0.8857715430859948, f1: 0.48385331139975973\n",
            "epoch: 884, step: 0, Train: label_loss: 0.09661456942558289, precision: 0.31219806763283137, recall: 0.8837606837605326, f1: 0.46140116015771965\n",
            "epoch: 884, step: 1, Train: label_loss: 0.11485186964273453, precision: 0.3237804878048583, recall: 0.8835274542427813, f1: 0.4738955822900227\n",
            "epoch: 884, step: 2, Train: label_loss: 0.11993681639432907, precision: 0.31756756756754806, recall: 0.8545454545453133, f1: 0.46305418715257085\n",
            "epoch: 884, step: 3, Train: label_loss: 0.10421153157949448, precision: 0.3276595744680652, recall: 0.8850574712642224, f1: 0.4782608695257379\n",
            "epoch: 884, step: 4, Train: label_loss: 0.11022202670574188, precision: 0.30175015087505724, recall: 0.869565217391153, f1: 0.44802867379683525\n",
            "epoch: 884, step: 5, Train: label_loss: 0.10697557032108307, precision: 0.32548309178741996, recall: 0.8953488372091535, f1: 0.47741364035057754\n",
            "epoch: 884, step: 6, Train: label_loss: 0.11545360833406448, precision: 0.3097893432465731, recall: 0.8264462809915989, f1: 0.45065344745917074\n",
            "epoch: 884, step: 7, Train: label_loss: 0.11869771778583527, precision: 0.30055316533495385, recall: 0.8387650085761854, f1: 0.44253393661270163\n",
            "epoch: 884, step: 8, Train: label_loss: 0.11500857770442963, precision: 0.3213175885643057, recall: 0.8180379746834148, f1: 0.46140116015580296\n",
            "epoch: 884, step: 9, Train: label_loss: 0.11666420847177505, precision: 0.32684114424830635, recall: 0.8731707317071751, f1: 0.4756421611649273\n",
            "epoch: 884, step: 10, Train: label_loss: 0.11365175247192383, precision: 0.3299031476997379, recall: 0.8706070287538544, f1: 0.4784899033841569\n",
            "epoch: 884, step: 11, Train: label_loss: 0.12083432078361511, precision: 0.3168927250308066, recall: 0.838499184339178, f1: 0.4599552572308429\n",
            "epoch: 884, step: 12, Train: label_loss: 0.11699964106082916, precision: 0.31292517006800785, recall: 0.8363636363634981, f1: 0.45544554451478597\n",
            "epoch: 884, step: 13, Train: label_loss: 0.11787772178649902, precision: 0.3210558624923069, recall: 0.8394863563401541, f1: 0.4644760212743236\n",
            "epoch: 884, step: 14, Train: label_loss: 0.11801455169916153, precision: 0.31520395550059854, recall: 0.8360655737703547, f1: 0.45780969475373\n",
            "epoch: 884, step: 15, Train: label_loss: 0.10966772586107254, precision: 0.30479659987854857, recall: 0.8670120898098674, f1: 0.45103324344754275\n",
            "epoch: 884, step: 16, Train: label_loss: 0.11043805629014969, precision: 0.3201460742543932, recall: 0.8580750407828942, f1: 0.46631205669796966\n",
            "epoch: 884, step: 17, Train: label_loss: 0.10917726904153824, precision: 0.32024539877298647, recall: 0.8446601941746206, f1: 0.464412811347992\n",
            "epoch: 884, step: 18, Train: label_loss: 0.12142955511808395, precision: 0.3007290400971871, recall: 0.8776595744679294, f1: 0.4479638008669219\n",
            "epoch: 884, step: 19, Train: label_loss: 0.100547194480896, precision: 0.31144578313251137, recall: 0.8913793103446739, f1: 0.46160714281872467\n",
            "epoch: 884, step: 20, Train: label_loss: 0.11792746931314468, precision: 0.3305439330543735, recall: 0.9125412541252619, f1: 0.4853005703865427\n",
            "epoch: 884, step: 21, Train: label_loss: 0.11627690494060516, precision: 0.3312845728334154, recall: 0.8749999999998579, f1: 0.48060633076707016\n",
            "epoch: 884, step: 22, Train: label_loss: 0.10818055272102356, precision: 0.31348724179827986, recall: 0.8599999999998567, f1: 0.45948352622972616\n",
            "epoch: 884, step: 23, Train: label_loss: 0.08952443301677704, precision: 0.3064046579330199, recall: 0.9273127753301923, f1: 0.46061269142869743\n",
            "epoch: 885, step: 0, Train: label_loss: 0.09061907231807709, precision: 0.34978928356409694, recall: 0.8938461538460163, f1: 0.5028126351823728\n",
            "epoch: 885, step: 1, Train: label_loss: 0.09991400688886642, precision: 0.3325257419745407, recall: 0.8783999999998594, f1: 0.4824253075172359\n",
            "epoch: 885, step: 2, Train: label_loss: 0.1077004075050354, precision: 0.3204182041820221, recall: 0.8756302521006931, f1: 0.4691580368810383\n",
            "epoch: 885, step: 3, Train: label_loss: 0.09918871521949768, precision: 0.3234761617380613, recall: 0.880131362889839, f1: 0.4730803177011649\n",
            "epoch: 885, step: 4, Train: label_loss: 0.10857866704463959, precision: 0.2975903614457652, recall: 0.8727915194344747, f1: 0.44384546267542413\n",
            "epoch: 885, step: 5, Train: label_loss: 0.09638875722885132, precision: 0.3333333333333132, recall: 0.9155629139071331, f1: 0.4887317719449155\n",
            "epoch: 885, step: 6, Train: label_loss: 0.10884438455104828, precision: 0.300543150271557, recall: 0.8861209964411234, f1: 0.44885083367101275\n",
            "epoch: 885, step: 7, Train: label_loss: 0.08938305824995041, precision: 0.33413461538459527, recall: 0.8910256410254982, f1: 0.48601398597427403\n",
            "epoch: 885, step: 8, Train: label_loss: 0.08925985544919968, precision: 0.3365269461077643, recall: 0.9123376623375141, f1: 0.49168853889321956\n",
            "epoch: 885, step: 9, Train: label_loss: 0.09368084371089935, precision: 0.3283223090799562, recall: 0.88206785137304, f1: 0.47852760732238625\n",
            "epoch: 885, step: 10, Train: label_loss: 0.08367710560560226, precision: 0.3208999407933498, recall: 0.9124579124577588, f1: 0.4748138413981668\n",
            "epoch: 885, step: 11, Train: label_loss: 0.09535308182239532, precision: 0.305125148986871, recall: 0.8982456140349301, f1: 0.4555160141969815\n",
            "epoch: 885, step: 12, Train: label_loss: 0.10968311131000519, precision: 0.30885009030702537, recall: 0.8709677419353359, f1: 0.4559999999613094\n",
            "epoch: 885, step: 13, Train: label_loss: 0.10140636563301086, precision: 0.32002419842708285, recall: 0.8816666666665196, f1: 0.4695960940576402\n",
            "epoch: 885, step: 14, Train: label_loss: 0.10696303844451904, precision: 0.3096385542168488, recall: 0.8711864406778184, f1: 0.45688888885015594\n",
            "epoch: 885, step: 15, Train: label_loss: 0.10251589119434357, precision: 0.3264058679706402, recall: 0.8516746411481895, f1: 0.47193990274381326\n",
            "epoch: 885, step: 16, Train: label_loss: 0.10350470244884491, precision: 0.3233353329333939, recall: 0.880718954248222, f1: 0.4730144799957764\n",
            "epoch: 885, step: 17, Train: label_loss: 0.09407320618629456, precision: 0.3010234798314087, recall: 0.8665511265163143, f1: 0.4468275245372041\n",
            "epoch: 885, step: 18, Train: label_loss: 0.09691006690263748, precision: 0.31512605042014913, recall: 0.883838383838235, f1: 0.46460176987271307\n",
            "epoch: 885, step: 19, Train: label_loss: 0.09837941825389862, precision: 0.3184019370459856, recall: 0.8855218855217364, f1: 0.4683882457313113\n",
            "epoch: 885, step: 20, Train: label_loss: 0.10392960160970688, precision: 0.32726168791740573, recall: 0.8610223642171148, f1: 0.47426308838943504\n",
            "epoch: 885, step: 21, Train: label_loss: 0.09662756323814392, precision: 0.3242442205097614, recall: 0.9041322314048091, f1: 0.4773123908860575\n",
            "epoch: 885, step: 22, Train: label_loss: 0.11296730488538742, precision: 0.31291291291289414, recall: 0.9060869565215814, f1: 0.4651785713903692\n",
            "epoch: 885, step: 23, Train: label_loss: 0.10693439096212387, precision: 0.3205033308660014, recall: 0.8729838709675659, f1: 0.4688684352611509\n",
            "epoch: 886, step: 0, Train: label_loss: 0.08456755429506302, precision: 0.30586840545344957, recall: 0.8911917098444055, f1: 0.4554280670404668\n",
            "epoch: 886, step: 1, Train: label_loss: 0.10784915089607239, precision: 0.304639804639786, recall: 0.850085178875494, f1: 0.44853932580381245\n",
            "epoch: 886, step: 2, Train: label_loss: 0.10459795594215393, precision: 0.31455961653682957, recall: 0.894378194207684, f1: 0.46542553187635366\n",
            "epoch: 886, step: 3, Train: label_loss: 0.099138043820858, precision: 0.3002406738868652, recall: 0.8847517730494885, f1: 0.44833782565844127\n",
            "epoch: 886, step: 4, Train: label_loss: 0.08331046998500824, precision: 0.3121661721068064, recall: 0.9084628670119328, f1: 0.46466431091595495\n",
            "epoch: 886, step: 5, Train: label_loss: 0.105364590883255, precision: 0.3317249698431645, recall: 0.8914100486222217, f1: 0.4835164834769101\n",
            "epoch: 886, step: 6, Train: label_loss: 0.09243124723434448, precision: 0.30906921241048274, recall: 0.886986301369711, f1: 0.45840707960765054\n",
            "epoch: 886, step: 7, Train: label_loss: 0.08427707850933075, precision: 0.31519138755978976, recall: 0.8887015177064268, f1: 0.46534216331671413\n",
            "epoch: 886, step: 8, Train: label_loss: 0.08848309516906738, precision: 0.33254297569648295, recall: 0.9107142857141378, f1: 0.4871906208899938\n",
            "epoch: 886, step: 9, Train: label_loss: 0.09437992423772812, precision: 0.3319226118500404, recall: 0.8840579710143504, f1: 0.48263736259762896\n",
            "epoch: 886, step: 10, Train: label_loss: 0.09121891856193542, precision: 0.3246831623415616, recall: 0.8607999999998622, f1: 0.47151621380768666\n",
            "epoch: 886, step: 11, Train: label_loss: 0.10244107246398926, precision: 0.3135233474833042, recall: 0.8733108108106632, f1: 0.461401160157423\n",
            "epoch: 886, step: 12, Train: label_loss: 0.09465532004833221, precision: 0.32035928143710657, recall: 0.8887043189367294, f1: 0.470950704186359\n",
            "epoch: 886, step: 13, Train: label_loss: 0.09659841656684875, precision: 0.3070439494280369, recall: 0.8703071672353463, f1: 0.45393858474110993\n",
            "epoch: 886, step: 14, Train: label_loss: 0.0920332670211792, precision: 0.3199999999999809, recall: 0.9084745762710323, f1: 0.4732891831843897\n",
            "epoch: 886, step: 15, Train: label_loss: 0.09826932102441788, precision: 0.32776119402983117, recall: 0.9014778325121672, f1: 0.48073555162459736\n",
            "epoch: 886, step: 16, Train: label_loss: 0.09988032281398773, precision: 0.32809667673714027, recall: 0.8715890850720912, f1: 0.47673397713317867\n",
            "epoch: 886, step: 17, Train: label_loss: 0.08751818537712097, precision: 0.32720806164787625, recall: 0.8817891373800508, f1: 0.47730220488914354\n",
            "epoch: 886, step: 18, Train: label_loss: 0.0867266058921814, precision: 0.33055390113160626, recall: 0.8995137763369693, f1: 0.48344947731257165\n",
            "epoch: 886, step: 19, Train: label_loss: 0.09829365462064743, precision: 0.33777239709441054, recall: 0.8732394366195816, f1: 0.4871235268039058\n",
            "epoch: 886, step: 20, Train: label_loss: 0.10552345961332321, precision: 0.31674757281551474, recall: 0.8773109243696003, f1: 0.46544806059405874\n",
            "epoch: 886, step: 21, Train: label_loss: 0.09280940890312195, precision: 0.3271420011983027, recall: 0.9069767441858958, f1: 0.4808454424973226\n",
            "epoch: 886, step: 22, Train: label_loss: 0.0888943076133728, precision: 0.3333333333333138, recall: 0.9235772357722075, f1: 0.4898663216513677\n",
            "epoch: 886, step: 23, Train: label_loss: 0.09240628778934479, precision: 0.30351906158355546, recall: 0.8789808917195586, f1: 0.45122615799993926\n",
            "epoch: 887, step: 0, Train: label_loss: 0.0741213709115982, precision: 0.31591309453903016, recall: 0.9259896729774654, f1: 0.47110332745764644\n",
            "epoch: 887, step: 1, Train: label_loss: 0.08969959616661072, precision: 0.29660512209646833, recall: 0.9005424954790414, f1: 0.44623655910246995\n",
            "epoch: 887, step: 2, Train: label_loss: 0.07721510529518127, precision: 0.31815493790654537, recall: 0.9042016806721169, f1: 0.47069116356600144\n",
            "epoch: 887, step: 3, Train: label_loss: 0.09914809465408325, precision: 0.3307086614173028, recall: 0.8907014681890879, f1: 0.48233215543749947\n",
            "epoch: 887, step: 4, Train: label_loss: 0.10151715576648712, precision: 0.30308529945551704, recall: 0.859348198970693, f1: 0.448121645757474\n",
            "epoch: 887, step: 5, Train: label_loss: 0.09293903410434723, precision: 0.30727600721585646, recall: 0.8675721561967966, f1: 0.45381882767003523\n",
            "epoch: 887, step: 6, Train: label_loss: 0.09352939575910568, precision: 0.32337118947995674, recall: 0.8971807628522558, f1: 0.4753954305409738\n",
            "epoch: 887, step: 7, Train: label_loss: 0.10314423590898514, precision: 0.3247298919567632, recall: 0.8768233387356763, f1: 0.4739378010993671\n",
            "epoch: 887, step: 8, Train: label_loss: 0.09556055068969727, precision: 0.3149038461538272, recall: 0.8762541806018601, f1: 0.46330680809545777\n",
            "epoch: 887, step: 9, Train: label_loss: 0.08523394167423248, precision: 0.33690476190474183, recall: 0.9188311688310196, f1: 0.4930313588457121\n",
            "epoch: 887, step: 10, Train: label_loss: 0.10225582867860794, precision: 0.3042424242424058, recall: 0.8522920203733697, f1: 0.4484144707070563\n",
            "epoch: 887, step: 11, Train: label_loss: 0.08737356960773468, precision: 0.32761679479595934, recall: 0.9157024793386915, f1: 0.4825783971736878\n",
            "epoch: 887, step: 12, Train: label_loss: 0.08643557131290436, precision: 0.3305687203791273, recall: 0.9147540983605057, f1: 0.4856396866450337\n",
            "epoch: 887, step: 13, Train: label_loss: 0.10159054398536682, precision: 0.3110976349302419, recall: 0.8665540540539076, f1: 0.4578313252622873\n",
            "epoch: 887, step: 14, Train: label_loss: 0.08739984035491943, precision: 0.3305338932213359, recall: 0.891585760517655, f1: 0.48227571112023304\n",
            "epoch: 887, step: 15, Train: label_loss: 0.10239963233470917, precision: 0.33888228299641265, recall: 0.9105431309902698, f1: 0.493934142074809\n",
            "epoch: 887, step: 16, Train: label_loss: 0.07462232559919357, precision: 0.320597014925354, recall: 0.9070945945944413, f1: 0.47375385968788003\n",
            "epoch: 887, step: 17, Train: label_loss: 0.09987078607082367, precision: 0.2978339350180326, recall: 0.8807829181493094, f1: 0.44514388485427797\n",
            "epoch: 887, step: 18, Train: label_loss: 0.08903458714485168, precision: 0.31904761904760004, recall: 0.9054054054052524, f1: 0.47183098587691735\n",
            "epoch: 887, step: 19, Train: label_loss: 0.09591326117515564, precision: 0.325257419745589, recall: 0.8689320388348107, f1: 0.4733362714455574\n",
            "epoch: 887, step: 20, Train: label_loss: 0.09888479113578796, precision: 0.3134777376654444, recall: 0.8800675675674189, f1: 0.4622892634927261\n",
            "epoch: 887, step: 21, Train: label_loss: 0.08848679065704346, precision: 0.32953181272507026, recall: 0.8897893030792723, f1: 0.4809461234821961\n",
            "epoch: 887, step: 22, Train: label_loss: 0.09423208236694336, precision: 0.3335369578497047, recall: 0.8611987381702111, f1: 0.48084544249603817\n",
            "epoch: 887, step: 23, Train: label_loss: 0.07863795757293701, precision: 0.3470715835140747, recall: 0.9160305343509701, f1: 0.5034084949784458\n",
            "epoch: 888, step: 0, Train: label_loss: 0.08742564171552658, precision: 0.32758620689653223, recall: 0.9018003273320946, f1: 0.48059310942445077\n",
            "epoch: 888, step: 1, Train: label_loss: 0.11536010354757309, precision: 0.31696969696967775, recall: 0.8731218697828258, f1: 0.4650955980044529\n",
            "epoch: 888, step: 2, Train: label_loss: 0.09484978020191193, precision: 0.310262529832917, recall: 0.8858603066438013, f1: 0.4595669464926913\n",
            "epoch: 888, step: 3, Train: label_loss: 0.10244406759738922, precision: 0.30152905198774915, recall: 0.851468048359093, f1: 0.445347786772536\n",
            "epoch: 888, step: 4, Train: label_loss: 0.07520931959152222, precision: 0.33195266272187385, recall: 0.9121951219510711, f1: 0.48676789583935814\n",
            "epoch: 888, step: 5, Train: label_loss: 0.09409531950950623, precision: 0.3226761397276304, recall: 0.917508417508263, f1: 0.4774419622917277\n",
            "epoch: 888, step: 6, Train: label_loss: 0.08799499273300171, precision: 0.33333333333331333, recall: 0.8867623604464295, f1: 0.4845315903741885\n",
            "epoch: 888, step: 7, Train: label_loss: 0.10372508317232132, precision: 0.3134418324291553, recall: 0.8710217755442426, f1: 0.4609929077624576\n",
            "epoch: 888, step: 8, Train: label_loss: 0.09690285474061966, precision: 0.3198795180722699, recall: 0.880597014925227, f1: 0.4692885549763329\n",
            "epoch: 888, step: 9, Train: label_loss: 0.08724647760391235, precision: 0.31955109273477145, recall: 0.9046822742473403, f1: 0.47228284588019365\n",
            "epoch: 888, step: 10, Train: label_loss: 0.077979676425457, precision: 0.32900943396224475, recall: 0.9117647058822039, f1: 0.48353552855717474\n",
            "epoch: 888, step: 11, Train: label_loss: 0.09728425741195679, precision: 0.33492537313430837, recall: 0.9077669902911152, f1: 0.48931530741806123\n",
            "epoch: 888, step: 12, Train: label_loss: 0.0974157378077507, precision: 0.33413461538459527, recall: 0.8953301127212728, f1: 0.48665207873499194\n",
            "epoch: 888, step: 13, Train: label_loss: 0.08583419024944305, precision: 0.3333333333333134, recall: 0.8983870967740486, f1: 0.4862505455737495\n",
            "epoch: 888, step: 14, Train: label_loss: 0.07625232636928558, precision: 0.33683596030354135, recall: 0.9474548440064124, f1: 0.4969853574117337\n",
            "epoch: 888, step: 15, Train: label_loss: 0.09841087460517883, precision: 0.307968843618915, recall: 0.8986013986012414, f1: 0.45872378398692903\n",
            "epoch: 888, step: 16, Train: label_loss: 0.08414433151483536, precision: 0.3225426721600752, recall: 0.9194630872481678, f1: 0.47755991281553817\n",
            "epoch: 888, step: 17, Train: label_loss: 0.08272245526313782, precision: 0.3220439691027735, recall: 0.9003322259134716, f1: 0.4743982494141031\n",
            "epoch: 888, step: 18, Train: label_loss: 0.07925739884376526, precision: 0.33432304038002764, recall: 0.9022435897434451, f1: 0.48786828418927375\n",
            "epoch: 888, step: 19, Train: label_loss: 0.0873589962720871, precision: 0.2982561635598137, recall: 0.8841354723706089, f1: 0.446043165429862\n",
            "epoch: 888, step: 20, Train: label_loss: 0.07941840589046478, precision: 0.3201650943396038, recall: 0.9250425894376617, f1: 0.4756898816963165\n",
            "epoch: 888, step: 21, Train: label_loss: 0.08785881102085114, precision: 0.3319402985074429, recall: 0.90553745928324, f1: 0.4858016600742869\n",
            "epoch: 888, step: 22, Train: label_loss: 0.08871302753686905, precision: 0.3164179104477423, recall: 0.895270270270119, f1: 0.467578297270589\n",
            "epoch: 888, step: 23, Train: label_loss: 0.08017915487289429, precision: 0.31376811594200626, recall: 0.9002079002077131, f1: 0.4653412143624777\n",
            "epoch: 889, step: 0, Train: label_loss: 0.0807383805513382, precision: 0.3238265002970693, recall: 0.9098497495824858, f1: 0.47765118313389593\n",
            "epoch: 889, step: 1, Train: label_loss: 0.08634034544229507, precision: 0.33095662507425244, recall: 0.8954983922828141, f1: 0.48329718000393596\n",
            "epoch: 889, step: 2, Train: label_loss: 0.08297792077064514, precision: 0.3194527067221702, recall: 0.8994974874370352, f1: 0.4714661983809469\n",
            "epoch: 889, step: 3, Train: label_loss: 0.09042000025510788, precision: 0.3085169743894992, recall: 0.8779661016947664, f1: 0.4565888056027289\n",
            "epoch: 889, step: 4, Train: label_loss: 0.0872659757733345, precision: 0.3242603550295666, recall: 0.8925081433223302, f1: 0.47569444440530834\n",
            "epoch: 889, step: 5, Train: label_loss: 0.07940574735403061, precision: 0.2997616209773361, recall: 0.8855633802815341, f1: 0.44790739087935844\n",
            "epoch: 889, step: 6, Train: label_loss: 0.09078037738800049, precision: 0.29721549636802075, recall: 0.8614035087717786, f1: 0.44194419438125815\n",
            "epoch: 889, step: 7, Train: label_loss: 0.08512993156909943, precision: 0.32516437537356097, recall: 0.8976897689767495, f1: 0.4774023694212077\n",
            "epoch: 889, step: 8, Train: label_loss: 0.08214229345321655, precision: 0.34474616292796073, recall: 0.9182389937105474, f1: 0.5012875536083349\n",
            "epoch: 889, step: 9, Train: label_loss: 0.08382920920848846, precision: 0.32897085068409704, recall: 0.8933764135701302, f1: 0.4808695651780096\n",
            "epoch: 889, step: 10, Train: label_loss: 0.09223964810371399, precision: 0.30579010856451716, recall: 0.8863636363634814, f1: 0.4547085201411897\n",
            "epoch: 889, step: 11, Train: label_loss: 0.07662549614906311, precision: 0.3099345627602433, recall: 0.9013840830448266, f1: 0.4612660468852969\n",
            "epoch: 889, step: 12, Train: label_loss: 0.0849800705909729, precision: 0.3220035778175121, recall: 0.8940397350991897, f1: 0.4734765453358582\n",
            "epoch: 889, step: 13, Train: label_loss: 0.08314386755228043, precision: 0.3363255535607219, recall: 0.8949044585985836, f1: 0.4889082209258857\n",
            "epoch: 889, step: 14, Train: label_loss: 0.10423526167869568, precision: 0.31326034063258434, recall: 0.8894645941276529, f1: 0.4633378317203188\n",
            "epoch: 889, step: 15, Train: label_loss: 0.09120123088359833, precision: 0.3123877917414535, recall: 0.8984509466435631, f1: 0.46358792180891917\n",
            "epoch: 889, step: 16, Train: label_loss: 0.07971970736980438, precision: 0.3417796110783535, recall: 0.926517571884836, f1: 0.4993542832149973\n",
            "epoch: 889, step: 17, Train: label_loss: 0.09062955528497696, precision: 0.3276370064820078, recall: 0.9144736842103759, f1: 0.4824295010457173\n",
            "epoch: 889, step: 18, Train: label_loss: 0.1038040816783905, precision: 0.324275362318821, recall: 0.874592833876079, f1: 0.47312775326445855\n",
            "epoch: 889, step: 19, Train: label_loss: 0.08893625438213348, precision: 0.334525939177082, recall: 0.9077669902911152, f1: 0.4888888888494925\n",
            "epoch: 889, step: 20, Train: label_loss: 0.09957760572433472, precision: 0.3303464755077461, recall: 0.8876404494380598, f1: 0.48149760553291165\n",
            "epoch: 889, step: 21, Train: label_loss: 0.10687470436096191, precision: 0.32793764988007623, recall: 0.8894308943087984, f1: 0.47919404288656947\n",
            "epoch: 889, step: 22, Train: label_loss: 0.09801710397005081, precision: 0.32035928143710657, recall: 0.8931552587644586, f1: 0.471573380304862\n",
            "epoch: 889, step: 23, Train: label_loss: 0.07950607687234879, precision: 0.29733621310293035, recall: 0.9116997792492469, f1: 0.44842562428425153\n",
            "epoch: 890, step: 0, Train: label_loss: 0.08393989503383636, precision: 0.332144979203783, recall: 0.9089430894307464, f1: 0.4865100086639776\n",
            "epoch: 890, step: 1, Train: label_loss: 0.08584287762641907, precision: 0.3391148325358649, recall: 0.8929133858266309, f1: 0.49154746419933176\n",
            "epoch: 890, step: 2, Train: label_loss: 0.09092531353235245, precision: 0.3283403235470145, recall: 0.8698412698411317, f1: 0.47672901257435096\n",
            "epoch: 890, step: 3, Train: label_loss: 0.11106216907501221, precision: 0.32340425531912925, recall: 0.8764415156505969, f1: 0.47246891647923067\n",
            "epoch: 890, step: 4, Train: label_loss: 0.13252678513526917, precision: 0.30207677784768394, recall: 0.7986688851912148, f1: 0.438356164343698\n",
            "epoch: 890, step: 5, Train: label_loss: 0.11745820939540863, precision: 0.29556650246303595, recall: 0.8135593220337604, f1: 0.433604336004227\n",
            "epoch: 890, step: 6, Train: label_loss: 0.12158551812171936, precision: 0.3041044776119214, recall: 0.8232323232321845, f1: 0.4441416893338592\n",
            "epoch: 890, step: 7, Train: label_loss: 0.10316532850265503, precision: 0.3110976349302419, recall: 0.8578595317724317, f1: 0.4566088117098968\n",
            "epoch: 890, step: 8, Train: label_loss: 0.10825927555561066, precision: 0.2933657942787405, recall: 0.863799283153967, f1: 0.43798273508251034\n",
            "epoch: 890, step: 9, Train: label_loss: 0.09964542090892792, precision: 0.32815301852956796, recall: 0.888349514562963, f1: 0.4792666957266021\n",
            "epoch: 890, step: 10, Train: label_loss: 0.1036939024925232, precision: 0.3235653235653038, recall: 0.8548387096772814, f1: 0.4694419840168087\n",
            "epoch: 890, step: 11, Train: label_loss: 0.11450698971748352, precision: 0.3258084197681314, recall: 0.8640776699027728, f1: 0.4731945059415812\n",
            "epoch: 890, step: 12, Train: label_loss: 0.10723021626472473, precision: 0.32725060827248614, recall: 0.8805237315874171, f1: 0.4771618624881663\n",
            "epoch: 890, step: 13, Train: label_loss: 0.11480440944433212, precision: 0.29839704069048717, recall: 0.8461538461536982, f1: 0.4412032816387133\n",
            "epoch: 890, step: 14, Train: label_loss: 0.10907210409641266, precision: 0.32549504950493036, recall: 0.8525121555914339, f1: 0.47111509176471217\n",
            "epoch: 890, step: 15, Train: label_loss: 0.1022135391831398, precision: 0.30324909747290596, recall: 0.8644939965693199, f1: 0.4489977727900178\n",
            "epoch: 890, step: 16, Train: label_loss: 0.09238699078559875, precision: 0.33313253012046184, recall: 0.8962722852510703, f1: 0.48572683351336865\n",
            "epoch: 890, step: 17, Train: label_loss: 0.09132830798625946, precision: 0.32917409387995666, recall: 0.9279731993298277, f1: 0.485964912242003\n",
            "epoch: 890, step: 18, Train: label_loss: 0.10552441328763962, precision: 0.3192261185005853, recall: 0.8727272727271284, f1: 0.46746347937641103\n",
            "epoch: 890, step: 19, Train: label_loss: 0.10678933560848236, precision: 0.31268973891922813, recall: 0.8569051580697409, f1: 0.4581850533415675\n",
            "epoch: 890, step: 20, Train: label_loss: 0.10914814472198486, precision: 0.30072463768114127, recall: 0.8601036269428566, f1: 0.445637583854188\n",
            "epoch: 890, step: 21, Train: label_loss: 0.08113689720630646, precision: 0.3240685984624291, recall: 0.913333333333181, f1: 0.47839371449643453\n",
            "epoch: 890, step: 22, Train: label_loss: 0.08565432578325272, precision: 0.298140371925597, recall: 0.8874999999998414, f1: 0.4463403681706664\n",
            "epoch: 890, step: 23, Train: label_loss: 0.09241150319576263, precision: 0.3223924142961107, recall: 0.8965517241377492, f1: 0.4742489269996692\n",
            "epoch: 891, step: 0, Train: label_loss: 0.10059215128421783, precision: 0.32994620442317213, recall: 0.8946515397081207, f1: 0.48209606982958586\n",
            "epoch: 891, step: 1, Train: label_loss: 0.08025684952735901, precision: 0.32504440497333775, recall: 0.8999999999998524, f1: 0.47759895602882774\n",
            "epoch: 891, step: 2, Train: label_loss: 0.07759122550487518, precision: 0.31394658753707333, recall: 0.8875838926173006, f1: 0.4638316527452226\n",
            "epoch: 891, step: 3, Train: label_loss: 0.10931643843650818, precision: 0.3251982916412248, recall: 0.8610662358641581, f1: 0.4720992027945278\n",
            "epoch: 891, step: 4, Train: label_loss: 0.09449918568134308, precision: 0.3035279805352613, recall: 0.8573883161510554, f1: 0.4483378256576567\n",
            "epoch: 891, step: 5, Train: label_loss: 0.09881656616926193, precision: 0.2961841308297822, recall: 0.8654867256635635, f1: 0.4413357400341708\n",
            "epoch: 891, step: 6, Train: label_loss: 0.09048902988433838, precision: 0.313549160671444, recall: 0.8804713804712322, f1: 0.4624226347976588\n",
            "epoch: 891, step: 7, Train: label_loss: 0.10655021667480469, precision: 0.30680437424056456, recall: 0.8721934369601256, f1: 0.45393258423112054\n",
            "epoch: 891, step: 8, Train: label_loss: 0.07764922082424164, precision: 0.32772098616955336, recall: 0.8733974358972959, f1: 0.4766069085741828\n",
            "epoch: 891, step: 9, Train: label_loss: 0.09163230657577515, precision: 0.3186157517899571, recall: 0.868292682926688, f1: 0.4661719772631711\n",
            "epoch: 891, step: 10, Train: label_loss: 0.09320282191038132, precision: 0.3319352905931497, recall: 0.8978930307940197, f1: 0.4846894137838185\n",
            "epoch: 891, step: 11, Train: label_loss: 0.09667393565177917, precision: 0.3046874999999817, recall: 0.8726333907055296, f1: 0.4516703785807492\n",
            "epoch: 891, step: 12, Train: label_loss: 0.0889197587966919, precision: 0.3180737217597908, recall: 0.9098639455780765, f1: 0.4713656387280915\n",
            "epoch: 891, step: 13, Train: label_loss: 0.08925246447324753, precision: 0.3259036144578117, recall: 0.8854337152208043, f1: 0.4764420959535808\n",
            "epoch: 891, step: 14, Train: label_loss: 0.1088632121682167, precision: 0.28580134064593016, recall: 0.8405017921145447, f1: 0.426557526110338\n",
            "epoch: 891, step: 15, Train: label_loss: 0.0793597549200058, precision: 0.33273703041142916, recall: 0.8942307692306258, f1: 0.4850065188652529\n",
            "epoch: 891, step: 16, Train: label_loss: 0.08083812892436981, precision: 0.32621589561089404, recall: 0.9197324414714181, f1: 0.48161120836760835\n",
            "epoch: 891, step: 17, Train: label_loss: 0.08651220798492432, precision: 0.32443653618028917, recall: 0.9131886477460912, f1: 0.47877461702910684\n",
            "epoch: 891, step: 18, Train: label_loss: 0.09475289285182953, precision: 0.32217573221755397, recall: 0.8923841059601171, f1: 0.4734299516518002\n",
            "epoch: 891, step: 19, Train: label_loss: 0.08604048937559128, precision: 0.32733812949638325, recall: 0.8892508143321026, f1: 0.4785276073225877\n",
            "epoch: 891, step: 20, Train: label_loss: 0.08947107195854187, precision: 0.31966726084371244, recall: 0.9134125636670775, f1: 0.4735915492573257\n",
            "epoch: 891, step: 21, Train: label_loss: 0.08579087257385254, precision: 0.3179122182680713, recall: 0.913117546848226, f1: 0.47162340515302426\n",
            "epoch: 891, step: 22, Train: label_loss: 0.08995828032493591, precision: 0.33838690115219294, recall: 0.8899521531099058, f1: 0.4903339191164532\n",
            "epoch: 891, step: 23, Train: label_loss: 0.09264075756072998, precision: 0.33997050147490115, recall: 0.8848368522071237, f1: 0.4912093766247334\n",
            "epoch: 892, step: 0, Train: label_loss: 0.08737840503454208, precision: 0.3137603795966599, recall: 0.8875838926173006, f1: 0.4636283961051005\n",
            "epoch: 892, step: 1, Train: label_loss: 0.10044737160205841, precision: 0.31359516616312305, recall: 0.876689189189041, f1: 0.46194926564873234\n",
            "epoch: 892, step: 2, Train: label_loss: 0.08635154366493225, precision: 0.3130177514792714, recall: 0.9089347079036239, f1: 0.46566901404635747\n",
            "epoch: 892, step: 3, Train: label_loss: 0.08016523718833923, precision: 0.3251935675997424, recall: 0.8849270664504237, f1: 0.47560975605821687\n",
            "epoch: 892, step: 4, Train: label_loss: 0.09828613698482513, precision: 0.3343337334933773, recall: 0.9071661237783538, f1: 0.48859649118867193\n",
            "epoch: 892, step: 5, Train: label_loss: 0.07915264368057251, precision: 0.3351001177856104, recall: 0.9147909967844188, f1: 0.4905172413400233\n",
            "epoch: 892, step: 6, Train: label_loss: 0.08717498183250427, precision: 0.3043478260869384, recall: 0.8902439024388692, f1: 0.45361739898551123\n",
            "epoch: 892, step: 7, Train: label_loss: 0.0693259984254837, precision: 0.3166472642607499, recall: 0.9395509499134819, f1: 0.47366129730661505\n",
            "epoch: 892, step: 8, Train: label_loss: 0.09111029654741287, precision: 0.32930513595164174, recall: 0.8861788617884737, f1: 0.48017621141419725\n",
            "epoch: 892, step: 9, Train: label_loss: 0.06744430214166641, precision: 0.3211978860833634, recall: 0.9302721088433792, f1: 0.47752073326603556\n",
            "epoch: 892, step: 10, Train: label_loss: 0.09540925174951553, precision: 0.3215962441314365, recall: 0.9028006589784344, f1: 0.47425356984439276\n",
            "epoch: 892, step: 11, Train: label_loss: 0.10167890787124634, precision: 0.3202416918428809, recall: 0.8702791461410722, f1: 0.4681978798192887\n",
            "epoch: 892, step: 12, Train: label_loss: 0.07958141714334488, precision: 0.3088322465915644, recall: 0.9029462738299994, f1: 0.4602473497852997\n",
            "epoch: 892, step: 13, Train: label_loss: 0.07841797173023224, precision: 0.3106910809214229, recall: 0.9179755671900666, f1: 0.46425419237170606\n",
            "epoch: 892, step: 14, Train: label_loss: 0.08610904216766357, precision: 0.3255535607420511, recall: 0.9066666666665155, f1: 0.4790841038800565\n",
            "epoch: 892, step: 15, Train: label_loss: 0.08243568986654282, precision: 0.3249850924269335, recall: 0.8905228758168479, f1: 0.47619047615125837\n",
            "epoch: 892, step: 16, Train: label_loss: 0.08813458681106567, precision: 0.3158208955223692, recall: 0.8846153846152366, f1: 0.46546414426386806\n",
            "epoch: 892, step: 17, Train: label_loss: 0.0883626639842987, precision: 0.32170775706552485, recall: 0.8887043189367294, f1: 0.47240618097638226\n",
            "epoch: 892, step: 18, Train: label_loss: 0.07571275532245636, precision: 0.32815301852956796, recall: 0.8897893030792723, f1: 0.4794759824933415\n",
            "epoch: 892, step: 19, Train: label_loss: 0.0830962061882019, precision: 0.3339275103980788, recall: 0.8934817170109867, f1: 0.4861591695105223\n",
            "epoch: 892, step: 20, Train: label_loss: 0.08605994284152985, precision: 0.3103651354534564, recall: 0.8993174061431912, f1: 0.46147110328930707\n",
            "epoch: 892, step: 21, Train: label_loss: 0.0900941863656044, precision: 0.33173365326932625, recall: 0.879173290937857, f1: 0.4817073170333482\n",
            "epoch: 892, step: 22, Train: label_loss: 0.08237674832344055, precision: 0.32684365781708985, recall: 0.9081967213113264, f1: 0.4806941431280651\n",
            "epoch: 892, step: 23, Train: label_loss: 0.08798173069953918, precision: 0.31988472622476083, recall: 0.9042769857431967, f1: 0.47259180411248863\n",
            "epoch: 893, step: 0, Train: label_loss: 0.08951172977685928, precision: 0.3158205430932517, recall: 0.9098639455780765, f1: 0.4688869412412831\n",
            "epoch: 893, step: 1, Train: label_loss: 0.08609354496002197, precision: 0.33688573120187465, recall: 0.9177419354837228, f1: 0.49285404933269683\n",
            "epoch: 893, step: 2, Train: label_loss: 0.07968224585056305, precision: 0.3368920521945233, recall: 0.9059011164272877, f1: 0.4911370514087742\n",
            "epoch: 893, step: 3, Train: label_loss: 0.09613499045372009, precision: 0.33095662507425244, recall: 0.8969404186794047, f1: 0.48350694440502556\n",
            "epoch: 893, step: 4, Train: label_loss: 0.08461779356002808, precision: 0.3056716417910265, recall: 0.893542757416947, f1: 0.45551601419685034\n",
            "epoch: 893, step: 5, Train: label_loss: 0.08327247202396393, precision: 0.3364872856297849, recall: 0.9147909967844188, f1: 0.4920017293164524\n",
            "epoch: 893, step: 6, Train: label_loss: 0.09390991181135178, precision: 0.30986762936219553, recall: 0.8925476603118037, f1: 0.4600267976392349\n",
            "epoch: 893, step: 7, Train: label_loss: 0.07707934081554413, precision: 0.32208407341620354, recall: 0.9096989966553662, f1: 0.47573240048604176\n",
            "epoch: 893, step: 8, Train: label_loss: 0.08019862323999405, precision: 0.3349140486069748, recall: 0.923202614378934, f1: 0.4915180512875532\n",
            "epoch: 893, step: 9, Train: label_loss: 0.08590532094240189, precision: 0.32300357568532045, recall: 0.9170896785108431, f1: 0.4777434993003489\n",
            "epoch: 893, step: 10, Train: label_loss: 0.07573164999485016, precision: 0.30891907855875317, recall: 0.9001721170394319, f1: 0.45998240981239963\n",
            "epoch: 893, step: 11, Train: label_loss: 0.06857647001743317, precision: 0.3131195335276785, recall: 0.9371727748689463, f1: 0.4694055943680097\n",
            "epoch: 893, step: 12, Train: label_loss: 0.08103342354297638, precision: 0.30481283422458083, recall: 0.9047619047617451, f1: 0.4559999999622603\n",
            "epoch: 893, step: 13, Train: label_loss: 0.08144792169332504, precision: 0.33647613435472384, recall: 0.9224555735055052, f1: 0.4930915370937779\n",
            "epoch: 893, step: 14, Train: label_loss: 0.09114646911621094, precision: 0.32102441929718156, recall: 0.8953488372091535, f1: 0.4725997369185801\n",
            "epoch: 893, step: 15, Train: label_loss: 0.08701473474502563, precision: 0.3214501510573824, recall: 0.870703764320643, f1: 0.46954986756869194\n",
            "epoch: 893, step: 16, Train: label_loss: 0.08451303839683533, precision: 0.31535269709541697, recall: 0.9001692047375803, f1: 0.4670763827534557\n",
            "epoch: 893, step: 17, Train: label_loss: 0.0926806777715683, precision: 0.31900726392249884, recall: 0.8797996661100367, f1: 0.46823633936560893\n",
            "epoch: 893, step: 18, Train: label_loss: 0.08214925229549408, precision: 0.3198813056379632, recall: 0.9135593220337433, f1: 0.47384615380769557\n",
            "epoch: 893, step: 19, Train: label_loss: 0.09038509428501129, precision: 0.30509478672983975, recall: 0.8956521739128877, f1: 0.45514803354579275\n",
            "epoch: 893, step: 20, Train: label_loss: 0.08154547214508057, precision: 0.3327423167848503, recall: 0.9036918138040282, f1: 0.48639308851353535\n",
            "epoch: 893, step: 21, Train: label_loss: 0.07655274122953415, precision: 0.3386809269162009, recall: 0.9076433121017662, f1: 0.4932929467366647\n",
            "epoch: 893, step: 22, Train: label_loss: 0.09457902610301971, precision: 0.3315315315315116, recall: 0.8917609046848316, f1: 0.4833625218518629\n",
            "epoch: 893, step: 23, Train: label_loss: 0.08336633443832397, precision: 0.32672540381789084, recall: 0.8691406249998301, f1: 0.4749199572708015\n",
            "epoch: 894, step: 0, Train: label_loss: 0.0819421038031578, precision: 0.3349225268176201, recall: 0.9064516129030795, f1: 0.48912097472121724\n",
            "epoch: 894, step: 1, Train: label_loss: 0.08541420102119446, precision: 0.30131264916465983, recall: 0.8797909407663972, f1: 0.44888888885084305\n",
            "epoch: 894, step: 2, Train: label_loss: 0.08519257605075836, precision: 0.33530106257377007, recall: 0.9131832797426184, f1: 0.4905008635185283\n",
            "epoch: 894, step: 3, Train: label_loss: 0.0791388750076294, precision: 0.32087781731907944, recall: 0.8868852459014939, f1: 0.47125435536163696\n",
            "epoch: 894, step: 4, Train: label_loss: 0.08212599158287048, precision: 0.3223140495867578, recall: 0.9054726368157702, f1: 0.4754026991340724\n",
            "epoch: 894, step: 5, Train: label_loss: 0.08141028881072998, precision: 0.34256472004814315, recall: 0.8862928348908277, f1: 0.4941380807239664\n",
            "epoch: 894, step: 6, Train: label_loss: 0.07821981608867645, precision: 0.328217237308127, recall: 0.9099836333877397, f1: 0.48242950104559473\n",
            "epoch: 894, step: 7, Train: label_loss: 0.09162755310535431, precision: 0.3182089552238616, recall: 0.9095563139930187, f1: 0.47147279960773164\n",
            "epoch: 894, step: 8, Train: label_loss: 0.0860547423362732, precision: 0.3271531100478273, recall: 0.9056291390726977, f1: 0.4806678382737968\n",
            "epoch: 894, step: 9, Train: label_loss: 0.06610531359910965, precision: 0.3339222614840793, recall: 0.927986906710159, f1: 0.4911216976656726\n",
            "epoch: 894, step: 10, Train: label_loss: 0.08330678939819336, precision: 0.3313644418192362, recall: 0.9196721311473901, f1: 0.48719062089023746\n",
            "epoch: 894, step: 11, Train: label_loss: 0.08966393768787384, precision: 0.32340678975578774, recall: 0.9187817258881693, f1: 0.4784140968777436\n",
            "epoch: 894, step: 12, Train: label_loss: 0.08206065744161606, precision: 0.3172905525846514, recall: 0.8944723618088953, f1: 0.4684210525928817\n",
            "epoch: 894, step: 13, Train: label_loss: 0.07428890466690063, precision: 0.31249999999998157, recall: 0.9281961471101701, f1: 0.4675782972714912\n",
            "epoch: 894, step: 14, Train: label_loss: 0.07697198539972305, precision: 0.33687943262409353, recall: 0.9268292682925322, f1: 0.49414824443419614\n",
            "epoch: 894, step: 15, Train: label_loss: 0.07573047280311584, precision: 0.3179941002949665, recall: 0.9089376053961367, f1: 0.471153846115404\n",
            "epoch: 894, step: 16, Train: label_loss: 0.08061563968658447, precision: 0.3313539192398853, recall: 0.8971061093246145, f1: 0.4839549002207535\n",
            "epoch: 894, step: 17, Train: label_loss: 0.08104868978261948, precision: 0.32023460410555304, recall: 0.9238578680201481, f1: 0.47560975605929007\n",
            "epoch: 894, step: 18, Train: label_loss: 0.08240649104118347, precision: 0.3223140495867578, recall: 0.9333333333331737, f1: 0.47915752519216187\n",
            "epoch: 894, step: 19, Train: label_loss: 0.08804220706224442, precision: 0.3297746144721038, recall: 0.9040650406502594, f1: 0.48326814424588366\n",
            "epoch: 894, step: 20, Train: label_loss: 0.0831640213727951, precision: 0.29563135846796557, recall: 0.8621291448515074, f1: 0.4402852049530191\n",
            "epoch: 894, step: 21, Train: label_loss: 0.08617205917835236, precision: 0.31947743467931594, recall: 0.9149659863944022, f1: 0.4735915492573681\n",
            "epoch: 894, step: 22, Train: label_loss: 0.07119576632976532, precision: 0.3254577672770038, recall: 0.930743243243086, f1: 0.4822757111213036\n",
            "epoch: 894, step: 23, Train: label_loss: 0.09339220821857452, precision: 0.32442196531789563, recall: 0.9107505070992068, f1: 0.47842301541140214\n",
            "epoch: 895, step: 0, Train: label_loss: 0.06126558780670166, precision: 0.32049036777581313, recall: 0.9195979899495946, f1: 0.47532467528630423\n",
            "epoch: 895, step: 1, Train: label_loss: 0.08606888353824615, precision: 0.32045184304397617, recall: 0.8998330550916694, f1: 0.47259973691870466\n",
            "epoch: 895, step: 2, Train: label_loss: 0.08442867547273636, precision: 0.31575829383884385, recall: 0.9033898305083214, f1: 0.4679543458790466\n",
            "epoch: 895, step: 3, Train: label_loss: 0.08014515787363052, precision: 0.3186157517899571, recall: 0.8855721393033357, f1: 0.46862659057095907\n",
            "epoch: 895, step: 4, Train: label_loss: 0.09162391722202301, precision: 0.3305489260143001, recall: 0.8978930307940197, f1: 0.48320976882237576\n",
            "epoch: 895, step: 5, Train: label_loss: 0.08486773073673248, precision: 0.33373134328356213, recall: 0.9001610305956682, f1: 0.48693379786990204\n",
            "epoch: 895, step: 6, Train: label_loss: 0.0949418842792511, precision: 0.317383403997558, recall: 0.8718801996670762, f1: 0.4653641207423557\n",
            "epoch: 895, step: 7, Train: label_loss: 0.09208296984434128, precision: 0.32091346153844225, recall: 0.8797364085665765, f1: 0.4702774107930225\n",
            "epoch: 895, step: 8, Train: label_loss: 0.08848078548908234, precision: 0.31147540983604666, recall: 0.8875432525950021, f1: 0.46112359546711806\n",
            "epoch: 895, step: 9, Train: label_loss: 0.09231723845005035, precision: 0.31204819277106555, recall: 0.8900343642610153, f1: 0.4620874219062105\n",
            "epoch: 895, step: 10, Train: label_loss: 0.08298102021217346, precision: 0.31212484993995726, recall: 0.8828522920202235, f1: 0.46119733920748424\n",
            "epoch: 895, step: 11, Train: label_loss: 0.09203527867794037, precision: 0.31883194278901555, recall: 0.9021922428329001, f1: 0.47115808010227844\n",
            "epoch: 895, step: 12, Train: label_loss: 0.07557204365730286, precision: 0.33411903358866624, recall: 0.9219512195120452, f1: 0.4904844290266524\n",
            "epoch: 895, step: 13, Train: label_loss: 0.08361309766769409, precision: 0.32092198581558384, recall: 0.9065108514188803, f1: 0.4740288083419589\n",
            "epoch: 895, step: 14, Train: label_loss: 0.08168625086545944, precision: 0.328783382789298, recall: 0.9037520391515654, f1: 0.4821583985683235\n",
            "epoch: 895, step: 15, Train: label_loss: 0.08489792048931122, precision: 0.31668625146884155, recall: 0.9261168384878133, f1: 0.4719789842001603\n",
            "epoch: 895, step: 16, Train: label_loss: 0.07204215228557587, precision: 0.3313817330210579, recall: 0.9233278955952816, f1: 0.48772080995677825\n",
            "epoch: 895, step: 17, Train: label_loss: 0.08092164993286133, precision: 0.3243566726510877, recall: 0.8899835796386059, f1: 0.47543859645203435\n",
            "epoch: 895, step: 18, Train: label_loss: 0.09088123589754105, precision: 0.3235117257967334, recall: 0.8922056384741471, f1: 0.47484554276760704\n",
            "epoch: 895, step: 19, Train: label_loss: 0.09411653876304626, precision: 0.3122743682310281, recall: 0.8796610169490033, f1: 0.4609236234071148\n",
            "epoch: 895, step: 20, Train: label_loss: 0.0713430792093277, precision: 0.3333333333333137, recall: 0.9218241042343774, f1: 0.4896193771235789\n",
            "epoch: 895, step: 21, Train: label_loss: 0.08930414915084839, precision: 0.325943678849591, recall: 0.873194221508688, f1: 0.47469458983820817\n",
            "epoch: 895, step: 22, Train: label_loss: 0.0929996520280838, precision: 0.3261776982707021, recall: 0.9131886477460912, f1: 0.48066783827400394\n",
            "epoch: 895, step: 23, Train: label_loss: 0.0825413316488266, precision: 0.316947909024188, recall: 0.8962655601657892, f1: 0.4682926828881791\n",
            "epoch: 896, step: 0, Train: label_loss: 0.09008230268955231, precision: 0.3349168646080561, recall: 0.9126213592231532, f1: 0.49000868805798603\n",
            "epoch: 896, step: 1, Train: label_loss: 0.08775845170021057, precision: 0.31172657631111894, recall: 0.9073756432245441, f1: 0.46403508768119384\n",
            "epoch: 896, step: 2, Train: label_loss: 0.08227631449699402, precision: 0.32784958871913467, recall: 0.9331103678928205, f1: 0.48521739126582564\n",
            "epoch: 896, step: 3, Train: label_loss: 0.08833079785108566, precision: 0.3407318536292537, recall: 0.8847352024920739, f1: 0.49198787349813866\n",
            "epoch: 896, step: 4, Train: label_loss: 0.08302906900644302, precision: 0.31578947368419186, recall: 0.9097103918226729, f1: 0.4688323090047226\n",
            "epoch: 896, step: 5, Train: label_loss: 0.09575671702623367, precision: 0.303614457831307, recall: 0.8704663212433729, f1: 0.45020098254312446\n",
            "epoch: 896, step: 6, Train: label_loss: 0.07846829295158386, precision: 0.3382526564344546, recall: 0.9227053140095132, f1: 0.49503239736890614\n",
            "epoch: 896, step: 7, Train: label_loss: 0.08404538035392761, precision: 0.32294117647056925, recall: 0.9195979899495946, f1: 0.47801480187702955\n",
            "epoch: 896, step: 8, Train: label_loss: 0.08391906321048737, precision: 0.31872037914690055, recall: 0.9057239057237532, f1: 0.4715162138089522\n",
            "epoch: 896, step: 9, Train: label_loss: 0.08557352423667908, precision: 0.3170441001191706, recall: 0.9016949152540844, f1: 0.4691358024306009\n",
            "epoch: 896, step: 10, Train: label_loss: 0.0869159996509552, precision: 0.3146936347412067, recall: 0.905821917808064, f1: 0.4671081677321068\n",
            "epoch: 896, step: 11, Train: label_loss: 0.0766206607222557, precision: 0.3217910447761002, recall: 0.8923841059601171, f1: 0.4730144799961039\n",
            "epoch: 896, step: 12, Train: label_loss: 0.09899671375751495, precision: 0.3247143716175391, recall: 0.9015025041734721, f1: 0.47745358086287737\n",
            "epoch: 896, step: 13, Train: label_loss: 0.0837828665971756, precision: 0.31978798586570556, recall: 0.9203389830506914, f1: 0.47465034961203384\n",
            "epoch: 896, step: 14, Train: label_loss: 0.08019909262657166, precision: 0.31828839390385005, recall: 0.9250425894376617, f1: 0.4736153510303355\n",
            "epoch: 896, step: 15, Train: label_loss: 0.09590594470500946, precision: 0.3315539739027087, recall: 0.9119086460031138, f1: 0.48629839056546\n",
            "epoch: 896, step: 16, Train: label_loss: 0.08254996687173843, precision: 0.3210023866348257, recall: 0.9087837837836302, f1: 0.47442680772152124\n",
            "epoch: 896, step: 17, Train: label_loss: 0.07805581390857697, precision: 0.3173475429247888, recall: 0.9054054054052524, f1: 0.46996931166691575\n",
            "epoch: 896, step: 18, Train: label_loss: 0.08548314869403839, precision: 0.3215780035863526, recall: 0.8733766233764816, f1: 0.4700742682000265\n",
            "epoch: 896, step: 19, Train: label_loss: 0.08713454008102417, precision: 0.3267973856208956, recall: 0.9016393442621472, f1: 0.47972088962510223\n",
            "epoch: 896, step: 20, Train: label_loss: 0.08541836589574814, precision: 0.33710541989277326, recall: 0.8913385826770249, f1: 0.48919619702150086\n",
            "epoch: 896, step: 21, Train: label_loss: 0.07208899408578873, precision: 0.3354725787631076, recall: 0.9395424836599772, f1: 0.4944110059800972\n",
            "epoch: 896, step: 22, Train: label_loss: 0.09033812582492828, precision: 0.31127012522359504, recall: 0.909407665505068, f1: 0.46379386935334566\n",
            "epoch: 896, step: 23, Train: label_loss: 0.07306116819381714, precision: 0.3318713450292155, recall: 0.9043824701193418, f1: 0.4855614972868744\n",
            "epoch: 897, step: 0, Train: label_loss: 0.08631467819213867, precision: 0.338452451269915, recall: 0.908082408874658, f1: 0.49311531837692185\n",
            "epoch: 897, step: 1, Train: label_loss: 0.07115474343299866, precision: 0.33827014218007473, recall: 0.9121405750797265, f1: 0.4935177181973082\n",
            "epoch: 897, step: 2, Train: label_loss: 0.08427740633487701, precision: 0.308101714961543, recall: 0.8951890034362723, f1: 0.4584249889631819\n",
            "epoch: 897, step: 3, Train: label_loss: 0.08282866328954697, precision: 0.29415239220317224, recall: 0.9188191881917123, f1: 0.44563758385583824\n",
            "epoch: 897, step: 4, Train: label_loss: 0.0868525505065918, precision: 0.29958308516972604, recall: 0.8934280639430029, f1: 0.44870651200516765\n",
            "epoch: 897, step: 5, Train: label_loss: 0.09778155386447906, precision: 0.3230220107078927, recall: 0.8960396039602481, f1: 0.4748578923965107\n",
            "epoch: 897, step: 6, Train: label_loss: 0.09616037458181381, precision: 0.30893821235750996, recall: 0.867003367003221, f1: 0.4555506412703757\n",
            "epoch: 897, step: 7, Train: label_loss: 0.07346341758966446, precision: 0.32318501170958297, recall: 0.918469217969897, f1: 0.47812906016067164\n",
            "epoch: 897, step: 8, Train: label_loss: 0.08958031982183456, precision: 0.3317220543806446, recall: 0.8578124999998659, f1: 0.47843137250875784\n",
            "epoch: 897, step: 9, Train: label_loss: 0.0838129073381424, precision: 0.3182359952324006, recall: 0.9035532994922328, f1: 0.47069193473446147\n",
            "epoch: 897, step: 10, Train: label_loss: 0.0835968628525734, precision: 0.3224271267102723, recall: 0.8885245901637887, f1: 0.47315582711060183\n",
            "epoch: 897, step: 11, Train: label_loss: 0.09927109628915787, precision: 0.3140794223826526, recall: 0.8832487309643174, f1: 0.4633821570850924\n",
            "epoch: 897, step: 12, Train: label_loss: 0.09065313637256622, precision: 0.3309481216457763, recall: 0.893719806763141, f1: 0.4830287205871482\n",
            "epoch: 897, step: 13, Train: label_loss: 0.08029860258102417, precision: 0.32800473653047196, recall: 0.8949919224554288, f1: 0.48006932405082614\n",
            "epoch: 897, step: 14, Train: label_loss: 0.08749426156282425, precision: 0.3335322195703858, recall: 0.9059967585087672, f1: 0.48757086781932263\n",
            "epoch: 897, step: 15, Train: label_loss: 0.06842157244682312, precision: 0.3439153439153237, recall: 0.912636505460076, f1: 0.49957301447770625\n",
            "epoch: 897, step: 16, Train: label_loss: 0.0828930214047432, precision: 0.33234597156396134, recall: 0.9181669394433849, f1: 0.48803827747289213\n",
            "epoch: 897, step: 17, Train: label_loss: 0.07611963152885437, precision: 0.31320307874480086, recall: 0.9089347079036239, f1: 0.4658740642506989\n",
            "epoch: 897, step: 18, Train: label_loss: 0.07430419325828552, precision: 0.32269503546097383, recall: 0.9069767441858958, f1: 0.47602441146952945\n",
            "epoch: 897, step: 19, Train: label_loss: 0.08670541644096375, precision: 0.32040572792360855, recall: 0.9025210084032096, f1: 0.47291941871954346\n",
            "epoch: 897, step: 20, Train: label_loss: 0.09464861452579498, precision: 0.31377245508980156, recall: 0.9003436426115291, f1: 0.4653641207431567\n",
            "epoch: 897, step: 21, Train: label_loss: 0.08560102432966232, precision: 0.3107947805456518, recall: 0.8896434634973022, f1: 0.4606593406209259\n",
            "epoch: 897, step: 22, Train: label_loss: 0.08566071093082428, precision: 0.31563245823387137, recall: 0.9011925042587902, f1: 0.4675209897980376\n",
            "epoch: 897, step: 23, Train: label_loss: 0.08409509062767029, precision: 0.3299856527976808, recall: 0.9274193548385227, f1: 0.48677248673372275\n",
            "epoch: 898, step: 0, Train: label_loss: 0.08511678874492645, precision: 0.3331364441819059, recall: 0.9111470113084149, f1: 0.4878892733171487\n",
            "epoch: 898, step: 1, Train: label_loss: 0.08534464240074158, precision: 0.3276370064820078, recall: 0.9099836333877397, f1: 0.4818024263041827\n",
            "epoch: 898, step: 2, Train: label_loss: 0.08479370176792145, precision: 0.33077377436501293, recall: 0.9105691056909088, f1: 0.4852686308100858\n",
            "epoch: 898, step: 3, Train: label_loss: 0.0847085639834404, precision: 0.32121573301547546, recall: 0.8909090909089435, f1: 0.47218572050414825\n",
            "epoch: 898, step: 4, Train: label_loss: 0.07511540502309799, precision: 0.31594724220621606, recall: 0.8783333333331869, f1: 0.46472663135434444\n",
            "epoch: 898, step: 5, Train: label_loss: 0.07811406254768372, precision: 0.3325471698113011, recall: 0.9200652528546622, f1: 0.4885231701645086\n",
            "epoch: 898, step: 6, Train: label_loss: 0.08377958089113235, precision: 0.3236686390532353, recall: 0.8996710526314309, f1: 0.4760661444344984\n",
            "epoch: 898, step: 7, Train: label_loss: 0.0735318511724472, precision: 0.3493270918665682, recall: 0.9313572542900262, f1: 0.5080851063432625\n",
            "epoch: 898, step: 8, Train: label_loss: 0.08759406208992004, precision: 0.32620320855613033, recall: 0.8999999999998524, f1: 0.47884866982571284\n",
            "epoch: 898, step: 9, Train: label_loss: 0.08797651529312134, precision: 0.31862152357918266, recall: 0.8739635157544156, f1: 0.4669915817064808\n",
            "epoch: 898, step: 10, Train: label_loss: 0.09506931900978088, precision: 0.33051869722555305, recall: 0.8983606557375576, f1: 0.4832451498724499\n",
            "epoch: 898, step: 11, Train: label_loss: 0.07846684753894806, precision: 0.32214369846876784, recall: 0.9177852348991749, f1: 0.47689625105129635\n",
            "epoch: 898, step: 12, Train: label_loss: 0.0795610174536705, precision: 0.3144391408114371, recall: 0.9008547008545468, f1: 0.46616541349543505\n",
            "epoch: 898, step: 13, Train: label_loss: 0.08248850703239441, precision: 0.32856290995823917, recall: 0.9137645107792846, f1: 0.4833333332943855\n",
            "epoch: 898, step: 14, Train: label_loss: 0.07649099826812744, precision: 0.31404958677684097, recall: 0.9094017094015538, f1: 0.4668714348016409\n",
            "epoch: 898, step: 15, Train: label_loss: 0.09490886330604553, precision: 0.3079249848759644, recall: 0.8554621848738058, f1: 0.4528469750500028\n",
            "epoch: 898, step: 16, Train: label_loss: 0.08113458752632141, precision: 0.3174041297934916, recall: 0.9134125636670775, f1: 0.47110332745730477\n",
            "epoch: 898, step: 17, Train: label_loss: 0.08091980218887329, precision: 0.3270698766881781, recall: 0.9131147540982109, f1: 0.4816255944271847\n",
            "epoch: 898, step: 18, Train: label_loss: 0.08300796151161194, precision: 0.29858657243814496, recall: 0.9118705035969582, f1: 0.4498669032458473\n",
            "epoch: 898, step: 19, Train: label_loss: 0.0845993161201477, precision: 0.3199999999999812, recall: 0.9096989966553662, f1: 0.473455178377471\n",
            "epoch: 898, step: 20, Train: label_loss: 0.0864173173904419, precision: 0.3138773079213631, recall: 0.8902027027025523, f1: 0.4641127256329245\n",
            "epoch: 898, step: 21, Train: label_loss: 0.07067437469959259, precision: 0.31868775629757945, recall: 0.908180300500683, f1: 0.4718126625807565\n",
            "epoch: 898, step: 22, Train: label_loss: 0.0935640037059784, precision: 0.31625967837996927, recall: 0.8924369747897659, f1: 0.46701846961831284\n",
            "epoch: 898, step: 23, Train: label_loss: 0.07337594032287598, precision: 0.31502890173408127, recall: 0.906444906444718, f1: 0.4675603216774892\n",
            "epoch: 899, step: 0, Train: label_loss: 0.07518906891345978, precision: 0.3185053380782729, recall: 0.897993311036639, f1: 0.4702276707143695\n",
            "epoch: 899, step: 1, Train: label_loss: 0.0905265361070633, precision: 0.32915173237751916, recall: 0.8930307941651713, f1: 0.48101265818844924\n",
            "epoch: 899, step: 2, Train: label_loss: 0.08568703383207321, precision: 0.3172787477423048, recall: 0.866776315789331, f1: 0.4645218157386033\n",
            "epoch: 899, step: 3, Train: label_loss: 0.08253879845142365, precision: 0.3152238805969961, recall: 0.8888888888887392, f1: 0.46540326130991955\n",
            "epoch: 899, step: 4, Train: label_loss: 0.08490699529647827, precision: 0.3331357439241059, recall: 0.8991999999998561, f1: 0.4861591695106807\n",
            "epoch: 899, step: 5, Train: label_loss: 0.07854627817869186, precision: 0.298639858072129, recall: 0.9066427289046846, f1: 0.44928825619044144\n",
            "epoch: 899, step: 6, Train: label_loss: 0.07616480439901352, precision: 0.33589591957419657, recall: 0.9117174959870125, f1: 0.49092480549215556\n",
            "epoch: 899, step: 7, Train: label_loss: 0.0715944841504097, precision: 0.3234946871310317, recall: 0.917922948073548, f1: 0.4783937144965596\n",
            "epoch: 899, step: 8, Train: label_loss: 0.07180318236351013, precision: 0.31936245572607325, recall: 0.9092436974788387, f1: 0.4726955001799205\n",
            "epoch: 899, step: 9, Train: label_loss: 0.08806711435317993, precision: 0.32194244604314615, recall: 0.8890728476819719, f1: 0.4727112675665578\n",
            "epoch: 899, step: 10, Train: label_loss: 0.07413783669471741, precision: 0.33116499112948955, recall: 0.9090909090907614, f1: 0.48547897698725573\n",
            "epoch: 899, step: 11, Train: label_loss: 0.08421493321657181, precision: 0.32920353982298944, recall: 0.9207920792077687, f1: 0.4850065188659812\n",
            "epoch: 899, step: 12, Train: label_loss: 0.07969576120376587, precision: 0.3168552709946208, recall: 0.9063032367971198, f1: 0.46954986756969025\n",
            "epoch: 899, step: 13, Train: label_loss: 0.07385913282632828, precision: 0.3313748531139641, recall: 0.9200652528546622, f1: 0.4872570193994671\n",
            "epoch: 899, step: 14, Train: label_loss: 0.07625109702348709, precision: 0.3071895424836419, recall: 0.9006968641113413, f1: 0.45813026137098106\n",
            "epoch: 899, step: 15, Train: label_loss: 0.07900206744670868, precision: 0.328428487345478, recall: 0.9117647058822039, f1: 0.482907832068333\n",
            "epoch: 899, step: 16, Train: label_loss: 0.08944029361009598, precision: 0.2964943553178671, recall: 0.89426523297475, f1: 0.44533690313078933\n",
            "epoch: 899, step: 17, Train: label_loss: 0.07377291470766068, precision: 0.33768545994063276, recall: 0.9060509554138684, f1: 0.492001729316214\n",
            "epoch: 899, step: 18, Train: label_loss: 0.07556706666946411, precision: 0.32256169212689056, recall: 0.9149999999998474, f1: 0.4769765420986888\n",
            "epoch: 899, step: 19, Train: label_loss: 0.084029421210289, precision: 0.30737217598095673, recall: 0.8852739726025881, f1: 0.4563106795733498\n",
            "epoch: 899, step: 20, Train: label_loss: 0.09775573760271072, precision: 0.3093955715140449, recall: 0.8852739726025881, f1: 0.458536585327431\n",
            "epoch: 899, step: 21, Train: label_loss: 0.0909823477268219, precision: 0.32850241545891734, recall: 0.8774193548385681, f1: 0.4780316344067148\n",
            "epoch: 899, step: 22, Train: label_loss: 0.0773899108171463, precision: 0.313829787234024, recall: 0.9015280135821898, f1: 0.465585269580239\n",
            "epoch: 899, step: 23, Train: label_loss: 0.08669307827949524, precision: 0.35090252707578695, recall: 0.9169811320752986, f1: 0.5075718015264936\n",
            "epoch: 900, step: 0, Train: label_loss: 0.07688257098197937, precision: 0.3346986541837136, recall: 0.9285714285712777, f1: 0.49204301071369594\n",
            "epoch: 900, step: 1, Train: label_loss: 0.08489218354225159, precision: 0.2963407318536115, recall: 0.8837209302324, f1: 0.4438454626757353\n",
            "epoch: 900, step: 2, Train: label_loss: 0.08329514414072037, precision: 0.3321342925659273, recall: 0.9022801302930126, f1: 0.485539000837048\n",
            "epoch: 900, step: 3, Train: label_loss: 0.07274089753627777, precision: 0.31404958677684097, recall: 0.9316987740803971, f1: 0.4697571743551856\n",
            "epoch: 900, step: 4, Train: label_loss: 0.07972559332847595, precision: 0.3199052132701232, recall: 0.8866995073890169, f1: 0.4701784936484103\n",
            "epoch: 900, step: 5, Train: label_loss: 0.07296334207057953, precision: 0.32786885245899716, recall: 0.9210526315787958, f1: 0.4835924006520837\n",
            "epoch: 900, step: 6, Train: label_loss: 0.06753679364919662, precision: 0.31892523364484116, recall: 0.9333333333331737, f1: 0.4754026991348291\n",
            "epoch: 900, step: 7, Train: label_loss: 0.08376260101795197, precision: 0.31519138755978976, recall: 0.8917089678509489, f1: 0.4657534246189022\n",
            "epoch: 900, step: 8, Train: label_loss: 0.08427995443344116, precision: 0.330351818723892, recall: 0.9008130081299348, f1: 0.4834205933289298\n",
            "epoch: 900, step: 9, Train: label_loss: 0.08202651888132095, precision: 0.31127012522359504, recall: 0.8862478777587629, f1: 0.46072374223862644\n",
            "epoch: 900, step: 10, Train: label_loss: 0.08078034967184067, precision: 0.3343265792610051, recall: 0.9166666666665169, f1: 0.4899563318385211\n",
            "epoch: 900, step: 11, Train: label_loss: 0.08010420948266983, precision: 0.33076467101361406, recall: 0.9117647058822039, f1: 0.4854284471118252\n",
            "epoch: 900, step: 12, Train: label_loss: 0.08526480197906494, precision: 0.3490453460620317, recall: 0.9027777777776383, f1: 0.5034423407514783\n",
            "epoch: 900, step: 13, Train: label_loss: 0.08467896282672882, precision: 0.3138773079213631, recall: 0.9008547008545468, f1: 0.4655477031418458\n",
            "epoch: 900, step: 14, Train: label_loss: 0.09182506799697876, precision: 0.32497013142172493, recall: 0.8918032786883783, f1: 0.47635726791177235\n",
            "epoch: 900, step: 15, Train: label_loss: 0.08364929258823395, precision: 0.3305687203791273, recall: 0.9073170731705841, f1: 0.4845853234519102\n",
            "epoch: 900, step: 16, Train: label_loss: 0.08923286944627762, precision: 0.32147093712928104, recall: 0.8899835796386059, f1: 0.47233115464506586\n",
            "epoch: 900, step: 17, Train: label_loss: 0.07991861552000046, precision: 0.3210023866348257, recall: 0.8936877076410475, f1: 0.4723441615062876\n",
            "epoch: 900, step: 18, Train: label_loss: 0.08907712250947952, precision: 0.32624113475175376, recall: 0.9277310924368188, f1: 0.48272846519976526\n",
            "epoch: 900, step: 19, Train: label_loss: 0.07533014565706253, precision: 0.31917404129791627, recall: 0.912310286677755, f1: 0.47290209786365556\n",
            "epoch: 900, step: 20, Train: label_loss: 0.07862517982721329, precision: 0.319436288901919, recall: 0.9411764705880724, f1: 0.47698377900639954\n",
            "epoch: 900, step: 21, Train: label_loss: 0.07945147901773453, precision: 0.32461355529130054, recall: 0.895081967212968, f1: 0.47643979053681246\n",
            "epoch: 900, step: 22, Train: label_loss: 0.07196112722158432, precision: 0.3154796939375918, recall: 0.9100169779285381, f1: 0.46853146849319555\n",
            "epoch: 900, step: 23, Train: label_loss: 0.09429153800010681, precision: 0.328424153166397, recall: 0.8849206349204594, f1: 0.47905477976712585\n",
            "epoch: 901, step: 0, Train: label_loss: 0.06653358042240143, precision: 0.30602691632531853, recall: 0.91915641476258, f1: 0.45917471462446585\n",
            "epoch: 901, step: 1, Train: label_loss: 0.07936722040176392, precision: 0.3174322732626432, recall: 0.9166666666665108, f1: 0.47156605420496694\n",
            "epoch: 901, step: 2, Train: label_loss: 0.07896292954683304, precision: 0.3167848699763406, recall: 0.9008403361343024, f1: 0.4687363357725693\n",
            "epoch: 901, step: 3, Train: label_loss: 0.07748879492282867, precision: 0.32897085068409704, recall: 0.8962722852510703, f1: 0.4812880765490148\n",
            "epoch: 901, step: 4, Train: label_loss: 0.0929151326417923, precision: 0.3141831238778986, recall: 0.898972602739572, f1: 0.46563192900813993\n",
            "epoch: 901, step: 5, Train: label_loss: 0.07321584224700928, precision: 0.33999999999998, recall: 0.924799999999852, f1: 0.4972043010359152\n",
            "epoch: 901, step: 6, Train: label_loss: 0.0783892422914505, precision: 0.32261904761902843, recall: 0.9078726968172683, f1: 0.47606499776539735\n",
            "epoch: 901, step: 7, Train: label_loss: 0.07625365257263184, precision: 0.3249266862169897, recall: 0.9141914191417633, f1: 0.47944612717892066\n",
            "epoch: 901, step: 8, Train: label_loss: 0.08530832827091217, precision: 0.3412887828162087, recall: 0.8937499999998603, f1: 0.49395509495132667\n",
            "epoch: 901, step: 9, Train: label_loss: 0.07578211277723312, precision: 0.3149792776790814, recall: 0.9032258064514594, f1: 0.4670763827535403\n",
            "epoch: 901, step: 10, Train: label_loss: 0.09242042899131775, precision: 0.3217703349282104, recall: 0.9042016806721169, f1: 0.4746360828902241\n",
            "epoch: 901, step: 11, Train: label_loss: 0.06929556280374527, precision: 0.31591309453903016, recall: 0.9134125636670775, f1: 0.4694589877453658\n",
            "epoch: 901, step: 12, Train: label_loss: 0.06722007691860199, precision: 0.34295816146138225, recall: 0.9136577708004845, f1: 0.49871465291656825\n",
            "epoch: 901, step: 13, Train: label_loss: 0.0758545845746994, precision: 0.32542975696500737, recall: 0.9044481054364243, f1: 0.478639930213874\n",
            "epoch: 901, step: 14, Train: label_loss: 0.07951748371124268, precision: 0.33055390113160626, recall: 0.8980582524270391, f1: 0.48323900736158354\n",
            "epoch: 901, step: 15, Train: label_loss: 0.09627210348844528, precision: 0.29880952380950604, recall: 0.8745644599301612, f1: 0.445430346013463\n",
            "epoch: 901, step: 16, Train: label_loss: 0.08768226206302643, precision: 0.32275449101794473, recall: 0.9043624161072308, f1: 0.4757281553009958\n",
            "epoch: 901, step: 17, Train: label_loss: 0.0707094594836235, precision: 0.3479020979020776, recall: 0.9284603421460452, f1: 0.5061466722790807\n",
            "epoch: 901, step: 18, Train: label_loss: 0.08221311867237091, precision: 0.3023952095808202, recall: 0.8782608695650646, f1: 0.4498886413872447\n",
            "epoch: 901, step: 19, Train: label_loss: 0.08170545101165771, precision: 0.32246591582689255, recall: 0.9112227805693616, f1: 0.4763572679123091\n",
            "epoch: 901, step: 20, Train: label_loss: 0.07397187501192093, precision: 0.31675547661336195, recall: 0.9083191850592685, f1: 0.4697102721301863\n",
            "epoch: 901, step: 21, Train: label_loss: 0.08466280996799469, precision: 0.32698034544369703, recall: 0.9044481054364243, f1: 0.48031496059087453\n",
            "epoch: 901, step: 22, Train: label_loss: 0.07985903322696686, precision: 0.31879787860929176, recall: 0.9153976311335168, f1: 0.47290209786373993\n",
            "epoch: 901, step: 23, Train: label_loss: 0.08842650800943375, precision: 0.32246376811591865, recall: 0.9063136456209967, f1: 0.47568145372927584\n",
            "epoch: 902, step: 0, Train: label_loss: 0.06799276173114777, precision: 0.32784958871913467, recall: 0.9269102990031682, f1: 0.4843749999613549\n",
            "epoch: 902, step: 1, Train: label_loss: 0.09122329950332642, precision: 0.3260741612713169, recall: 0.9172185430462056, f1: 0.4811115935348613\n",
            "epoch: 902, step: 2, Train: label_loss: 0.07044190913438797, precision: 0.3376546847377526, recall: 0.9332247557001737, f1: 0.4958892254044686\n",
            "epoch: 902, step: 3, Train: label_loss: 0.07641062140464783, precision: 0.2995255041518209, recall: 0.895390070921827, f1: 0.4488888888512824\n",
            "epoch: 902, step: 4, Train: label_loss: 0.07210543006658554, precision: 0.32885514018689666, recall: 0.9446308724830629, f1: 0.48786828419041756\n",
            "epoch: 902, step: 5, Train: label_loss: 0.07530856132507324, precision: 0.3138773079213631, recall: 0.8902027027025523, f1: 0.4641127256329245\n",
            "epoch: 902, step: 6, Train: label_loss: 0.07476066797971725, precision: 0.32569077013519543, recall: 0.9172185430462056, f1: 0.48069414312831155\n",
            "epoch: 902, step: 7, Train: label_loss: 0.07087667286396027, precision: 0.32858837485170056, recall: 0.9052287581697867, f1: 0.4821583985683641\n",
            "epoch: 902, step: 8, Train: label_loss: 0.08521750569343567, precision: 0.31431966726082505, recall: 0.8950930626056014, f1: 0.46525945466685426\n",
            "epoch: 902, step: 9, Train: label_loss: 0.0858755111694336, precision: 0.31619385342787726, recall: 0.9114139693354494, f1: 0.46950416845666715\n",
            "epoch: 902, step: 10, Train: label_loss: 0.08598171174526215, precision: 0.3321385902030865, recall: 0.8953301127212728, f1: 0.4845315903744271\n",
            "epoch: 902, step: 11, Train: label_loss: 0.08429499715566635, precision: 0.3426035502958377, recall: 0.9075235109716445, f1: 0.4974226803725386\n",
            "epoch: 902, step: 12, Train: label_loss: 0.07290846854448318, precision: 0.32507374631266517, recall: 0.9198664440733021, f1: 0.4803836093772387\n",
            "epoch: 902, step: 13, Train: label_loss: 0.07462070137262344, precision: 0.3380447585394383, recall: 0.9318181818180304, f1: 0.49611063090298074\n",
            "epoch: 902, step: 14, Train: label_loss: 0.07870107889175415, precision: 0.31604054859866926, recall: 0.8892617449662937, f1: 0.46634403867662205\n",
            "epoch: 902, step: 15, Train: label_loss: 0.08597506582736969, precision: 0.31739390316794275, recall: 0.898477157360254, f1: 0.46908127204618427\n",
            "epoch: 902, step: 16, Train: label_loss: 0.08821883797645569, precision: 0.2950329144224838, recall: 0.8915009041589708, f1: 0.4433453237036025\n",
            "epoch: 902, step: 17, Train: label_loss: 0.08547612279653549, precision: 0.32818073721757857, recall: 0.9078947368419559, f1: 0.4820960698299514\n",
            "epoch: 902, step: 18, Train: label_loss: 0.07977284491062164, precision: 0.33550681683459777, recall: 0.9099678456590177, f1: 0.49025552183153437\n",
            "epoch: 902, step: 19, Train: label_loss: 0.0856107696890831, precision: 0.31067382230171076, recall: 0.8815566835869912, f1: 0.45943562606371646\n",
            "epoch: 902, step: 20, Train: label_loss: 0.07576899230480194, precision: 0.31644077784323416, recall: 0.9025210084032096, f1: 0.46858638739607267\n",
            "epoch: 902, step: 21, Train: label_loss: 0.09395602345466614, precision: 0.3361244019138555, recall: 0.8963317384368585, f1: 0.4889082209259253\n",
            "epoch: 902, step: 22, Train: label_loss: 0.08250027894973755, precision: 0.3220439691027735, recall: 0.9003322259134716, f1: 0.4743982494141031\n",
            "epoch: 902, step: 23, Train: label_loss: 0.08073324710130692, precision: 0.32038123167153076, recall: 0.8846153846152056, f1: 0.47039827767888837\n",
            "epoch: 903, step: 0, Train: label_loss: 0.07249011099338531, precision: 0.3115429917549875, recall: 0.9073756432245441, f1: 0.4638316527457733\n",
            "epoch: 903, step: 1, Train: label_loss: 0.07211737334728241, precision: 0.32278851786758506, recall: 0.9198664440733021, f1: 0.47788378140122434\n",
            "epoch: 903, step: 2, Train: label_loss: 0.0828486979007721, precision: 0.2999999999999821, recall: 0.9163636363634696, f1: 0.4520179371825289\n",
            "epoch: 903, step: 3, Train: label_loss: 0.0682186633348465, precision: 0.3351001177856104, recall: 0.9343185550080567, f1: 0.4932813176897503\n",
            "epoch: 903, step: 4, Train: label_loss: 0.08137771487236023, precision: 0.31389870435804984, recall: 0.9049235993207292, f1: 0.4661128115052231\n",
            "epoch: 903, step: 5, Train: label_loss: 0.08042493462562561, precision: 0.3347255369928201, recall: 0.8933121019106857, f1: 0.48697916662696933\n",
            "epoch: 903, step: 6, Train: label_loss: 0.06848879903554916, precision: 0.3267326732673077, recall: 0.9349999999998441, f1: 0.4842468709153983\n",
            "epoch: 903, step: 7, Train: label_loss: 0.05346941202878952, precision: 0.35153980244042116, recall: 0.939440993788674, f1: 0.5116279069370699\n",
            "epoch: 903, step: 8, Train: label_loss: 0.08550512790679932, precision: 0.31644815256255565, recall: 0.9030612244896423, f1: 0.46866725503655\n",
            "epoch: 903, step: 9, Train: label_loss: 0.07806674391031265, precision: 0.30946745562128347, recall: 0.9143356643355044, f1: 0.4624226347986014\n",
            "epoch: 903, step: 10, Train: label_loss: 0.07895796746015549, precision: 0.32130177514791, recall: 0.9156829679593733, f1: 0.4756898816960625\n",
            "epoch: 903, step: 11, Train: label_loss: 0.08238312602043152, precision: 0.30673758865246414, recall: 0.9251336898394072, f1: 0.46071904124085483\n",
            "epoch: 903, step: 12, Train: label_loss: 0.06997045874595642, precision: 0.3481613285883542, recall: 0.9100775193797038, f1: 0.5036465036064326\n",
            "epoch: 903, step: 13, Train: label_loss: 0.08046688884496689, precision: 0.31279342723002856, recall: 0.9064625850338593, f1: 0.46509598600020796\n",
            "epoch: 903, step: 14, Train: label_loss: 0.08838917315006256, precision: 0.32132309509744117, recall: 0.9220338983049284, f1: 0.4765659219940428\n",
            "epoch: 903, step: 15, Train: label_loss: 0.08238612115383148, precision: 0.3214285714285523, recall: 0.8970099667772595, f1: 0.47326906218723364\n",
            "epoch: 903, step: 16, Train: label_loss: 0.08452173322439194, precision: 0.3274231678486804, recall: 0.9295302013421258, f1: 0.484265734227165\n",
            "epoch: 903, step: 17, Train: label_loss: 0.07721427083015442, precision: 0.33432304038002764, recall: 0.9022435897434451, f1: 0.48786828418927375\n",
            "epoch: 903, step: 18, Train: label_loss: 0.08046351373195648, precision: 0.3297872340425337, recall: 0.9087947882734676, f1: 0.4839549002210755\n",
            "epoch: 903, step: 19, Train: label_loss: 0.07422306388616562, precision: 0.3298245614034895, recall: 0.9276315789472158, f1: 0.4866264020320094\n",
            "epoch: 903, step: 20, Train: label_loss: 0.07500982284545898, precision: 0.3073313782991022, recall: 0.9192982456138737, f1: 0.4606593406217452\n",
            "epoch: 903, step: 21, Train: label_loss: 0.07460340857505798, precision: 0.3274021352312973, recall: 0.8860353130014629, f1: 0.47812906015977613\n",
            "epoch: 903, step: 22, Train: label_loss: 0.07969717681407928, precision: 0.327197149643686, recall: 0.9092409240922591, f1: 0.4812227073846187\n",
            "epoch: 903, step: 23, Train: label_loss: 0.0745893269777298, precision: 0.3554434030280926, recall: 0.9180633147111884, f1: 0.5124740124337179\n",
            "epoch: 904, step: 0, Train: label_loss: 0.07236388325691223, precision: 0.31853167554764245, recall: 0.8922056384741471, f1: 0.46945898774477945\n",
            "epoch: 904, step: 1, Train: label_loss: 0.08371856063604355, precision: 0.31473869641806723, recall: 0.9162393162391596, f1: 0.46853146849336585\n",
            "epoch: 904, step: 2, Train: label_loss: 0.07504066079854965, precision: 0.3258426966291942, recall: 0.9107438016527419, f1: 0.4799651567555695\n",
            "epoch: 904, step: 3, Train: label_loss: 0.07906270772218704, precision: 0.32486709982278056, recall: 0.9151414309482669, f1: 0.4795117697956386\n",
            "epoch: 904, step: 4, Train: label_loss: 0.0885261744260788, precision: 0.30979228486645044, recall: 0.8953687821610813, f1: 0.46031746027922416\n",
            "epoch: 904, step: 5, Train: label_loss: 0.08038362860679626, precision: 0.3198332340678785, recall: 0.9070945945944413, f1: 0.4729194187196696\n",
            "epoch: 904, step: 6, Train: label_loss: 0.0780496671795845, precision: 0.32958579881654854, recall: 0.9191419141912675, f1: 0.4851916375917648\n",
            "epoch: 904, step: 7, Train: label_loss: 0.08208925276994705, precision: 0.3254156769596006, recall: 0.9102990033221079, f1: 0.47944006995241045\n",
            "epoch: 904, step: 8, Train: label_loss: 0.07169359922409058, precision: 0.3409893992932661, recall: 0.9190476190474731, f1: 0.49742268037285153\n",
            "epoch: 904, step: 9, Train: label_loss: 0.08698450028896332, precision: 0.3371121718376887, recall: 0.9069020866772219, f1: 0.4915180512871103\n",
            "epoch: 904, step: 10, Train: label_loss: 0.08231036365032196, precision: 0.3128358208955037, recall: 0.8821548821547336, f1: 0.46187747902697585\n",
            "epoch: 904, step: 11, Train: label_loss: 0.06825396418571472, precision: 0.3254855797527766, recall: 0.9309764309762741, f1: 0.48233754902393305\n",
            "epoch: 904, step: 12, Train: label_loss: 0.07663522660732269, precision: 0.32337434094901446, recall: 0.9215358931551049, f1: 0.4787510840898626\n",
            "epoch: 904, step: 13, Train: label_loss: 0.06219671666622162, precision: 0.3360560093348695, recall: 0.9186602870811932, f1: 0.4920973942366885\n",
            "epoch: 904, step: 14, Train: label_loss: 0.07903045415878296, precision: 0.3417796110783535, recall: 0.9090909090907665, f1: 0.49678800852555255\n",
            "epoch: 904, step: 15, Train: label_loss: 0.07952447235584259, precision: 0.3232502965598859, recall: 0.9083333333331819, f1: 0.4768153980364832\n",
            "epoch: 904, step: 16, Train: label_loss: 0.06701482832431793, precision: 0.3077373974208495, recall: 0.9226713532511559, f1: 0.46153846150091\n",
            "epoch: 904, step: 17, Train: label_loss: 0.07727264612913132, precision: 0.32115497937534937, recall: 0.9159663865544678, f1: 0.4755671901883931\n",
            "epoch: 904, step: 18, Train: label_loss: 0.07381105422973633, precision: 0.29852507374629506, recall: 0.9019607843135646, f1: 0.4485815602462815\n",
            "epoch: 904, step: 19, Train: label_loss: 0.071334108710289, precision: 0.3281159420289665, recall: 0.9401993355480165, f1: 0.4864632573745811\n",
            "epoch: 904, step: 20, Train: label_loss: 0.08403429388999939, precision: 0.31753554502367787, recall: 0.9069373942468854, f1: 0.47038174634153496\n",
            "epoch: 904, step: 21, Train: label_loss: 0.08825899660587311, precision: 0.31052944675786376, recall: 0.8984509466435631, f1: 0.46153846150024486\n",
            "epoch: 904, step: 22, Train: label_loss: 0.08016093075275421, precision: 0.34447761194027793, recall: 0.8876923076921711, f1: 0.49634408598118046\n",
            "epoch: 904, step: 23, Train: label_loss: 0.07519233971834183, precision: 0.32104121475051905, recall: 0.9098360655735841, f1: 0.4746125066423097\n",
            "epoch: 905, step: 0, Train: label_loss: 0.07074834406375885, precision: 0.30256104824298374, recall: 0.9055258467021559, f1: 0.4535714285338434\n",
            "epoch: 905, step: 1, Train: label_loss: 0.08467209339141846, precision: 0.3147268408550882, recall: 0.8907563025208586, f1: 0.4651162790311432\n",
            "epoch: 905, step: 2, Train: label_loss: 0.07279831916093826, precision: 0.336873156342163, recall: 0.9194847020932496, f1: 0.4930915370936976\n",
            "epoch: 905, step: 3, Train: label_loss: 0.07973218709230423, precision: 0.3478773584905455, recall: 0.9204368174725552, f1: 0.5049208386422174\n",
            "epoch: 905, step: 4, Train: label_loss: 0.06910119205713272, precision: 0.3249266862169897, recall: 0.9264214046821193, f1: 0.4811115935351104\n",
            "epoch: 905, step: 5, Train: label_loss: 0.06643419712781906, precision: 0.33234946871308546, recall: 0.9124797406805651, f1: 0.4872349631802027\n",
            "epoch: 905, step: 6, Train: label_loss: 0.08067911863327026, precision: 0.3106682297772385, recall: 0.9380530973449667, f1: 0.46675473356011443\n",
            "epoch: 905, step: 7, Train: label_loss: 0.09060636907815933, precision: 0.3329334133173166, recall: 0.8781645569618863, f1: 0.48281861675000054\n",
            "epoch: 905, step: 8, Train: label_loss: 0.08650138974189758, precision: 0.32208407341620354, recall: 0.9158249158247616, f1: 0.4765659219938741\n",
            "epoch: 905, step: 9, Train: label_loss: 0.06804713606834412, precision: 0.32631578947366513, recall: 0.9223140495866243, f1: 0.4820734340866201\n",
            "epoch: 905, step: 10, Train: label_loss: 0.07783879339694977, precision: 0.29894490035168236, recall: 0.9172661870501947, f1: 0.4509283819257484\n",
            "epoch: 905, step: 11, Train: label_loss: 0.08142155408859253, precision: 0.3359004739336294, recall: 0.9159935379643107, f1: 0.49154746419996487\n",
            "epoch: 905, step: 12, Train: label_loss: 0.08070388436317444, precision: 0.33431952662719916, recall: 0.9069020866772219, f1: 0.48854301768649494\n",
            "epoch: 905, step: 13, Train: label_loss: 0.07585272192955017, precision: 0.31625967837996927, recall: 0.9123711340204618, f1: 0.46970367090378967\n",
            "epoch: 905, step: 14, Train: label_loss: 0.07647274434566498, precision: 0.3269916765754859, recall: 0.9306260575294533, f1: 0.48394192693024024\n",
            "epoch: 905, step: 15, Train: label_loss: 0.08190761506557465, precision: 0.31421744324968254, recall: 0.8900169204736226, f1: 0.464459161109293\n",
            "epoch: 905, step: 16, Train: label_loss: 0.08163027465343475, precision: 0.34462269756385355, recall: 0.9206349206347745, f1: 0.5015131862984085\n",
            "epoch: 905, step: 17, Train: label_loss: 0.07112443447113037, precision: 0.30647058823527606, recall: 0.9045138888887317, f1: 0.4578207380992367\n",
            "epoch: 905, step: 18, Train: label_loss: 0.08851580321788788, precision: 0.3299340131973407, recall: 0.8885298869142344, f1: 0.4811898512290578\n",
            "epoch: 905, step: 19, Train: label_loss: 0.08503840118646622, precision: 0.31377245508980156, recall: 0.8926746166949074, f1: 0.4643331856061322\n",
            "epoch: 905, step: 20, Train: label_loss: 0.07870517671108246, precision: 0.3393903868698511, recall: 0.9293739967895779, f1: 0.49720910257991857\n",
            "epoch: 905, step: 21, Train: label_loss: 0.08810168504714966, precision: 0.3219540906415349, recall: 0.9131886477460912, f1: 0.47606614443487033\n",
            "epoch: 905, step: 22, Train: label_loss: 0.09191910922527313, precision: 0.3267504488330146, recall: 0.8921568627449522, f1: 0.4783180025888375\n",
            "epoch: 905, step: 23, Train: label_loss: 0.08978523313999176, precision: 0.313357400721999, recall: 0.9004149377591493, f1: 0.4649169790725197\n",
            "epoch: 906, step: 0, Train: label_loss: 0.09399102628231049, precision: 0.30600118835411133, recall: 0.8925476603118037, f1: 0.4557522123513148\n",
            "epoch: 906, step: 1, Train: label_loss: 0.07521094381809235, precision: 0.33114166168557496, recall: 0.8765822784808739, f1: 0.4806941431271849\n",
            "epoch: 906, step: 2, Train: label_loss: 0.06995507329702377, precision: 0.33980011757787537, recall: 0.9131121642968542, f1: 0.49528706080018675\n",
            "epoch: 906, step: 3, Train: label_loss: 0.07639859616756439, precision: 0.3307508939213152, recall: 0.902439024390097, f1: 0.4840819886218459\n",
            "epoch: 906, step: 4, Train: label_loss: 0.07476536184549332, precision: 0.3052445492044605, recall: 0.9217081850532167, f1: 0.4586100043893189\n",
            "epoch: 906, step: 5, Train: label_loss: 0.07548224925994873, precision: 0.335689045936376, recall: 0.9105431309902698, f1: 0.49053356278331595\n",
            "epoch: 906, step: 6, Train: label_loss: 0.0688176155090332, precision: 0.33411903358866624, recall: 0.9402985074625305, f1: 0.49304347822213895\n",
            "epoch: 906, step: 7, Train: label_loss: 0.07692133635282516, precision: 0.3198332340678785, recall: 0.9055649241145184, f1: 0.472711267567016\n",
            "epoch: 906, step: 8, Train: label_loss: 0.09529966115951538, precision: 0.3158208955223692, recall: 0.8890756302519514, f1: 0.46607929511546187\n",
            "epoch: 906, step: 9, Train: label_loss: 0.09209854900836945, precision: 0.31726190476188587, recall: 0.9158075601372996, f1: 0.4712643677778315\n",
            "epoch: 906, step: 10, Train: label_loss: 0.0823960229754448, precision: 0.3197640117993912, recall: 0.928082191780663, f1: 0.4756472136520558\n",
            "epoch: 906, step: 11, Train: label_loss: 0.07289835810661316, precision: 0.3279952550414989, recall: 0.9170812603646903, f1: 0.483180428095707\n",
            "epoch: 906, step: 12, Train: label_loss: 0.0956987589597702, precision: 0.31295399515736605, recall: 0.8733108108106632, f1: 0.46078431368660583\n",
            "epoch: 906, step: 13, Train: label_loss: 0.07443709671497345, precision: 0.3226761397276304, recall: 0.9083333333331819, f1: 0.4761904761517516\n",
            "epoch: 906, step: 14, Train: label_loss: 0.07828285545110703, precision: 0.3087971274685632, recall: 0.89739130434767, f1: 0.45948352623078775\n",
            "epoch: 906, step: 15, Train: label_loss: 0.07624447345733643, precision: 0.3319477434679138, recall: 0.9089430894307464, f1: 0.486298390565379\n",
            "epoch: 906, step: 16, Train: label_loss: 0.06955525279045105, precision: 0.3142188414277171, recall: 0.9163822525595705, f1: 0.4679738561710815\n",
            "epoch: 906, step: 17, Train: label_loss: 0.08683224022388458, precision: 0.3193529059316765, recall: 0.8809917355370444, f1: 0.4687774845695243\n",
            "epoch: 906, step: 18, Train: label_loss: 0.06648090481758118, precision: 0.33116113744073866, recall: 0.9119086460031138, f1: 0.4858757061755603\n",
            "epoch: 906, step: 19, Train: label_loss: 0.07713258266448975, precision: 0.3204678362572912, recall: 0.9225589225587671, f1: 0.4756944444061341\n",
            "epoch: 906, step: 20, Train: label_loss: 0.06492412835359573, precision: 0.3308051341890122, recall: 0.9159935379643107, f1: 0.486069438452186\n",
            "epoch: 906, step: 21, Train: label_loss: 0.07005278766155243, precision: 0.3353045535186082, recall: 0.899999999999857, f1: 0.48858250750025983\n",
            "epoch: 906, step: 22, Train: label_loss: 0.09276410937309265, precision: 0.31694312796206653, recall: 0.9021922428329001, f1: 0.46909250324951296\n",
            "epoch: 906, step: 23, Train: label_loss: 0.08952230960130692, precision: 0.32111436950144273, recall: 0.8902439024388434, f1: 0.47198275858167565\n",
            "epoch: 907, step: 0, Train: label_loss: 0.07594265043735504, precision: 0.31619385342787726, recall: 0.9067796610167954, f1: 0.46888694124119823\n",
            "epoch: 907, step: 1, Train: label_loss: 0.07039190828800201, precision: 0.34462616822427894, recall: 0.9247648902819866, f1: 0.5021276595348688\n",
            "epoch: 907, step: 2, Train: label_loss: 0.07413727790117264, precision: 0.33254156769594223, recall: 0.9165302782322559, f1: 0.48801742915478685\n",
            "epoch: 907, step: 3, Train: label_loss: 0.08198969066143036, precision: 0.3121319199057531, recall: 0.9298245614033456, f1: 0.46737213400112754\n",
            "epoch: 907, step: 4, Train: label_loss: 0.06619110703468323, precision: 0.34199645599525447, recall: 0.9249201277953794, f1: 0.4993531694301411\n",
            "epoch: 907, step: 5, Train: label_loss: 0.08185312151908875, precision: 0.3236857649143341, recall: 0.9163879598660675, f1: 0.47839371449651785\n",
            "epoch: 907, step: 6, Train: label_loss: 0.08687081933021545, precision: 0.3181008902076963, recall: 0.9023569023567504, f1: 0.4703817463414085\n",
            "epoch: 907, step: 7, Train: label_loss: 0.08650551736354828, precision: 0.3360800470865017, recall: 0.93148450244683, f1: 0.4939446366391899\n",
            "epoch: 907, step: 8, Train: label_loss: 0.07300493866205215, precision: 0.3276370064820078, recall: 0.9159802306423531, f1: 0.48263888885003764\n",
            "epoch: 907, step: 9, Train: label_loss: 0.06930366158485413, precision: 0.336668628605042, recall: 0.9315960912050599, f1: 0.4945957630392127\n",
            "epoch: 907, step: 10, Train: label_loss: 0.08043991029262543, precision: 0.31557134399050824, recall: 0.8913043478259378, f1: 0.46611281150484457\n",
            "epoch: 907, step: 11, Train: label_loss: 0.08336694538593292, precision: 0.3164179104477423, recall: 0.905982905982751, f1: 0.46902654863415555\n",
            "epoch: 907, step: 12, Train: label_loss: 0.08438573777675629, precision: 0.32354703415216757, recall: 0.8970099667772595, f1: 0.4755614266452755\n",
            "epoch: 907, step: 13, Train: label_loss: 0.07658128440380096, precision: 0.3222026947861557, recall: 0.91362126245832, f1: 0.4763967084932418\n",
            "epoch: 907, step: 14, Train: label_loss: 0.07503299415111542, precision: 0.33037300177617934, recall: 0.9043760129658177, f1: 0.4839549002209542\n",
            "epoch: 907, step: 15, Train: label_loss: 0.07328358292579651, precision: 0.32235294117645164, recall: 0.9335604770015444, f1: 0.4792304328433043\n",
            "epoch: 907, step: 16, Train: label_loss: 0.06922901421785355, precision: 0.32882352941174536, recall: 0.917898193760112, f1: 0.4841922909962009\n",
            "epoch: 907, step: 17, Train: label_loss: 0.07482841610908508, precision: 0.3204678362572912, recall: 0.9210084033611897, f1: 0.4754880693759752\n",
            "epoch: 907, step: 18, Train: label_loss: 0.07009702175855637, precision: 0.31863609641385543, recall: 0.928082191780663, f1: 0.47439824941486064\n",
            "epoch: 907, step: 19, Train: label_loss: 0.0870760828256607, precision: 0.31212841854932744, recall: 0.8959044368599153, f1: 0.4629629629245984\n",
            "epoch: 907, step: 20, Train: label_loss: 0.07327058911323547, precision: 0.32392710170486044, recall: 0.9092409240922591, f1: 0.4776766362854534\n",
            "epoch: 907, step: 21, Train: label_loss: 0.08142869174480438, precision: 0.30463182897860425, recall: 0.9015817223197009, f1: 0.4553928095494227\n",
            "epoch: 907, step: 22, Train: label_loss: 0.08532020449638367, precision: 0.31866825208083716, recall: 0.9054054054052524, f1: 0.4714160069975063\n",
            "epoch: 907, step: 23, Train: label_loss: 0.07918854057788849, precision: 0.3449781659388395, recall: 0.901140684410475, f1: 0.49894736838095993\n",
            "epoch: 908, step: 0, Train: label_loss: 0.08390936255455017, precision: 0.31091445427726777, recall: 0.9086206896550156, f1: 0.4632967032586729\n",
            "epoch: 908, step: 1, Train: label_loss: 0.08104181289672852, precision: 0.3317507418397429, recall: 0.9089430894307464, f1: 0.4860869564825182\n",
            "epoch: 908, step: 2, Train: label_loss: 0.07688231766223907, precision: 0.31075460487223344, recall: 0.8849407783416438, f1: 0.4599824098119733\n",
            "epoch: 908, step: 3, Train: label_loss: 0.07065471261739731, precision: 0.3321470937129103, recall: 0.9210526315787958, f1: 0.4882301656105192\n",
            "epoch: 908, step: 4, Train: label_loss: 0.07831461727619171, precision: 0.3036556603773406, recall: 0.9196428571426929, f1: 0.45656028365058077\n",
            "epoch: 908, step: 5, Train: label_loss: 0.06918231397867203, precision: 0.33703271028035414, recall: 0.9291465378420404, f1: 0.4946420916882815\n",
            "epoch: 908, step: 6, Train: label_loss: 0.0738605260848999, precision: 0.33216374269003907, recall: 0.9235772357722075, f1: 0.48860215049868294\n",
            "epoch: 908, step: 7, Train: label_loss: 0.07464811205863953, precision: 0.31644077784323416, recall: 0.9210977701542159, f1: 0.4710526315408423\n",
            "epoch: 908, step: 8, Train: label_loss: 0.0743984803557396, precision: 0.3137603795966599, recall: 0.8875838926173006, f1: 0.4636283961051005\n",
            "epoch: 908, step: 9, Train: label_loss: 0.07226694375276566, precision: 0.32863021751908705, recall: 0.9224422442242701, f1: 0.4846120502429734\n",
            "epoch: 908, step: 10, Train: label_loss: 0.06730935722589493, precision: 0.3122786304604302, recall: 0.9232111692843066, f1: 0.46669607406893365\n",
            "epoch: 908, step: 11, Train: label_loss: 0.07955598086118698, precision: 0.3448071216617006, recall: 0.9063962558500925, f1: 0.4995700773461003\n",
            "epoch: 908, step: 12, Train: label_loss: 0.09388147294521332, precision: 0.31625967837996927, recall: 0.8969594594593079, f1: 0.4676354028676225\n",
            "epoch: 908, step: 13, Train: label_loss: 0.08648501336574554, precision: 0.3212803793716466, recall: 0.9033333333331827, f1: 0.473983384307559\n",
            "epoch: 908, step: 14, Train: label_loss: 0.07971310615539551, precision: 0.3152238805969961, recall: 0.890387858347236, f1: 0.4656084655698044\n",
            "epoch: 908, step: 15, Train: label_loss: 0.08383747935295105, precision: 0.3341162654139557, recall: 0.9147909967844188, f1: 0.4894623655521645\n",
            "epoch: 908, step: 16, Train: label_loss: 0.08473312854766846, precision: 0.31246308328409256, recall: 0.9042735042733496, f1: 0.4644424933770645\n",
            "epoch: 908, step: 17, Train: label_loss: 0.07772437483072281, precision: 0.3418701608099856, recall: 0.9010989010987596, f1: 0.4956822106681957\n",
            "epoch: 908, step: 18, Train: label_loss: 0.08160948753356934, precision: 0.3420427553443977, recall: 0.9085173501575854, f1: 0.496980155266515\n",
            "epoch: 908, step: 19, Train: label_loss: 0.08441973477602005, precision: 0.3201650943396038, recall: 0.9219015280134257, f1: 0.47527352293762365\n",
            "epoch: 908, step: 20, Train: label_loss: 0.09002050757408142, precision: 0.3163204747774293, recall: 0.9126712328765559, f1: 0.46981048916402296\n",
            "epoch: 908, step: 21, Train: label_loss: 0.08160476386547089, precision: 0.33115727002965395, recall: 0.9087947882734676, f1: 0.485428447111744\n",
            "epoch: 908, step: 22, Train: label_loss: 0.0868358165025711, precision: 0.3176400476757856, recall: 0.9173838209981209, f1: 0.47189021687188637\n",
            "epoch: 908, step: 23, Train: label_loss: 0.07895210385322571, precision: 0.32806891600859095, recall: 0.9158316633264698, f1: 0.48308668072221184\n",
            "epoch: 909, step: 0, Train: label_loss: 0.08073251694440842, precision: 0.3309817754262004, recall: 0.9305785123965403, f1: 0.4882914136646347\n",
            "epoch: 909, step: 1, Train: label_loss: 0.07661434262990952, precision: 0.3167848699763406, recall: 0.92573402417946, f1: 0.4720387494115496\n",
            "epoch: 909, step: 2, Train: label_loss: 0.082791268825531, precision: 0.32064247471741103, recall: 0.89386401326685, f1: 0.4719789841992755\n",
            "epoch: 909, step: 3, Train: label_loss: 0.08664360642433167, precision: 0.33234244946490293, recall: 0.9030694668819219, f1: 0.485875706175318\n",
            "epoch: 909, step: 4, Train: label_loss: 0.0767609179019928, precision: 0.3265913146936153, recall: 0.9059405940592564, f1: 0.4801049409317093\n",
            "epoch: 909, step: 5, Train: label_loss: 0.08252892643213272, precision: 0.3219628964691609, recall: 0.9026845637582377, f1: 0.4746360828901823\n",
            "epoch: 909, step: 6, Train: label_loss: 0.07072563469409943, precision: 0.3380530973451128, recall: 0.9124203821654597, f1: 0.4933275935894343\n",
            "epoch: 909, step: 7, Train: label_loss: 0.08827540278434753, precision: 0.3113377324534906, recall: 0.8994800693239342, f1: 0.462566844881542\n",
            "epoch: 909, step: 8, Train: label_loss: 0.08856676518917084, precision: 0.3254577672770038, recall: 0.9062499999998509, f1: 0.4789222076968427\n",
            "epoch: 909, step: 9, Train: label_loss: 0.08147900551557541, precision: 0.3295249549007619, recall: 0.8983606557375576, f1: 0.482182138104111\n",
            "epoch: 909, step: 10, Train: label_loss: 0.08035536110401154, precision: 0.3409893992932661, recall: 0.9132492113563228, f1: 0.4965694682279475\n",
            "epoch: 909, step: 11, Train: label_loss: 0.07469762861728668, precision: 0.30501474926251887, recall: 0.9134275618372943, f1: 0.4573197699756948\n",
            "epoch: 909, step: 12, Train: label_loss: 0.08583775162696838, precision: 0.2970885323826324, recall: 0.9074410163337735, f1: 0.44762757382134766\n",
            "epoch: 909, step: 13, Train: label_loss: 0.07225882261991501, precision: 0.3177790903721017, recall: 0.8966666666665172, f1: 0.4692542520328417\n",
            "epoch: 909, step: 14, Train: label_loss: 0.08058981597423553, precision: 0.31468110709986075, recall: 0.8834459459457966, f1: 0.4640638863853613\n",
            "epoch: 909, step: 15, Train: label_loss: 0.08570347726345062, precision: 0.29756965026672805, recall: 0.8916518650087225, f1: 0.44622222218466034\n",
            "epoch: 909, step: 16, Train: label_loss: 0.07054351270198822, precision: 0.3305882352940982, recall: 0.9093851132684612, f1: 0.48490077649234514\n",
            "epoch: 909, step: 17, Train: label_loss: 0.08438585698604584, precision: 0.2989690721649303, recall: 0.8456260720410212, f1: 0.4417562723627991\n",
            "epoch: 909, step: 18, Train: label_loss: 0.07163232564926147, precision: 0.3355029585798618, recall: 0.9145161290321105, f1: 0.4909090908697763\n",
            "epoch: 909, step: 19, Train: label_loss: 0.08081068098545074, precision: 0.3425381903642572, recall: 0.9123630672925019, f1: 0.49807774451387643\n",
            "epoch: 909, step: 20, Train: label_loss: 0.0734507143497467, precision: 0.33078281341963917, recall: 0.9064516129030795, f1: 0.4846916774079583\n",
            "epoch: 909, step: 21, Train: label_loss: 0.07549715042114258, precision: 0.3472385428906964, recall: 0.9205607476634079, f1: 0.5042662115642776\n",
            "epoch: 909, step: 22, Train: label_loss: 0.08877940475940704, precision: 0.3138905592302878, recall: 0.8999999999998448, f1: 0.4654480605946957\n",
            "epoch: 909, step: 23, Train: label_loss: 0.07136283069849014, precision: 0.32352941176468264, recall: 0.9395833333331376, f1: 0.4813233724271572\n",
            "epoch: 910, step: 0, Train: label_loss: 0.08302962779998779, precision: 0.314759928867794, recall: 0.8999999999998474, f1: 0.4664031620169003\n",
            "epoch: 910, step: 1, Train: label_loss: 0.06778901815414429, precision: 0.3178613396004514, recall: 0.9185059422748865, f1: 0.4722828458805723\n",
            "epoch: 910, step: 2, Train: label_loss: 0.08930985629558563, precision: 0.3085169743894992, recall: 0.8977469670709015, f1: 0.4592198581179181\n",
            "epoch: 910, step: 3, Train: label_loss: 0.07400234043598175, precision: 0.3353186420488186, recall: 0.9036918138040282, f1: 0.489139878327117\n",
            "epoch: 910, step: 4, Train: label_loss: 0.06912785023450851, precision: 0.3101045296167067, recall: 0.940140845070257, f1: 0.46637554581418483\n",
            "epoch: 910, step: 5, Train: label_loss: 0.07695121318101883, precision: 0.3448071216617006, recall: 0.9178515007897443, f1: 0.5012942191146987\n",
            "epoch: 910, step: 6, Train: label_loss: 0.07912556082010269, precision: 0.3212803793716466, recall: 0.9063545150500156, f1: 0.4743982494142693\n",
            "epoch: 910, step: 7, Train: label_loss: 0.07573041319847107, precision: 0.32107413893751774, recall: 0.9274873524450374, f1: 0.4770164787128375\n",
            "epoch: 910, step: 8, Train: label_loss: 0.08593924343585968, precision: 0.3214285714285523, recall: 0.9106239460369459, f1: 0.47514298280345196\n",
            "epoch: 910, step: 9, Train: label_loss: 0.07883425801992416, precision: 0.3115044247787427, recall: 0.9166666666665074, f1: 0.4649933949422833\n",
            "epoch: 910, step: 10, Train: label_loss: 0.08307118713855743, precision: 0.31389870435804984, recall: 0.9064625850338593, f1: 0.4663167103729464\n",
            "epoch: 910, step: 11, Train: label_loss: 0.06980955600738525, precision: 0.3309776207302514, recall: 0.9064516129030795, f1: 0.4849007764922646\n",
            "epoch: 910, step: 12, Train: label_loss: 0.08244147896766663, precision: 0.33862433862431873, recall: 0.9230769230767751, f1: 0.49548387092842827\n",
            "epoch: 910, step: 13, Train: label_loss: 0.07602812349796295, precision: 0.3242117787031336, recall: 0.8861788617884737, f1: 0.4747386759189249\n",
            "epoch: 910, step: 14, Train: label_loss: 0.07013924419879913, precision: 0.3289863663307452, recall: 0.9009740259738797, f1: 0.4819800260137459\n",
            "epoch: 910, step: 15, Train: label_loss: 0.07466618716716766, precision: 0.3345070422535015, recall: 0.919354838709529, f1: 0.4905335627835553\n",
            "epoch: 910, step: 16, Train: label_loss: 0.07590065896511078, precision: 0.3467836257309739, recall: 0.9280125195616701, f1: 0.5048957002583502\n",
            "epoch: 910, step: 17, Train: label_loss: 0.08380375802516937, precision: 0.31962397179786606, recall: 0.9158249158247616, f1: 0.47386759578041804\n",
            "epoch: 910, step: 18, Train: label_loss: 0.081991046667099, precision: 0.32202380952379034, recall: 0.9061976549412216, f1: 0.4751866490609618\n",
            "epoch: 910, step: 19, Train: label_loss: 0.07617896050214767, precision: 0.316478286734068, recall: 0.9094017094015538, f1: 0.4695498675697755\n",
            "epoch: 910, step: 20, Train: label_loss: 0.07924346625804901, precision: 0.33019423190109887, recall: 0.9092382495946661, f1: 0.48445595851009404\n",
            "epoch: 910, step: 21, Train: label_loss: 0.09207075834274292, precision: 0.3151658767772325, recall: 0.9047619047617508, f1: 0.46748681894230587\n",
            "epoch: 910, step: 22, Train: label_loss: 0.07320248335599899, precision: 0.33333333333331366, recall: 0.9157212317664641, f1: 0.48875432522034334\n",
            "epoch: 910, step: 23, Train: label_loss: 0.07614296674728394, precision: 0.30406386066761215, recall: 0.9128540305008904, f1: 0.4561785519493991\n",
            "epoch: 911, step: 0, Train: label_loss: 0.07071425765752792, precision: 0.32488207547167897, recall: 0.9214046822740933, f1: 0.48038360937728036\n",
            "epoch: 911, step: 1, Train: label_loss: 0.08364123106002808, precision: 0.34221432800471624, recall: 0.907378335949622, f1: 0.4969905416626786\n",
            "epoch: 911, step: 2, Train: label_loss: 0.06560565531253815, precision: 0.2961448598130668, recall: 0.9302752293576274, f1: 0.4492689410355474\n",
            "epoch: 911, step: 3, Train: label_loss: 0.08080685883760452, precision: 0.3305833824395798, recall: 0.9196721311473901, f1: 0.48634590373218944\n",
            "epoch: 911, step: 4, Train: label_loss: 0.07552935183048248, precision: 0.31597633136092806, recall: 0.9050847457625584, f1: 0.46842105259317607\n",
            "epoch: 911, step: 5, Train: label_loss: 0.08429360389709473, precision: 0.30970815961880227, recall: 0.8996539792385986, f1: 0.46078865747182635\n",
            "epoch: 911, step: 6, Train: label_loss: 0.09060666710138321, precision: 0.32192192192190255, recall: 0.8978224455609886, f1: 0.47391688767109535\n",
            "epoch: 911, step: 7, Train: label_loss: 0.08398003876209259, precision: 0.30970815961880227, recall: 0.8843537414964482, f1: 0.4587560652460567\n",
            "epoch: 911, step: 8, Train: label_loss: 0.07466402649879456, precision: 0.311942959001764, recall: 0.902061855669948, f1: 0.46357615890217074\n",
            "epoch: 911, step: 9, Train: label_loss: 0.0708029717206955, precision: 0.3266627427898572, recall: 0.9083469721766106, f1: 0.4805194804805307\n",
            "epoch: 911, step: 10, Train: label_loss: 0.0937037393450737, precision: 0.3365041617122273, recall: 0.9027113237638114, f1: 0.49025552183133553\n",
            "epoch: 911, step: 11, Train: label_loss: 0.08089074492454529, precision: 0.3463126843657613, recall: 0.9287974683542833, f1: 0.5045122474893978\n",
            "epoch: 911, step: 12, Train: label_loss: 0.08339688181877136, precision: 0.3267622461170653, recall: 0.8794212218648103, f1: 0.476480836197389\n",
            "epoch: 911, step: 13, Train: label_loss: 0.06486169993877411, precision: 0.33884297520659157, recall: 0.9140127388533575, f1: 0.49440137808280377\n",
            "epoch: 911, step: 14, Train: label_loss: 0.07336579263210297, precision: 0.32379248658316495, recall: 0.8945634266884852, f1: 0.4754816111693381\n",
            "epoch: 911, step: 15, Train: label_loss: 0.07534623146057129, precision: 0.30891907855875317, recall: 0.9207746478871618, f1: 0.46262715608794597\n",
            "epoch: 911, step: 16, Train: label_loss: 0.08014820516109467, precision: 0.31966726084371244, recall: 0.8996655518393144, f1: 0.4717229285013857\n",
            "epoch: 911, step: 17, Train: label_loss: 0.07655420899391174, precision: 0.30746619635506717, recall: 0.9143356643355044, f1: 0.46018477778895583\n",
            "epoch: 911, step: 18, Train: label_loss: 0.07885625213384628, precision: 0.3242603550295666, recall: 0.904290429042755, f1: 0.4773519163374102\n",
            "epoch: 911, step: 19, Train: label_loss: 0.09035009145736694, precision: 0.31997607655500476, recall: 0.8857615894038268, f1: 0.4701230228080684\n",
            "epoch: 911, step: 20, Train: label_loss: 0.07855938374996185, precision: 0.3213859020310441, recall: 0.8892561983469603, f1: 0.4721369021110255\n",
            "epoch: 911, step: 21, Train: label_loss: 0.09248563647270203, precision: 0.32635983263596374, recall: 0.8878048780486361, f1: 0.47727272723337677\n",
            "epoch: 911, step: 22, Train: label_loss: 0.0737202912569046, precision: 0.3196960841612905, recall: 0.9302721088433792, f1: 0.47585906912239345\n",
            "epoch: 911, step: 23, Train: label_loss: 0.07539404183626175, precision: 0.33908045977009055, recall: 0.9236790606651814, f1: 0.49605885440102143\n",
            "epoch: 912, step: 0, Train: label_loss: 0.0867680013179779, precision: 0.311942959001764, recall: 0.8974358974357439, f1: 0.46296296292464106\n",
            "epoch: 912, step: 1, Train: label_loss: 0.07180742174386978, precision: 0.33684827182189003, recall: 0.9289176090466996, f1: 0.4944110059798138\n",
            "epoch: 912, step: 2, Train: label_loss: 0.07333431392908096, precision: 0.3360897814530221, recall: 0.9060509554138684, f1: 0.49030590258866263\n",
            "epoch: 912, step: 3, Train: label_loss: 0.07371196150779724, precision: 0.3299941072480654, recall: 0.9256198347105907, f1: 0.48653344913583985\n",
            "epoch: 912, step: 4, Train: label_loss: 0.07564480602741241, precision: 0.33274021352311195, recall: 0.9211822660097009, f1: 0.4888888888498575\n",
            "epoch: 912, step: 5, Train: label_loss: 0.06632199138402939, precision: 0.32044522554186755, recall: 0.9255499153974744, f1: 0.47606614443520606\n",
            "epoch: 912, step: 6, Train: label_loss: 0.07852007448673248, precision: 0.345838218053907, recall: 0.9218749999998559, f1: 0.5029838021768194\n",
            "epoch: 912, step: 7, Train: label_loss: 0.06682885438203812, precision: 0.32767700409594336, recall: 0.9286898839136104, f1: 0.48442906570534483\n",
            "epoch: 912, step: 8, Train: label_loss: 0.08750154078006744, precision: 0.3478780633592141, recall: 0.8967642526963179, f1: 0.5012919896237634\n",
            "epoch: 912, step: 9, Train: label_loss: 0.0906575471162796, precision: 0.3128760529482363, recall: 0.9012131715769668, f1: 0.4644930772283368\n",
            "epoch: 912, step: 10, Train: label_loss: 0.08272860199213028, precision: 0.3049434187015899, recall: 0.8919860627176146, f1: 0.45450510426735774\n",
            "epoch: 912, step: 11, Train: label_loss: 0.076405830681324, precision: 0.3110447761193844, recall: 0.8921232876710801, f1: 0.4612660468850389\n",
            "epoch: 912, step: 12, Train: label_loss: 0.07336176931858063, precision: 0.31997642899232054, recall: 0.8990066225164074, f1: 0.4719687092180856\n",
            "epoch: 912, step: 13, Train: label_loss: 0.0766146257519722, precision: 0.3337285121517289, recall: 0.9184339314843526, f1: 0.48956521735216424\n",
            "epoch: 912, step: 14, Train: label_loss: 0.07426777482032776, precision: 0.3087367178276087, recall: 0.9159369527143755, f1: 0.4618101544876367\n",
            "epoch: 912, step: 15, Train: label_loss: 0.08967512845993042, precision: 0.3214072748956278, recall: 0.8998330550916694, f1: 0.4736379612968516\n",
            "epoch: 912, step: 16, Train: label_loss: 0.08033132553100586, precision: 0.32430841671569605, recall: 0.9137645107792846, f1: 0.47871416155990215\n",
            "epoch: 912, step: 17, Train: label_loss: 0.07028470933437347, precision: 0.3222748815165686, recall: 0.8976897689767495, f1: 0.47428073230633055\n",
            "epoch: 912, step: 18, Train: label_loss: 0.08103140443563461, precision: 0.3033775633292941, recall: 0.8568994889266002, f1: 0.4481069041929652\n",
            "epoch: 912, step: 19, Train: label_loss: 0.07949258387088776, precision: 0.3082840236686208, recall: 0.9124343257441484, f1: 0.4608580273837011\n",
            "epoch: 912, step: 20, Train: label_loss: 0.08607804775238037, precision: 0.30760095011874655, recall: 0.8885077186962455, f1: 0.4569916188413296\n",
            "epoch: 912, step: 21, Train: label_loss: 0.07522299885749817, precision: 0.3440608543007405, recall: 0.9130434782607277, f1: 0.49978750527256766\n",
            "epoch: 912, step: 22, Train: label_loss: 0.07017381489276886, precision: 0.31992903607331047, recall: 0.9185059422748865, f1: 0.4745614034704108\n",
            "epoch: 912, step: 23, Train: label_loss: 0.07723630964756012, precision: 0.31785195936137023, recall: 0.9030927835049685, f1: 0.4702093397359947\n",
            "epoch: 913, step: 0, Train: label_loss: 0.09187023341655731, precision: 0.30565583634173854, recall: 0.8758620689653661, f1: 0.4531668153050482\n",
            "epoch: 913, step: 1, Train: label_loss: 0.06173411384224892, precision: 0.33255131964807433, recall: 0.927986906710159, f1: 0.48963730566059604\n",
            "epoch: 913, step: 2, Train: label_loss: 0.08375781029462814, precision: 0.31995206710603236, recall: 0.8826446280990276, f1: 0.4696569920453378\n",
            "epoch: 913, step: 3, Train: label_loss: 0.0735178217291832, precision: 0.31659775546365526, recall: 0.9069373942468854, f1: 0.46935201397210646\n",
            "epoch: 913, step: 4, Train: label_loss: 0.06957745552062988, precision: 0.35630841121493245, recall: 0.9472049689439522, f1: 0.5178268250875651\n",
            "epoch: 913, step: 5, Train: label_loss: 0.07786422222852707, precision: 0.2951205173427222, recall: 0.926199261992449, f1: 0.4476148015683033\n",
            "epoch: 913, step: 6, Train: label_loss: 0.0794869214296341, precision: 0.3104265402843418, recall: 0.8926746166949074, f1: 0.46065934062101077\n",
            "epoch: 913, step: 7, Train: label_loss: 0.0740261822938919, precision: 0.34024896265558147, recall: 0.9258064516127539, f1: 0.4976159514127547\n",
            "epoch: 913, step: 8, Train: label_loss: 0.07077626138925552, precision: 0.33095662507425244, recall: 0.9252491694350622, f1: 0.4875273522587408\n",
            "epoch: 913, step: 9, Train: label_loss: 0.06626491248607635, precision: 0.3231132075471507, recall: 0.917922948073548, f1: 0.4779764500268604\n",
            "epoch: 913, step: 10, Train: label_loss: 0.07558014243841171, precision: 0.3319599764567197, recall: 0.9126213592231532, f1: 0.48683642637430713\n",
            "epoch: 913, step: 11, Train: label_loss: 0.0932505652308464, precision: 0.3366983372921415, recall: 0.9130434782607225, f1: 0.4919739695918276\n",
            "epoch: 913, step: 12, Train: label_loss: 0.0770396962761879, precision: 0.3177790903721017, recall: 0.9087837837836302, f1: 0.47089715532261744\n",
            "epoch: 913, step: 13, Train: label_loss: 0.06876301765441895, precision: 0.3186101295641744, recall: 0.9031719532552749, f1: 0.47104919456305905\n",
            "epoch: 913, step: 14, Train: label_loss: 0.08564518392086029, precision: 0.30011723329423795, recall: 0.9142857142855509, f1: 0.4518976169089092\n",
            "epoch: 913, step: 15, Train: label_loss: 0.07047652453184128, precision: 0.32094395280234095, recall: 0.9158249158247616, f1: 0.47531673215899245\n",
            "epoch: 913, step: 16, Train: label_loss: 0.08052784949541092, precision: 0.30229817324688846, recall: 0.89685314685299, f1: 0.45218157774982326\n",
            "epoch: 913, step: 17, Train: label_loss: 0.07622022926807404, precision: 0.34535777646361054, recall: 0.9026275115918233, f1: 0.4995722839633487\n",
            "epoch: 913, step: 18, Train: label_loss: 0.08096328377723694, precision: 0.33176193282260863, recall: 0.9080645161288857, f1: 0.48597324122101154\n",
            "epoch: 913, step: 19, Train: label_loss: 0.0790015310049057, precision: 0.3313644418192362, recall: 0.9019292604500158, f1: 0.4846652267425172\n",
            "epoch: 913, step: 20, Train: label_loss: 0.07559684664011002, precision: 0.32021466905185925, recall: 0.8935108153076715, f1: 0.47146619838078035\n",
            "epoch: 913, step: 21, Train: label_loss: 0.07637923210859299, precision: 0.31264916467778564, recall: 0.8957264957263426, f1: 0.4635117204392655\n",
            "epoch: 913, step: 22, Train: label_loss: 0.07076084613800049, precision: 0.3372572101235823, recall: 0.9182692307690835, f1: 0.49332759358959316\n",
            "epoch: 913, step: 23, Train: label_loss: 0.07878642529249191, precision: 0.3185131195335045, recall: 0.9010309278348658, f1: 0.4706515885450941\n",
            "epoch: 914, step: 0, Train: label_loss: 0.07799385488033295, precision: 0.33568075117368923, recall: 0.9346405228756642, f1: 0.4939550949524375\n",
            "epoch: 914, step: 1, Train: label_loss: 0.0970618948340416, precision: 0.30773881499393546, recall: 0.8497495826375876, f1: 0.4518419884207548\n",
            "epoch: 914, step: 2, Train: label_loss: 0.08720757812261581, precision: 0.32049763033173456, recall: 0.9107744107742574, f1: 0.4741454863768749\n",
            "epoch: 914, step: 3, Train: label_loss: 0.07852014899253845, precision: 0.3205204021288988, recall: 0.9186440677964544, f1: 0.4752301621711646\n",
            "epoch: 914, step: 4, Train: label_loss: 0.07626957446336746, precision: 0.3421361502347217, recall: 0.9239302694134827, f1: 0.4993576016735776\n",
            "epoch: 914, step: 5, Train: label_loss: 0.06328141689300537, precision: 0.3280235988200396, recall: 0.90553745928324, f1: 0.4815937634949147\n",
            "epoch: 914, step: 6, Train: label_loss: 0.06160779669880867, precision: 0.3358556461000969, recall: 0.9336569579286514, f1: 0.4940068492761131\n",
            "epoch: 914, step: 7, Train: label_loss: 0.06788572669029236, precision: 0.32803297997642356, recall: 0.9298831385641185, f1: 0.48498040919083324\n",
            "epoch: 914, step: 8, Train: label_loss: 0.08598171174526215, precision: 0.3187463039621337, recall: 0.9089376053961367, f1: 0.4719789841996926\n",
            "epoch: 914, step: 9, Train: label_loss: 0.0789605975151062, precision: 0.3242117787031336, recall: 0.8993399339932509, f1: 0.4766069085749103\n",
            "epoch: 914, step: 10, Train: label_loss: 0.07541313767433167, precision: 0.32193396226413196, recall: 0.9285714285712706, f1: 0.47810858139780193\n",
            "epoch: 914, step: 11, Train: label_loss: 0.07323742657899857, precision: 0.32309509746011084, recall: 0.9271186440676394, f1: 0.4791940428876036\n",
            "epoch: 914, step: 12, Train: label_loss: 0.08127765357494354, precision: 0.3372641509433763, recall: 0.9151999999998535, f1: 0.4928909952212673\n",
            "epoch: 914, step: 13, Train: label_loss: 0.0647454783320427, precision: 0.3337222870478218, recall: 0.9377049180326331, f1: 0.49225473317982954\n",
            "epoch: 914, step: 14, Train: label_loss: 0.0723785012960434, precision: 0.31139835487659745, recall: 0.9028960817715668, f1: 0.4630843162571489\n",
            "epoch: 914, step: 15, Train: label_loss: 0.06841006129980087, precision: 0.32846288720044836, recall: 0.9138211382112335, f1: 0.4832330180178095\n",
            "epoch: 914, step: 16, Train: label_loss: 0.08013688772916794, precision: 0.31463990554897786, recall: 0.9003378378376857, f1: 0.46631671037277717\n",
            "epoch: 914, step: 17, Train: label_loss: 0.0858764797449112, precision: 0.30805970149251893, recall: 0.8850771869638275, f1: 0.4570416297225039\n",
            "epoch: 914, step: 18, Train: label_loss: 0.09752672910690308, precision: 0.33115727002965395, recall: 0.8942307692306258, f1: 0.4833261151619013\n",
            "epoch: 914, step: 19, Train: label_loss: 0.08210640400648117, precision: 0.3252225519287641, recall: 0.8881685575363227, f1: 0.4761077323673238\n",
            "epoch: 914, step: 20, Train: label_loss: 0.08008314669132233, precision: 0.30649970184852077, recall: 0.8846815834766119, f1: 0.4552701505374703\n",
            "epoch: 914, step: 21, Train: label_loss: 0.08061224222183228, precision: 0.30288461538459716, recall: 0.881118881118727, f1: 0.4508050089064289\n",
            "epoch: 914, step: 22, Train: label_loss: 0.06599992513656616, precision: 0.32339181286547813, recall: 0.9262981574537811, f1: 0.4794104897752068\n",
            "epoch: 914, step: 23, Train: label_loss: 0.08460141718387604, precision: 0.3135409123823089, recall: 0.8983402489624692, f1: 0.46484165320904336\n",
            "epoch: 915, step: 0, Train: label_loss: 0.06777589023113251, precision: 0.3099345627602433, recall: 0.8967297762476941, f1: 0.46065428820227855\n",
            "epoch: 915, step: 1, Train: label_loss: 0.08011956512928009, precision: 0.3301886792452635, recall: 0.9195402298849064, f1: 0.48590021688081697\n",
            "epoch: 915, step: 2, Train: label_loss: 0.07448795437812805, precision: 0.3313644418192362, recall: 0.9166666666665169, f1: 0.4867678958394799\n",
            "epoch: 915, step: 3, Train: label_loss: 0.06798797100782394, precision: 0.31644077784323416, recall: 0.9210977701542159, f1: 0.4710526315408423\n",
            "epoch: 915, step: 4, Train: label_loss: 0.0853954404592514, precision: 0.307232516437519, recall: 0.8923611111109562, f1: 0.4570920408689253\n",
            "epoch: 915, step: 5, Train: label_loss: 0.07750500738620758, precision: 0.3268321513002171, recall: 0.9140495867767083, f1: 0.48149760553364107\n",
            "epoch: 915, step: 6, Train: label_loss: 0.09590201079845428, precision: 0.3182912154031096, recall: 0.8890756302519514, f1: 0.46876384577415925\n",
            "epoch: 915, step: 7, Train: label_loss: 0.0844743624329567, precision: 0.3148911124190515, recall: 0.916095890410802, f1: 0.46868155931361544\n",
            "epoch: 915, step: 8, Train: label_loss: 0.07281196117401123, precision: 0.345070422535191, recall: 0.9187499999998564, f1: 0.5017064846018978\n",
            "epoch: 915, step: 9, Train: label_loss: 0.07811357080936432, precision: 0.3448071216617006, recall: 0.9049844236758714, f1: 0.49935539317014366\n",
            "epoch: 915, step: 10, Train: label_loss: 0.085952028632164, precision: 0.32508833922259567, recall: 0.9154228855719875, f1: 0.4797913950069137\n",
            "epoch: 915, step: 11, Train: label_loss: 0.08673544973134995, precision: 0.32626619552412683, recall: 0.9264214046821193, f1: 0.4825783971739781\n",
            "epoch: 915, step: 12, Train: label_loss: 0.07781385630369186, precision: 0.34020011771628367, recall: 0.9262820512819028, f1: 0.4976323718935101\n",
            "epoch: 915, step: 13, Train: label_loss: 0.08555291593074799, precision: 0.3242442205097614, recall: 0.9116666666665146, f1: 0.4783559247535577\n",
            "epoch: 915, step: 14, Train: label_loss: 0.07171932607889175, precision: 0.3387387387387184, recall: 0.8854003139716035, f1: 0.4900086880572352\n",
            "epoch: 915, step: 15, Train: label_loss: 0.06985969841480255, precision: 0.3327423167848503, recall: 0.9290429042902757, f1: 0.48999129674093267\n",
            "epoch: 915, step: 16, Train: label_loss: 0.08387227356433868, precision: 0.32035928143710657, recall: 0.8741830065358048, f1: 0.4688869412402858\n",
            "epoch: 915, step: 17, Train: label_loss: 0.0781722366809845, precision: 0.30742255990646944, recall: 0.9276895943560973, f1: 0.46180860400119983\n",
            "epoch: 915, step: 18, Train: label_loss: 0.09277670085430145, precision: 0.3217910447761002, recall: 0.8923841059601171, f1: 0.4730144799961039\n",
            "epoch: 915, step: 19, Train: label_loss: 0.07763363420963287, precision: 0.31610219845512083, recall: 0.9032258064514594, f1: 0.46830985911648115\n",
            "epoch: 915, step: 20, Train: label_loss: 0.07885861396789551, precision: 0.3264340626847826, recall: 0.9139072847680605, f1: 0.4810457515951616\n",
            "epoch: 915, step: 21, Train: label_loss: 0.0926329493522644, precision: 0.29461077844309613, recall: 0.8864864864863267, f1: 0.44224719097375254\n",
            "epoch: 915, step: 22, Train: label_loss: 0.0693712830543518, precision: 0.33747044917255686, recall: 0.9077901430841163, f1: 0.492029297676947\n",
            "epoch: 915, step: 23, Train: label_loss: 0.07746993750333786, precision: 0.30901287553645856, recall: 0.93103448275842, f1: 0.46401718578422796\n",
            "epoch: 916, step: 0, Train: label_loss: 0.06869116425514221, precision: 0.3244994110718301, recall: 0.8973941368076713, f1: 0.47664359857686706\n",
            "epoch: 916, step: 1, Train: label_loss: 0.07047076523303986, precision: 0.31898584905658495, recall: 0.9107744107742574, f1: 0.47248908293096975\n",
            "epoch: 916, step: 2, Train: label_loss: 0.0761031061410904, precision: 0.3178340200117529, recall: 0.903010033444665, f1: 0.4701784936488648\n",
            "epoch: 916, step: 3, Train: label_loss: 0.07233580201864243, precision: 0.3211117681844872, recall: 0.9004975124376615, f1: 0.4734088927249373\n",
            "epoch: 916, step: 4, Train: label_loss: 0.06337936222553253, precision: 0.32453051643190584, recall: 0.9232053422369075, f1: 0.480243161055694\n",
            "epoch: 916, step: 5, Train: label_loss: 0.07753751426935196, precision: 0.32534451767523515, recall: 0.8843648208467615, f1: 0.47568988169519544\n",
            "epoch: 916, step: 6, Train: label_loss: 0.07184857130050659, precision: 0.3065179095713267, recall: 0.9031141868510547, f1: 0.4576939938244634\n",
            "epoch: 916, step: 7, Train: label_loss: 0.07232919335365295, precision: 0.3343125734429886, recall: 0.9133226324236093, f1: 0.4894623655521246\n",
            "epoch: 916, step: 8, Train: label_loss: 0.06363976001739502, precision: 0.32004689331768343, recall: 0.9222972972971414, f1: 0.4751958224160167\n",
            "epoch: 916, step: 9, Train: label_loss: 0.07844404876232147, precision: 0.3198118753674121, recall: 0.9173693086001825, f1: 0.47428073230687157\n",
            "epoch: 916, step: 10, Train: label_loss: 0.07956904172897339, precision: 0.33647613435472384, recall: 0.9284552845526944, f1: 0.4939446366391088\n",
            "epoch: 916, step: 11, Train: label_loss: 0.08016173541545868, precision: 0.3234946871310317, recall: 0.9057851239667923, f1: 0.47672901257535744\n",
            "epoch: 916, step: 12, Train: label_loss: 0.08305042237043381, precision: 0.30186410102223077, recall: 0.8822495606325338, f1: 0.4498207884924377\n",
            "epoch: 916, step: 13, Train: label_loss: 0.07208681106567383, precision: 0.3238602723504841, recall: 0.9162479061975014, f1: 0.47856517931394843\n",
            "epoch: 916, step: 14, Train: label_loss: 0.08608156442642212, precision: 0.33709869203327364, recall: 0.8915094339621239, f1: 0.48921484033977675\n",
            "epoch: 916, step: 15, Train: label_loss: 0.07918480038642883, precision: 0.32720806164787625, recall: 0.9154228855719875, f1: 0.48209606983015707\n",
            "epoch: 916, step: 16, Train: label_loss: 0.09407481551170349, precision: 0.3055062166962519, recall: 0.9036777583185808, f1: 0.45663716810378835\n",
            "epoch: 916, step: 17, Train: label_loss: 0.08856543898582458, precision: 0.30815347721820696, recall: 0.8970331588131069, f1: 0.4587237839868855\n",
            "epoch: 916, step: 18, Train: label_loss: 0.07573767751455307, precision: 0.33846153846151844, recall: 0.9210950080513814, f1: 0.49502379918177214\n",
            "epoch: 916, step: 19, Train: label_loss: 0.08081932365894318, precision: 0.3103654883163385, recall: 0.8900343642610153, f1: 0.4602398933423382\n",
            "epoch: 916, step: 20, Train: label_loss: 0.08093428611755371, precision: 0.3436018957345768, recall: 0.9148264984225686, f1: 0.49956933673889814\n",
            "epoch: 916, step: 21, Train: label_loss: 0.09115028381347656, precision: 0.3474626865671434, recall: 0.9093749999998578, f1: 0.5028077753379205\n",
            "epoch: 916, step: 22, Train: label_loss: 0.07494714111089706, precision: 0.3135294117646874, recall: 0.9221453287195636, f1: 0.46795434587956003\n",
            "epoch: 916, step: 23, Train: label_loss: 0.09086796641349792, precision: 0.3247988295537436, recall: 0.9117043121148025, f1: 0.4789644012557113\n",
            "epoch: 917, step: 0, Train: label_loss: 0.06978227198123932, precision: 0.32456140350875295, recall: 0.926544240400513, f1: 0.4807275876618373\n",
            "epoch: 917, step: 1, Train: label_loss: 0.06493828445672989, precision: 0.3233038348082405, recall: 0.9087893864011759, f1: 0.4769364664538513\n",
            "epoch: 917, step: 2, Train: label_loss: 0.0863240659236908, precision: 0.33233890214795153, recall: 0.8954983922828141, f1: 0.48476936462540227\n",
            "epoch: 917, step: 3, Train: label_loss: 0.06557810306549072, precision: 0.33490288404942115, recall: 0.9312602291324171, f1: 0.49264069260174187\n",
            "epoch: 917, step: 4, Train: label_loss: 0.08379402756690979, precision: 0.31132075471696274, recall: 0.8979591836733166, f1: 0.4623467600317788\n",
            "epoch: 917, step: 5, Train: label_loss: 0.06860321015119553, precision: 0.3438596491227869, recall: 0.9116279069766028, f1: 0.49936305728502384\n",
            "epoch: 917, step: 6, Train: label_loss: 0.06577420234680176, precision: 0.31958163858220107, recall: 0.9322033898303504, f1: 0.4759844222899309\n",
            "epoch: 917, step: 7, Train: label_loss: 0.0884171798825264, precision: 0.3000597728631022, recall: 0.8685121107264933, f1: 0.44602398929986403\n",
            "epoch: 917, step: 8, Train: label_loss: 0.08070431649684906, precision: 0.30886670581325254, recall: 0.9084628670119328, f1: 0.46099912353790057\n",
            "epoch: 917, step: 9, Train: label_loss: 0.0732230618596077, precision: 0.30842230130484527, recall: 0.9043478260867992, f1: 0.4599734630314701\n",
            "epoch: 917, step: 10, Train: label_loss: 0.07536116242408752, precision: 0.31687242798352044, recall: 0.9104729729728192, f1: 0.47012647183256606\n",
            "epoch: 917, step: 11, Train: label_loss: 0.08681312203407288, precision: 0.31506024096383645, recall: 0.8864406779659514, f1: 0.4648888888501552\n",
            "epoch: 917, step: 12, Train: label_loss: 0.08069910109043121, precision: 0.31268436578169245, recall: 0.905982905982751, f1: 0.4649122806635644\n",
            "epoch: 917, step: 13, Train: label_loss: 0.06216684728860855, precision: 0.33196480938414474, recall: 0.9158576051778453, f1: 0.4873009039643498\n",
            "epoch: 917, step: 14, Train: label_loss: 0.09324847161769867, precision: 0.3128019323671309, recall: 0.8647746243738121, f1: 0.45942350328688725\n",
            "epoch: 917, step: 15, Train: label_loss: 0.0678015798330307, precision: 0.33839859731149396, recall: 0.9278846153844666, f1: 0.4959314774768531\n",
            "epoch: 917, step: 16, Train: label_loss: 0.08088290691375732, precision: 0.32279236276847717, recall: 0.9185059422748865, f1: 0.47770419422195926\n",
            "epoch: 917, step: 17, Train: label_loss: 0.09922917187213898, precision: 0.32429174201324146, recall: 0.883415435139428, f1: 0.47442680772081597\n",
            "epoch: 917, step: 18, Train: label_loss: 0.07582485675811768, precision: 0.32716417910445805, recall: 0.9072847682117703, f1: 0.48091268096143885\n",
            "epoch: 917, step: 19, Train: label_loss: 0.09239968657493591, precision: 0.3119709794437538, recall: 0.8865979381441775, f1: 0.4615384614999128\n",
            "epoch: 917, step: 20, Train: label_loss: 0.10021843016147614, precision: 0.3065693430656748, recall: 0.855687606111909, f1: 0.4514106582683304\n",
            "epoch: 917, step: 21, Train: label_loss: 0.0945715457201004, precision: 0.30024213075058714, recall: 0.8641114982576891, f1: 0.44564240786824494\n",
            "epoch: 917, step: 22, Train: label_loss: 0.11843018233776093, precision: 0.3496672716273231, recall: 0.8784194528874044, f1: 0.500216356514829\n",
            "epoch: 917, step: 23, Train: label_loss: 0.08667439222335815, precision: 0.33895818048420107, recall: 0.8953488372091287, f1: 0.4917509313065682\n",
            "epoch: 918, step: 0, Train: label_loss: 0.07911574840545654, precision: 0.3262786596119738, recall: 0.9128289473682708, f1: 0.4807275876614653\n",
            "epoch: 918, step: 1, Train: label_loss: 0.10299685597419739, precision: 0.3398058252426978, recall: 0.8860759493669483, f1: 0.4912280701353241\n",
            "epoch: 918, step: 2, Train: label_loss: 0.08112207055091858, precision: 0.3404634581104967, recall: 0.908082408874658, f1: 0.49524632666729224\n",
            "epoch: 918, step: 3, Train: label_loss: 0.09783537685871124, precision: 0.2999999999999817, recall: 0.8497409326423402, f1: 0.4434429923002824\n",
            "epoch: 918, step: 4, Train: label_loss: 0.10809685289859772, precision: 0.3115055079559173, recall: 0.8715753424656041, f1: 0.4589720468502532\n",
            "epoch: 918, step: 5, Train: label_loss: 0.08589112758636475, precision: 0.320307874481923, recall: 0.9031719532552749, f1: 0.4729020978634043\n",
            "epoch: 918, step: 6, Train: label_loss: 0.08139066398143768, precision: 0.32737030411447066, recall: 0.9149999999998474, f1: 0.48221343869632155\n",
            "epoch: 918, step: 7, Train: label_loss: 0.10529439151287079, precision: 0.32309582309580326, recall: 0.8402555910541788, f1: 0.4667258207229274\n",
            "epoch: 918, step: 8, Train: label_loss: 0.09844893217086792, precision: 0.3171753441053072, recall: 0.892255892255742, f1: 0.46799116993918843\n",
            "epoch: 918, step: 9, Train: label_loss: 0.11158803105354309, precision: 0.31306990881457064, recall: 0.8583333333331902, f1: 0.458797327355002\n",
            "epoch: 918, step: 10, Train: label_loss: 0.09942029416561127, precision: 0.3186157517899571, recall: 0.8870431893686234, f1: 0.468832309004093\n",
            "epoch: 918, step: 11, Train: label_loss: 0.09931622445583344, precision: 0.325257419745589, recall: 0.8788870703762882, f1: 0.47480106096848507\n",
            "epoch: 918, step: 12, Train: label_loss: 0.08260264992713928, precision: 0.294015107495625, recall: 0.9183303085297788, f1: 0.44542253517448777\n",
            "epoch: 918, step: 13, Train: label_loss: 0.08190222829580307, precision: 0.33568075117368923, recall: 0.9210950080513814, f1: 0.49204301071349466\n",
            "epoch: 918, step: 14, Train: label_loss: 0.08260586112737656, precision: 0.32488207547167897, recall: 0.916805324459082, f1: 0.4797562037053347\n",
            "epoch: 918, step: 15, Train: label_loss: 0.0862855464220047, precision: 0.32955899880808526, recall: 0.9006514657978989, f1: 0.48254799297993023\n",
            "epoch: 918, step: 16, Train: label_loss: 0.07733538746833801, precision: 0.30999999999998173, recall: 0.9070567986229074, f1: 0.4620780359111378\n",
            "epoch: 918, step: 17, Train: label_loss: 0.08170568943023682, precision: 0.3213859020310441, recall: 0.8981636060098667, f1: 0.47338319397786\n",
            "epoch: 918, step: 18, Train: label_loss: 0.08863740414381027, precision: 0.32602252519263036, recall: 0.9121061359865816, f1: 0.4803493449393276\n",
            "epoch: 918, step: 19, Train: label_loss: 0.083284392952919, precision: 0.31563245823387137, recall: 0.8920741989880451, f1: 0.46628470688069756\n",
            "epoch: 918, step: 20, Train: label_loss: 0.08061149716377258, precision: 0.32639714625443955, recall: 0.9119601328902139, f1: 0.48073555162488524\n",
            "epoch: 918, step: 21, Train: label_loss: 0.09275716543197632, precision: 0.31094978826374403, recall: 0.8481848184817081, f1: 0.4550686143918646\n",
            "epoch: 918, step: 22, Train: label_loss: 0.08087888360023499, precision: 0.3233890214796943, recall: 0.8885245901637887, f1: 0.47419072612006113\n",
            "epoch: 918, step: 23, Train: label_loss: 0.09056323766708374, precision: 0.31363967906635204, recall: 0.9110169491523494, f1: 0.46663049372202003\n",
            "epoch: 919, step: 0, Train: label_loss: 0.06793111562728882, precision: 0.3202614379084777, recall: 0.8923841059601171, f1: 0.4713598600397942\n",
            "epoch: 919, step: 1, Train: label_loss: 0.09846007823944092, precision: 0.3295724465557999, recall: 0.9143327841843633, f1: 0.4845045831124696\n",
            "epoch: 919, step: 2, Train: label_loss: 0.08351019024848938, precision: 0.3135391923990313, recall: 0.8979591836733166, f1: 0.46478873235596047\n",
            "epoch: 919, step: 3, Train: label_loss: 0.089497871696949, precision: 0.3056716417910265, recall: 0.8737201365186221, f1: 0.45289694821454446\n",
            "epoch: 919, step: 4, Train: label_loss: 0.09421885758638382, precision: 0.35442260442258267, recall: 0.882262996941761, f1: 0.5056967571895639\n",
            "epoch: 919, step: 5, Train: label_loss: 0.11035314202308655, precision: 0.33395061728393, recall: 0.8560126582277126, f1: 0.4804618116824941\n",
            "epoch: 919, step: 6, Train: label_loss: 0.11195692420005798, precision: 0.2975517890771941, recall: 0.8033898305083383, f1: 0.4342647732083394\n",
            "epoch: 919, step: 7, Train: label_loss: 0.09694226086139679, precision: 0.31170406306850745, recall: 0.860971524287963, f1: 0.45770258232958394\n",
            "epoch: 919, step: 8, Train: label_loss: 0.09873040020465851, precision: 0.3073229291716502, recall: 0.8888888888887345, f1: 0.45673505794572034\n",
            "epoch: 919, step: 9, Train: label_loss: 0.10754931718111038, precision: 0.3192771084337157, recall: 0.8789386401325242, f1: 0.46840477238684997\n",
            "epoch: 919, step: 10, Train: label_loss: 0.09102585166692734, precision: 0.3009708737863895, recall: 0.8611111111109615, f1: 0.44604316542920264\n",
            "epoch: 919, step: 11, Train: label_loss: 0.09934784471988678, precision: 0.31884944920438685, recall: 0.8527004909982238, f1: 0.46414253893584195\n",
            "epoch: 919, step: 12, Train: label_loss: 0.09479889273643494, precision: 0.3317249698431645, recall: 0.8814102564101151, f1: 0.48203330407941686\n",
            "epoch: 919, step: 13, Train: label_loss: 0.12583938241004944, precision: 0.3011750154607111, recall: 0.8282312925168659, f1: 0.4417233559699191\n",
            "epoch: 919, step: 14, Train: label_loss: 0.10205093026161194, precision: 0.3138905592302878, recall: 0.8862478777587629, f1: 0.4635879218085779\n",
            "epoch: 919, step: 15, Train: label_loss: 0.09766863286495209, precision: 0.3097398669086322, recall: 0.8561872909697564, f1: 0.4549089293256695\n",
            "epoch: 919, step: 16, Train: label_loss: 0.09904631972312927, precision: 0.3130644190246651, recall: 0.8888888888887369, f1: 0.46304541403089117\n",
            "epoch: 919, step: 17, Train: label_loss: 0.09242520481348038, precision: 0.333530805687184, recall: 0.9229508196719798, f1: 0.4899912967407688\n",
            "epoch: 919, step: 18, Train: label_loss: 0.09887538850307465, precision: 0.3253676470588036, recall: 0.8349056603772271, f1: 0.46825396821356974\n",
            "epoch: 919, step: 19, Train: label_loss: 0.08097779005765915, precision: 0.330732292917147, recall: 0.9018003273320946, f1: 0.48397013610474027\n",
            "epoch: 919, step: 20, Train: label_loss: 0.10710375756025314, precision: 0.3100303951367593, recall: 0.8557046979864336, f1: 0.4551539490907678\n",
            "epoch: 919, step: 21, Train: label_loss: 0.10177682340145111, precision: 0.3101991550995588, recall: 0.8711864406778184, f1: 0.4574988873666631\n",
            "epoch: 919, step: 22, Train: label_loss: 0.12195827066898346, precision: 0.3082107843137066, recall: 0.8355481727573362, f1: 0.45031333926228934\n",
            "epoch: 919, step: 23, Train: label_loss: 0.098921038210392, precision: 0.30249632892802475, recall: 0.88412017167363, f1: 0.4507658642945671\n",
            "epoch: 920, step: 0, Train: label_loss: 0.08934664726257324, precision: 0.3251497005987829, recall: 0.893092105263011, f1: 0.47673397713378385\n",
            "epoch: 920, step: 1, Train: label_loss: 0.09219088405370712, precision: 0.3126120741183316, recall: 0.8819561551431901, f1: 0.4616063547715555\n",
            "epoch: 920, step: 2, Train: label_loss: 0.0926271453499794, precision: 0.3457382953181065, recall: 0.8999999999998594, f1: 0.4995663486155355\n",
            "epoch: 920, step: 3, Train: label_loss: 0.08850821852684021, precision: 0.32052821128449455, recall: 0.8826446280990276, f1: 0.4702774107931046\n",
            "epoch: 920, step: 4, Train: label_loss: 0.09746348857879639, precision: 0.32123411978219474, recall: 0.8648208469053965, f1: 0.46846052047215075\n",
            "epoch: 920, step: 5, Train: label_loss: 0.09345611184835434, precision: 0.30989272943979085, recall: 0.8813559322032404, f1: 0.45855379184859124\n",
            "epoch: 920, step: 6, Train: label_loss: 0.10326345264911652, precision: 0.30727600721585646, recall: 0.8765008576327827, f1: 0.45503116647977515\n",
            "epoch: 920, step: 7, Train: label_loss: 0.09990096092224121, precision: 0.34156626506022036, recall: 0.9057507987219, f1: 0.49606299208617044\n",
            "epoch: 920, step: 8, Train: label_loss: 0.0910646989941597, precision: 0.3274711946634125, recall: 0.891089108910744, f1: 0.47893569840854766\n",
            "epoch: 920, step: 9, Train: label_loss: 0.09789499640464783, precision: 0.3068459657701524, recall: 0.8508474576269743, f1: 0.45103324344707346\n",
            "epoch: 920, step: 10, Train: label_loss: 0.09572615474462509, precision: 0.31832014607423503, recall: 0.8716666666665214, f1: 0.4663397235452548\n",
            "epoch: 920, step: 11, Train: label_loss: 0.08638571947813034, precision: 0.3339361060879847, recall: 0.9022801302930126, f1: 0.487461504579971\n",
            "epoch: 920, step: 12, Train: label_loss: 0.08998164534568787, precision: 0.31212484993995726, recall: 0.8919382504286634, f1: 0.4624277456262932\n",
            "epoch: 920, step: 13, Train: label_loss: 0.10092192888259888, precision: 0.33110571081407464, recall: 0.8776167471818231, f1: 0.48081164530645165\n",
            "epoch: 920, step: 14, Train: label_loss: 0.0974867194890976, precision: 0.31295399515736605, recall: 0.868907563025064, f1: 0.46016911433574487\n",
            "epoch: 920, step: 15, Train: label_loss: 0.09355088323354721, precision: 0.3113377324534906, recall: 0.8841567291310248, f1: 0.46051464060030245\n",
            "epoch: 920, step: 16, Train: label_loss: 0.07577633112668991, precision: 0.3084279736999218, recall: 0.8927335640136863, f1: 0.45846290533717965\n",
            "epoch: 920, step: 17, Train: label_loss: 0.08509260416030884, precision: 0.3434886499402423, recall: 0.8956386292833495, f1: 0.4965457685263789\n",
            "epoch: 920, step: 18, Train: label_loss: 0.07553679496049881, precision: 0.3053571428571247, recall: 0.8769230769229269, f1: 0.452980132411977\n",
            "epoch: 920, step: 19, Train: label_loss: 0.08512448519468307, precision: 0.3288155568650366, recall: 0.9132569558099978, f1: 0.48353552855721554\n",
            "epoch: 920, step: 20, Train: label_loss: 0.08801768720149994, precision: 0.3047107930828679, recall: 0.884083044982546, f1: 0.45321507756715734\n",
            "epoch: 920, step: 21, Train: label_loss: 0.10176663100719452, precision: 0.2975404919016018, recall: 0.8747795414460537, f1: 0.44404655322976394\n",
            "epoch: 920, step: 22, Train: label_loss: 0.08619929850101471, precision: 0.3319551092734594, recall: 0.9064516129030795, f1: 0.4859489839641768\n",
            "epoch: 920, step: 23, Train: label_loss: 0.09917719662189484, precision: 0.31093057607087804, recall: 0.8716356107658652, f1: 0.45835601520343344\n",
            "epoch: 921, step: 0, Train: label_loss: 0.08624115586280823, precision: 0.31683765841881006, recall: 0.8808724832213286, f1: 0.4660452729304214\n",
            "epoch: 921, step: 1, Train: label_loss: 0.09888234734535217, precision: 0.32093581283741324, recall: 0.8741830065358048, f1: 0.46950416845562754\n",
            "epoch: 921, step: 2, Train: label_loss: 0.07706156373023987, precision: 0.32801418439714375, recall: 0.9083469721766106, f1: 0.48198002601394874\n",
            "epoch: 921, step: 3, Train: label_loss: 0.08940478414297104, precision: 0.32955899880808526, recall: 0.9095394736840609, f1: 0.4838145231455139\n",
            "epoch: 921, step: 4, Train: label_loss: 0.0874568298459053, precision: 0.3374558303886727, recall: 0.9182692307690835, f1: 0.49354005164024084\n",
            "epoch: 921, step: 5, Train: label_loss: 0.08047458529472351, precision: 0.34060106069532464, recall: 0.9189189189187728, f1: 0.496990541662992\n",
            "epoch: 921, step: 6, Train: label_loss: 0.0924619734287262, precision: 0.32166172106823016, recall: 0.9003322259134716, f1: 0.473983384307476\n",
            "epoch: 921, step: 7, Train: label_loss: 0.08501368761062622, precision: 0.29957805907171187, recall: 0.8906810035840697, f1: 0.44835363099521824\n",
            "epoch: 921, step: 8, Train: label_loss: 0.0850733146071434, precision: 0.307507507507489, recall: 0.8707482993195798, f1: 0.45450510426675583\n",
            "epoch: 921, step: 9, Train: label_loss: 0.08424321562051773, precision: 0.32050511124471914, recall: 0.8913043478259378, f1: 0.47147279960722605\n",
            "epoch: 921, step: 10, Train: label_loss: 0.07497981190681458, precision: 0.3168141592920167, recall: 0.9258620689653575, f1: 0.47208791204988093\n",
            "epoch: 921, step: 11, Train: label_loss: 0.08494317531585693, precision: 0.3222156045264847, recall: 0.8854337152208043, f1: 0.4724890829302663\n",
            "epoch: 921, step: 12, Train: label_loss: 0.114890918135643, precision: 0.3229548229548032, recall: 0.8700657894735411, f1: 0.4710596615811323\n",
            "epoch: 921, step: 13, Train: label_loss: 0.08997802436351776, precision: 0.30669034931910555, recall: 0.9135802469134191, f1: 0.459219858118355\n",
            "epoch: 921, step: 14, Train: label_loss: 0.07258220762014389, precision: 0.3197640117993912, recall: 0.9155405405403858, f1: 0.473983384307894\n",
            "epoch: 921, step: 15, Train: label_loss: 0.08712798357009888, precision: 0.33392434988177694, recall: 0.9172077922076433, f1: 0.48960138644262735\n",
            "epoch: 921, step: 16, Train: label_loss: 0.08190399408340454, precision: 0.31420118343193404, recall: 0.8999999999998474, f1: 0.4657894736458078\n",
            "epoch: 921, step: 17, Train: label_loss: 0.09687620401382446, precision: 0.3351001177856104, recall: 0.9252032520323699, f1: 0.492001729316734\n",
            "epoch: 921, step: 18, Train: label_loss: 0.08447900414466858, precision: 0.3201911589008172, recall: 0.8903654485048355, f1: 0.47100175743029504\n",
            "epoch: 921, step: 19, Train: label_loss: 0.0736326277256012, precision: 0.33958944281522935, recall: 0.9175911251979528, f1: 0.4957191780427183\n",
            "epoch: 921, step: 20, Train: label_loss: 0.07785104215145111, precision: 0.32081097197374353, recall: 0.8892561983469603, f1: 0.4715162138084948\n",
            "epoch: 921, step: 21, Train: label_loss: 0.07786565274000168, precision: 0.3254156769596006, recall: 0.9028006589784344, f1: 0.4783937144961455\n",
            "epoch: 921, step: 22, Train: label_loss: 0.08043882995843887, precision: 0.3033908387864186, recall: 0.8963093145868372, f1: 0.45333333329550574\n",
            "epoch: 921, step: 23, Train: label_loss: 0.07843628525733948, precision: 0.3311499272197721, recall: 0.9099999999998181, f1: 0.4855923158626381\n",
            "epoch: 922, step: 0, Train: label_loss: 0.08167235553264618, precision: 0.3267622461170653, recall: 0.8967213114752628, f1: 0.4789842381394428\n",
            "epoch: 922, step: 1, Train: label_loss: 0.07554290443658829, precision: 0.31917404129791627, recall: 0.9153976311335168, f1: 0.47331583548218004\n",
            "epoch: 922, step: 2, Train: label_loss: 0.07037188857793808, precision: 0.3333333333333139, recall: 0.9285714285712777, f1: 0.49056603769693197\n",
            "epoch: 922, step: 3, Train: label_loss: 0.08726899325847626, precision: 0.33413173652692607, recall: 0.8759811616953098, f1: 0.483745123497044\n",
            "epoch: 922, step: 4, Train: label_loss: 0.09122355282306671, precision: 0.30843373493974047, recall: 0.8648648648647187, f1: 0.4547069271370487\n",
            "epoch: 922, step: 5, Train: label_loss: 0.07230717688798904, precision: 0.30728241563053244, recall: 0.9169611307418873, f1: 0.46031042124839067\n",
            "epoch: 922, step: 6, Train: label_loss: 0.0851491168141365, precision: 0.31654676258990905, recall: 0.8741721854303188, f1: 0.46478873235529095\n",
            "epoch: 922, step: 7, Train: label_loss: 0.07908295094966888, precision: 0.31389870435804984, recall: 0.9318181818180188, f1: 0.46960352419133605\n",
            "epoch: 922, step: 8, Train: label_loss: 0.07635219395160675, precision: 0.3210093896713427, recall: 0.9116666666665146, f1: 0.47482638885032774\n",
            "epoch: 922, step: 9, Train: label_loss: 0.08120954036712646, precision: 0.34130304841599873, recall: 0.8921874999998606, f1: 0.4937310851307041\n",
            "epoch: 922, step: 10, Train: label_loss: 0.07497511804103851, precision: 0.313196480938398, recall: 0.920689655172255, f1: 0.4673960612312257\n",
            "epoch: 922, step: 11, Train: label_loss: 0.08498591184616089, precision: 0.3287995269071361, recall: 0.9114754098359161, f1: 0.48326814424608683\n",
            "epoch: 922, step: 12, Train: label_loss: 0.08141882717609406, precision: 0.32818073721757857, recall: 0.9108910891087605, f1: 0.4825174824784985\n",
            "epoch: 922, step: 13, Train: label_loss: 0.0799921527504921, precision: 0.3170441001191706, recall: 0.9001692047375803, f1: 0.46892904359298954\n",
            "epoch: 922, step: 14, Train: label_loss: 0.0820254534482956, precision: 0.33293697978594927, recall: 0.9076175040517167, f1: 0.48716833401897364\n",
            "epoch: 922, step: 15, Train: label_loss: 0.06943904608488083, precision: 0.33528722157090646, recall: 0.9210950080513814, f1: 0.49162011169267145\n",
            "epoch: 922, step: 16, Train: label_loss: 0.08572937548160553, precision: 0.32102441929718156, recall: 0.8968386023293016, f1: 0.47280701750499543\n",
            "epoch: 922, step: 17, Train: label_loss: 0.07563658803701401, precision: 0.31759149940966247, recall: 0.910321489001538, f1: 0.4708971553226597\n",
            "epoch: 922, step: 18, Train: label_loss: 0.07585375010967255, precision: 0.34378698224850035, recall: 0.9207606973057177, f1: 0.5006462731184874\n",
            "epoch: 922, step: 19, Train: label_loss: 0.08513755351305008, precision: 0.32102441929718156, recall: 0.8909090909089435, f1: 0.471978984199193\n",
            "epoch: 922, step: 20, Train: label_loss: 0.08664469420909882, precision: 0.32912912912910935, recall: 0.8968903436987075, f1: 0.481546572895654\n",
            "epoch: 922, step: 21, Train: label_loss: 0.0654483437538147, precision: 0.3267326732673077, recall: 0.9303482587063133, f1: 0.48362068961665894\n",
            "epoch: 922, step: 22, Train: label_loss: 0.08858031034469604, precision: 0.29684711481259385, recall: 0.8847517730494885, f1: 0.44454342980643613\n",
            "epoch: 922, step: 23, Train: label_loss: 0.08111929893493652, precision: 0.2969208211143477, recall: 0.8804347826085043, f1: 0.44407894733065395\n",
            "epoch: 923, step: 0, Train: label_loss: 0.08219665288925171, precision: 0.33353186420486397, recall: 0.9017713365537999, f1: 0.486956521699668\n",
            "epoch: 923, step: 1, Train: label_loss: 0.06445704400539398, precision: 0.34673659673657653, recall: 0.9399684044232322, f1: 0.5065985525361492\n",
            "epoch: 923, step: 2, Train: label_loss: 0.07908818125724792, precision: 0.31761932822626293, recall: 0.9043624161072308, f1: 0.470126471832398\n",
            "epoch: 923, step: 3, Train: label_loss: 0.08932115137577057, precision: 0.3189706762417523, recall: 0.8988195615512817, f1: 0.47084805649839667\n",
            "epoch: 923, step: 4, Train: label_loss: 0.07173116505146027, precision: 0.3199065966141086, recall: 0.9367521367519765, f1: 0.4769364664546081\n",
            "epoch: 923, step: 5, Train: label_loss: 0.07527019828557968, precision: 0.3256637168141401, recall: 0.9277310924368188, f1: 0.4820960698304903\n",
            "epoch: 923, step: 6, Train: label_loss: 0.0766497552394867, precision: 0.32396891811115813, recall: 0.910924369747746, f1: 0.4779541445820649\n",
            "epoch: 923, step: 7, Train: label_loss: 0.07448332011699677, precision: 0.2997601918465048, recall: 0.8771929824559864, f1: 0.4468275245375091\n",
            "epoch: 923, step: 8, Train: label_loss: 0.08162464201450348, precision: 0.31276213301376193, recall: 0.8862478777587629, f1: 0.4623560672776066\n",
            "epoch: 923, step: 9, Train: label_loss: 0.08341275155544281, precision: 0.32931968693556113, recall: 0.8780096308184786, f1: 0.47898423813891905\n",
            "epoch: 923, step: 10, Train: label_loss: 0.07984430342912674, precision: 0.3301606186793379, recall: 0.906862745097891, f1: 0.48408198862196755\n",
            "epoch: 923, step: 11, Train: label_loss: 0.07948537170886993, precision: 0.3357142857142657, recall: 0.8938193343897156, f1: 0.48810038940205985\n",
            "epoch: 923, step: 12, Train: label_loss: 0.08093086630105972, precision: 0.3240521327014026, recall: 0.9011532125204446, f1: 0.47668845312009295\n",
            "epoch: 923, step: 13, Train: label_loss: 0.06830063462257385, precision: 0.30962099125362624, recall: 0.9155172413791525, f1: 0.46274509800140456\n",
            "epoch: 923, step: 14, Train: label_loss: 0.08924007415771484, precision: 0.29275534441803486, recall: 0.8915009041589708, f1: 0.44076888686484256\n",
            "epoch: 923, step: 15, Train: label_loss: 0.07654066383838654, precision: 0.3136553369111322, recall: 0.8915254237286624, f1: 0.4640494044607928\n",
            "epoch: 923, step: 16, Train: label_loss: 0.09011568129062653, precision: 0.3258426966291942, recall: 0.9077429983524039, f1: 0.4795474325111274\n",
            "epoch: 923, step: 17, Train: label_loss: 0.08365923911333084, precision: 0.3371121718376887, recall: 0.8841940532079993, f1: 0.4881209502839647\n",
            "epoch: 923, step: 18, Train: label_loss: 0.06926333159208298, precision: 0.3428571428571229, recall: 0.9318541996828951, f1: 0.501278772339149\n",
            "epoch: 923, step: 19, Train: label_loss: 0.079207643866539, precision: 0.3376243417202845, recall: 0.9158730158728704, f1: 0.493373236386421\n",
            "epoch: 923, step: 20, Train: label_loss: 0.08253908902406693, precision: 0.34082840236684375, recall: 0.9171974522291533, f1: 0.4969801552667509\n",
            "epoch: 923, step: 21, Train: label_loss: 0.07979623973369598, precision: 0.3117960877296792, recall: 0.9100346020759671, f1: 0.4644591611098485\n",
            "epoch: 923, step: 22, Train: label_loss: 0.08320151269435883, precision: 0.31096464949069436, recall: 0.9073426573424986, f1: 0.46318607760584884\n",
            "epoch: 923, step: 23, Train: label_loss: 0.08161023259162903, precision: 0.3036496350364742, recall: 0.9023861171364637, f1: 0.45439650460454545\n",
            "epoch: 924, step: 0, Train: label_loss: 0.07342836260795593, precision: 0.33177022274323964, recall: 0.9248366013070384, f1: 0.48835202757110374\n",
            "epoch: 924, step: 1, Train: label_loss: 0.07209737598896027, precision: 0.32507374631266517, recall: 0.912251655628988, f1: 0.479338842936425\n",
            "epoch: 924, step: 2, Train: label_loss: 0.07574420422315598, precision: 0.31898584905658495, recall: 0.9247863247861666, f1: 0.4743533537540165\n",
            "epoch: 924, step: 3, Train: label_loss: 0.07536593824625015, precision: 0.34114888628368456, recall: 0.9252782193957193, f1: 0.4985010706244061\n",
            "epoch: 924, step: 4, Train: label_loss: 0.08081625401973724, precision: 0.3333333333333135, recall: 0.9032258064514671, f1: 0.48695652169970816\n",
            "epoch: 924, step: 5, Train: label_loss: 0.06951642781496048, precision: 0.3150357995226542, recall: 0.8859060402683077, f1: 0.46478873235562324\n",
            "epoch: 924, step: 6, Train: label_loss: 0.07247015088796616, precision: 0.3238039673278691, recall: 0.9173553719006747, f1: 0.47865459245815944\n",
            "epoch: 924, step: 7, Train: label_loss: 0.08020713925361633, precision: 0.3462686567163972, recall: 0.9048361934475967, f1: 0.5008635578182996\n",
            "epoch: 924, step: 8, Train: label_loss: 0.0720130056142807, precision: 0.3214494447691221, recall: 0.9259259259257699, f1: 0.4772234272935876\n",
            "epoch: 924, step: 9, Train: label_loss: 0.09105242788791656, precision: 0.3077844311377061, recall: 0.901754385964754, f1: 0.4589285713905879\n",
            "epoch: 924, step: 10, Train: label_loss: 0.07961112260818481, precision: 0.3299881936245378, recall: 0.9089430894307464, f1: 0.4841922909959568\n",
            "epoch: 924, step: 11, Train: label_loss: 0.0697445347905159, precision: 0.3155111633372317, recall: 0.9148211243610025, f1: 0.46920052420821867\n",
            "epoch: 924, step: 12, Train: label_loss: 0.07944948971271515, precision: 0.3219137625516644, recall: 0.8993399339932509, f1: 0.47411918221428995\n",
            "epoch: 924, step: 13, Train: label_loss: 0.07646623998880386, precision: 0.3335297583971518, recall: 0.9158576051778453, f1: 0.48898488117032296\n",
            "epoch: 924, step: 14, Train: label_loss: 0.08191409707069397, precision: 0.3125371360665293, recall: 0.8976109215015532, f1: 0.4636403701687861\n",
            "epoch: 924, step: 15, Train: label_loss: 0.08006645739078522, precision: 0.3154796939375918, recall: 0.9023569023567504, f1: 0.4675098124343138\n",
            "epoch: 924, step: 16, Train: label_loss: 0.07873943448066711, precision: 0.3207769276044543, recall: 0.9237288135591654, f1: 0.4761904761521712\n",
            "epoch: 924, step: 17, Train: label_loss: 0.073436439037323, precision: 0.3317674691720298, recall: 0.9039999999998553, f1: 0.4853951889641158\n",
            "epoch: 924, step: 18, Train: label_loss: 0.08315704762935638, precision: 0.32279236276847717, recall: 0.9092436974788387, f1: 0.4764420959542416\n",
            "epoch: 924, step: 19, Train: label_loss: 0.07989014685153961, precision: 0.3206106870228819, recall: 0.9191919191917644, f1: 0.47540269913444766\n",
            "epoch: 924, step: 20, Train: label_loss: 0.07306995987892151, precision: 0.31492361927142687, recall: 0.9193825042880069, f1: 0.4691466082770484\n",
            "epoch: 924, step: 21, Train: label_loss: 0.07109620422124863, precision: 0.32746478873237517, recall: 0.9087947882734676, f1: 0.4814495254139912\n",
            "epoch: 924, step: 22, Train: label_loss: 0.08316227793693542, precision: 0.295023696682447, recall: 0.912087912087745, f1: 0.4458370635261414\n",
            "epoch: 924, step: 23, Train: label_loss: 0.07125281542539597, precision: 0.3381191672648716, recall: 0.9235294117645249, f1: 0.4950078822518322\n",
            "epoch: 925, step: 0, Train: label_loss: 0.073371522128582, precision: 0.29851632047475973, recall: 0.8871252204583973, f1: 0.44671403193386416\n",
            "epoch: 925, step: 1, Train: label_loss: 0.07646313309669495, precision: 0.3163507109004552, recall: 0.8870431893686234, f1: 0.46637554581273266\n",
            "epoch: 925, step: 2, Train: label_loss: 0.0673953965306282, precision: 0.32827988338190506, recall: 0.9259868421051108, f1: 0.4847180369824061\n",
            "epoch: 925, step: 3, Train: label_loss: 0.07272964715957642, precision: 0.2976331360946569, recall: 0.8998211091232736, f1: 0.44730991548061316\n",
            "epoch: 925, step: 4, Train: label_loss: 0.07538768649101257, precision: 0.33840749414517923, recall: 0.924799999999852, f1: 0.4954993570117393\n",
            "epoch: 925, step: 5, Train: label_loss: 0.07051670551300049, precision: 0.3215130023640472, recall: 0.9096989966553662, f1: 0.4751091702670466\n",
            "epoch: 925, step: 6, Train: label_loss: 0.06853927671909332, precision: 0.33626760563378305, recall: 0.9227053140095132, f1: 0.492903225767258\n",
            "epoch: 925, step: 7, Train: label_loss: 0.07754625380039215, precision: 0.32475131655937245, recall: 0.9188741721852782, f1: 0.47989623861247244\n",
            "epoch: 925, step: 8, Train: label_loss: 0.07835127413272858, precision: 0.32956573468171746, recall: 0.8892455858746565, f1: 0.4809027777382793\n",
            "epoch: 925, step: 9, Train: label_loss: 0.07775714993476868, precision: 0.31594546532303996, recall: 0.8942953020132727, f1: 0.4669294787174003\n",
            "epoch: 925, step: 10, Train: label_loss: 0.07459229230880737, precision: 0.3276269185359901, recall: 0.9113300492609341, f1: 0.4819800260140304\n",
            "epoch: 925, step: 11, Train: label_loss: 0.07403748482465744, precision: 0.3374558303886727, recall: 0.9153354632586397, f1: 0.49311531837711947\n",
            "epoch: 925, step: 12, Train: label_loss: 0.08427217602729797, precision: 0.32018834608591407, recall: 0.9189189189187636, f1: 0.47490178957315576\n",
            "epoch: 925, step: 13, Train: label_loss: 0.08497169613838196, precision: 0.31515877771118544, recall: 0.8795986622072107, f1: 0.46404940446045695\n",
            "epoch: 925, step: 14, Train: label_loss: 0.08438609540462494, precision: 0.3178016726403633, recall: 0.9063032367971198, f1: 0.4705882352556324\n",
            "epoch: 925, step: 15, Train: label_loss: 0.07818837463855743, precision: 0.3323546682325113, recall: 0.9203252032518828, f1: 0.48835202757098195\n",
            "epoch: 925, step: 16, Train: label_loss: 0.08433409035205841, precision: 0.3185893604303456, recall: 0.8737704918031354, f1: 0.4669294787168218\n",
            "epoch: 925, step: 17, Train: label_loss: 0.07131768763065338, precision: 0.3233038348082405, recall: 0.917922948073548, f1: 0.47818499123542957\n",
            "epoch: 925, step: 18, Train: label_loss: 0.07399557530879974, precision: 0.32922535211265674, recall: 0.9242174629323023, f1: 0.4855041107357808\n",
            "epoch: 925, step: 19, Train: label_loss: 0.07548163831233978, precision: 0.3305882352940982, recall: 0.9183006535946211, f1: 0.4861591695112036\n",
            "epoch: 925, step: 20, Train: label_loss: 0.08417385816574097, precision: 0.3113596233078098, recall: 0.91999999999984, f1: 0.4652594546675399\n",
            "epoch: 925, step: 21, Train: label_loss: 0.07286617159843445, precision: 0.3347156398104067, recall: 0.9157212317664641, f1: 0.490238611674418\n",
            "epoch: 925, step: 22, Train: label_loss: 0.07624063640832901, precision: 0.3313713949381794, recall: 0.9398998330549349, f1: 0.48999129674122244\n",
            "epoch: 925, step: 23, Train: label_loss: 0.07370994240045547, precision: 0.30874909616772894, recall: 0.904661016948961, f1: 0.46037735845257566\n",
            "epoch: 926, step: 0, Train: label_loss: 0.07510112971067429, precision: 0.3297935103244643, recall: 0.9224422442242701, f1: 0.4858757061758464\n",
            "epoch: 926, step: 1, Train: label_loss: 0.0739113986492157, precision: 0.33372641509431994, recall: 0.9158576051778453, f1: 0.4891961970221746\n",
            "epoch: 926, step: 2, Train: label_loss: 0.09302633255720139, precision: 0.328189910979209, recall: 0.9065573770490316, f1: 0.48191721128990445\n",
            "epoch: 926, step: 3, Train: label_loss: 0.06268052011728287, precision: 0.3274956217162681, recall: 0.9365609348913294, f1: 0.4852941176086251\n",
            "epoch: 926, step: 4, Train: label_loss: 0.07288023829460144, precision: 0.3205882352940988, recall: 0.9237288135591654, f1: 0.4759825327127976\n",
            "epoch: 926, step: 5, Train: label_loss: 0.0920449048280716, precision: 0.289127837514917, recall: 0.8996282527879368, f1: 0.4376130198546487\n",
            "epoch: 926, step: 6, Train: label_loss: 0.08451393246650696, precision: 0.31997607655500476, recall: 0.879934210526171, f1: 0.4692982455748828\n",
            "epoch: 926, step: 7, Train: label_loss: 0.07576204836368561, precision: 0.3244523386619109, recall: 0.904290429042755, f1: 0.4775599128151231\n",
            "epoch: 926, step: 8, Train: label_loss: 0.08039572834968567, precision: 0.3086419753086238, recall: 0.902061855669948, f1: 0.45992115633516495\n",
            "epoch: 926, step: 9, Train: label_loss: 0.07587948441505432, precision: 0.3246290801186751, recall: 0.9086378737540018, f1: 0.47835592475347477\n",
            "epoch: 926, step: 10, Train: label_loss: 0.07719611376523972, precision: 0.31694312796206653, recall: 0.8946488294312884, f1: 0.46806649164986563\n",
            "epoch: 926, step: 11, Train: label_loss: 0.09075397998094559, precision: 0.31610219845512083, recall: 0.8881469115190503, f1: 0.46625766867289775\n",
            "epoch: 926, step: 12, Train: label_loss: 0.08441609144210815, precision: 0.32956573468171746, recall: 0.8949919224554288, f1: 0.48173913039540084\n",
            "epoch: 926, step: 13, Train: label_loss: 0.08703276515007019, precision: 0.3264705882352749, recall: 0.9173553719006747, f1: 0.4815618220870555\n",
            "epoch: 926, step: 14, Train: label_loss: 0.07362810522317886, precision: 0.31955109273477145, recall: 0.9016666666665163, f1: 0.4718709114310098\n",
            "epoch: 926, step: 15, Train: label_loss: 0.08020036667585373, precision: 0.322655794991245, recall: 0.9279731993298277, f1: 0.4788245462019485\n",
            "epoch: 926, step: 16, Train: label_loss: 0.06917986273765564, precision: 0.3438228438228238, recall: 0.9305993690850266, f1: 0.5021276595350249\n",
            "epoch: 926, step: 17, Train: label_loss: 0.08159951865673065, precision: 0.3112033195020562, recall: 0.9098786828421299, f1: 0.46378091868989296\n",
            "epoch: 926, step: 18, Train: label_loss: 0.07939744740724564, precision: 0.31801909307874, recall: 0.9173838209981209, f1: 0.4723083739094452\n",
            "epoch: 926, step: 19, Train: label_loss: 0.08548152446746826, precision: 0.32818073721757857, recall: 0.9049180327867369, f1: 0.4816753926310528\n",
            "epoch: 926, step: 20, Train: label_loss: 0.08015025407075882, precision: 0.32147093712928104, recall: 0.9078726968172683, f1: 0.47481384139804117\n",
            "epoch: 926, step: 21, Train: label_loss: 0.08239784091711044, precision: 0.31995277449821014, recall: 0.9003322259134716, f1: 0.47212543550133873\n",
            "epoch: 926, step: 22, Train: label_loss: 0.06870865821838379, precision: 0.3347205707490883, recall: 0.9022435897434451, f1: 0.4882914136638651\n",
            "epoch: 926, step: 23, Train: label_loss: 0.07905113697052002, precision: 0.34081041968159614, recall: 0.911025145067522, f1: 0.49605055288291267\n",
            "epoch: 927, step: 0, Train: label_loss: 0.07655876129865646, precision: 0.30331753554500573, recall: 0.9061946902653263, f1: 0.4545051042677528\n",
            "epoch: 927, step: 1, Train: label_loss: 0.07805359363555908, precision: 0.3258293838862366, recall: 0.9046052631577459, f1: 0.4790940766160735\n",
            "epoch: 927, step: 2, Train: label_loss: 0.0842367634177208, precision: 0.3303357314148483, recall: 0.9092409240922591, f1: 0.4846086191341256\n",
            "epoch: 927, step: 3, Train: label_loss: 0.0722108781337738, precision: 0.3104056437389588, recall: 0.9025641025639483, f1: 0.46194225717972376\n",
            "epoch: 927, step: 4, Train: label_loss: 0.08038458228111267, precision: 0.31921241050117427, recall: 0.8857615894038268, f1: 0.4692982455750471\n",
            "epoch: 927, step: 5, Train: label_loss: 0.0661129280924797, precision: 0.32130177514791, recall: 0.9065108514188803, f1: 0.4744429881657733\n",
            "epoch: 927, step: 6, Train: label_loss: 0.0852292999625206, precision: 0.32932692307690326, recall: 0.8939641109297073, f1: 0.4813350899913524\n",
            "epoch: 927, step: 7, Train: label_loss: 0.06487394869327545, precision: 0.33880422039857333, recall: 0.9233226837059227, f1: 0.4957118352951584\n",
            "epoch: 927, step: 8, Train: label_loss: 0.07755937427282333, precision: 0.3262910798121874, recall: 0.9328859060401119, f1: 0.4834782608311267\n",
            "epoch: 927, step: 9, Train: label_loss: 0.06522149592638016, precision: 0.3327495621716093, recall: 0.925324675324525, f1: 0.4894804636793849\n",
            "epoch: 927, step: 10, Train: label_loss: 0.06867057085037231, precision: 0.318023255813935, recall: 0.9398625429551649, f1: 0.4752389226381119\n",
            "epoch: 927, step: 11, Train: label_loss: 0.09262135624885559, precision: 0.31744115872056017, recall: 0.8885135135133634, f1: 0.46776345038358047\n",
            "epoch: 927, step: 12, Train: label_loss: 0.07750889658927917, precision: 0.34798099762468243, recall: 0.922834645669146, f1: 0.5053902543801961\n",
            "epoch: 927, step: 13, Train: label_loss: 0.07672885060310364, precision: 0.30760095011874655, recall: 0.8977469670709015, f1: 0.45820433432727026\n",
            "epoch: 927, step: 14, Train: label_loss: 0.08635483682155609, precision: 0.33510324483773835, recall: 0.9117174959870125, f1: 0.49007765310991813\n",
            "epoch: 927, step: 15, Train: label_loss: 0.08892552554607391, precision: 0.330930930930911, recall: 0.8973941368076713, f1: 0.4835454146161419\n",
            "epoch: 927, step: 16, Train: label_loss: 0.08794093132019043, precision: 0.3366923532898437, recall: 0.9001584786052456, f1: 0.4900776531096013\n",
            "epoch: 927, step: 17, Train: label_loss: 0.07764525711536407, precision: 0.30588235294115845, recall: 0.9171075837740886, f1: 0.45875606524696544\n",
            "epoch: 927, step: 18, Train: label_loss: 0.09514930844306946, precision: 0.32140653917332995, recall: 0.8322683706068957, f1: 0.46372941696020786\n",
            "epoch: 927, step: 19, Train: label_loss: 0.07501920312643051, precision: 0.322294500295664, recall: 0.9068219633941919, f1: 0.4755671901881428\n",
            "epoch: 927, step: 20, Train: label_loss: 0.06888369470834732, precision: 0.3299999999999806, recall: 0.8947368421051204, f1: 0.48216587877451306\n",
            "epoch: 927, step: 21, Train: label_loss: 0.07131994515657425, precision: 0.3163808397397802, recall: 0.917667238421798, f1: 0.4705364995220753\n",
            "epoch: 927, step: 22, Train: label_loss: 0.06593286991119385, precision: 0.32004689331768343, recall: 0.9317406143343119, f1: 0.4764397905378138\n",
            "epoch: 927, step: 23, Train: label_loss: 0.07967384159564972, precision: 0.2954876273653351, recall: 0.8884026258203745, f1: 0.44347351170471\n",
            "epoch: 928, step: 0, Train: label_loss: 0.08460995554924011, precision: 0.32859680284189885, recall: 0.9009740259738797, f1: 0.48156182208660664\n",
            "epoch: 928, step: 1, Train: label_loss: 0.08605219423770905, precision: 0.31345926800470403, recall: 0.910806174956962, f1: 0.46640316201719845\n",
            "epoch: 928, step: 2, Train: label_loss: 0.09186474233865738, precision: 0.32002383790224553, recall: 0.8949999999998508, f1: 0.471466198380822\n",
            "epoch: 928, step: 3, Train: label_loss: 0.08754793554544449, precision: 0.28045157456920494, recall: 0.8872180451126152, f1: 0.4261851015435981\n",
            "epoch: 928, step: 4, Train: label_loss: 0.07905066013336182, precision: 0.3228486646884081, recall: 0.894736842105116, f1: 0.4744875708288477\n",
            "epoch: 928, step: 5, Train: label_loss: 0.0843404084444046, precision: 0.2988023952095629, recall: 0.8754385964910744, f1: 0.44553571424773203\n",
            "epoch: 928, step: 6, Train: label_loss: 0.08602350205183029, precision: 0.3227326266195334, recall: 0.9210084033611897, f1: 0.47797645002694417\n",
            "epoch: 928, step: 7, Train: label_loss: 0.08171862363815308, precision: 0.3351063829787036, recall: 0.9189627228523631, f1: 0.49112169766542924\n",
            "epoch: 928, step: 8, Train: label_loss: 0.08757452666759491, precision: 0.34826762246115006, recall: 0.8914373088683651, f1: 0.5008591064887652\n",
            "epoch: 928, step: 9, Train: label_loss: 0.07754282653331757, precision: 0.3153258954785487, recall: 0.9148211243610025, f1: 0.46899563314960685\n",
            "epoch: 928, step: 10, Train: label_loss: 0.080488421022892, precision: 0.3146936347412067, recall: 0.9027303754264671, f1: 0.4666960740683731\n",
            "epoch: 928, step: 11, Train: label_loss: 0.07734332233667374, precision: 0.32214369846876784, recall: 0.9255499153974744, f1: 0.4779379641381488\n",
            "epoch: 928, step: 12, Train: label_loss: 0.07295169681310654, precision: 0.32508833922259567, recall: 0.9215358931551049, f1: 0.4806269046196537\n",
            "epoch: 928, step: 13, Train: label_loss: 0.07897140085697174, precision: 0.331563421828889, recall: 0.9320066334990161, f1: 0.48912097472190946\n",
            "epoch: 928, step: 14, Train: label_loss: 0.06935694068670273, precision: 0.32786885245899716, recall: 0.9286898839136104, f1: 0.48463868451353115\n",
            "epoch: 928, step: 15, Train: label_loss: 0.09738684445619583, precision: 0.325943678849591, recall: 0.8845528455283114, f1: 0.47635726791156924\n",
            "epoch: 928, step: 16, Train: label_loss: 0.06475775688886642, precision: 0.32237228420432634, recall: 0.913477537437452, f1: 0.47656249996139705\n",
            "epoch: 928, step: 17, Train: label_loss: 0.0776052251458168, precision: 0.31420118343193404, recall: 0.9015280135821898, f1: 0.46599385691643347\n",
            "epoch: 928, step: 18, Train: label_loss: 0.07672594487667084, precision: 0.3343057176195838, recall: 0.9301948051946541, f1: 0.49184549352329315\n",
            "epoch: 928, step: 19, Train: label_loss: 0.08552789688110352, precision: 0.33451746595616727, recall: 0.9157212317664641, f1: 0.49002601904142196\n",
            "epoch: 928, step: 20, Train: label_loss: 0.08959732949733734, precision: 0.3371394230769028, recall: 0.8820754716979744, f1: 0.4878260869164678\n",
            "epoch: 928, step: 21, Train: label_loss: 0.09020125865936279, precision: 0.3251497005987829, recall: 0.8743961352655596, f1: 0.4740288083410611\n",
            "epoch: 928, step: 22, Train: label_loss: 0.09214136004447937, precision: 0.3118541033434461, recall: 0.8665540540539076, f1: 0.45864997760967446\n",
            "epoch: 928, step: 23, Train: label_loss: 0.10097452253103256, precision: 0.3190229459659275, recall: 0.8831967213112945, f1: 0.4687330070300193\n",
            "epoch: 929, step: 0, Train: label_loss: 0.0849885493516922, precision: 0.3150357995226542, recall: 0.9056603773583352, f1: 0.4674634793773344\n",
            "epoch: 929, step: 1, Train: label_loss: 0.0861223042011261, precision: 0.3283403235470145, recall: 0.8838709677417929, f1: 0.4788117081299655\n",
            "epoch: 929, step: 2, Train: label_loss: 0.0798874944448471, precision: 0.3601173020527648, recall: 0.9317147192714822, f1: 0.5194585447990006\n",
            "epoch: 929, step: 3, Train: label_loss: 0.06808570772409439, precision: 0.3117715617715436, recall: 0.9320557491287574, f1: 0.4672489082593369\n",
            "epoch: 929, step: 4, Train: label_loss: 0.1004379391670227, precision: 0.2982561635598137, recall: 0.8936936936935326, f1: 0.4472497745341234\n",
            "epoch: 929, step: 5, Train: label_loss: 0.07870401442050934, precision: 0.33611940298505455, recall: 0.8979266347685968, f1: 0.48913987832695816\n",
            "epoch: 929, step: 6, Train: label_loss: 0.08826267719268799, precision: 0.3122009569377804, recall: 0.8892674616693544, f1: 0.46215139438380426\n",
            "epoch: 929, step: 7, Train: label_loss: 0.07099375873804092, precision: 0.33039906103284444, recall: 0.9139610389608905, f1: 0.4853448275471614\n",
            "epoch: 929, step: 8, Train: label_loss: 0.09327445179224014, precision: 0.312350119904058, recall: 0.8921232876710801, f1: 0.4626998223416503\n",
            "epoch: 929, step: 9, Train: label_loss: 0.06965342164039612, precision: 0.3331357439241059, recall: 0.903536977491816, f1: 0.4867908184967577\n",
            "epoch: 929, step: 10, Train: label_loss: 0.08972369134426117, precision: 0.3315508021390177, recall: 0.9014539579966233, f1: 0.4847958296739324\n",
            "epoch: 929, step: 11, Train: label_loss: 0.08590249717235565, precision: 0.3104886769964058, recall: 0.8875638841565778, f1: 0.4600441500719352\n",
            "epoch: 929, step: 12, Train: label_loss: 0.07823817431926727, precision: 0.3150204558737396, recall: 0.9197952218428463, f1: 0.46930779273513523\n",
            "epoch: 929, step: 13, Train: label_loss: 0.07632981240749359, precision: 0.3325443786982052, recall: 0.9049919484700636, f1: 0.48636953695762747\n",
            "epoch: 929, step: 14, Train: label_loss: 0.08238288760185242, precision: 0.3130590339892479, recall: 0.9036144578311697, f1: 0.46501328605562714\n",
            "epoch: 929, step: 15, Train: label_loss: 0.076692596077919, precision: 0.32504440497333775, recall: 0.9089403973508429, f1: 0.4788486698259591\n",
            "epoch: 929, step: 16, Train: label_loss: 0.08792714774608612, precision: 0.33493686109438753, recall: 0.8799368088466224, f1: 0.4851916375906821\n",
            "epoch: 929, step: 17, Train: label_loss: 0.09289161115884781, precision: 0.3090257023311232, recall: 0.8913793103446739, f1: 0.45894363067632965\n",
            "epoch: 929, step: 18, Train: label_loss: 0.0833926796913147, precision: 0.30915576694409574, recall: 0.8934707903778533, f1: 0.45936395755893583\n",
            "epoch: 929, step: 19, Train: label_loss: 0.09274425357580185, precision: 0.3125748502993825, recall: 0.880269814502381, f1: 0.46133451167140344\n",
            "epoch: 929, step: 20, Train: label_loss: 0.0703916847705841, precision: 0.31603498542272207, recall: 0.9233390119248852, f1: 0.4708948739845536\n",
            "epoch: 929, step: 21, Train: label_loss: 0.09441113471984863, precision: 0.3362831858406881, recall: 0.911999999999854, f1: 0.49137931030542076\n",
            "epoch: 929, step: 22, Train: label_loss: 0.06972935795783997, precision: 0.3188490898414375, recall: 0.9049999999998491, f1: 0.47155883626190587\n",
            "epoch: 929, step: 23, Train: label_loss: 0.07794823497533798, precision: 0.32372025955296874, recall: 0.9089068825909091, f1: 0.4774056352615906\n",
            "epoch: 930, step: 0, Train: label_loss: 0.07652176916599274, precision: 0.331357439241237, recall: 0.9059967585087672, f1: 0.48524305551629715\n",
            "epoch: 930, step: 1, Train: label_loss: 0.07525027543306351, precision: 0.31641086186538864, recall: 0.9023569023567504, f1: 0.4685314684929845\n",
            "epoch: 930, step: 2, Train: label_loss: 0.07857534289360046, precision: 0.327444051825658, recall: 0.9040650406502594, f1: 0.48076091651950204\n",
            "epoch: 930, step: 3, Train: label_loss: 0.08885999023914337, precision: 0.3254156769596006, recall: 0.914858096827894, f1: 0.4800700831850794\n",
            "epoch: 930, step: 4, Train: label_loss: 0.07582071423530579, precision: 0.3218527315914298, recall: 0.8958677685948931, f1: 0.4735692441725148\n",
            "epoch: 930, step: 5, Train: label_loss: 0.08519834280014038, precision: 0.31141661685592875, recall: 0.8815566835869912, f1: 0.460247349784701\n",
            "epoch: 930, step: 6, Train: label_loss: 0.09371806681156158, precision: 0.3245666467423596, recall: 0.8945634266884852, f1: 0.47631578943457226\n",
            "epoch: 930, step: 7, Train: label_loss: 0.07406304031610489, precision: 0.32275132275130375, recall: 0.9320882852290437, f1: 0.4794759824944991\n",
            "epoch: 930, step: 8, Train: label_loss: 0.0829508975148201, precision: 0.3349140486069748, recall: 0.9039999999998553, f1: 0.48875432522002316\n",
            "epoch: 930, step: 9, Train: label_loss: 0.09515063464641571, precision: 0.32542975696500737, recall: 0.913477537437452, f1: 0.4798951048563276\n",
            "epoch: 930, step: 10, Train: label_loss: 0.07129910588264465, precision: 0.32959243945656647, recall: 0.9102773246328041, f1: 0.4839549002211161\n",
            "epoch: 930, step: 11, Train: label_loss: 0.08030186593532562, precision: 0.3077837195484071, recall: 0.9151943462895908, f1: 0.46064917737447597\n",
            "epoch: 930, step: 12, Train: label_loss: 0.080777607858181, precision: 0.31506849315066615, recall: 0.8950930626056014, f1: 0.4660792951156301\n",
            "epoch: 930, step: 13, Train: label_loss: 0.07878529280424118, precision: 0.3137019230769042, recall: 0.8877551020406653, f1: 0.4635879218086202\n",
            "epoch: 930, step: 14, Train: label_loss: 0.0713343694806099, precision: 0.35064935064932995, recall: 0.923794712286015, f1: 0.5083440307687981\n",
            "epoch: 930, step: 15, Train: label_loss: 0.09950277954339981, precision: 0.31812652068124586, recall: 0.867330016583604, f1: 0.46550956827399687\n",
            "epoch: 930, step: 16, Train: label_loss: 0.09126336127519608, precision: 0.3055062166962519, recall: 0.89739130434767, f1: 0.45583038865464487\n",
            "epoch: 930, step: 17, Train: label_loss: 0.07646115869283676, precision: 0.3074204946996285, recall: 0.8999999999998448, f1: 0.45829675149843846\n",
            "epoch: 930, step: 18, Train: label_loss: 0.06829135119915009, precision: 0.33917104495035966, recall: 0.9340836012860234, f1: 0.4976445395754339\n",
            "epoch: 930, step: 19, Train: label_loss: 0.0818057730793953, precision: 0.3111373011196045, recall: 0.8829431438125613, f1: 0.460130718915674\n",
            "epoch: 930, step: 20, Train: label_loss: 0.08103640377521515, precision: 0.3132458233890028, recall: 0.894378194207684, f1: 0.4639858594401059\n",
            "epoch: 930, step: 21, Train: label_loss: 0.08568006753921509, precision: 0.32093581283741324, recall: 0.8931552587644586, f1: 0.4721977051684791\n",
            "epoch: 930, step: 22, Train: label_loss: 0.08500581234693527, precision: 0.3098086124401728, recall: 0.8824531516182482, f1: 0.45861000438823135\n",
            "epoch: 930, step: 23, Train: label_loss: 0.07889516651630402, precision: 0.34949348769896166, recall: 0.9217557251906637, f1: 0.5068205665917682\n",
            "epoch: 931, step: 0, Train: label_loss: 0.06727062165737152, precision: 0.32961222091654935, recall: 0.9077669902911152, f1: 0.48362068961604643\n",
            "epoch: 931, step: 1, Train: label_loss: 0.07445600628852844, precision: 0.31010041346719963, recall: 0.9178321678320073, f1: 0.4635761589026038\n",
            "epoch: 931, step: 2, Train: label_loss: 0.08115632832050323, precision: 0.31928783382787423, recall: 0.9026845637582377, f1: 0.47172292850146924\n",
            "epoch: 931, step: 3, Train: label_loss: 0.08252587169408798, precision: 0.3052445492044605, recall: 0.9266547406080632, f1: 0.4592198581187102\n",
            "epoch: 931, step: 4, Train: label_loss: 0.08153574168682098, precision: 0.33546511627905024, recall: 0.9366883116881596, f1: 0.49400684927619387\n",
            "epoch: 931, step: 5, Train: label_loss: 0.06637591123580933, precision: 0.3372572101235823, recall: 0.9286871961100601, f1: 0.4948186528106113\n",
            "epoch: 931, step: 6, Train: label_loss: 0.07593347132205963, precision: 0.3179941002949665, recall: 0.9182282793865556, f1: 0.47239263799855585\n",
            "epoch: 931, step: 7, Train: label_loss: 0.06828080862760544, precision: 0.34325744308229167, recall: 0.9187499999998564, f1: 0.49978750527272214\n",
            "epoch: 931, step: 8, Train: label_loss: 0.08467036485671997, precision: 0.3077844311377061, recall: 0.8786324786323284, f1: 0.45587583144712257\n",
            "epoch: 931, step: 9, Train: label_loss: 0.08300457894802094, precision: 0.30814639905547175, recall: 0.9109947643977467, f1: 0.46052051165164254\n",
            "epoch: 931, step: 10, Train: label_loss: 0.08723753690719604, precision: 0.3214285714285523, recall: 0.8809135399672298, f1: 0.4709986916310863\n",
            "epoch: 931, step: 11, Train: label_loss: 0.07968325912952423, precision: 0.32939787485240085, recall: 0.9223140495866243, f1: 0.4854284471121118\n",
            "epoch: 931, step: 12, Train: label_loss: 0.089390829205513, precision: 0.33293556085916864, recall: 0.9014539579966233, f1: 0.48627450976448533\n",
            "epoch: 931, step: 13, Train: label_loss: 0.08314090967178345, precision: 0.29805352798051715, recall: 0.858143607705629, f1: 0.44243792321225767\n",
            "epoch: 931, step: 14, Train: label_loss: 0.08171840012073517, precision: 0.3311494937462578, recall: 0.9190082644626579, f1: 0.48686514882265924\n",
            "epoch: 931, step: 15, Train: label_loss: 0.0856153592467308, precision: 0.33910447761192003, recall: 0.9030206677264064, f1: 0.4930555555158182\n",
            "epoch: 931, step: 16, Train: label_loss: 0.08329135179519653, precision: 0.3108348134990935, recall: 0.8974358974357439, f1: 0.4617414247638551\n",
            "epoch: 931, step: 17, Train: label_loss: 0.0738137736916542, precision: 0.32446808510636377, recall: 0.9029605263156409, f1: 0.4773913043088909\n",
            "epoch: 931, step: 18, Train: label_loss: 0.10624426603317261, precision: 0.3069427527405416, recall: 0.8513513513512074, f1: 0.4512085944104231\n",
            "epoch: 931, step: 19, Train: label_loss: 0.08385979384183884, precision: 0.33096926713946034, recall: 0.8974358974357536, f1: 0.48359240065143705\n",
            "epoch: 931, step: 20, Train: label_loss: 0.0950389951467514, precision: 0.3283403235470145, recall: 0.8881685575363227, f1: 0.47944006995179805\n",
            "epoch: 931, step: 21, Train: label_loss: 0.09223852306604385, precision: 0.33194278903454516, recall: 0.9116202945988687, f1: 0.48667540406741866\n",
            "epoch: 931, step: 22, Train: label_loss: 0.09615400433540344, precision: 0.32110643415512197, recall: 0.87684729064025, f1: 0.4700704224959304\n",
            "epoch: 931, step: 23, Train: label_loss: 0.08556985855102539, precision: 0.3078045222465129, recall: 0.9017094017092091, f1: 0.458945078809205\n",
            "epoch: 932, step: 0, Train: label_loss: 0.0830625519156456, precision: 0.32040572792360855, recall: 0.883223684210381, f1: 0.4702276707139561\n",
            "epoch: 932, step: 1, Train: label_loss: 0.062160804867744446, precision: 0.3360752056404033, recall: 0.9196141479098199, f1: 0.4922547331793443\n",
            "epoch: 932, step: 2, Train: label_loss: 0.07460116595029831, precision: 0.33884297520659157, recall: 0.9363784665577591, f1: 0.49761595141303727\n",
            "epoch: 932, step: 3, Train: label_loss: 0.07878535985946655, precision: 0.3039099526066171, recall: 0.8984238178632401, f1: 0.4541832668944556\n",
            "epoch: 932, step: 4, Train: label_loss: 0.08828319609165192, precision: 0.3337292161519992, recall: 0.903536977491816, f1: 0.4874241109753066\n",
            "epoch: 932, step: 5, Train: label_loss: 0.08587397634983063, precision: 0.330351818723892, recall: 0.9022801302930126, f1: 0.4836316018812808\n",
            "epoch: 932, step: 6, Train: label_loss: 0.07267924398183823, precision: 0.3389731621936792, recall: 0.9310897435895943, f1: 0.49700598798477713\n",
            "epoch: 932, step: 7, Train: label_loss: 0.0874229222536087, precision: 0.32134433962262254, recall: 0.917508417508263, f1: 0.4759825327126288\n",
            "epoch: 932, step: 8, Train: label_loss: 0.06672778725624084, precision: 0.3137829912023276, recall: 0.917667238421798, f1: 0.46765734261932557\n",
            "epoch: 932, step: 9, Train: label_loss: 0.08375666290521622, precision: 0.3252225519287641, recall: 0.9028006589784344, f1: 0.4781849912350154\n",
            "epoch: 932, step: 10, Train: label_loss: 0.08524486422538757, precision: 0.3374999999999799, recall: 0.9086538461537005, f1: 0.49218749996046074\n",
            "epoch: 932, step: 11, Train: label_loss: 0.08524433523416519, precision: 0.32818073721757857, recall: 0.916943521594532, f1: 0.4833625218525558\n",
            "epoch: 932, step: 12, Train: label_loss: 0.08116498589515686, precision: 0.3247058823529221, recall: 0.918469217969897, f1: 0.4797913950069965\n",
            "epoch: 932, step: 13, Train: label_loss: 0.0757032260298729, precision: 0.3434704830053462, recall: 0.8971962616821032, f1: 0.4967658473079117\n",
            "epoch: 932, step: 14, Train: label_loss: 0.09302688390016556, precision: 0.32291040288633055, recall: 0.8788870703762882, f1: 0.47229551447253265\n",
            "epoch: 932, step: 15, Train: label_loss: 0.0698297843337059, precision: 0.3040659988214317, recall: 0.9148936170211143, f1: 0.4564352056237268\n",
            "epoch: 932, step: 16, Train: label_loss: 0.10138587653636932, precision: 0.316867469879499, recall: 0.8840336134452295, f1: 0.4665188469677631\n",
            "epoch: 932, step: 17, Train: label_loss: 0.08105534315109253, precision: 0.3105480259280901, recall: 0.9165217391302753, f1: 0.46390845066637826\n",
            "epoch: 932, step: 18, Train: label_loss: 0.09544345736503601, precision: 0.3149792776790814, recall: 0.910958904109433, f1: 0.46810382750247054\n",
            "epoch: 932, step: 19, Train: label_loss: 0.08359961956739426, precision: 0.32300357568532045, recall: 0.8988391376449587, f1: 0.47523016217062103\n",
            "epoch: 932, step: 20, Train: label_loss: 0.07440584152936935, precision: 0.3343212803793518, recall: 0.9096774193546919, f1: 0.4889466839658547\n",
            "epoch: 932, step: 21, Train: label_loss: 0.0850135087966919, precision: 0.2863933452168576, recall: 0.8942486085341569, f1: 0.4338433843016484\n",
            "epoch: 932, step: 22, Train: label_loss: 0.0795712023973465, precision: 0.3284023668638859, recall: 0.9128289473682708, f1: 0.48302872058767454\n",
            "epoch: 932, step: 23, Train: label_loss: 0.06752157211303711, precision: 0.316400580551501, recall: 0.8843813387422141, f1: 0.46606092994510295\n",
            "epoch: 933, step: 0, Train: label_loss: 0.08183171600103378, precision: 0.3378537735848857, recall: 0.9167999999998533, f1: 0.4937526927654292\n",
            "epoch: 933, step: 1, Train: label_loss: 0.07355991005897522, precision: 0.31458699472757384, recall: 0.9117147707978078, f1: 0.46777003480502005\n",
            "epoch: 933, step: 2, Train: label_loss: 0.08556079864501953, precision: 0.3092537313432651, recall: 0.880952380952231, f1: 0.4577993813136831\n",
            "epoch: 933, step: 3, Train: label_loss: 0.08745995163917542, precision: 0.3218322427126519, recall: 0.8927392739272454, f1: 0.47310887621811115\n",
            "epoch: 933, step: 4, Train: label_loss: 0.08186459541320801, precision: 0.31928783382787423, recall: 0.8907284768210445, f1: 0.4700742682005162\n",
            "epoch: 933, step: 5, Train: label_loss: 0.07548259943723679, precision: 0.3410438908659347, recall: 0.9112519809824229, f1: 0.4963314630591581\n",
            "epoch: 933, step: 6, Train: label_loss: 0.08667200803756714, precision: 0.3112033195020562, recall: 0.8959044368599153, f1: 0.4619445666136924\n",
            "epoch: 933, step: 7, Train: label_loss: 0.07262768596410751, precision: 0.3301886792452635, recall: 0.9210526315787958, f1: 0.48611111107221866\n",
            "epoch: 933, step: 8, Train: label_loss: 0.07513781636953354, precision: 0.3343125734429886, recall: 0.9312602291324171, f1: 0.4920017293168966\n",
            "epoch: 933, step: 9, Train: label_loss: 0.07629501819610596, precision: 0.3329404832056374, recall: 0.9186991869917205, f1: 0.4887543252204241\n",
            "epoch: 933, step: 10, Train: label_loss: 0.08473119884729385, precision: 0.3309222423146274, recall: 0.8826366559484111, f1: 0.4813678210913748\n",
            "epoch: 933, step: 11, Train: label_loss: 0.08976219594478607, precision: 0.331962397179769, recall: 0.9292763157893208, f1: 0.4891774891386613\n",
            "epoch: 933, step: 12, Train: label_loss: 0.09184330701828003, precision: 0.3261776982707021, recall: 0.8967213114752628, f1: 0.478355924753146\n",
            "epoch: 933, step: 13, Train: label_loss: 0.070187509059906, precision: 0.31703005303474857, recall: 0.9149659863944022, f1: 0.4708971553227868\n",
            "epoch: 933, step: 14, Train: label_loss: 0.08306506276130676, precision: 0.32918149466190216, recall: 0.9219269102988501, f1: 0.4851398601010408\n",
            "epoch: 933, step: 15, Train: label_loss: 0.08771225810050964, precision: 0.3178571428571239, recall: 0.914383561643679, f1: 0.4717314487249267\n",
            "epoch: 933, step: 16, Train: label_loss: 0.07640253007411957, precision: 0.31828839390385005, recall: 0.9313893653514697, f1: 0.4744429881664495\n",
            "epoch: 933, step: 17, Train: label_loss: 0.07672532647848129, precision: 0.35115864527627144, recall: 0.9148606811144094, f1: 0.5075139544467733\n",
            "epoch: 933, step: 18, Train: label_loss: 0.08698482066392899, precision: 0.2986235786953741, recall: 0.8974820143883278, f1: 0.44813650647349473\n",
            "epoch: 933, step: 19, Train: label_loss: 0.08017598092556, precision: 0.315602836879414, recall: 0.9097103918226729, f1: 0.46862659057163003\n",
            "epoch: 933, step: 20, Train: label_loss: 0.07006129622459412, precision: 0.3205430932703471, recall: 0.9049999999998491, f1: 0.4734088927250617\n",
            "epoch: 933, step: 21, Train: label_loss: 0.07845274358987808, precision: 0.315140845070404, recall: 0.9258620689653575, f1: 0.4702276707151326\n",
            "epoch: 933, step: 22, Train: label_loss: 0.07547575235366821, precision: 0.32294117647056925, recall: 0.913477537437452, f1: 0.47718383307740103\n",
            "epoch: 933, step: 23, Train: label_loss: 0.0787670761346817, precision: 0.3130434782608469, recall: 0.8834355828219053, f1: 0.46227929370128173\n",
            "epoch: 934, step: 0, Train: label_loss: 0.0756249725818634, precision: 0.31804820693707714, recall: 0.9107744107742574, f1: 0.47145969495069884\n",
            "epoch: 934, step: 1, Train: label_loss: 0.08416058123111725, precision: 0.29030339083876916, recall: 0.8714285714284158, f1: 0.4355198571690765\n",
            "epoch: 934, step: 2, Train: label_loss: 0.07577735930681229, precision: 0.3268551236748924, recall: 0.9039087947881264, f1: 0.4801038061893236\n",
            "epoch: 934, step: 3, Train: label_loss: 0.06993376463651657, precision: 0.32823529411762775, recall: 0.9253731343282047, f1: 0.48458532345240124\n",
            "epoch: 934, step: 4, Train: label_loss: 0.08669991791248322, precision: 0.31005917159761476, recall: 0.9034482758619131, f1: 0.4616740087724873\n",
            "epoch: 934, step: 5, Train: label_loss: 0.08886419981718063, precision: 0.3327380952380754, recall: 0.9224422442242701, f1: 0.4890638669776165\n",
            "epoch: 934, step: 6, Train: label_loss: 0.07550948113203049, precision: 0.3160682754561321, recall: 0.9101694915252694, f1: 0.4692005242080914\n",
            "epoch: 934, step: 7, Train: label_loss: 0.07642848789691925, precision: 0.33549911399879884, recall: 0.9117174959870125, f1: 0.4905008635184883\n",
            "epoch: 934, step: 8, Train: label_loss: 0.07300195097923279, precision: 0.31246308328409256, recall: 0.9216027874562853, f1: 0.4666960740688901\n",
            "epoch: 934, step: 9, Train: label_loss: 0.07168848812580109, precision: 0.33489461358311856, recall: 0.9210950080513814, f1: 0.4911979389904759\n",
            "epoch: 934, step: 10, Train: label_loss: 0.0913642942905426, precision: 0.31440526001193575, recall: 0.8976109215015532, f1: 0.4656927843794198\n",
            "epoch: 934, step: 11, Train: label_loss: 0.10242190957069397, precision: 0.33590963139118096, recall: 0.9025559105429868, f1: 0.4896013864422271\n",
            "epoch: 934, step: 12, Train: label_loss: 0.081313855946064, precision: 0.32300357568532045, recall: 0.8899835796386059, f1: 0.47398338430718806\n",
            "epoch: 934, step: 13, Train: label_loss: 0.09535075724124908, precision: 0.3313361294187938, recall: 0.894822006472347, f1: 0.4836029732880205\n",
            "epoch: 934, step: 14, Train: label_loss: 0.1133180633187294, precision: 0.3143203883494955, recall: 0.857615894039593, f1: 0.46003552393939035\n",
            "epoch: 934, step: 15, Train: label_loss: 0.11512979865074158, precision: 0.3249540159411205, recall: 0.892255892255742, f1: 0.47640449434284055\n",
            "epoch: 934, step: 16, Train: label_loss: 0.1312388777732849, precision: 0.29729729729727905, recall: 0.8301886792451405, f1: 0.43781094523476155\n",
            "epoch: 934, step: 17, Train: label_loss: 0.1187504380941391, precision: 0.314641744548267, recall: 0.8360927152316496, f1: 0.4572204617076226\n",
            "epoch: 934, step: 18, Train: label_loss: 0.1101856678724289, precision: 0.31468110709986075, recall: 0.8658940397349559, f1: 0.46160635477109746\n",
            "epoch: 934, step: 19, Train: label_loss: 0.12609067559242249, precision: 0.3136167590880891, recall: 0.8441127694857637, f1: 0.4573225516226315\n",
            "epoch: 934, step: 20, Train: label_loss: 0.10896863043308258, precision: 0.314373088684996, recall: 0.8566666666665238, f1: 0.45995525723137476\n",
            "epoch: 934, step: 21, Train: label_loss: 0.1286773979663849, precision: 0.32763880414885127, recall: 0.864734299516769, f1: 0.475221238898156\n",
            "epoch: 934, step: 22, Train: label_loss: 0.11279751360416412, precision: 0.318654434250745, recall: 0.8611570247932461, f1: 0.46517857138910157\n",
            "epoch: 934, step: 23, Train: label_loss: 0.10388360917568207, precision: 0.3240391861341127, recall: 0.8651911468811136, f1: 0.471491228030477\n",
            "epoch: 935, step: 0, Train: label_loss: 0.10535290837287903, precision: 0.3176328502415267, recall: 0.8752079866887063, f1: 0.4661054496728905\n",
            "epoch: 935, step: 1, Train: label_loss: 0.10998810827732086, precision: 0.3339427178549461, recall: 0.8698412698411317, f1: 0.48260678111354344\n",
            "epoch: 935, step: 2, Train: label_loss: 0.14116445183753967, precision: 0.3289800995024671, recall: 0.8410174880761778, f1: 0.4729548502053991\n",
            "epoch: 935, step: 3, Train: label_loss: 0.10228317975997925, precision: 0.32971669680528454, recall: 0.8724082934607859, f1: 0.4785651793127291\n",
            "epoch: 935, step: 4, Train: label_loss: 0.09733156859874725, precision: 0.32648125755741675, recall: 0.8667736757623006, f1: 0.4743083003554661\n",
            "epoch: 935, step: 5, Train: label_loss: 0.12324705719947815, precision: 0.30222496909763275, recall: 0.8330494037477285, f1: 0.4435374149268774\n",
            "epoch: 935, step: 6, Train: label_loss: 0.09800690412521362, precision: 0.30741410488244075, recall: 0.8823529411763179, f1: 0.45596781399829134\n",
            "epoch: 935, step: 7, Train: label_loss: 0.1147964596748352, precision: 0.3252427184465822, recall: 0.8772504091651592, f1: 0.4745462593673116\n",
            "epoch: 935, step: 8, Train: label_loss: 0.10802555084228516, precision: 0.30321406913278937, recall: 0.8576329331044841, f1: 0.44802867379649036\n",
            "epoch: 935, step: 9, Train: label_loss: 0.1020856648683548, precision: 0.3221680876979097, recall: 0.8573743922202823, f1: 0.46834882687481655\n",
            "epoch: 935, step: 10, Train: label_loss: 0.1033795103430748, precision: 0.30614729153984743, recall: 0.865748709122054, f1: 0.4523381294577633\n",
            "epoch: 935, step: 11, Train: label_loss: 0.12707750499248505, precision: 0.3316770186335198, recall: 0.8304821150854074, f1: 0.47403462046516076\n",
            "epoch: 935, step: 12, Train: label_loss: 0.12026957422494888, precision: 0.31049382716047463, recall: 0.8510998307951182, f1: 0.4549977385406168\n",
            "epoch: 935, step: 13, Train: label_loss: 0.09837736189365387, precision: 0.3076452599388191, recall: 0.8613013698628661, f1: 0.4533573681450423\n",
            "epoch: 935, step: 14, Train: label_loss: 0.11851496994495392, precision: 0.29957028852054635, recall: 0.8413793103446825, f1: 0.4418288818082249\n",
            "epoch: 935, step: 15, Train: label_loss: 0.0960632935166359, precision: 0.32007233273054125, recall: 0.8835274542427813, f1: 0.46991150438569496\n",
            "epoch: 935, step: 16, Train: label_loss: 0.11416728794574738, precision: 0.31149567367117975, recall: 0.841402337228574, f1: 0.4546684708671525\n",
            "epoch: 935, step: 17, Train: label_loss: 0.10087823867797852, precision: 0.3048484848484664, recall: 0.8732638888887372, f1: 0.45193171604425825\n",
            "epoch: 935, step: 18, Train: label_loss: 0.11776654422283173, precision: 0.29968847352023054, recall: 0.8264604810995143, f1: 0.4398719706970682\n",
            "epoch: 935, step: 19, Train: label_loss: 0.12433090806007385, precision: 0.31172839506170913, recall: 0.8374792703149523, f1: 0.454340980617194\n",
            "epoch: 935, step: 20, Train: label_loss: 0.11003828048706055, precision: 0.3128457283343385, recall: 0.8525963149077298, f1: 0.4577338129103236\n",
            "epoch: 935, step: 21, Train: label_loss: 0.11919086426496506, precision: 0.32254123396454965, recall: 0.8627450980390746, f1: 0.4695420186353107\n",
            "epoch: 935, step: 22, Train: label_loss: 0.10055859386920929, precision: 0.31242460796138044, recall: 0.8720538720537252, f1: 0.4600355239398061\n",
            "epoch: 935, step: 23, Train: label_loss: 0.10620133578777313, precision: 0.3185513673318316, recall: 0.8795918367345144, f1: 0.46771568091587723\n",
            "epoch: 936, step: 0, Train: label_loss: 0.10018216818571091, precision: 0.31376146788988907, recall: 0.8396072013091915, f1: 0.45681211037887437\n",
            "epoch: 936, step: 1, Train: label_loss: 0.09824100136756897, precision: 0.30852340936372696, recall: 0.860971524287963, f1: 0.4542642509553725\n",
            "epoch: 936, step: 2, Train: label_loss: 0.09030424803495407, precision: 0.3515764425936733, recall: 0.9022900763357401, f1: 0.5059931506445335\n",
            "epoch: 936, step: 3, Train: label_loss: 0.10138708353042603, precision: 0.3319174757281352, recall: 0.8794212218648103, f1: 0.4819383259513614\n",
            "epoch: 936, step: 4, Train: label_loss: 0.09121236950159073, precision: 0.30257639304971223, recall: 0.8767361111109588, f1: 0.44988864138720125\n",
            "epoch: 936, step: 5, Train: label_loss: 0.0926467627286911, precision: 0.3187537447573206, recall: 0.8851913477535964, f1: 0.46872246692137887\n",
            "epoch: 936, step: 6, Train: label_loss: 0.08326196670532227, precision: 0.31187241582986935, recall: 0.9010238907848291, f1: 0.4633611232614493\n",
            "epoch: 936, step: 7, Train: label_loss: 0.09347417950630188, precision: 0.3387193297426488, recall: 0.8969889064974806, f1: 0.49174630751880727\n",
            "epoch: 936, step: 8, Train: label_loss: 0.10178930312395096, precision: 0.3102189781021709, recall: 0.8673469387753626, f1: 0.45698924727297907\n",
            "epoch: 936, step: 9, Train: label_loss: 0.09940867125988007, precision: 0.32608695652171943, recall: 0.8695652173911642, f1: 0.4743083003555458\n",
            "epoch: 936, step: 10, Train: label_loss: 0.09178237617015839, precision: 0.30398069963809987, recall: 0.8826619964972183, f1: 0.452220726745161\n",
            "epoch: 936, step: 11, Train: label_loss: 0.08886805176734924, precision: 0.3139604553624737, recall: 0.8926746166949074, f1: 0.46453900705365864\n",
            "epoch: 936, step: 12, Train: label_loss: 0.08936026692390442, precision: 0.32512019230767275, recall: 0.8942148760329099, f1: 0.47686205372902946\n",
            "epoch: 936, step: 13, Train: label_loss: 0.08990807831287384, precision: 0.3096234309623246, recall: 0.8915662650600874, f1: 0.4596273291542415\n",
            "epoch: 936, step: 14, Train: label_loss: 0.10009253025054932, precision: 0.3057553956834349, recall: 0.8869565217389761, f1: 0.45474810517806047\n",
            "epoch: 936, step: 15, Train: label_loss: 0.09083245694637299, precision: 0.32361870066786136, recall: 0.876644736841961, f1: 0.47272727268784553\n",
            "epoch: 936, step: 16, Train: label_loss: 0.07199139893054962, precision: 0.3137603795966599, recall: 0.9152249134946513, f1: 0.46731448759444316\n",
            "epoch: 936, step: 17, Train: label_loss: 0.09598003327846527, precision: 0.3107207752876856, recall: 0.884482758620537, f1: 0.4598834602931711\n",
            "epoch: 936, step: 18, Train: label_loss: 0.11012402176856995, precision: 0.3167281672816533, recall: 0.859766277128404, f1: 0.46292134827521764\n",
            "epoch: 936, step: 19, Train: label_loss: 0.07879843562841415, precision: 0.33943329397872846, recall: 0.9229534510431905, f1: 0.49633146305947484\n",
            "epoch: 936, step: 20, Train: label_loss: 0.09181466698646545, precision: 0.33611940298505455, recall: 0.8993610223640736, f1: 0.48935245541449957\n",
            "epoch: 936, step: 21, Train: label_loss: 0.0992249995470047, precision: 0.33252427184464, recall: 0.8698412698411317, f1: 0.4811237927606453\n",
            "epoch: 936, step: 22, Train: label_loss: 0.10692067444324493, precision: 0.32416267942581795, recall: 0.9063545150500156, f1: 0.4775330396087275\n",
            "epoch: 936, step: 23, Train: label_loss: 0.08798621594905853, precision: 0.30553505535053094, recall: 0.8808510638295999, f1: 0.4536986300986945\n",
            "epoch: 937, step: 0, Train: label_loss: 0.0785859078168869, precision: 0.3297619047618851, recall: 0.9022801302930126, f1: 0.4829991281211732\n",
            "epoch: 937, step: 1, Train: label_loss: 0.08533226698637009, precision: 0.3283759666864766, recall: 0.9034369885432236, f1: 0.48167539263101206\n",
            "epoch: 937, step: 2, Train: label_loss: 0.07740871608257294, precision: 0.3447664104080222, recall: 0.9166666666665225, f1: 0.501074344609998\n",
            "epoch: 937, step: 3, Train: label_loss: 0.08434762805700302, precision: 0.31513353115725135, recall: 0.8849999999998525, f1: 0.4647702406614516\n",
            "epoch: 937, step: 4, Train: label_loss: 0.0855788141489029, precision: 0.32225519287831916, recall: 0.9049999999998491, f1: 0.4752735229371618\n",
            "epoch: 937, step: 5, Train: label_loss: 0.09653717279434204, precision: 0.3111380145278262, recall: 0.8697123519457073, f1: 0.45831475698299257\n",
            "epoch: 937, step: 6, Train: label_loss: 0.08716427534818649, precision: 0.30989272943979085, recall: 0.8996539792385986, f1: 0.4609929077632648\n",
            "epoch: 937, step: 7, Train: label_loss: 0.09084463119506836, precision: 0.3374999999999799, recall: 0.920454545454396, f1: 0.4939024389850849\n",
            "epoch: 937, step: 8, Train: label_loss: 0.08246291428804398, precision: 0.3057703747769003, recall: 0.901754385964754, f1: 0.45668591733219704\n",
            "epoch: 937, step: 9, Train: label_loss: 0.08912529051303864, precision: 0.3106508875739461, recall: 0.9098786828421299, f1: 0.4631671812588791\n",
            "epoch: 937, step: 10, Train: label_loss: 0.09176230430603027, precision: 0.3024954351795312, recall: 0.8568965517239902, f1: 0.4471434997364714\n",
            "epoch: 937, step: 11, Train: label_loss: 0.09113389253616333, precision: 0.2974910394265055, recall: 0.8706293706292183, f1: 0.44345503112851553\n",
            "epoch: 937, step: 12, Train: label_loss: 0.09083371609449387, precision: 0.3407185628742311, recall: 0.8988941548181834, f1: 0.4941380807243153\n",
            "epoch: 937, step: 13, Train: label_loss: 0.08266588300466537, precision: 0.3277411623726586, recall: 0.8908794788272164, f1: 0.47919404288660994\n",
            "epoch: 937, step: 14, Train: label_loss: 0.08665940165519714, precision: 0.30106888361043344, recall: 0.9021352313165654, f1: 0.451469278680158\n",
            "epoch: 937, step: 15, Train: label_loss: 0.0770769864320755, precision: 0.3198830409356538, recall: 0.9193277310922824, f1: 0.47462039041719006\n",
            "epoch: 937, step: 16, Train: label_loss: 0.07794984430074692, precision: 0.34736218138705705, recall: 0.9257503949445615, f1: 0.5051724137533798\n",
            "epoch: 937, step: 17, Train: label_loss: 0.08601386845111847, precision: 0.32793764988007623, recall: 0.8766025641024235, f1: 0.47731239088528854\n",
            "epoch: 937, step: 18, Train: label_loss: 0.0926961898803711, precision: 0.3168552709946208, recall: 0.8926174496642797, f1: 0.4676923076535975\n",
            "epoch: 937, step: 19, Train: label_loss: 0.09763526171445847, precision: 0.3321342925659273, recall: 0.8835725677829531, f1: 0.48278867098421036\n",
            "epoch: 937, step: 20, Train: label_loss: 0.09429776668548584, precision: 0.30232558139533033, recall: 0.8697183098590018, f1: 0.44868301540218575\n",
            "epoch: 937, step: 21, Train: label_loss: 0.08438046276569366, precision: 0.31912374185906933, recall: 0.9089376053961367, f1: 0.4723926379983019\n",
            "epoch: 937, step: 22, Train: label_loss: 0.09347386658191681, precision: 0.33195020746886, recall: 0.9090909090907614, f1: 0.4863221884106192\n",
            "epoch: 937, step: 23, Train: label_loss: 0.09946280717849731, precision: 0.3348281016442201, recall: 0.8732943469783871, f1: 0.48406266878754106\n",
            "epoch: 938, step: 0, Train: label_loss: 0.08659926801919937, precision: 0.3297746144721038, recall: 0.8953301127212728, f1: 0.48201127000829475\n",
            "epoch: 938, step: 1, Train: label_loss: 0.08143244683742523, precision: 0.3337285121517289, recall: 0.9199346405227254, f1: 0.4897781643802024\n",
            "epoch: 938, step: 2, Train: label_loss: 0.07232137024402618, precision: 0.3260741612713169, recall: 0.9037520391515654, f1: 0.47923875428625\n",
            "epoch: 938, step: 3, Train: label_loss: 0.08248741179704666, precision: 0.33096506808760623, recall: 0.901612903225661, f1: 0.48419229099575534\n",
            "epoch: 938, step: 4, Train: label_loss: 0.08423197269439697, precision: 0.3005988023951916, recall: 0.8884955752210816, f1: 0.44921700219931815\n",
            "epoch: 938, step: 5, Train: label_loss: 0.0882154032588005, precision: 0.3335322195703858, recall: 0.9089430894307464, f1: 0.48799650803575756\n",
            "epoch: 938, step: 6, Train: label_loss: 0.07805979251861572, precision: 0.32434017595306014, recall: 0.9232053422369075, f1: 0.48003472218370213\n",
            "epoch: 938, step: 7, Train: label_loss: 0.07896320521831512, precision: 0.33489736070379267, recall: 0.9254457050241611, f1: 0.49181739875507813\n",
            "epoch: 938, step: 8, Train: label_loss: 0.08037295192480087, precision: 0.3404255319148735, recall: 0.9171974522291533, f1: 0.49655172409840487\n",
            "epoch: 938, step: 9, Train: label_loss: 0.07634331285953522, precision: 0.3157276995304979, recall: 0.9259896729774654, f1: 0.47089715532308607\n",
            "epoch: 938, step: 10, Train: label_loss: 0.08580724149942398, precision: 0.3201940570042256, recall: 0.8669950738914832, f1: 0.4676705048321333\n",
            "epoch: 938, step: 11, Train: label_loss: 0.0859631821513176, precision: 0.3190591073582437, recall: 0.861563517915169, f1: 0.4656690140450234\n",
            "epoch: 938, step: 12, Train: label_loss: 0.08995227515697479, precision: 0.3225030084235666, recall: 0.8844884488447384, f1: 0.4726631392906039\n",
            "epoch: 938, step: 13, Train: label_loss: 0.09146638214588165, precision: 0.3126131563065593, recall: 0.8662207357858083, f1: 0.45942350328692894\n",
            "epoch: 938, step: 14, Train: label_loss: 0.08223608136177063, precision: 0.3223487118034558, recall: 0.8996655518393144, f1: 0.4746360828900987\n",
            "epoch: 938, step: 15, Train: label_loss: 0.08337080478668213, precision: 0.3325567850902544, recall: 0.9485049833885467, f1: 0.4924536437735044\n",
            "epoch: 938, step: 16, Train: label_loss: 0.08344865590333939, precision: 0.3044758539458007, recall: 0.9038461538459958, f1: 0.4555066078917779\n",
            "epoch: 938, step: 17, Train: label_loss: 0.08378180861473083, precision: 0.3218116805720905, recall: 0.8970099667772595, f1: 0.4736842104874101\n",
            "epoch: 938, step: 18, Train: label_loss: 0.08998467773199081, precision: 0.3270477312904934, recall: 0.9143327841843633, f1: 0.48177083329448217\n",
            "epoch: 938, step: 19, Train: label_loss: 0.07794155180454254, precision: 0.3311764705882158, recall: 0.9184339314843526, f1: 0.4868136618719388\n",
            "epoch: 938, step: 20, Train: label_loss: 0.08954295516014099, precision: 0.3045045045044862, recall: 0.8666666666665185, f1: 0.45066666662814653\n",
            "epoch: 938, step: 21, Train: label_loss: 0.07996760308742523, precision: 0.310240963855403, recall: 0.8879310344826055, f1: 0.4598214285330106\n",
            "epoch: 938, step: 22, Train: label_loss: 0.09565652161836624, precision: 0.3211940298507271, recall: 0.9042016806721169, f1: 0.4740088105339634\n",
            "epoch: 938, step: 23, Train: label_loss: 0.08235202729701996, precision: 0.3110785033015179, recall: 0.907922912205373, f1: 0.46338797810401205\n",
            "epoch: 939, step: 0, Train: label_loss: 0.07366237789392471, precision: 0.3207769276044543, recall: 0.9098497495824858, f1: 0.4743255003965763\n",
            "epoch: 939, step: 1, Train: label_loss: 0.07319553196430206, precision: 0.2970414201183256, recall: 0.898032200357621, f1: 0.44642063135433485\n",
            "epoch: 939, step: 2, Train: label_loss: 0.08741098642349243, precision: 0.30943847072877484, recall: 0.8794567062816843, f1: 0.4577993813136406\n",
            "epoch: 939, step: 3, Train: label_loss: 0.07112704962491989, precision: 0.34628975265015627, recall: 0.9318541996828951, f1: 0.5049377414804167\n",
            "epoch: 939, step: 4, Train: label_loss: 0.09745241701602936, precision: 0.303337306317026, recall: 0.883680555555402, f1: 0.4516415261375991\n",
            "epoch: 939, step: 5, Train: label_loss: 0.08880210667848587, precision: 0.32042882668253003, recall: 0.8907284768210445, f1: 0.47130968020633596\n",
            "epoch: 939, step: 6, Train: label_loss: 0.0809711366891861, precision: 0.3329348475791791, recall: 0.8883572567781677, f1: 0.48434782604725574\n",
            "epoch: 939, step: 7, Train: label_loss: 0.08633652329444885, precision: 0.33474065138719333, recall: 0.8837579617832987, f1: 0.4855643044220504\n",
            "epoch: 939, step: 8, Train: label_loss: 0.077920101583004, precision: 0.29285714285712544, recall: 0.8929219600724332, f1: 0.44105782156742646\n",
            "epoch: 939, step: 9, Train: label_loss: 0.07883799076080322, precision: 0.33727111636146856, recall: 0.9006309148263563, f1: 0.4907606359723459\n",
            "epoch: 939, step: 10, Train: label_loss: 0.08359719067811966, precision: 0.32841110454812, recall: 0.9084967320259952, f1: 0.48242950104555393\n",
            "epoch: 939, step: 11, Train: label_loss: 0.07545539736747742, precision: 0.3402612826603123, recall: 0.9153354632586397, f1: 0.4961038960643417\n",
            "epoch: 939, step: 12, Train: label_loss: 0.07663942873477936, precision: 0.3333333333333137, recall: 0.9234527687294912, f1: 0.4898488120560138\n",
            "epoch: 939, step: 13, Train: label_loss: 0.0822756364941597, precision: 0.3194029850746078, recall: 0.9021922428329001, f1: 0.47178130507597665\n",
            "epoch: 939, step: 14, Train: label_loss: 0.08090009540319443, precision: 0.32087781731907944, recall: 0.8927392739272454, f1: 0.472076788791776\n",
            "epoch: 939, step: 15, Train: label_loss: 0.0804782509803772, precision: 0.32384341637008757, recall: 0.9145728643214548, f1: 0.4783180025894556\n",
            "epoch: 939, step: 16, Train: label_loss: 0.08598771691322327, precision: 0.32491186839011016, recall: 0.924749163879444, f1: 0.4808695651788695\n",
            "epoch: 939, step: 17, Train: label_loss: 0.08151417970657349, precision: 0.3240685984624291, recall: 0.9057851239667923, f1: 0.4773519163374513\n",
            "epoch: 939, step: 18, Train: label_loss: 0.06816530227661133, precision: 0.33547632963177465, recall: 0.9318181818180304, f1: 0.4933390631324945\n",
            "epoch: 939, step: 19, Train: label_loss: 0.07468795776367188, precision: 0.3238095238095045, recall: 0.9096989966553662, f1: 0.4776119402597456\n",
            "epoch: 939, step: 20, Train: label_loss: 0.08149586617946625, precision: 0.35160905840283957, recall: 0.9233176838809196, f1: 0.5092792403570754\n",
            "epoch: 939, step: 21, Train: label_loss: 0.09519357979297638, precision: 0.28234582829502525, recall: 0.8811320754715318, f1: 0.42765567761888185\n",
            "epoch: 939, step: 22, Train: label_loss: 0.08936327695846558, precision: 0.30681133212776934, recall: 0.8730703259003647, f1: 0.4540588759650443\n",
            "epoch: 939, step: 23, Train: label_loss: 0.07199366390705109, precision: 0.33309506790562304, recall: 0.9246031746029911, f1: 0.48975302150593714\n",
            "epoch: 940, step: 0, Train: label_loss: 0.07996360212564468, precision: 0.3309481216457763, recall: 0.9053833605218751, f1: 0.4847161571659918\n",
            "epoch: 940, step: 1, Train: label_loss: 0.09078159928321838, precision: 0.31525015069316964, recall: 0.8601973684209111, f1: 0.46140273485263356\n",
            "epoch: 940, step: 2, Train: label_loss: 0.07206401228904724, precision: 0.3100177830468103, recall: 0.9064124783360646, f1: 0.4620141342375964\n",
            "epoch: 940, step: 3, Train: label_loss: 0.08608097583055496, precision: 0.3047107930828679, recall: 0.898066783831125, f1: 0.4550311664803824\n",
            "epoch: 940, step: 4, Train: label_loss: 0.06794347614049911, precision: 0.2990599294946945, recall: 0.908928571428409, f1: 0.45004420862760275\n",
            "epoch: 940, step: 5, Train: label_loss: 0.06726910173892975, precision: 0.3236857649143341, recall: 0.9057851239667923, f1: 0.47693646645376864\n",
            "epoch: 940, step: 6, Train: label_loss: 0.07796426862478256, precision: 0.32098765432096876, recall: 0.9161073825501818, f1: 0.4754026991343637\n",
            "epoch: 940, step: 7, Train: label_loss: 0.07137948274612427, precision: 0.33411903358866624, recall: 0.9145161290321105, f1: 0.4894259818338727\n",
            "epoch: 940, step: 8, Train: label_loss: 0.08602527529001236, precision: 0.31071428571426724, recall: 0.8969072164946912, f1: 0.4615384615002019\n",
            "epoch: 940, step: 9, Train: label_loss: 0.07472631335258484, precision: 0.32922535211265674, recall: 0.9303482587063133, f1: 0.48634590373247727\n",
            "epoch: 940, step: 10, Train: label_loss: 0.07640974968671799, precision: 0.3235995232419354, recall: 0.8945634266884852, f1: 0.4752735229368728\n",
            "epoch: 940, step: 11, Train: label_loss: 0.08364076912403107, precision: 0.35071090047391285, recall: 0.9010654490105173, f1: 0.5049040511323297\n",
            "epoch: 940, step: 12, Train: label_loss: 0.07212918251752853, precision: 0.30416911332940083, recall: 0.9151943462895908, f1: 0.4565888056037665\n",
            "epoch: 940, step: 13, Train: label_loss: 0.06673771888017654, precision: 0.3443396226414891, recall: 0.9040247678017176, f1: 0.4987190435125268\n",
            "epoch: 940, step: 14, Train: label_loss: 0.0782923549413681, precision: 0.3222156045264847, recall: 0.8986710963453656, f1: 0.47435335375330157\n",
            "epoch: 940, step: 15, Train: label_loss: 0.08537638187408447, precision: 0.32321428571426647, recall: 0.9034941763725618, f1: 0.47610697058806456\n",
            "epoch: 940, step: 16, Train: label_loss: 0.07951219379901886, precision: 0.31433607520562196, recall: 0.9129692832762947, f1: 0.46765734261919734\n",
            "epoch: 940, step: 17, Train: label_loss: 0.09457629919052124, precision: 0.34615384615382566, recall: 0.912636505460076, f1: 0.5019305018905849\n",
            "epoch: 940, step: 18, Train: label_loss: 0.0881858617067337, precision: 0.3141831238778986, recall: 0.908304498269739, f1: 0.4668741662578996\n",
            "epoch: 940, step: 19, Train: label_loss: 0.07251185178756714, precision: 0.3374631268436379, recall: 0.9361702127658041, f1: 0.496097137862133\n",
            "epoch: 940, step: 20, Train: label_loss: 0.08026041090488434, precision: 0.3189093064611548, recall: 0.9180887372012084, f1: 0.47338319397840756\n",
            "epoch: 940, step: 21, Train: label_loss: 0.08947563171386719, precision: 0.3266152934202533, recall: 0.9276094276092713, f1: 0.4831214379272425\n",
            "epoch: 940, step: 22, Train: label_loss: 0.08803287148475647, precision: 0.3353151010701346, recall: 0.8909952606633663, f1: 0.4872570193986692\n",
            "epoch: 940, step: 23, Train: label_loss: 0.08075311779975891, precision: 0.3135095447870548, recall: 0.8933054393303571, f1: 0.4641304347440991\n",
            "epoch: 941, step: 0, Train: label_loss: 0.08857680857181549, precision: 0.33942251031229587, recall: 0.9157392686802995, f1: 0.49527085120727427\n",
            "epoch: 941, step: 1, Train: label_loss: 0.08659577369689941, precision: 0.3094812164579422, recall: 0.8902229845624544, f1: 0.45929203535990565\n",
            "epoch: 941, step: 2, Train: label_loss: 0.10332109034061432, precision: 0.3135593220338793, recall: 0.8561983471072965, f1: 0.459016393403342\n",
            "epoch: 941, step: 3, Train: label_loss: 0.10505655407905579, precision: 0.3026796589524785, recall: 0.8481228668940531, f1: 0.44614003586783485\n",
            "epoch: 941, step: 4, Train: label_loss: 0.08194280415773392, precision: 0.3248945147679129, recall: 0.8721682847895028, f1: 0.47342995165123036\n",
            "epoch: 941, step: 5, Train: label_loss: 0.10136061906814575, precision: 0.2935384615384435, recall: 0.8224137931033064, f1: 0.4326530611856807\n",
            "epoch: 941, step: 6, Train: label_loss: 0.07725531607866287, precision: 0.3040095751047095, recall: 0.8624787775889876, f1: 0.44955752208531463\n",
            "epoch: 941, step: 7, Train: label_loss: 0.09396158903837204, precision: 0.3063444108761144, recall: 0.8622448979590369, f1: 0.4520731163232895\n",
            "epoch: 941, step: 8, Train: label_loss: 0.08210764825344086, precision: 0.3353186420488186, recall: 0.8894154818324028, f1: 0.4870242214134793\n",
            "epoch: 941, step: 9, Train: label_loss: 0.08685169368982315, precision: 0.31414868105513705, recall: 0.8791946308723356, f1: 0.4628975264629358\n",
            "epoch: 941, step: 10, Train: label_loss: 0.0828910544514656, precision: 0.33552238805968143, recall: 0.8906497622819507, f1: 0.4874241109749502\n",
            "epoch: 941, step: 11, Train: label_loss: 0.08813376724720001, precision: 0.31645569620251257, recall: 0.8779264214045354, f1: 0.46521931763934216\n",
            "epoch: 941, step: 12, Train: label_loss: 0.08992892503738403, precision: 0.3199037883343163, recall: 0.8941176470586731, f1: 0.47121346320295093\n",
            "epoch: 941, step: 13, Train: label_loss: 0.08499924838542938, precision: 0.31051051051049183, recall: 0.8733108108106632, f1: 0.45813026137021\n",
            "epoch: 941, step: 14, Train: label_loss: 0.09373793005943298, precision: 0.32934131736524974, recall: 0.9046052631577459, f1: 0.4828797190126245\n",
            "epoch: 941, step: 15, Train: label_loss: 0.08923213183879852, precision: 0.3394988066825573, recall: 0.8808049535602351, f1: 0.49009474586849544\n",
            "epoch: 941, step: 16, Train: label_loss: 0.0746481865644455, precision: 0.32252358490564137, recall: 0.9208754208752657, f1: 0.47772925760345847\n",
            "epoch: 941, step: 17, Train: label_loss: 0.07977388054132462, precision: 0.32743362831856476, recall: 0.9188741721852782, f1: 0.48281861675112675\n",
            "epoch: 941, step: 18, Train: label_loss: 0.0953495055437088, precision: 0.31223628691981237, recall: 0.8647746243738121, f1: 0.458813108906948\n",
            "epoch: 941, step: 19, Train: label_loss: 0.0944814682006836, precision: 0.3035279805352613, recall: 0.8618307426596092, f1: 0.4489428699569371\n",
            "epoch: 941, step: 20, Train: label_loss: 0.09010173380374908, precision: 0.3217237308146209, recall: 0.9206081081079526, f1: 0.4768153980368182\n",
            "epoch: 941, step: 21, Train: label_loss: 0.08630113303661346, precision: 0.31175771971494587, recall: 0.8974358974357439, f1: 0.4627589245980928\n",
            "epoch: 941, step: 22, Train: label_loss: 0.09084579348564148, precision: 0.32050511124471914, recall: 0.8913043478259378, f1: 0.47147279960722605\n",
            "epoch: 941, step: 23, Train: label_loss: 0.08727726340293884, precision: 0.32344428364686517, recall: 0.9103869653765967, f1: 0.47730912969965156\n",
            "epoch: 942, step: 0, Train: label_loss: 0.08067896217107773, precision: 0.32170775706552485, recall: 0.8756137479540301, f1: 0.47053649952090576\n",
            "epoch: 942, step: 1, Train: label_loss: 0.07622233033180237, precision: 0.32398568019091145, recall: 0.8990066225164074, f1: 0.47631578943469566\n",
            "epoch: 942, step: 2, Train: label_loss: 0.09342130273580551, precision: 0.3258631132646683, recall: 0.8892561983469603, f1: 0.47695035457063545\n",
            "epoch: 942, step: 3, Train: label_loss: 0.08136242628097534, precision: 0.3441943127961881, recall: 0.9078124999998581, f1: 0.4991408934308802\n",
            "epoch: 942, step: 4, Train: label_loss: 0.08412394672632217, precision: 0.32319618366128067, recall: 0.8958677685948931, f1: 0.47502191056572496\n",
            "epoch: 942, step: 5, Train: label_loss: 0.09005016088485718, precision: 0.3244873341374955, recall: 0.884868421052486, f1: 0.4748455427674016\n",
            "epoch: 942, step: 6, Train: label_loss: 0.08018183708190918, precision: 0.2998812351543765, recall: 0.8828671328669785, f1: 0.4476950354231012\n",
            "epoch: 942, step: 7, Train: label_loss: 0.0954531878232956, precision: 0.3271308523409167, recall: 0.8993399339932509, f1: 0.4797535210876017\n",
            "epoch: 942, step: 8, Train: label_loss: 0.0789957344532013, precision: 0.30669034931910555, recall: 0.8961937716261424, f1: 0.45699161884154477\n",
            "epoch: 942, step: 9, Train: label_loss: 0.0962502658367157, precision: 0.3174791914387445, recall: 0.8974789915964877, f1: 0.46903820812999647\n",
            "epoch: 942, step: 10, Train: label_loss: 0.08378314971923828, precision: 0.29338103756706657, recall: 0.8896925858949566, f1: 0.4412556053438289\n",
            "epoch: 942, step: 11, Train: label_loss: 0.07451055943965912, precision: 0.32724056603771656, recall: 0.9113300492609341, f1: 0.48156182208689124\n",
            "epoch: 942, step: 12, Train: label_loss: 0.08543612062931061, precision: 0.33955448524982906, recall: 0.870370370370236, f1: 0.48852317016313274\n",
            "epoch: 942, step: 13, Train: label_loss: 0.08439119905233383, precision: 0.3347255369928201, recall: 0.9033816425119318, f1: 0.4884632128468786\n",
            "epoch: 942, step: 14, Train: label_loss: 0.0897611677646637, precision: 0.31279904306218226, recall: 0.9017241379308789, f1: 0.4644760212761025\n",
            "epoch: 942, step: 15, Train: label_loss: 0.07340838760137558, precision: 0.3123529411764522, recall: 0.90924657534231, f1: 0.4649737302596198\n",
            "epoch: 942, step: 16, Train: label_loss: 0.08186030387878418, precision: 0.3323477232406663, recall: 0.9108589951376157, f1: 0.48700173306303773\n",
            "epoch: 942, step: 17, Train: label_loss: 0.07104570418596268, precision: 0.3191489361701939, recall: 0.9075630252099315, f1: 0.4722343681293683\n",
            "epoch: 942, step: 18, Train: label_loss: 0.07632958143949509, precision: 0.31575829383884385, recall: 0.9080068143098964, f1: 0.468571428533098\n",
            "epoch: 942, step: 19, Train: label_loss: 0.07340945303440094, precision: 0.3289863663307452, recall: 0.9128289473682708, f1: 0.4836601306799643\n",
            "epoch: 942, step: 20, Train: label_loss: 0.08660653233528137, precision: 0.3117893476959718, recall: 0.9029462738299994, f1: 0.46352313163439823\n",
            "epoch: 942, step: 21, Train: label_loss: 0.11147329956293106, precision: 0.33333333333331355, recall: 0.9183006535946211, f1: 0.4891209747215402\n",
            "epoch: 942, step: 22, Train: label_loss: 0.10936078429222107, precision: 0.3066746843054536, recall: 0.8703071672353463, f1: 0.4535349043633823\n",
            "epoch: 942, step: 23, Train: label_loss: 0.07736111432313919, precision: 0.34248554913292323, recall: 0.9150579150577384, f1: 0.4984227128940669\n",
            "epoch: 943, step: 0, Train: label_loss: 0.08031187951564789, precision: 0.33137829912021516, recall: 0.9262295081965694, f1: 0.4881209502851184\n",
            "epoch: 943, step: 1, Train: label_loss: 0.0704617127776146, precision: 0.318289786223259, recall: 0.8888888888887414, f1: 0.4687363357722361\n",
            "epoch: 943, step: 2, Train: label_loss: 0.08051840960979462, precision: 0.31515877771118544, recall: 0.8637110016418942, f1: 0.461808603999416\n",
            "epoch: 943, step: 3, Train: label_loss: 0.07491856813430786, precision: 0.31644077784323416, recall: 0.9117147707978078, f1: 0.4698162729275843\n",
            "epoch: 943, step: 4, Train: label_loss: 0.07631035149097443, precision: 0.3231492361926955, recall: 0.9121061359865816, f1: 0.4772234272932122\n",
            "epoch: 943, step: 5, Train: label_loss: 0.07456529885530472, precision: 0.34498834498832487, recall: 0.9352290679303419, f1: 0.504044274119802\n",
            "epoch: 943, step: 6, Train: label_loss: 0.07370541244745255, precision: 0.3410438908659347, recall: 0.888717156104963, f1: 0.4929275610400288\n",
            "epoch: 943, step: 7, Train: label_loss: 0.08001609891653061, precision: 0.32092198581558384, recall: 0.8960396039602481, f1: 0.4725848563579925\n",
            "epoch: 943, step: 8, Train: label_loss: 0.09176485985517502, precision: 0.3258026159333932, recall: 0.8954248366011608, f1: 0.47776809063215275\n",
            "epoch: 943, step: 9, Train: label_loss: 0.07331490516662598, precision: 0.32373678025850033, recall: 0.9260504201679115, f1: 0.479756203705585\n",
            "epoch: 943, step: 10, Train: label_loss: 0.07343138009309769, precision: 0.3341303048415819, recall: 0.9148936170211268, f1: 0.48949211905008416\n",
            "epoch: 943, step: 11, Train: label_loss: 0.07641270756721497, precision: 0.3199999999999812, recall: 0.9315068493149089, f1: 0.4763572679128589\n",
            "epoch: 943, step: 12, Train: label_loss: 0.07942834496498108, precision: 0.30687203791467377, recall: 0.8961937716261424, f1: 0.4571932921067058\n",
            "epoch: 943, step: 13, Train: label_loss: 0.0653846487402916, precision: 0.3143851508120467, recall: 0.9328743545609409, f1: 0.47028199562385914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_self.load_state_dict(torch.load(\"/content/drive/My Drive/GNN_PPI/58self_train.ckpt\"))\n",
        "#model_self.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMN_dK4NOZL3",
        "outputId": "db25ba83-c5fb-40da-ea7e-c351de496e22"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test\n",
        "def test_s(model_self, model_ngb, graph, test_mask, device):\n",
        "    valid_pre_result_list_self = []\n",
        "    valid_pre_result_list_ngb = []\n",
        "    valid_label_list = []\n",
        "    model_self.eval()\n",
        "    model_ngb.eval()\n",
        "    batch_size = 256\n",
        "    valid_steps = math.ceil(len(test_mask) / batch_size)\n",
        "\n",
        "    for step in tqdm(range(valid_steps)):\n",
        "        if step == valid_steps-1:\n",
        "            valid_edge_id = test_mask[step*batch_size:]\n",
        "        else:\n",
        "            valid_edge_id = test_mask[step*batch_size : step*batch_size + batch_size]\n",
        "\n",
        "        # output = model(graph.x, graph.edge_index, valid_edge_id)\n",
        "        # label = graph.edge_attr_1[valid_edge_id]\n",
        "        # label = label.type(torch.FloatTensor).to(device)\n",
        "\n",
        "\n",
        "        label = graph.edge_attr_1[valid_edge_id]            \n",
        "        exact_input=graph.x\n",
        "        noise_1 = torch.randn_like(exact_input)\n",
        "        noisy_input = ((noise_1 + exact_input).detach() - exact_input).detach() + exact_input\n",
        "        ngb_output_self=model_ngb(model_self(noisy_input,graph.edge_index, valid_edge_id),graph.edge_index, valid_edge_id)\n",
        "\n",
        "        exact_self=model_self(graph.x,graph.edge_index, valid_edge_id)\n",
        "        noise=torch.randn_like(exact_self)\n",
        "        noisy_input_ngb=((noise + exact_self).detach() - exact_self).detach() + exact_self\n",
        "        ngb_output_ngb=model_ngb(noisy_input_ngb,graph.edge_index, valid_edge_id)\n",
        "\n",
        "        label = label.type(torch.FloatTensor).to(device)\n",
        "        # self_loss=loss_fn_s(ngb_output_self, ngb_output_ngb, label)\n",
        "        # ngb_loss=loss_fn_s(ngb_output_self, ngb_output_ngb, label)\n",
        "        \n",
        "        del exact_input,noise_1,exact_self,noise,noisy_input_ngb\n",
        "        gc.collect()\n",
        "\n",
        "    m = nn.Sigmoid()\n",
        "    pre_result_self = (m(ngb_output_self) > 0.5).type(torch.FloatTensor).to(device)\n",
        "    pre_result_ngb = (m(ngb_output_ngb) > 0.5).type(torch.FloatTensor).to(device)\n",
        "\n",
        "    valid_pre_result_list_self.append(pre_result_self.cpu().data)\n",
        "    valid_label_list.append(label.cpu().data)\n",
        "\n",
        "    valid_pre_result_list_ngb.append(pre_result_ngb.cpu().data)\n",
        "\n",
        "    valid_pre_result_list_self = torch.cat(valid_pre_result_list_self, dim=0)\n",
        "    valid_label_list = torch.cat(valid_label_list, dim=0)\n",
        "\n",
        "    valid_pre_result_list_ngb = torch.cat(valid_pre_result_list_ngb, dim=0)\n",
        "    # valid_label_list = torch.cat(valid_label_list, dim=0)\n",
        "\n",
        "    metrics_self = Metrictor_PPI(valid_pre_result_list_self, valid_label_list)\n",
        "    metrics_ngb = Metrictor_PPI(valid_pre_result_list_ngb, valid_label_list)\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    l=['reaction', 'binding', 'ptmod', 'activation', 'inhibition', 'catalysis', 'expression']\n",
        "\n",
        "    for j,i in zip(l,range(7)):\n",
        "      fpr[i], tpr[i], _= roc_curve(valid_label_list[:, i], valid_pre_result_list_ngb[:, i])\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "      print(\"The AUC of subclass \", j,\" is \"+str(roc_auc[i]))\n",
        "    plt.figure()\n",
        "    fig, axs = plt.subplots(7, 1, figsize=(5, 20)) \n",
        "    for i, ax in zip(range(7), axs.ravel()):\n",
        "      ax.plot(fpr[i],tpr[i],color='magenta',label= 'ROC curve (AUC = %0.4f)' % roc_auc[i]) \n",
        "      ax.plot([0, 1], [0, 1], 'b--')\n",
        "      ax.set_xlim([0.0, 1.0])\n",
        "      ax.set_ylim([0.0, 1.05])\n",
        "      ax.set_xlabel(\"False Positive Rate\")\n",
        "      ax.set_ylabel(\"True Positive Rate\")\n",
        "      ax.set_title('ROC Curve of neighbors for class '+ l[i]) \n",
        "      ax.legend(loc= \"lower right\")\n",
        "      fig.tight_layout(pad=3.0)\n",
        "    x=random.randint(1,100)\n",
        "    plt.savefig('./ROC_Curve_'+str(x)+'_.png')\n",
        "\n",
        "    for j,i in zip(l,range(7)):\n",
        "      fpr[i], tpr[i], _= roc_curve(valid_label_list[:, i], valid_pre_result_list_self[:, i])\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "      print(\"The AUC of subclass \", j,\" is \"+str(roc_auc[i]))\n",
        "    plt.figure()\n",
        "    fig, axs = plt.subplots(7, 1, figsize=(5, 20)) \n",
        "    for i, ax in zip(range(7), axs.ravel()):\n",
        "      ax.plot(fpr[i],tpr[i],color='magenta',label= 'ROC curve (AUC = %0.4f)' % roc_auc[i]) \n",
        "      ax.plot([0, 1], [0, 1], 'b--')\n",
        "      ax.set_xlim([0.0, 1.0])\n",
        "      ax.set_ylim([0.0, 1.05])\n",
        "      ax.set_xlabel(\"False Positive Rate\")\n",
        "      ax.set_ylabel(\"True Positive Rate\")\n",
        "      ax.set_title('ROC Curve of self for class '+ l[i]) \n",
        "      ax.legend(loc= \"lower right\")\n",
        "      fig.tight_layout(pad=3.0)\n",
        "    x=random.randint(1,100)\n",
        "    plt.savefig('./ROC_Curve_'+str(x)+'_.png')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    metrics_self.show_result()\n",
        "    metrics_ngb.show_result()\n",
        "    print(\"\\n\")\n",
        "    print(\"For self model Recall: {}, Precision: {}, F1: {}\".format(metrics_self.Recall, metrics_self.Precision, metrics_self.F1))\n",
        "    print(\"For neighbor model Recall: {}, Precision: {}, F1: {}\".format(metrics_ngb.Recall, metrics_ngb.Precision, metrics_ngb.F1))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EP4iquiyRlqD"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_vision_dict = {}\n",
        "for index in graph.train_mask:\n",
        "    ppi = ppi_list[index]\n",
        "    if ppi[0] not in node_vision_dict.keys():\n",
        "        node_vision_dict[ppi[0]] = 1\n",
        "    if ppi[1] not in node_vision_dict.keys():\n",
        "        node_vision_dict[ppi[1]] = 1\n",
        "\n",
        "for index in graph.val_mask:\n",
        "    ppi = ppi_list[index]\n",
        "    if ppi[0] not in node_vision_dict.keys():\n",
        "        node_vision_dict[ppi[0]] = 0\n",
        "    if ppi[1] not in node_vision_dict.keys():\n",
        "        node_vision_dict[ppi[1]] = 0\n"
      ],
      "metadata": {
        "id": "xl2YXAxPUpan"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vision_num = 0\n",
        "unvision_num = 0\n",
        "for node in node_vision_dict:\n",
        "    if node_vision_dict[node] == 1:\n",
        "        vision_num += 1\n",
        "    elif node_vision_dict[node] == 0:\n",
        "        unvision_num += 1\n",
        "print(\"vision node num: {}, unvision node num: {}\".format(vision_num, unvision_num))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRUXtzh2Ujdt",
        "outputId": "18c6c35a-4b0b-443d-a1fb-af382ed51350"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vision node num: 1511, unvision node num: 179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1_mask = []\n",
        "test2_mask = []\n",
        "test3_mask = []\n",
        "\n",
        "for index in graph.val_mask:\n",
        "    ppi = ppi_list[index]\n",
        "    temp = node_vision_dict[ppi[0]] + node_vision_dict[ppi[1]]\n",
        "    if temp == 2:\n",
        "        test1_mask.append(index)\n",
        "    elif temp == 1:\n",
        "        test2_mask.append(index)\n",
        "    elif temp == 0:\n",
        "        test3_mask.append(index)\n",
        "print(\"test1 edge num: {}, test2 edge num: {}, test3 edge num: {}\".format(len(test1_mask), len(test2_mask), len(test3_mask)))\n",
        "\n",
        "graph.test1_mask = test1_mask\n",
        "graph.test2_mask = test2_mask\n",
        "graph.test3_mask = test3_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUWUVjswUIh7",
        "outputId": "15bb36fe-fd6d-4fdf-de22-950608a3cd08"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test1 edge num: 0, test2 edge num: 1142, test3 edge num: 413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_s(model_self, model_ngb, graph, graph.val_mask, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cWZG_UPEpUdG",
        "outputId": "2720964b-36d9-4304-e3fc-4238cc3e267d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.38it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:1001: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The AUC of subclass  reaction  is 0.6785714285714286\n",
            "The AUC of subclass  binding  is 0.4642857142857143\n",
            "The AUC of subclass  ptmod  is 0.5\n",
            "The AUC of subclass  activation  is 0.5\n",
            "The AUC of subclass  inhibition  is 0.5\n",
            "The AUC of subclass  catalysis  is 0.6785714285714286\n",
            "The AUC of subclass  expression  is nan\n",
            "The AUC of subclass  reaction  is 0.625\n",
            "The AUC of subclass  binding  is 0.6428571428571428\n",
            "The AUC of subclass  ptmod  is 0.7857142857142857\n",
            "The AUC of subclass  activation  is 0.5714285714285714\n",
            "The AUC of subclass  inhibition  is 0.78125\n",
            "The AUC of subclass  catalysis  is 0.5357142857142857\n",
            "The AUC of subclass  expression  is nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:1001: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "For self model Recall: 0.3376623376618991, Precision: 0.999999999996154, F1: 0.504854368893317\n",
            "For neighbor model Recall: 0.3116883116879069, Precision: 0.7999999999973334, F1: 0.4485981307999301\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x1440 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x1440 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VcE-L-txaKNJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_s(model_self, graph, graph.val_mask, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkXQrmH0T5cX",
        "outputId": "0faa368b-08c6-46b9-a996-4ba80f053d0a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:01<00:00,  6.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.35064935064889524, Precision: 0.9310344827554102, F1: 0.5094339622234425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ngb.load_state_dict(torch.load('/content/drive/My Drive/GNN_PPI/58ngb_train.ckpt'))\n",
        "#model_ngb.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdsWIxN5OgTY",
        "outputId": "974084f9-28e1-43f8-ef58-86cdbfd6b980"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_s(model_ngb, graph, graph.val_mask, device)"
      ],
      "metadata": {
        "id": "xOdMvgtIVKRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison"
      ],
      "metadata": {
        "id": "_jCiPKZ4vcZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# comparison with benchmark model\n",
        "#Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction\n",
        "#GuofengLv, ZhiqiangHu, YanguangBi, ShaotingZhang\n",
        "\n",
        "def train(model, graph, ppi_list, loss_fn, optimizer, device,\n",
        "        result_file_path, summary_writer, save_path,\n",
        "        batch_size=128, epochs=1000, scheduler=None, \n",
        "        got=False):\n",
        "\n",
        "    global_step = 0\n",
        "    global_best_valid_f1 = 0.0\n",
        "    global_best_valid_f1_epoch = 0\n",
        "\n",
        "    truth_edge_num = graph.edge_index.shape[1] // 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        recall_sum = 0.0\n",
        "        precision_sum = 0.0\n",
        "        f1_sum = 0.0\n",
        "        loss_sum = 0.0\n",
        "\n",
        "        steps = math.ceil(len(graph.train_mask) / batch_size)\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        random.shuffle(graph.train_mask)\n",
        "        random.shuffle(graph.train_mask_got)\n",
        "\n",
        "        for step in range(steps):\n",
        "            if step == steps-1:\n",
        "                if got:\n",
        "                    train_edge_id = graph.train_mask_got[step*batch_size:]\n",
        "                else:\n",
        "                    train_edge_id = graph.train_mask[step*batch_size:]\n",
        "            else:\n",
        "                if got:\n",
        "                    train_edge_id = graph.train_mask_got[step*batch_size : step*batch_size + batch_size]\n",
        "                else:\n",
        "                    train_edge_id = graph.train_mask[step*batch_size : step*batch_size + batch_size]\n",
        "            \n",
        "            if got:\n",
        "                output = model(graph.x, graph.edge_index_got, train_edge_id)\n",
        "                label = graph.edge_attr_got[train_edge_id]\n",
        "            else:\n",
        "                output = model(graph.x, graph.edge_index, train_edge_id)\n",
        "                label = graph.edge_attr_1[train_edge_id]\n",
        "            \n",
        "            label = label.type(torch.FloatTensor).to(device)\n",
        "\n",
        "            loss = loss_fn(output, label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            m = nn.Sigmoid()\n",
        "            pre_result = (m(output) > 0.5).type(torch.FloatTensor).to(device)\n",
        "\n",
        "            metrics = Metrictor_PPI(pre_result.cpu().data, label.cpu().data)\n",
        "\n",
        "            metrics.show_result()\n",
        "\n",
        "            recall_sum += metrics.Recall\n",
        "            precision_sum += metrics.Precision\n",
        "            f1_sum += metrics.F1\n",
        "            loss_sum += loss.item()\n",
        "\n",
        "            summary_writer.add_scalar('train/loss', loss.item(), global_step)\n",
        "            summary_writer.add_scalar('train/precision', metrics.Precision, global_step)\n",
        "            summary_writer.add_scalar('train/recall', metrics.Recall, global_step)\n",
        "            summary_writer.add_scalar('train/F1', metrics.F1, global_step)\n",
        "\n",
        "            global_step += 1\n",
        "            print_file(\"epoch: {}, step: {}, Train: label_loss: {}, precision: {}, recall: {}, f1: {}\"\n",
        "                        .format(epoch, step, loss.item(), metrics.Precision, metrics.Recall, metrics.F1))\n",
        "        \n",
        "        torch.save({'epoch': epoch,\n",
        "                    'state_dict': model.state_dict()},\n",
        "                    os.path.join(save_path, 'gnn_model_train.ckpt'))\n",
        "        \n",
        "        valid_pre_result_list = []\n",
        "        valid_label_list = []\n",
        "        valid_loss_sum = 0.0\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        valid_steps = math.ceil(len(graph.val_mask) / batch_size)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for step in range(valid_steps):\n",
        "                if step == valid_steps-1:\n",
        "                    valid_edge_id = graph.val_mask[step*batch_size:]\n",
        "                else:\n",
        "                    valid_edge_id = graph.val_mask[step*batch_size : step*batch_size + batch_size]\n",
        "                \n",
        "                output = model(graph.x, graph.edge_index, valid_edge_id)\n",
        "                label = graph.edge_attr_1[valid_edge_id]\n",
        "                label = label.type(torch.FloatTensor).to(device)\n",
        "\n",
        "                loss = loss_fn(output, label)\n",
        "                valid_loss_sum += loss.item()\n",
        "\n",
        "                m = nn.Sigmoid()\n",
        "                pre_result = (m(output) > 0.5).type(torch.FloatTensor).to(device)\n",
        "\n",
        "                valid_pre_result_list.append(pre_result.cpu().data)\n",
        "                valid_label_list.append(label.cpu().data)\n",
        "        \n",
        "        valid_pre_result_list = torch.cat(valid_pre_result_list, dim=0)\n",
        "        valid_label_list = torch.cat(valid_label_list, dim=0)\n",
        "\n",
        "        metrics = Metrictor_PPI(valid_pre_result_list, valid_label_list)\n",
        "\n",
        "        metrics.show_result()\n",
        "\n",
        "        recall = recall_sum / steps\n",
        "        precision = precision_sum / steps\n",
        "        f1 = f1_sum / steps\n",
        "        loss = loss_sum / steps\n",
        "\n",
        "        valid_loss = valid_loss_sum / valid_steps\n",
        "\n",
        "        if scheduler != None:\n",
        "            scheduler.step(loss)\n",
        "            print_file(\"epoch: {}, now learning rate: {}\".format(epoch, scheduler.optimizer.param_groups[0]['lr']), save_file_path=result_file_path)\n",
        "        \n",
        "        if global_best_valid_f1 < metrics.F1:\n",
        "            global_best_valid_f1 = metrics.F1\n",
        "            global_best_valid_f1_epoch = epoch\n",
        "\n",
        "            torch.save({'epoch': epoch, \n",
        "                        'state_dict': model.state_dict()},\n",
        "                        os.path.join(save_path, 'gnn_model_valid_best.ckpt'))\n",
        "        \n",
        "        summary_writer.add_scalar('valid/precision', metrics.Precision, global_step)\n",
        "        summary_writer.add_scalar('valid/recall', metrics.Recall, global_step)\n",
        "        summary_writer.add_scalar('valid/F1', metrics.F1, global_step)\n",
        "        summary_writer.add_scalar('valid/loss', valid_loss, global_step)\n",
        "\n",
        "        print_file(\"epoch: {}, Training_avg: label_loss: {}, recall: {}, precision: {}, F1: {}, Validation_avg: loss: {}, recall: {}, precision: {}, F1: {}, Best valid_f1: {}, in {} epoch\"\n",
        "                    .format(epoch, loss, recall, precision, f1, valid_loss, metrics.Recall, metrics.Precision, metrics.F1, global_best_valid_f1, global_best_valid_f1_epoch), save_file_path=result_file_path)"
      ],
      "metadata": {
        "id": "j3Kxd90lNU4y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train and Evaluation\n",
        "\n",
        "ppi_path = \"/content/drive/My Drive/GNN_PPI/data/9606.protein.actions.all_connected.txt\"\n",
        "ppi_data = GNN_DATA(ppi_path)\n",
        "\n",
        "pseq_path = \"/content/drive/My Drive/GNN_PPI/data/protein.STRING_all_connected.sequences.dictionary.tsv\"\n",
        "vec_path = \"/content/drive/My Drive/GNN_PPI/data/vec5_CTC.txt\"\n",
        "\n",
        "ppi_data.get_feature_origin(pseq_path=pseq_path, vec_path=vec_path)\n",
        "ppi_data.generate_data()\n",
        "\n",
        "split_new=True\n",
        "split_mode = \"bfs\"\n",
        "train_valid_index_path = \"/content/drive/My Drive/GNN_PPI/string.bfs.fold1.json\"\n",
        "ppi_data.split_dataset(train_valid_index_path, random_new=split_new, mode=split_mode)\n",
        "\n",
        "split_new=False\n",
        "\n",
        "graph = ppi_data.data\n",
        "\n",
        "ppi_list = ppi_data.ppi_list\n",
        "\n",
        "graph.train_mask = ppi_data.ppi_split_dict['train_index']\n",
        "graph.val_mask = ppi_data.ppi_split_dict['valid_index']\n",
        "\n",
        "\n",
        "graph.edge_index_got = torch.cat((graph.edge_index[:, graph.train_mask], graph.edge_index[:, graph.train_mask][[1, 0]]), dim=1)\n",
        "graph.edge_attr_got = torch.cat((graph.edge_attr_1[graph.train_mask], graph.edge_attr_1[graph.train_mask]), dim=0)\n",
        "graph.train_mask_got = [i for i in range(len(graph.train_mask))]\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "graph.to(device)\n",
        "\n",
        "model = GIN_Net2(in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1, pool_size=3, cnn_hidden=1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "use_lr_scheduler = \"True\"\n",
        "scheduler = None\n",
        "if use_lr_scheduler:\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True)\n",
        "\n",
        "#loss func teacher\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "graph_only_train = \"False\"\n",
        "\n",
        "batch_size = 2048\n",
        "epochs = 300\n",
        "model.eval()\n",
        "\n"
      ],
      "metadata": {
        "id": "KXoOC-KQVTDi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the small data same as for our model\n",
        "# ppi_path = \"/content/drive/My Drive/GNN_PPI/data/9606.protein.actions.all_connected.txt\"\n",
        "# # ppi_data = GNN_DATA(ppi_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A01MDqiLyIz_",
        "outputId": "02c69e50-f948-4a03-9703-576c46649f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4775155it [00:14, 324603.35it/s]\n",
            "100%|██████████| 593397/593397 [00:00<00:00, 722010.57it/s]\n",
            "100%|██████████| 593397/593397 [00:00<00:00, 884084.94it/s]\n",
            "100%|██████████| 593397/593397 [00:00<00:00, 835024.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pseq_path = \"/content/drive/My Drive/GNN_PPI/data/protein.STRING_all_connected.sequences.dictionary.tsv\"\n",
        "# vec_path = \"/content/drive/My Drive/GNN_PPI/data/vec5_CTC.txt\"\n",
        "\n",
        "# ppi_data.get_feature_origin(pseq_path=pseq_path, vec_path=vec_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNkUZcKB3BjR",
        "outputId": "12841273-df20-4050-c03c-9c3271d30962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15335it [00:00, 241053.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protein num: 15335\n",
            "protein average length: 603.6829475057059\n",
            "protein max & min length: 33423, 25\n",
            "acid vector dimension: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15335/15335 [00:05<00:00, 2591.38it/s]\n",
            "100%|██████████| 15335/15335 [00:00<00:00, 1265711.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ppi_data.generate_data()"
      ],
      "metadata": {
        "id": "4VaiJzjYVkhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split_new=True\n",
        "# split_mode = \"bfs\"\n",
        "# train_valid_index_path = \"/content/drive/My Drive/GNN_PPI/string.bfs.fold1.json\"\n",
        "# ppi_data.split_dataset(train_valid_index_path, random_new=split_new, mode=split_mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVhAhbXZ9lX0",
        "outputId": "db8b72f9-c657-4069-b245-3b015f2cd9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use bfs methed split train and valid dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split_new=False"
      ],
      "metadata": {
        "id": "mdsEn-9N_nUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graph = ppi_data.data\n",
        "# print(graph.x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXBE48KE_m45",
        "outputId": "466ad5d9-7a11-4ebf-bdad-f7f1d6cceab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([15335, 2000, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ppi_list = ppi_data.ppi_list"
      ],
      "metadata": {
        "id": "ri6RMznx_-KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graph.train_mask = ppi_data.ppi_split_dict['train_index']\n",
        "# graph.val_mask = ppi_data.ppi_split_dict['valid_index']"
      ],
      "metadata": {
        "id": "YM4OxbyrAHaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"train gnn, train_num: {}, valid_num: {}\".format(len(graph.train_mask), len(graph.val_mask)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX0TpYPNAJxf",
        "outputId": "9d4d178f-9d9a-4070-d717-f0359e40afe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train gnn, train_num: 474637, valid_num: 118760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graph.edge_index_got = torch.cat((graph.edge_index[:, graph.train_mask], graph.edge_index[:, graph.train_mask][[1, 0]]), dim=1)\n",
        "# graph.edge_attr_got = torch.cat((graph.edge_attr_1[graph.train_mask], graph.edge_attr_1[graph.train_mask]), dim=0)\n",
        "# graph.train_mask_got = [i for i in range(len(graph.train_mask))]"
      ],
      "metadata": {
        "id": "GBrfkcAmANbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8gEAERBJcm",
        "outputId": "7736d4fb-33c4-4c85-bf9d-4bd98f40420a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graph.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om47_E1JBP5b",
        "outputId": "d48a18df-1884-4300-d8a2-a12dd5c60850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[15335, 2000, 13], edge_index=[2, 1186794], edge_attr_1=[1186794, 7], train_mask=[474637], val_mask=[118760], edge_index_got=[2, 949274], edge_attr_got=[949274, 7], train_mask_got=[474637])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GIN_Net2(in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1, pool_size=3, cnn_hidden=1).to(device)"
      ],
      "metadata": {
        "id": "CAxUdzRNBdjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title \n",
        "# #optimizer \n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "oUvrUPkABhum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title\n",
        "# use_lr_scheduler = \"True\"\n",
        "# scheduler = None\n",
        "# if use_lr_scheduler:\n",
        "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True)"
      ],
      "metadata": {
        "id": "O5OWzGN-BvrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title \n",
        "# #loss function teacher\n",
        "# loss_fn = nn.BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "-zXYEmvoCSje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title\n",
        "# graph_only_train = \"False\"\n",
        "\n",
        "# batch_size = 2048\n",
        "# epochs = 300\n"
      ],
      "metadata": {
        "id": "WLGav9coFI9R"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title\n",
        "# #teacher model summary\n",
        "# model.load_state_dict(torch.load(\"/content/drive/My Drive/GNN_PPI/save_model_/gnn_string_bfs/gnn_model_train.ckpt\")['state_dict'])\n",
        "# model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHfOxp2DFhkn",
        "outputId": "bb6f250c-4e6b-4f29-9222-d4878631ae78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GIN_Net2(\n",
              "  (conv1d): Conv1d(13, 1, kernel_size=(3,), stride=(1,))\n",
              "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (biGRU): GRU(1, 1, batch_first=True, bidirectional=True)\n",
              "  (maxpool1d): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avgpool1d): AdaptiveAvgPool1d(output_size=1)\n",
              "  (fc1): Linear(in_features=666, out_features=256, bias=True)\n",
              "  (gin_conv1): GINConv(nn=Sequential(\n",
              "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  ))\n",
              "  (gin_convs): ModuleList()\n",
              "  (lin1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_all = \"False\"\n",
        "# description = \"test\""
      ],
      "metadata": {
        "id": "5l1CuDmOJWmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ppi_data = GNN_DATA(ppi_path=ppi_path)\n",
        "# # ppi_data.get_feature_origin(pseq_path=pseq_path, vec_path=vec_path)\n",
        "# # ppi_data.generate_data()\n",
        "\n",
        "# # graph = ppi_data.data\n",
        "# temp =graph.edge_index.transpose(0, 1).cpu().numpy()\n",
        "# ppi_list = []\n",
        "\n",
        "# for edge in temp:\n",
        "#     ppi_list.append(list(edge))\n",
        "\n",
        "# truth_edge_num = len(ppi_list) // 2\n",
        "# # fake_edge_num = len(ppi_data.fake_edge) // 2\n",
        "# fake_edge_num = 0"
      ],
      "metadata": {
        "id": "eO062oCsMgUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index_path = \"/content/drive/My Drive/GNN_PPI/string.bfs.fold1.json\"\n",
        "# gnn_model = \"/content/drive/My Drive/GNN_PPI/save_model_/gnn_string_bfs/gnn_model_train.ckpt\""
      ],
      "metadata": {
        "id": "wBlelO9sJJnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(index_path, 'r') as f:\n",
        "#     index_dict = json.load(f)\n",
        "#     f.close()\n",
        "# graph.train_mask = index_dict['train_index']\n",
        "# graph.val_mask = index_dict['valid_index']\n",
        "\n",
        "# print(\"train gnn, train_num: {}, valid_num: {}\".format(len(graph.train_mask), len(graph.val_mask)))\n"
      ],
      "metadata": {
        "id": "Ix2hHXdnMyec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# node_vision_dict = {}\n",
        "# for index in graph.train_mask:\n",
        "#     ppi = ppi_list[index]\n",
        "#     if ppi[0] not in node_vision_dict.keys():\n",
        "#         node_vision_dict[ppi[0]] = 1\n",
        "#     if ppi[1] not in node_vision_dict.keys():\n",
        "#         node_vision_dict[ppi[1]] = 1\n",
        "\n",
        "# for index in graph.val_mask:\n",
        "#     ppi = ppi_list[index]\n",
        "#     if ppi[0] not in node_vision_dict.keys():\n",
        "#         node_vision_dict[ppi[0]] = 0\n",
        "#     if ppi[1] not in node_vision_dict.keys():\n",
        "#         node_vision_dict[ppi[1]] = 0\n",
        "\n",
        "# vision_num = 0\n",
        "# unvision_num = 0\n",
        "# for node in node_vision_dict:\n",
        "#     if node_vision_dict[node] == 1:\n",
        "#         vision_num += 1\n",
        "#     elif node_vision_dict[node] == 0:\n",
        "#         unvision_num += 1\n",
        "# print(\"vision node num: {}, unvision node num: {}\".format(vision_num, unvision_num))\n",
        "\n",
        "# test1_mask = []\n",
        "# test2_mask = []\n",
        "# test3_mask = []\n",
        "\n",
        "# for index in graph.val_mask:\n",
        "#     ppi = ppi_list[index]\n",
        "#     temp = node_vision_dict[ppi[0]] + node_vision_dict[ppi[1]]\n",
        "#     if temp == 2:\n",
        "#         test1_mask.append(index)\n",
        "#     elif temp == 1:\n",
        "#         test2_mask.append(index)\n",
        "#     elif temp == 0:\n",
        "#         test3_mask.append(index)\n",
        "# print(\"test1 edge num: {}, test2 edge num: {}, test3 edge num: {}\".format(len(test1_mask), len(test2_mask), len(test3_mask)))\n",
        "\n",
        "# graph.test1_mask = test1_mask\n",
        "# graph.test2_mask = test2_mask\n",
        "# graph.test3_mask = test3_mask\n"
      ],
      "metadata": {
        "id": "kWo8Itu5RXNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #changed 1 to 0 "
      ],
      "metadata": {
        "id": "fRxR5OAWR0VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# model architecture to load\n",
        "class GIN_Net2(torch.nn.Module):\n",
        "    def __init__(self, in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1, \n",
        "                hidden=512, use_jk=False, pool_size=3, cnn_hidden=1, train_eps=True, \n",
        "                feature_fusion=None, class_num=7):\n",
        "        super(GIN_Net2, self).__init__()\n",
        "        self.use_jk = use_jk\n",
        "        self.train_eps = train_eps\n",
        "        self.feature_fusion = feature_fusion\n",
        "\n",
        "        self.conv1d = nn.Conv1d(in_channels=in_feature, out_channels=cnn_hidden, kernel_size=3, padding=0)\n",
        "        self.bn1 = nn.BatchNorm1d(cnn_hidden)\n",
        "        self.biGRU = nn.GRU(cnn_hidden, cnn_hidden, bidirectional=True, batch_first=True, num_layers=1)\n",
        "        self.maxpool1d = nn.MaxPool1d(pool_size, stride=pool_size)\n",
        "        self.global_avgpool1d = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc1 = nn.Linear(math.floor(in_len / pool_size), gin_in_feature)\n",
        "\n",
        "        self.gin_conv1 = GINConv( \n",
        "            nn.Sequential(\n",
        "                nn.Linear(gin_in_feature, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden),\n",
        "            ), train_eps=self.train_eps\n",
        "        )\n",
        "        self.gin_convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers - 1):\n",
        "            self.gin_convs.append(\n",
        "                GINConv(\n",
        "                    nn.Sequential(\n",
        "                        nn.Linear(hidden, hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(hidden, hidden),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm1d(hidden),\n",
        "                    ), train_eps=self.train_eps\n",
        "                )\n",
        "            )\n",
        "        if self.use_jk:\n",
        "            mode = 'cat'\n",
        "            self.jump = JumpingKnowledge(mode)\n",
        "            self.lin1 = nn.Linear(num_layers*hidden, hidden)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(hidden, hidden)\n",
        "        self.lin2 = nn.Linear(hidden, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, class_num)\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        \n",
        "        self.conv1d.reset_parameters()\n",
        "        self.fc1.reset_parameters()\n",
        "\n",
        "        self.gin_conv1.reset_parameters()\n",
        "        for gin_conv in self.gin_convs:\n",
        "            gin_conv.reset_parameters()\n",
        "        \n",
        "        if self.use_jk:\n",
        "            self.jump.reset_parameters()\n",
        "        self.lin1.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "\n",
        "        self.fc2.reset_parameters()\n",
        "    \n",
        "    def forward(self, x, edge_index, train_edge_id, p=0.5):\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.conv1d(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.maxpool1d(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x, _ = self.biGRU(x)\n",
        "        x = self.global_avgpool1d(x)\n",
        "        x = x.squeeze()\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        x = self.gin_conv1(x, edge_index)\n",
        "        xs = [x]\n",
        "        for conv in self.gin_convs:\n",
        "            x = conv(x, edge_index)\n",
        "            xs += [x]\n",
        "\n",
        "        if self.use_jk:\n",
        "            x = self.jump(xs)\n",
        "        \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=p, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        # x  = torch.add(x, x_)\n",
        "\n",
        "        node_id = edge_index[:, train_edge_id]\n",
        "        x1 = x[node_id[0]]\n",
        "        x2 = x[node_id[1]]\n",
        "\n",
        "        if self.feature_fusion == 'concat':\n",
        "            x = torch.cat([x1, x2], dim=1)\n",
        "        else:\n",
        "            x = torch.mul(x1, x2)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GuqiE5kbgJV4"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GIN_Net2(in_len=2000, in_feature=13, gin_in_feature=256, num_layers=1, pool_size=3, cnn_hidden=1).to(device)"
      ],
      "metadata": {
        "id": "vdMvgkcvRl1v"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbf5ojW0b3nv",
        "outputId": "51f8813a-7f9e-4254-b351-486f87582563"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GIN_Net2(\n",
              "  (conv1d): Conv1d(13, 1, kernel_size=(3,), stride=(1,))\n",
              "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (biGRU): GRU(1, 1, batch_first=True, bidirectional=True)\n",
              "  (maxpool1d): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avgpool1d): AdaptiveAvgPool1d(output_size=1)\n",
              "  (fc1): Linear(in_features=666, out_features=256, bias=True)\n",
              "  (gin_conv1): GINConv(nn=Sequential(\n",
              "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  ))\n",
              "  (gin_convs): ModuleList()\n",
              "  (lin1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test\n",
        "def test(model, graph, test_mask, device):\n",
        "    valid_pre_result_list = []\n",
        "    valid_label_list = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = 256\n",
        "\n",
        "    valid_steps = math.ceil(len(test_mask) / batch_size)\n",
        "\n",
        "    for step in tqdm(range(valid_steps)):\n",
        "        if step == valid_steps-1:\n",
        "            valid_edge_id = test_mask[step*batch_size:]\n",
        "        else:\n",
        "            valid_edge_id = test_mask[step*batch_size : step*batch_size + batch_size]\n",
        "\n",
        "        output = model(graph.x, graph.edge_index, valid_edge_id)\n",
        "        label = graph.edge_attr_1[valid_edge_id]\n",
        "        label = label.type(torch.FloatTensor).to(device)\n",
        "\n",
        "        m = nn.Sigmoid()\n",
        "        pre_result = (m(output) > 0.5).type(torch.FloatTensor).to(device)\n",
        "\n",
        "        valid_pre_result_list.append(pre_result.cpu().data)\n",
        "        valid_label_list.append(label.cpu().data)\n",
        "\n",
        "    valid_pre_result_list = torch.cat(valid_pre_result_list, dim=0)\n",
        "    valid_label_list = torch.cat(valid_label_list, dim=0)\n",
        "\n",
        "    metrics = Metrictor_PPI(valid_pre_result_list, valid_label_list)\n",
        "\n",
        "    metrics.show_result()\n",
        "\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    l=['reaction', 'binding', 'ptmod', 'activation', 'inhibition', 'catalysis', 'expression']\n",
        "\n",
        "\n",
        "    for j,i in zip(l,range(7)):\n",
        "      fpr[i], tpr[i], _= roc_curve(valid_label_list[:, i], valid_pre_result_list[:, i])\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "      print(\"The AUC of subclass \", j,\" is \"+str(roc_auc[i]))\n",
        "    plt.figure()\n",
        "    fig, axs = plt.subplots(7, 1, figsize=(5, 20)) \n",
        "    for i, ax in zip(range(7), axs.ravel()):\n",
        "      ax.plot(fpr[i],tpr[i],color='magenta',label= 'ROC curve (AUC = %0.4f)' % roc_auc[i]) \n",
        "      ax.plot([0, 1], [0, 1], 'b--')\n",
        "      ax.set_xlim([0.0, 1.0])\n",
        "      ax.set_ylim([0.0, 1.05])\n",
        "      ax.set_xlabel(\"False Positive Rate\")\n",
        "      ax.set_ylabel(\"True Positive Rate\")\n",
        "      ax.set_title('ROC Curve of benchmark for class '+ l[i]) \n",
        "      ax.legend(loc= \"lower right\")\n",
        "      fig.tight_layout(pad=3.0)\n",
        "    x=random.randint(1,100)\n",
        "    plt.savefig('./ROC_Curve_'+str(x)+'_.png')\n",
        "\n",
        "    print(\"Recall: {}, Precision: {}, F1: {}\".format(metrics.Recall, metrics.Precision, metrics.F1))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xkAtYgWCVmX4"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, graph, graph.val_mask, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K6A1WbAEpJuE",
        "outputId": "82e74cc3-7dd7-4f03-d5b4-bd9ed73c855b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 38.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The AUC of subclass  reaction  is 0.5\n",
            "The AUC of subclass  binding  is 0.5\n",
            "The AUC of subclass  ptmod  is 0.4584717927047118\n",
            "The AUC of subclass  activation  is 0.5\n",
            "The AUC of subclass  inhibition  is 0.5098676735080805\n",
            "The AUC of subclass  catalysis  is 0.5656224288942813\n",
            "The AUC of subclass  expression  is 0.5\n",
            "Recall: 0.551876379690929, Precision: 0.27208416470160945, F1: 0.36447576231755946\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x1440 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, graph, graph.val_mask, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utc46SuggjVi",
        "outputId": "c7c385aa-0aa7-4ef5-c55f-3691b7314b02"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 42.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.551876379690929, Precision: 0.27208416470160945, F1: 0.36447576231755946\n"
          ]
        }
      ]
    }
  ]
}